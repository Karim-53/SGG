2020-07-08 07:54:59,864 maskrcnn_benchmark INFO: Using 7 GPUs
2020-07-08 07:54:59,864 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'mfb', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '56', 'TEST.IMS_PER_BATCH', '7', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE'], skip_test=False)
2020-07-08 07:54:59,864 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-07-08 07:55:04,057 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-07-08 07:55:04,057 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-07-08 07:55:04,058 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate', 'dist'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-07-08 07:55:04,060 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: TDE
      FUSION_TYPE: mfb
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 56
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 7
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-07-08 07:55:04,061 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/config.yml
2020-07-08 07:55:04,097 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-07-08 07:55:07,314 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-07-08 07:55:07,314 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-07-08 07:55:34,698 maskrcnn_benchmark.data.build INFO: finish
2020-07-08 07:55:34,698 maskrcnn_benchmark.data.build INFO: Save data statistics to: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-07-08 07:55:34,699 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-07-08 07:55:36,016 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-07-08 07:55:36,788 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-07-08 07:55:36,820 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-07-08 07:55:36,822 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2020-07-08 07:55:37,667 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2020-07-08 07:55:37,746 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)
2020-07-08 07:55:37,747 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)
2020-07-08 07:55:37,748 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress_2.bias of shape (51,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress_2.weight of shape (51, 8192)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress_2.bias of shape (51,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress_2.weight of shape (51, 8192)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-07-08 07:55:37,749 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2020-07-08 07:55:37,750 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2020-07-08 07:55:40,043 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-07-08 07:55:40,043 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-07-08 07:55:42,693 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/labels.json
2020-07-08 07:55:43,927 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-07-08 07:55:43,927 maskrcnn_benchmark INFO: Validate before training
2020-07-08 07:55:43,936 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 07:57:26,202 maskrcnn_benchmark INFO: Total run time: 0:01:42.265116 (0.14317116303443908 s / img per device, on 7 devices)
2020-07-08 07:57:26,202 maskrcnn_benchmark INFO: Model inference time: 0:01:20.824467 (0.11315425372123718 s / img per device, on 7 devices)
2020-07-08 07:58:55,866 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2351;   R @ 50: 0.2816;   R @ 100: 0.3029;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2691; ngR @ 50: 0.3368; ngR @ 100: 0.3831;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0044;  zR @ 50: 0.0089;  zR @ 100: 0.0089;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0569;  mR @ 50: 0.0768;  mR @ 100: 0.0894;  for mode=predcls, type=Mean Recall.
(above:0.1502) (across:0.0000) (against:0.0000) (along:0.1603) (and:0.0161) (at:0.1786) (attached to:0.0000) (behind:0.3810) (belonging to:0.0000) (between:0.0000) (carrying:0.1382) (covered in:0.1190) (covering:0.0327) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0662) (has:0.2109) (holding:0.1444) (in:0.4016) (in front of:0.0128) (laying on:0.0476) (looking at:0.1304) (lying on:0.0000) (made of:0.1429) (mounted on:0.0000) (near:0.3788) (of:0.0955) (on:0.4002) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.2745) (part of:0.0000) (playing:0.0000) (riding:0.0060) (says:0.0000) (sitting on:0.1204) (standing on:0.0946) (to:0.0000) (under:0.0000) (using:0.0769) (walking in:0.0000) (walking on:0.0184) (watching:0.0000) (wearing:0.2745) (wears:0.0000) (with:0.2077) 
SGG eval:   A @ 20: 0.2973;   A @ 50: 0.2980;   A @ 100: 0.2980;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 07:58:56,631 maskrcnn_benchmark INFO: Start training
2020-07-08 07:58:58,503 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: inf, (torch.Size([51]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: inf, (torch.Size([51, 4096]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: inf, (torch.Size([51]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 62130.39453, (torch.Size([4096, 512]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 20621.25977, (torch.Size([4096]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 19720.31250, (torch.Size([512, 32]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 6135.13330, (torch.Size([512]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 536.60797, (torch.Size([22801, 51]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 19.39045, (torch.Size([4096, 4096]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 18.18664, (torch.Size([4096, 12544]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 3.36696, (torch.Size([256, 1024, 3, 3]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.77402, (torch.Size([256, 128, 3, 3]))
2020-07-08 07:58:58,514 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.94916, (torch.Size([51, 4096]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.56778, (torch.Size([512, 1024]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.56510, (torch.Size([4096, 1024]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.46745, (torch.Size([4096, 4096]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.41789, (torch.Size([128, 2, 7, 7]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.29014, (torch.Size([2048, 4808]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.28088, (torch.Size([2048, 4808]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.23844, (torch.Size([4096, 12544]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.22639, (torch.Size([4096]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.21905, (torch.Size([512]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.15324, (torch.Size([256]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.09789, (torch.Size([4096]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.08428, (torch.Size([128]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.07683, (torch.Size([256]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.06613, (torch.Size([512, 1024]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.04951, (torch.Size([2048, 512]))
2020-07-08 07:58:58,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.04922, (torch.Size([2048, 512]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.03613, (torch.Size([4096]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.03556, (torch.Size([256]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.03240, (torch.Size([2048, 4424]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.03216, (torch.Size([128]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.03215, (torch.Size([256]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.03183, (torch.Size([2048, 4424]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.03121, (torch.Size([128]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.02982, (torch.Size([2048]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.02982, (torch.Size([2048]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.02878, (torch.Size([2048]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.02878, (torch.Size([2048]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02575, (torch.Size([1024, 512]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.02425, (torch.Size([512]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.02293, (torch.Size([1024]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01269, (torch.Size([4096]))
2020-07-08 07:58:58,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00582, (torch.Size([2048, 512]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00547, (torch.Size([2048, 512]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00320, (torch.Size([2048]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00320, (torch.Size([2048]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00315, (torch.Size([2048]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00315, (torch.Size([2048]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00293, (torch.Size([4096]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00232, (torch.Size([151, 200]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00159, (torch.Size([128, 32]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00100, (torch.Size([32, 9]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00066, (torch.Size([128]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00044, (torch.Size([32]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00027, (torch.Size([151, 200]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00016, (torch.Size([32]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 07:58:58,517 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 08:02:45,290 maskrcnn_benchmark INFO: eta: 12:38:22  iter: 200  loss: 3.5440 (3.8051)  auxiliary_ctx: 0.1699 (0.3247)  auxiliary_frq: 0.2110 (0.2091)  auxiliary_vis: 0.1803 (0.2697)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9859 (3.0017)  time: 1.1341 (1.1433)  data: 0.0264 (0.0293)  lr: 0.256592  max mem: 6072
2020-07-08 08:06:33,225 maskrcnn_benchmark INFO: eta: 12:33:22  iter: 400  loss: 3.5447 (3.6704)  auxiliary_ctx: 0.1619 (0.2440)  auxiliary_frq: 0.2122 (0.2086)  auxiliary_vis: 0.1827 (0.2243)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9854 (2.9934)  time: 1.1314 (1.1415)  data: 0.0257 (0.0272)  lr: 0.458192  max mem: 6072
2020-07-08 08:10:21,533 maskrcnn_benchmark INFO: eta: 12:29:35  iter: 600  loss: 3.4959 (3.6191)  auxiliary_ctx: 0.1499 (0.2139)  auxiliary_frq: 0.2007 (0.2076)  auxiliary_vis: 0.1662 (0.2073)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9836 (2.9903)  time: 1.1398 (1.1415)  data: 0.0254 (0.0264)  lr: 0.560000  max mem: 6134
2020-07-08 08:14:09,672 maskrcnn_benchmark INFO: eta: 12:25:38  iter: 800  loss: 3.4996 (3.5897)  auxiliary_ctx: 0.1474 (0.1973)  auxiliary_frq: 0.2035 (0.2063)  auxiliary_vis: 0.1661 (0.1975)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9833 (2.9886)  time: 1.1362 (1.1413)  data: 0.0242 (0.0260)  lr: 0.560000  max mem: 6134
2020-07-08 08:17:58,274 maskrcnn_benchmark INFO: eta: 12:22:04  iter: 1000  loss: 3.4998 (3.5716)  auxiliary_ctx: 0.1456 (0.1870)  auxiliary_frq: 0.2069 (0.2057)  auxiliary_vis: 0.1685 (0.1914)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9838 (2.9876)  time: 1.1443 (1.1416)  data: 0.0251 (0.0257)  lr: 0.560000  max mem: 6134
2020-07-08 08:21:46,604 maskrcnn_benchmark INFO: eta: 12:18:15  iter: 1200  loss: 3.4977 (3.5574)  auxiliary_ctx: 0.1477 (0.1795)  auxiliary_frq: 0.2010 (0.2047)  auxiliary_vis: 0.1647 (0.1865)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9829 (2.9868)  time: 1.1380 (1.1416)  data: 0.0258 (0.0254)  lr: 0.560000  max mem: 6134
2020-07-08 08:25:34,726 maskrcnn_benchmark INFO: eta: 12:14:21  iter: 1400  loss: 3.4617 (3.5468)  auxiliary_ctx: 0.1345 (0.1740)  auxiliary_frq: 0.1910 (0.2038)  auxiliary_vis: 0.1546 (0.1828)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9822 (2.9862)  time: 1.1415 (1.1415)  data: 0.0255 (0.0253)  lr: 0.560000  max mem: 6193
2020-07-08 08:29:23,048 maskrcnn_benchmark INFO: eta: 12:10:33  iter: 1600  loss: 3.4864 (3.5376)  auxiliary_ctx: 0.1427 (0.1695)  auxiliary_frq: 0.2001 (0.2029)  auxiliary_vis: 0.1621 (0.1796)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9826 (2.9857)  time: 1.1415 (1.1415)  data: 0.0246 (0.0250)  lr: 0.560000  max mem: 6193
2020-07-08 08:33:10,886 maskrcnn_benchmark INFO: eta: 12:06:35  iter: 1800  loss: 3.4579 (3.5308)  auxiliary_ctx: 0.1313 (0.1660)  auxiliary_frq: 0.1906 (0.2022)  auxiliary_vis: 0.1495 (0.1773)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9817 (2.9853)  time: 1.1264 (1.1413)  data: 0.0251 (0.0249)  lr: 0.560000  max mem: 6193
2020-07-08 08:36:58,277 maskrcnn_benchmark INFO: eta: 12:02:31  iter: 2000  loss: 3.4771 (3.5257)  auxiliary_ctx: 0.1413 (0.1635)  auxiliary_frq: 0.1954 (0.2016)  auxiliary_vis: 0.1581 (0.1755)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9825 (2.9850)  time: 1.1348 (1.1408)  data: 0.0202 (0.0247)  lr: 0.560000  max mem: 6193
2020-07-08 08:36:58,280 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0002000.pth
2020-07-08 08:37:00,624 maskrcnn_benchmark INFO: Start validating
2020-07-08 08:37:00,652 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 08:38:40,443 maskrcnn_benchmark INFO: Total run time: 0:01:39.790376 (0.13970652599334718 s / img per device, on 7 devices)
2020-07-08 08:38:40,443 maskrcnn_benchmark INFO: Model inference time: 0:01:21.535455 (0.11414963631629944 s / img per device, on 7 devices)
2020-07-08 08:40:15,826 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2988;   R @ 50: 0.3581;   R @ 100: 0.3775;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3911; ngR @ 50: 0.5480; ngR @ 100: 0.6469;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0911;  zR @ 50: 0.1474;  zR @ 100: 0.1785;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1478;  mR @ 50: 0.1747;  mR @ 100: 0.1821;  for mode=predcls, type=Mean Recall.
(above:0.3503) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.4603) (attached to:0.0275) (behind:0.2766) (belonging to:0.0000) (between:0.0000) (carrying:0.1382) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5929) (holding:0.6132) (in:0.4387) (in front of:0.1071) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.6127) (of:0.7243) (on:0.2028) (on back of:0.0000) (over:0.0366) (painted on:0.0000) (parked on:0.6823) (part of:0.0000) (playing:0.0000) (riding:0.8527) (says:0.0000) (sitting on:0.3310) (standing on:0.1272) (to:0.0000) (under:0.2423) (using:0.0000) (walking in:0.0000) (walking on:0.7469) (watching:0.1765) (wearing:0.9336) (wears:0.0000) (with:0.2448) 
SGG eval:   A @ 20: 0.3755;   A @ 50: 0.3778;   A @ 100: 0.3778;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 08:40:16,499 maskrcnn_benchmark INFO: Validation Result: 0.3775
2020-07-08 08:44:03,500 maskrcnn_benchmark INFO: eta: 12:55:08  iter: 2200  loss: 3.4613 (3.5206)  auxiliary_ctx: 0.1332 (0.1611)  auxiliary_frq: 0.1922 (0.2010)  auxiliary_vis: 0.1542 (0.1737)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9817 (2.9848)  time: 1.1305 (1.2304)  data: 0.0248 (0.1147)  lr: 0.560000  max mem: 6222
2020-07-08 08:47:50,600 maskrcnn_benchmark INFO: eta: 12:46:05  iter: 2400  loss: 3.4665 (3.5165)  auxiliary_ctx: 0.1353 (0.1592)  auxiliary_frq: 0.1951 (0.2005)  auxiliary_vis: 0.1551 (0.1723)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9823 (2.9845)  time: 1.1338 (1.2225)  data: 0.0251 (0.1072)  lr: 0.560000  max mem: 6222
2020-07-08 08:51:38,354 maskrcnn_benchmark INFO: eta: 12:38:00  iter: 2600  loss: 3.4778 (3.5125)  auxiliary_ctx: 0.1400 (0.1574)  auxiliary_frq: 0.1960 (0.1998)  auxiliary_vis: 0.1569 (0.1709)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9819 (2.9844)  time: 1.1398 (1.2160)  data: 0.0229 (0.1008)  lr: 0.560000  max mem: 6222
2020-07-08 08:55:26,054 maskrcnn_benchmark INFO: eta: 12:30:30  iter: 2800  loss: 3.4676 (3.5094)  auxiliary_ctx: 0.1392 (0.1560)  auxiliary_frq: 0.1940 (0.1994)  auxiliary_vis: 0.1547 (0.1698)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9821 (2.9842)  time: 1.1298 (1.2105)  data: 0.0222 (0.0953)  lr: 0.560000  max mem: 6222
2020-07-08 08:59:13,745 maskrcnn_benchmark INFO: eta: 12:23:31  iter: 3000  loss: 3.4695 (3.5065)  auxiliary_ctx: 0.1352 (0.1547)  auxiliary_frq: 0.1923 (0.1989)  auxiliary_vis: 0.1567 (0.1689)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9817 (2.9840)  time: 1.1361 (1.2057)  data: 0.0256 (0.0905)  lr: 0.560000  max mem: 6222
2020-07-08 09:03:00,682 maskrcnn_benchmark INFO: eta: 12:16:46  iter: 3200  loss: 3.4750 (3.5039)  auxiliary_ctx: 0.1399 (0.1535)  auxiliary_frq: 0.1936 (0.1985)  auxiliary_vis: 0.1564 (0.1680)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9818 (2.9839)  time: 1.1277 (1.2013)  data: 0.0245 (0.0864)  lr: 0.560000  max mem: 6222
2020-07-08 09:06:48,513 maskrcnn_benchmark INFO: eta: 12:10:32  iter: 3400  loss: 3.4490 (3.5013)  auxiliary_ctx: 0.1313 (0.1525)  auxiliary_frq: 0.1871 (0.1980)  auxiliary_vis: 0.1501 (0.1671)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9817 (2.9838)  time: 1.1366 (1.1976)  data: 0.0253 (0.0827)  lr: 0.560000  max mem: 6407
2020-07-08 09:10:36,490 maskrcnn_benchmark INFO: eta: 12:04:36  iter: 3600  loss: 3.4292 (3.4990)  auxiliary_ctx: 0.1255 (0.1515)  auxiliary_frq: 0.1814 (0.1975)  auxiliary_vis: 0.1407 (0.1663)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9806 (2.9837)  time: 1.1338 (1.1944)  data: 0.0254 (0.0793)  lr: 0.560000  max mem: 6407
2020-07-08 09:14:24,063 maskrcnn_benchmark INFO: eta: 11:58:49  iter: 3800  loss: 3.4625 (3.4970)  auxiliary_ctx: 0.1337 (0.1507)  auxiliary_frq: 0.1937 (0.1971)  auxiliary_vis: 0.1557 (0.1656)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9817 (2.9836)  time: 1.1480 (1.1914)  data: 0.0244 (0.0764)  lr: 0.560000  max mem: 6407
2020-07-08 09:18:11,800 maskrcnn_benchmark INFO: ---Total norm 0.20242 clip coef 24.70091-----------------
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.11060, (torch.Size([4096, 12544]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.07293, (torch.Size([256, 1024, 3, 3]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.07174, (torch.Size([51, 4096]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.06761, (torch.Size([4096, 12544]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.05663, (torch.Size([4096, 4096]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.04427, (torch.Size([4096, 4096]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.04417, (torch.Size([51, 4096]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03526, (torch.Size([4096, 1024]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03004, (torch.Size([2048, 4808]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02942, (torch.Size([256, 128, 3, 3]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.02911, (torch.Size([2048, 4808]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02453, (torch.Size([128, 2, 7, 7]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02398, (torch.Size([512, 1024]))
2020-07-08 09:18:11,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01711, (torch.Size([4096, 512]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01600, (torch.Size([51]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01280, (torch.Size([1024, 512]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01192, (torch.Size([512]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01169, (torch.Size([512, 32]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00873, (torch.Size([128]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00860, (torch.Size([256]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00664, (torch.Size([1024]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00641, (torch.Size([4096]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00632, (torch.Size([51]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00629, (torch.Size([151, 200]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00551, (torch.Size([4096]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00525, (torch.Size([2048, 512]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00492, (torch.Size([22801, 51]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00485, (torch.Size([256]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00447, (torch.Size([2048, 512]))
2020-07-08 09:18:11,812 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00402, (torch.Size([2048]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00402, (torch.Size([2048]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00391, (torch.Size([128]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00383, (torch.Size([2048]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00383, (torch.Size([2048]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00378, (torch.Size([256]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00289, (torch.Size([512]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00285, (torch.Size([128]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00221, (torch.Size([4096]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00190, (torch.Size([4096]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00145, (torch.Size([4096]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00078, (torch.Size([256]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00076, (torch.Size([512, 1024]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00067, (torch.Size([512]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00047, (torch.Size([2048, 4424]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00043, (torch.Size([4096]))
2020-07-08 09:18:11,813 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00040, (torch.Size([2048, 4424]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00008, (torch.Size([2048]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00008, (torch.Size([2048]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00007, (torch.Size([2048]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00007, (torch.Size([2048]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00006, (torch.Size([2048, 512]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00005, (torch.Size([2048, 512]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 09:18:11,814 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 09:18:11,817 maskrcnn_benchmark INFO: eta: 11:53:16  iter: 4000  loss: 3.4619 (3.4953)  auxiliary_ctx: 0.1376 (0.1500)  auxiliary_frq: 0.1898 (0.1967)  auxiliary_vis: 0.1562 (0.1650)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9819 (2.9835)  time: 1.1445 (1.1888)  data: 0.0166 (0.0737)  lr: 0.560000  max mem: 6407
2020-07-08 09:18:11,820 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0004000.pth
2020-07-08 09:18:14,049 maskrcnn_benchmark INFO: Start validating
2020-07-08 09:18:14,082 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 09:19:55,995 maskrcnn_benchmark INFO: Total run time: 0:01:41.912962 (0.1426781467437744 s / img per device, on 7 devices)
2020-07-08 09:19:55,996 maskrcnn_benchmark INFO: Model inference time: 0:01:21.426006 (0.11399640884399415 s / img per device, on 7 devices)
2020-07-08 09:21:30,490 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2786;   R @ 50: 0.3434;   R @ 100: 0.3668;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3650; ngR @ 50: 0.5460; ngR @ 100: 0.6643;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0978;  zR @ 50: 0.1785;  zR @ 100: 0.2119;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1609;  mR @ 50: 0.1889;  mR @ 100: 0.1979;  for mode=predcls, type=Mean Recall.
(above:0.4989) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2314) (attached to:0.0655) (behind:0.4404) (belonging to:0.0107) (between:0.0000) (carrying:0.6031) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.3795) (holding:0.4828) (in:0.4411) (in front of:0.1266) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5367) (of:0.6550) (on:0.2055) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.8216) (part of:0.0000) (playing:0.0000) (riding:0.9107) (says:0.0000) (sitting on:0.3541) (standing on:0.1152) (to:0.0000) (under:0.2543) (using:0.0000) (walking in:0.0000) (walking on:0.8208) (watching:0.3824) (wearing:0.9662) (wears:0.0000) (with:0.4247) 
SGG eval:   A @ 20: 0.3645;   A @ 50: 0.3672;   A @ 100: 0.3672;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 09:21:31,262 maskrcnn_benchmark INFO: Validation Result: 0.3668
2020-07-08 09:25:18,903 maskrcnn_benchmark INFO: eta: 12:16:12  iter: 4200  loss: 3.4489 (3.4937)  auxiliary_ctx: 0.1313 (0.1494)  auxiliary_frq: 0.1879 (0.1964)  auxiliary_vis: 0.1482 (0.1645)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9813 (2.9834)  time: 1.1384 (1.2339)  data: 0.0255 (0.1188)  lr: 0.560000  max mem: 6407
2020-07-08 09:29:06,723 maskrcnn_benchmark INFO: eta: 12:09:32  iter: 4400  loss: 3.4535 (3.4923)  auxiliary_ctx: 0.1331 (0.1489)  auxiliary_frq: 0.1903 (0.1961)  auxiliary_vis: 0.1525 (0.1640)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9815 (2.9833)  time: 1.1340 (1.2296)  data: 0.0234 (0.1145)  lr: 0.560000  max mem: 6407
2020-07-08 09:32:54,277 maskrcnn_benchmark INFO: eta: 12:03:05  iter: 4600  loss: 3.4675 (3.4908)  auxiliary_ctx: 0.1416 (0.1483)  auxiliary_frq: 0.1867 (0.1958)  auxiliary_vis: 0.1561 (0.1635)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9823 (2.9833)  time: 1.1270 (1.2256)  data: 0.0250 (0.1105)  lr: 0.560000  max mem: 6407
2020-07-08 09:36:41,838 maskrcnn_benchmark INFO: eta: 11:56:51  iter: 4800  loss: 3.4637 (3.4894)  auxiliary_ctx: 0.1365 (0.1478)  auxiliary_frq: 0.1895 (0.1954)  auxiliary_vis: 0.1541 (0.1630)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9817 (2.9832)  time: 1.1407 (1.2219)  data: 0.0254 (0.1070)  lr: 0.560000  max mem: 6407
2020-07-08 09:40:29,941 maskrcnn_benchmark INFO: eta: 11:50:53  iter: 5000  loss: 3.4643 (3.4880)  auxiliary_ctx: 0.1353 (0.1472)  auxiliary_frq: 0.1859 (0.1951)  auxiliary_vis: 0.1573 (0.1626)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9822 (2.9831)  time: 1.1364 (1.2187)  data: 0.0252 (0.1036)  lr: 0.560000  max mem: 6492
2020-07-08 09:44:17,747 maskrcnn_benchmark INFO: eta: 11:45:02  iter: 5200  loss: 3.4311 (3.4869)  auxiliary_ctx: 0.1284 (0.1468)  auxiliary_frq: 0.1746 (0.1948)  auxiliary_vis: 0.1409 (0.1622)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9808 (2.9831)  time: 1.1350 (1.2156)  data: 0.0242 (0.1005)  lr: 0.560000  max mem: 6492
2020-07-08 09:48:05,071 maskrcnn_benchmark INFO: eta: 11:39:18  iter: 5400  loss: 3.4390 (3.4859)  auxiliary_ctx: 0.1295 (0.1465)  auxiliary_frq: 0.1819 (0.1946)  auxiliary_vis: 0.1463 (0.1619)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9808 (2.9830)  time: 1.1253 (1.2127)  data: 0.0250 (0.0977)  lr: 0.560000  max mem: 6492
2020-07-08 09:51:52,692 maskrcnn_benchmark INFO: eta: 11:33:44  iter: 5600  loss: 3.4455 (3.4847)  auxiliary_ctx: 0.1292 (0.1460)  auxiliary_frq: 0.1836 (0.1943)  auxiliary_vis: 0.1488 (0.1614)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9811 (2.9830)  time: 1.1364 (1.2100)  data: 0.0247 (0.0950)  lr: 0.560000  max mem: 6492
2020-07-08 09:55:40,206 maskrcnn_benchmark INFO: eta: 11:28:16  iter: 5800  loss: 3.4550 (3.4836)  auxiliary_ctx: 0.1376 (0.1456)  auxiliary_frq: 0.1880 (0.1940)  auxiliary_vis: 0.1552 (0.1610)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9818 (2.9829)  time: 1.1253 (1.2075)  data: 0.0236 (0.0925)  lr: 0.560000  max mem: 6492
2020-07-08 09:59:28,495 maskrcnn_benchmark INFO: eta: 11:23:00  iter: 6000  loss: 3.4495 (3.4826)  auxiliary_ctx: 0.1331 (0.1453)  auxiliary_frq: 0.1847 (0.1937)  auxiliary_vis: 0.1486 (0.1607)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9811 (2.9829)  time: 1.1446 (1.2053)  data: 0.0243 (0.0902)  lr: 0.560000  max mem: 6492
2020-07-08 09:59:28,498 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0006000.pth
2020-07-08 09:59:30,807 maskrcnn_benchmark INFO: Start validating
2020-07-08 09:59:30,839 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 10:01:12,708 maskrcnn_benchmark INFO: Total run time: 0:01:41.868434 (0.14261580753326417 s / img per device, on 7 devices)
2020-07-08 10:01:12,708 maskrcnn_benchmark INFO: Model inference time: 0:01:21.486245 (0.11408074355125428 s / img per device, on 7 devices)
2020-07-08 10:02:47,320 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2802;   R @ 50: 0.3460;   R @ 100: 0.3675;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3710; ngR @ 50: 0.5495; ngR @ 100: 0.6648;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1104;  zR @ 50: 0.1637;  zR @ 100: 0.1963;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1467;  mR @ 50: 0.1703;  mR @ 100: 0.1819;  for mode=predcls, type=Mean Recall.
(above:0.4297) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.3859) (attached to:0.0793) (behind:0.4755) (belonging to:0.0179) (between:0.0000) (carrying:0.3772) (covered in:0.0714) (covering:0.0367) (eating:0.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0294) (has:0.3120) (holding:0.5625) (in:0.4328) (in front of:0.2628) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4430) (of:0.5887) (on:0.2667) (on back of:0.0000) (over:0.0488) (painted on:0.0000) (parked on:0.5833) (part of:0.0000) (playing:0.0000) (riding:0.7366) (says:0.0000) (sitting on:0.2333) (standing on:0.0551) (to:0.0000) (under:0.2730) (using:0.0000) (walking in:0.0769) (walking on:0.6898) (watching:0.1765) (wearing:0.9410) (wears:0.0000) (with:0.4729) 
SGG eval:   A @ 20: 0.3618;   A @ 50: 0.3653;   A @ 100: 0.3653;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 10:02:48,080 maskrcnn_benchmark INFO: Validation Result: 0.3675
2020-07-08 10:02:48,081 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-07-08 10:06:35,354 maskrcnn_benchmark INFO: eta: 11:35:52  iter: 6200  loss: 3.4524 (3.4814)  auxiliary_ctx: 0.1357 (0.1448)  auxiliary_frq: 0.1881 (0.1934)  auxiliary_vis: 0.1483 (0.1603)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9817 (2.9828)  time: 1.1253 (1.2353)  data: 0.0254 (0.1203)  lr: 0.056000  max mem: 6492
2020-07-08 10:10:23,066 maskrcnn_benchmark INFO: eta: 11:30:03  iter: 6400  loss: 3.4319 (3.4798)  auxiliary_ctx: 0.1233 (0.1443)  auxiliary_frq: 0.1850 (0.1932)  auxiliary_vis: 0.1377 (0.1597)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9802 (2.9828)  time: 1.1502 (1.2323)  data: 0.0244 (0.1173)  lr: 0.056000  max mem: 6492
2020-07-08 10:14:10,433 maskrcnn_benchmark INFO: eta: 11:24:20  iter: 6600  loss: 3.4256 (3.4785)  auxiliary_ctx: 0.1265 (0.1437)  auxiliary_frq: 0.1841 (0.1929)  auxiliary_vis: 0.1388 (0.1591)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9811 (2.9827)  time: 1.1304 (1.2294)  data: 0.0249 (0.1145)  lr: 0.056000  max mem: 6492
2020-07-08 10:17:57,855 maskrcnn_benchmark INFO: eta: 11:18:44  iter: 6800  loss: 3.4099 (3.4771)  auxiliary_ctx: 0.1191 (0.1432)  auxiliary_frq: 0.1823 (0.1927)  auxiliary_vis: 0.1310 (0.1585)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9798 (2.9826)  time: 1.1410 (1.2267)  data: 0.0254 (0.1118)  lr: 0.056000  max mem: 6492
2020-07-08 10:21:45,883 maskrcnn_benchmark INFO: eta: 11:13:17  iter: 7000  loss: 3.4079 (3.4757)  auxiliary_ctx: 0.1183 (0.1427)  auxiliary_frq: 0.1782 (0.1925)  auxiliary_vis: 0.1305 (0.1580)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9793 (2.9826)  time: 1.1424 (1.2242)  data: 0.0244 (0.1093)  lr: 0.056000  max mem: 6492
2020-07-08 10:25:33,947 maskrcnn_benchmark INFO: eta: 11:07:56  iter: 7200  loss: 3.4322 (3.4743)  auxiliary_ctx: 0.1260 (0.1422)  auxiliary_frq: 0.1796 (0.1922)  auxiliary_vis: 0.1429 (0.1574)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9807 (2.9825)  time: 1.1373 (1.2218)  data: 0.0245 (0.1069)  lr: 0.056000  max mem: 6492
2020-07-08 10:29:21,578 maskrcnn_benchmark INFO: eta: 11:02:38  iter: 7400  loss: 3.4255 (3.4730)  auxiliary_ctx: 0.1229 (0.1417)  auxiliary_frq: 0.1856 (0.1920)  auxiliary_vis: 0.1374 (0.1568)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9795 (2.9824)  time: 1.1377 (1.2196)  data: 0.0259 (0.1047)  lr: 0.056000  max mem: 6492
2020-07-08 10:33:09,341 maskrcnn_benchmark INFO: eta: 10:57:25  iter: 7600  loss: 3.4280 (3.4718)  auxiliary_ctx: 0.1247 (0.1412)  auxiliary_frq: 0.1856 (0.1919)  auxiliary_vis: 0.1365 (0.1563)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9803 (2.9824)  time: 1.1315 (1.2175)  data: 0.0244 (0.1026)  lr: 0.056000  max mem: 6492
2020-07-08 10:36:56,968 maskrcnn_benchmark INFO: eta: 10:52:16  iter: 7800  loss: 3.4281 (3.4707)  auxiliary_ctx: 0.1246 (0.1408)  auxiliary_frq: 0.1856 (0.1917)  auxiliary_vis: 0.1373 (0.1559)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9796 (2.9823)  time: 1.1304 (1.2154)  data: 0.0258 (0.1005)  lr: 0.056000  max mem: 6492
2020-07-08 10:40:44,797 maskrcnn_benchmark INFO: ---Total norm 0.20833 clip coef 24.00024-----------------
2020-07-08 10:40:44,807 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.11823, (torch.Size([4096, 12544]))
2020-07-08 10:40:44,807 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.10301, (torch.Size([4096, 12544]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06211, (torch.Size([4096, 4096]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.05986, (torch.Size([256, 1024, 3, 3]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.04581, (torch.Size([4096, 4096]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.04301, (torch.Size([51, 4096]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03638, (torch.Size([2048, 4808]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03429, (torch.Size([2048, 4808]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03414, (torch.Size([51, 4096]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03177, (torch.Size([4096, 1024]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02534, (torch.Size([256, 128, 3, 3]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02087, (torch.Size([512, 1024]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01972, (torch.Size([1024, 512]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01899, (torch.Size([128, 2, 7, 7]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01456, (torch.Size([4096, 512]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01114, (torch.Size([1024]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01076, (torch.Size([4096]))
2020-07-08 10:40:44,808 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00902, (torch.Size([151, 200]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00780, (torch.Size([512]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00704, (torch.Size([128]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00703, (torch.Size([2048, 512]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00556, (torch.Size([512, 32]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00516, (torch.Size([2048, 512]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00422, (torch.Size([51]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00416, (torch.Size([22801, 51]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00377, (torch.Size([128]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00367, (torch.Size([51]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00356, (torch.Size([2048]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00356, (torch.Size([2048]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00353, (torch.Size([128]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00344, (torch.Size([256]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00339, (torch.Size([256]))
2020-07-08 10:40:44,809 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00309, (torch.Size([256]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00303, (torch.Size([2048]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00303, (torch.Size([2048]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00290, (torch.Size([4096]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00233, (torch.Size([4096]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00145, (torch.Size([512]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00130, (torch.Size([4096]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00121, (torch.Size([4096]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00064, (torch.Size([4096]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00058, (torch.Size([256]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00019, (torch.Size([512, 1024]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00015, (torch.Size([512]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00007, (torch.Size([2048, 4424]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00007, (torch.Size([2048, 4424]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00001, (torch.Size([2048, 512]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00001, (torch.Size([2048]))
2020-07-08 10:40:44,810 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00001, (torch.Size([2048]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 10:40:44,811 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 10:40:44,814 maskrcnn_benchmark INFO: eta: 10:47:12  iter: 8000  loss: 3.4017 (3.4696)  auxiliary_ctx: 0.1153 (0.1403)  auxiliary_frq: 0.1788 (0.1916)  auxiliary_vis: 0.1297 (0.1554)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9791 (2.9823)  time: 1.1325 (1.2135)  data: 0.0193 (0.0986)  lr: 0.056000  max mem: 6492
2020-07-08 10:40:44,817 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0008000.pth
2020-07-08 10:40:47,223 maskrcnn_benchmark INFO: Start validating
2020-07-08 10:40:47,248 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 10:42:30,682 maskrcnn_benchmark INFO: Total run time: 0:01:43.433977 (0.14480756731033326 s / img per device, on 7 devices)
2020-07-08 10:42:30,683 maskrcnn_benchmark INFO: Model inference time: 0:01:22.331797 (0.11526451563835144 s / img per device, on 7 devices)
2020-07-08 10:44:06,778 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.3029;   R @ 50: 0.3680;   R @ 100: 0.3892;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3976; ngR @ 50: 0.5803; ngR @ 100: 0.6954;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1126;  zR @ 50: 0.1652;  zR @ 100: 0.1830;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1650;  mR @ 50: 0.1916;  mR @ 100: 0.2038;  for mode=predcls, type=Mean Recall.
(above:0.4892) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.4751) (attached to:0.0863) (behind:0.4157) (belonging to:0.0000) (between:0.0000) (carrying:0.3377) (covered in:0.1429) (covering:0.0796) (eating:0.2857) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0662) (has:0.4391) (holding:0.5439) (in:0.4854) (in front of:0.1225) (laying on:0.0000) (looking at:0.0217) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4931) (of:0.6903) (on:0.2483) (on back of:0.0000) (over:0.0762) (painted on:0.0000) (parked on:0.4492) (part of:0.0000) (playing:0.0000) (riding:0.8527) (says:0.0000) (sitting on:0.3781) (standing on:0.0754) (to:0.0000) (under:0.3384) (using:0.0000) (walking in:0.0000) (walking on:0.7903) (watching:0.4118) (wearing:0.9631) (wears:0.0000) (with:0.3951) 
SGG eval:   A @ 20: 0.3915;   A @ 50: 0.3958;   A @ 100: 0.3958;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 10:44:07,538 maskrcnn_benchmark INFO: Validation Result: 0.3892
2020-07-08 10:47:54,905 maskrcnn_benchmark INFO: eta: 10:55:16  iter: 8200  loss: 3.4106 (3.4684)  auxiliary_ctx: 0.1169 (0.1399)  auxiliary_frq: 0.1782 (0.1914)  auxiliary_vis: 0.1335 (0.1549)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9793 (2.9822)  time: 1.1340 (1.2364)  data: 0.0246 (0.1215)  lr: 0.056000  max mem: 6492
2020-07-08 10:51:42,663 maskrcnn_benchmark INFO: eta: 10:49:56  iter: 8400  loss: 3.4380 (3.4673)  auxiliary_ctx: 0.1298 (0.1395)  auxiliary_frq: 0.1886 (0.1913)  auxiliary_vis: 0.1419 (0.1544)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9803 (2.9821)  time: 1.1337 (1.2341)  data: 0.0178 (0.1192)  lr: 0.056000  max mem: 6492
2020-07-08 10:55:30,303 maskrcnn_benchmark INFO: eta: 10:44:39  iter: 8600  loss: 3.3990 (3.4663)  auxiliary_ctx: 0.1170 (0.1391)  auxiliary_frq: 0.1769 (0.1911)  auxiliary_vis: 0.1273 (0.1539)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9794 (2.9821)  time: 1.1405 (1.2318)  data: 0.0216 (0.1170)  lr: 0.056000  max mem: 6492
2020-07-08 10:59:17,934 maskrcnn_benchmark INFO: eta: 10:39:26  iter: 8800  loss: 3.4077 (3.4651)  auxiliary_ctx: 0.1142 (0.1387)  auxiliary_frq: 0.1810 (0.1910)  auxiliary_vis: 0.1307 (0.1534)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9790 (2.9820)  time: 1.1360 (1.2297)  data: 0.0252 (0.1149)  lr: 0.056000  max mem: 6492
2020-07-08 11:03:05,376 maskrcnn_benchmark INFO: eta: 10:34:16  iter: 9000  loss: 3.4064 (3.4641)  auxiliary_ctx: 0.1179 (0.1383)  auxiliary_frq: 0.1819 (0.1908)  auxiliary_vis: 0.1282 (0.1530)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9788 (2.9820)  time: 1.1243 (1.2276)  data: 0.0256 (0.1129)  lr: 0.056000  max mem: 6492
2020-07-08 11:06:52,814 maskrcnn_benchmark INFO: eta: 10:29:10  iter: 9200  loss: 3.4024 (3.4632)  auxiliary_ctx: 0.1182 (0.1379)  auxiliary_frq: 0.1799 (0.1907)  auxiliary_vis: 0.1266 (0.1526)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9790 (2.9819)  time: 1.1306 (1.2257)  data: 0.0243 (0.1109)  lr: 0.056000  max mem: 6492
2020-07-08 11:10:40,395 maskrcnn_benchmark INFO: eta: 10:24:08  iter: 9400  loss: 3.4232 (3.4622)  auxiliary_ctx: 0.1230 (0.1376)  auxiliary_frq: 0.1879 (0.1906)  auxiliary_vis: 0.1343 (0.1522)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9799 (2.9819)  time: 1.1362 (1.2238)  data: 0.0248 (0.1090)  lr: 0.056000  max mem: 6492
2020-07-08 11:14:27,971 maskrcnn_benchmark INFO: eta: 10:19:09  iter: 9600  loss: 3.4069 (3.4612)  auxiliary_ctx: 0.1165 (0.1372)  auxiliary_frq: 0.1840 (0.1905)  auxiliary_vis: 0.1275 (0.1517)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9795 (2.9818)  time: 1.1333 (1.2220)  data: 0.0241 (0.1073)  lr: 0.056000  max mem: 6492
2020-07-08 11:18:16,252 maskrcnn_benchmark INFO: eta: 10:14:15  iter: 9800  loss: 3.3856 (3.4603)  auxiliary_ctx: 0.1101 (0.1368)  auxiliary_frq: 0.1767 (0.1904)  auxiliary_vis: 0.1206 (0.1513)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9780 (2.9818)  time: 1.1370 (1.2204)  data: 0.0252 (0.1055)  lr: 0.056000  max mem: 6492
2020-07-08 11:22:04,660 maskrcnn_benchmark INFO: eta: 10:09:24  iter: 10000  loss: 3.3931 (3.4593)  auxiliary_ctx: 0.1109 (0.1365)  auxiliary_frq: 0.1754 (0.1903)  auxiliary_vis: 0.1180 (0.1509)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9781 (2.9817)  time: 1.1309 (1.2188)  data: 0.0253 (0.1039)  lr: 0.056000  max mem: 6492
2020-07-08 11:22:04,663 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0010000.pth
2020-07-08 11:22:06,938 maskrcnn_benchmark INFO: Start validating
2020-07-08 11:22:06,960 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 11:23:47,053 maskrcnn_benchmark INFO: Total run time: 0:01:40.092354 (0.14012929534912108 s / img per device, on 7 devices)
2020-07-08 11:23:47,053 maskrcnn_benchmark INFO: Model inference time: 0:01:22.176249 (0.11504674897193909 s / img per device, on 7 devices)
2020-07-08 11:25:25,901 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.3201;   R @ 50: 0.4006;   R @ 100: 0.4213;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4415; ngR @ 50: 0.6873; ngR @ 100: 0.7998;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1119;  zR @ 50: 0.1600;  zR @ 100: 0.1793;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1615;  mR @ 50: 0.1887;  mR @ 100: 0.2002;  for mode=predcls, type=Mean Recall.
(above:0.4656) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.3884) (attached to:0.0564) (behind:0.5311) (belonging to:0.0000) (between:0.0000) (carrying:0.3509) (covered in:0.1548) (covering:0.0612) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0662) (has:0.3701) (holding:0.5524) (in:0.4648) (in front of:0.1410) (laying on:0.0476) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4833) (of:0.5672) (on:0.3615) (on back of:0.0000) (over:0.0935) (painted on:0.0000) (parked on:0.4468) (part of:0.0000) (playing:0.0000) (riding:0.8795) (says:0.0000) (sitting on:0.3687) (standing on:0.0667) (to:0.0000) (under:0.3036) (using:0.0000) (walking in:0.0000) (walking on:0.7231) (watching:0.4118) (wearing:0.9705) (wears:0.0000) (with:0.4606) 
SGG eval:   A @ 20: 0.4391;   A @ 50: 0.4437;   A @ 100: 0.4437;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 11:25:26,587 maskrcnn_benchmark INFO: Validation Result: 0.4213
2020-07-08 11:29:14,044 maskrcnn_benchmark INFO: eta: 10:14:22  iter: 10200  loss: 3.4133 (3.4585)  auxiliary_ctx: 0.1185 (0.1361)  auxiliary_frq: 0.1866 (0.1902)  auxiliary_vis: 0.1280 (0.1504)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9791 (2.9817)  time: 1.1265 (1.2370)  data: 0.0252 (0.1221)  lr: 0.056000  max mem: 6492
2020-07-08 11:33:01,756 maskrcnn_benchmark INFO: eta: 10:09:19  iter: 10400  loss: 3.4062 (3.4576)  auxiliary_ctx: 0.1167 (0.1358)  auxiliary_frq: 0.1845 (0.1901)  auxiliary_vis: 0.1253 (0.1500)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9785 (2.9816)  time: 1.1321 (1.2351)  data: 0.0255 (0.1202)  lr: 0.056000  max mem: 6492
2020-07-08 11:36:48,658 maskrcnn_benchmark INFO: eta: 10:04:16  iter: 10600  loss: 3.3915 (3.4567)  auxiliary_ctx: 0.1118 (0.1355)  auxiliary_frq: 0.1766 (0.1900)  auxiliary_vis: 0.1207 (0.1496)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9779 (2.9816)  time: 1.1336 (1.2332)  data: 0.0246 (0.1184)  lr: 0.056000  max mem: 6492
2020-07-08 11:40:36,641 maskrcnn_benchmark INFO: eta: 9:59:19  iter: 10800  loss: 3.4184 (3.4558)  auxiliary_ctx: 0.1185 (0.1351)  auxiliary_frq: 0.1866 (0.1899)  auxiliary_vis: 0.1278 (0.1492)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9790 (2.9815)  time: 1.1339 (1.2315)  data: 0.0255 (0.1166)  lr: 0.056000  max mem: 6492
2020-07-08 11:44:24,439 maskrcnn_benchmark INFO: eta: 9:54:24  iter: 11000  loss: 3.4010 (3.4550)  auxiliary_ctx: 0.1145 (0.1348)  auxiliary_frq: 0.1813 (0.1898)  auxiliary_vis: 0.1253 (0.1488)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9786 (2.9815)  time: 1.1343 (1.2298)  data: 0.0253 (0.1149)  lr: 0.056000  max mem: 6492
2020-07-08 11:48:12,401 maskrcnn_benchmark INFO: eta: 9:49:31  iter: 11200  loss: 3.4036 (3.4542)  auxiliary_ctx: 0.1157 (0.1345)  auxiliary_frq: 0.1827 (0.1898)  auxiliary_vis: 0.1265 (0.1484)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9787 (2.9815)  time: 1.1362 (1.2282)  data: 0.0250 (0.1133)  lr: 0.056000  max mem: 6492
2020-07-08 11:52:00,340 maskrcnn_benchmark INFO: eta: 9:44:41  iter: 11400  loss: 3.4052 (3.4534)  auxiliary_ctx: 0.1174 (0.1342)  auxiliary_frq: 0.1872 (0.1897)  auxiliary_vis: 0.1231 (0.1481)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9788 (2.9814)  time: 1.1312 (1.2266)  data: 0.0257 (0.1118)  lr: 0.056000  max mem: 6492
2020-07-08 11:55:48,103 maskrcnn_benchmark INFO: eta: 9:39:53  iter: 11600  loss: 3.3925 (3.4526)  auxiliary_ctx: 0.1126 (0.1339)  auxiliary_frq: 0.1815 (0.1896)  auxiliary_vis: 0.1229 (0.1477)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9782 (2.9814)  time: 1.1310 (1.2251)  data: 0.0185 (0.1102)  lr: 0.056000  max mem: 6492
2020-07-08 11:59:35,556 maskrcnn_benchmark INFO: eta: 9:35:06  iter: 11800  loss: 3.4054 (3.4517)  auxiliary_ctx: 0.1157 (0.1336)  auxiliary_frq: 0.1863 (0.1895)  auxiliary_vis: 0.1233 (0.1473)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9785 (2.9813)  time: 1.1516 (1.2236)  data: 0.0206 (0.1087)  lr: 0.056000  max mem: 6492
2020-07-08 12:03:23,561 maskrcnn_benchmark INFO: ---Total norm 0.49053 clip coef 10.19302-----------------
2020-07-08 12:03:23,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.31755, (torch.Size([4096, 12544]))
2020-07-08 12:03:23,571 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.28892, (torch.Size([4096, 12544]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.12098, (torch.Size([4096, 4096]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.11466, (torch.Size([256, 1024, 3, 3]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.08380, (torch.Size([4096, 4096]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.06203, (torch.Size([51, 4096]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05499, (torch.Size([51, 4096]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.04965, (torch.Size([2048, 4808]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04890, (torch.Size([256, 128, 3, 3]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.04520, (torch.Size([4096, 512]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.04329, (torch.Size([2048, 4808]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04253, (torch.Size([4096, 1024]))
2020-07-08 12:03:23,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03112, (torch.Size([128, 2, 7, 7]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02359, (torch.Size([1024, 512]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02324, (torch.Size([512, 1024]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02092, (torch.Size([512, 32]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01424, (torch.Size([4096]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01356, (torch.Size([151, 200]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01196, (torch.Size([1024]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01165, (torch.Size([512]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01162, (torch.Size([128]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01025, (torch.Size([2048, 512]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01007, (torch.Size([128]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00806, (torch.Size([256]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00720, (torch.Size([2048, 512]))
2020-07-08 12:03:23,573 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00699, (torch.Size([128]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00693, (torch.Size([4096]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00601, (torch.Size([51]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00593, (torch.Size([256]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00567, (torch.Size([2048]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00567, (torch.Size([2048]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00552, (torch.Size([512]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00526, (torch.Size([2048]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00526, (torch.Size([2048]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00472, (torch.Size([4096]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00462, (torch.Size([51]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00455, (torch.Size([22801, 51]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00383, (torch.Size([256]))
2020-07-08 12:03:23,574 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00336, (torch.Size([4096]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00313, (torch.Size([4096]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00157, (torch.Size([4096]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00105, (torch.Size([256]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00040, (torch.Size([512, 1024]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00035, (torch.Size([512]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00024, (torch.Size([2048, 4424]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00021, (torch.Size([2048, 4424]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00003, (torch.Size([2048]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00003, (torch.Size([2048]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00003, (torch.Size([2048]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00003, (torch.Size([2048]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00003, (torch.Size([2048, 512]))
2020-07-08 12:03:23,575 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00002, (torch.Size([2048, 512]))
2020-07-08 12:03:23,576 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-08 12:03:23,576 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 12:03:23,576 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-08 12:03:23,576 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-08 12:03:23,576 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-08 12:03:23,576 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-08 12:03:23,576 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 12:03:23,576 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 12:03:23,579 maskrcnn_benchmark INFO: eta: 9:30:22  iter: 12000  loss: 3.4053 (3.4509)  auxiliary_ctx: 0.1132 (0.1333)  auxiliary_frq: 0.1866 (0.1895)  auxiliary_vis: 0.1278 (0.1468)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9791 (2.9813)  time: 1.1346 (1.2222)  data: 0.0245 (0.1073)  lr: 0.056000  max mem: 6492
2020-07-08 12:03:23,582 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0012000.pth
2020-07-08 12:03:25,902 maskrcnn_benchmark INFO: Start validating
2020-07-08 12:03:25,927 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 12:05:05,088 maskrcnn_benchmark INFO: Total run time: 0:01:39.161031 (0.1388254437446594 s / img per device, on 7 devices)
2020-07-08 12:05:05,089 maskrcnn_benchmark INFO: Model inference time: 0:01:20.840997 (0.11317739543914795 s / img per device, on 7 devices)
2020-07-08 12:06:44,108 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.3424;   R @ 50: 0.4269;   R @ 100: 0.4441;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4851; ngR @ 50: 0.7329; ngR @ 100: 0.8111;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1089;  zR @ 50: 0.1652;  zR @ 100: 0.1919;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1553;  mR @ 50: 0.1840;  mR @ 100: 0.1934;  for mode=predcls, type=Mean Recall.
(above:0.5145) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2114) (attached to:0.0413) (behind:0.4571) (belonging to:0.0000) (between:0.0000) (carrying:0.3246) (covered in:0.1071) (covering:0.0694) (eating:0.1429) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.3779) (holding:0.5297) (in:0.4818) (in front of:0.2490) (laying on:0.0476) (looking at:0.0217) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4832) (of:0.5909) (on:0.4024) (on back of:0.0000) (over:0.0854) (painted on:0.0000) (parked on:0.3341) (part of:0.0000) (playing:0.0000) (riding:0.8527) (says:0.0000) (sitting on:0.3271) (standing on:0.0743) (to:0.0000) (under:0.3214) (using:0.0769) (walking in:0.0000) (walking on:0.6392) (watching:0.4118) (wearing:0.9662) (wears:0.0000) (with:0.4405) 
SGG eval:   A @ 20: 0.4747;   A @ 50: 0.4796;   A @ 100: 0.4796;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 12:06:44,867 maskrcnn_benchmark INFO: Validation Result: 0.4441
2020-07-08 12:10:32,573 maskrcnn_benchmark INFO: eta: 9:33:18  iter: 12200  loss: 3.4080 (3.4500)  auxiliary_ctx: 0.1178 (0.1330)  auxiliary_frq: 0.1906 (0.1894)  auxiliary_vis: 0.1254 (0.1464)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9786 (2.9812)  time: 1.1327 (1.2374)  data: 0.0246 (0.1224)  lr: 0.056000  max mem: 6492
2020-07-08 12:14:20,488 maskrcnn_benchmark INFO: eta: 9:28:27  iter: 12400  loss: 3.3979 (3.4492)  auxiliary_ctx: 0.1158 (0.1327)  auxiliary_frq: 0.1867 (0.1893)  auxiliary_vis: 0.1206 (0.1460)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9786 (2.9812)  time: 1.1301 (1.2358)  data: 0.0176 (0.1208)  lr: 0.056000  max mem: 6492
2020-07-08 12:18:08,471 maskrcnn_benchmark INFO: eta: 9:23:39  iter: 12600  loss: 3.4069 (3.4483)  auxiliary_ctx: 0.1171 (0.1324)  auxiliary_frq: 0.1871 (0.1892)  auxiliary_vis: 0.1206 (0.1456)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9784 (2.9811)  time: 1.1328 (1.2343)  data: 0.0252 (0.1193)  lr: 0.056000  max mem: 6492
2020-07-08 12:21:55,947 maskrcnn_benchmark INFO: eta: 9:18:51  iter: 12800  loss: 3.3835 (3.4474)  auxiliary_ctx: 0.1134 (0.1320)  auxiliary_frq: 0.1801 (0.1891)  auxiliary_vis: 0.1179 (0.1452)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9777 (2.9811)  time: 1.1396 (1.2328)  data: 0.0255 (0.1178)  lr: 0.056000  max mem: 6492
2020-07-08 12:25:43,681 maskrcnn_benchmark INFO: eta: 9:14:05  iter: 13000  loss: 3.4005 (3.4466)  auxiliary_ctx: 0.1153 (0.1317)  auxiliary_frq: 0.1862 (0.1890)  auxiliary_vis: 0.1216 (0.1448)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9787 (2.9810)  time: 1.1362 (1.2313)  data: 0.0249 (0.1163)  lr: 0.056000  max mem: 6492
2020-07-08 12:29:32,001 maskrcnn_benchmark INFO: eta: 9:09:22  iter: 13200  loss: 3.3997 (3.4457)  auxiliary_ctx: 0.1135 (0.1315)  auxiliary_frq: 0.1848 (0.1890)  auxiliary_vis: 0.1201 (0.1444)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9780 (2.9810)  time: 1.1396 (1.2300)  data: 0.0251 (0.1149)  lr: 0.056000  max mem: 6492
2020-07-08 12:33:20,431 maskrcnn_benchmark INFO: eta: 9:04:41  iter: 13400  loss: 3.3951 (3.4448)  auxiliary_ctx: 0.1132 (0.1311)  auxiliary_frq: 0.1882 (0.1889)  auxiliary_vis: 0.1183 (0.1439)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9777 (2.9809)  time: 1.1349 (1.2286)  data: 0.0239 (0.1136)  lr: 0.056000  max mem: 6492
2020-07-08 12:37:07,986 maskrcnn_benchmark INFO: eta: 9:00:00  iter: 13600  loss: 3.3747 (3.4440)  auxiliary_ctx: 0.1063 (0.1308)  auxiliary_frq: 0.1810 (0.1888)  auxiliary_vis: 0.1111 (0.1435)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9770 (2.9809)  time: 1.1311 (1.2273)  data: 0.0248 (0.1122)  lr: 0.056000  max mem: 6492
2020-07-08 12:40:55,696 maskrcnn_benchmark INFO: eta: 8:55:21  iter: 13800  loss: 3.3830 (3.4432)  auxiliary_ctx: 0.1099 (0.1306)  auxiliary_frq: 0.1850 (0.1887)  auxiliary_vis: 0.1104 (0.1431)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9772 (2.9808)  time: 1.1387 (1.2260)  data: 0.0254 (0.1109)  lr: 0.056000  max mem: 6492
2020-07-08 12:44:42,714 maskrcnn_benchmark INFO: eta: 8:50:42  iter: 14000  loss: 3.3826 (3.4425)  auxiliary_ctx: 0.1092 (0.1303)  auxiliary_frq: 0.1799 (0.1887)  auxiliary_vis: 0.1146 (0.1427)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9776 (2.9808)  time: 1.1296 (1.2247)  data: 0.0250 (0.1097)  lr: 0.056000  max mem: 6492
2020-07-08 12:44:42,717 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0014000.pth
2020-07-08 12:44:45,151 maskrcnn_benchmark INFO: Start validating
2020-07-08 12:44:45,184 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 12:46:26,129 maskrcnn_benchmark INFO: Total run time: 0:01:40.943924 (0.14132149419784545 s / img per device, on 7 devices)
2020-07-08 12:46:26,129 maskrcnn_benchmark INFO: Model inference time: 0:01:21.441570 (0.11401819739341736 s / img per device, on 7 devices)
2020-07-08 12:48:06,760 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.3843;   R @ 50: 0.4690;   R @ 100: 0.4839;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.5332; ngR @ 50: 0.7493; ngR @ 100: 0.8043;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1104;  zR @ 50: 0.1704;  zR @ 100: 0.1985;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1522;  mR @ 50: 0.1781;  mR @ 100: 0.1896;  for mode=predcls, type=Mean Recall.
(above:0.3757) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2641) (attached to:0.0272) (behind:0.4419) (belonging to:0.0000) (between:0.0385) (carrying:0.4408) (covered in:0.0833) (covering:0.0367) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.4271) (holding:0.5221) (in:0.4315) (in front of:0.1843) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4808) (of:0.5514) (on:0.4955) (on back of:0.0000) (over:0.0996) (painted on:0.0000) (parked on:0.2419) (part of:0.0000) (playing:0.0000) (riding:0.8348) (says:0.0000) (sitting on:0.2603) (standing on:0.1051) (to:0.0000) (under:0.3495) (using:0.0769) (walking in:0.0000) (walking on:0.7351) (watching:0.3529) (wearing:0.9524) (wears:0.0000) (with:0.4297) 
SGG eval:   A @ 20: 0.5271;   A @ 50: 0.5320;   A @ 100: 0.5320;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 12:48:07,506 maskrcnn_benchmark INFO: Validation Result: 0.4839
2020-07-08 12:51:53,529 maskrcnn_benchmark INFO: eta: 8:52:15  iter: 14200  loss: 3.3957 (3.4417)  auxiliary_ctx: 0.1085 (0.1300)  auxiliary_frq: 0.1882 (0.1886)  auxiliary_vis: 0.1157 (0.1423)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9776 (2.9807)  time: 1.1211 (1.2378)  data: 0.0175 (0.1229)  lr: 0.056000  max mem: 6492
2020-07-08 12:55:40,092 maskrcnn_benchmark INFO: eta: 8:47:30  iter: 14400  loss: 3.3953 (3.4409)  auxiliary_ctx: 0.1116 (0.1297)  auxiliary_frq: 0.1890 (0.1886)  auxiliary_vis: 0.1170 (0.1419)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9774 (2.9807)  time: 1.1272 (1.2364)  data: 0.0240 (0.1215)  lr: 0.056000  max mem: 6492
2020-07-08 12:59:26,150 maskrcnn_benchmark INFO: eta: 8:42:46  iter: 14600  loss: 3.3730 (3.4401)  auxiliary_ctx: 0.1084 (0.1295)  auxiliary_frq: 0.1803 (0.1885)  auxiliary_vis: 0.1078 (0.1415)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9774 (2.9807)  time: 1.1305 (1.2349)  data: 0.0249 (0.1202)  lr: 0.056000  max mem: 6492
2020-07-08 13:03:11,805 maskrcnn_benchmark INFO: eta: 8:38:03  iter: 14800  loss: 3.3882 (3.4393)  auxiliary_ctx: 0.1106 (0.1292)  auxiliary_frq: 0.1808 (0.1885)  auxiliary_vis: 0.1124 (0.1411)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9773 (2.9806)  time: 1.1218 (1.2335)  data: 0.0245 (0.1188)  lr: 0.056000  max mem: 6492
2020-07-08 13:06:58,064 maskrcnn_benchmark INFO: eta: 8:33:22  iter: 15000  loss: 3.3484 (3.4385)  auxiliary_ctx: 0.0979 (0.1289)  auxiliary_frq: 0.1773 (0.1884)  auxiliary_vis: 0.1018 (0.1406)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9761 (2.9806)  time: 1.1212 (1.2321)  data: 0.0250 (0.1176)  lr: 0.056000  max mem: 6681
2020-07-08 13:10:44,230 maskrcnn_benchmark INFO: eta: 8:28:42  iter: 15200  loss: 3.3913 (3.4377)  auxiliary_ctx: 0.1126 (0.1286)  auxiliary_frq: 0.1873 (0.1884)  auxiliary_vis: 0.1124 (0.1402)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9773 (2.9805)  time: 1.1221 (1.2308)  data: 0.0248 (0.1163)  lr: 0.056000  max mem: 6681
2020-07-08 13:14:30,234 maskrcnn_benchmark INFO: eta: 8:24:04  iter: 15400  loss: 3.3659 (3.4370)  auxiliary_ctx: 0.1080 (0.1284)  auxiliary_frq: 0.1826 (0.1883)  auxiliary_vis: 0.1072 (0.1398)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9767 (2.9805)  time: 1.1292 (1.2295)  data: 0.0201 (0.1151)  lr: 0.056000  max mem: 6681
2020-07-08 13:18:16,675 maskrcnn_benchmark INFO: eta: 8:19:28  iter: 15600  loss: 3.3570 (3.4362)  auxiliary_ctx: 0.1012 (0.1281)  auxiliary_frq: 0.1797 (0.1883)  auxiliary_vis: 0.1000 (0.1394)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9761 (2.9804)  time: 1.1347 (1.2282)  data: 0.0247 (0.1140)  lr: 0.056000  max mem: 6681
2020-07-08 13:22:02,779 maskrcnn_benchmark INFO: eta: 8:14:52  iter: 15800  loss: 3.3575 (3.4354)  auxiliary_ctx: 0.1010 (0.1278)  auxiliary_frq: 0.1765 (0.1882)  auxiliary_vis: 0.1029 (0.1390)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9762 (2.9804)  time: 1.1274 (1.2270)  data: 0.0250 (0.1128)  lr: 0.056000  max mem: 6681
2020-07-08 13:25:49,113 maskrcnn_benchmark INFO: ---Total norm 0.61854 clip coef 8.08349-----------------
2020-07-08 13:25:49,123 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.42409, (torch.Size([4096, 12544]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.35071, (torch.Size([4096, 12544]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.16239, (torch.Size([4096, 4096]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.14373, (torch.Size([256, 1024, 3, 3]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.09735, (torch.Size([4096, 4096]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.06685, (torch.Size([51, 4096]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.06241, (torch.Size([2048, 4808]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.05433, (torch.Size([256, 128, 3, 3]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.05163, (torch.Size([2048, 4808]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04996, (torch.Size([4096, 1024]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.04447, (torch.Size([51, 4096]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03361, (torch.Size([128, 2, 7, 7]))
2020-07-08 13:25:49,124 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02860, (torch.Size([1024, 512]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02784, (torch.Size([512, 1024]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02076, (torch.Size([4096, 512]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01507, (torch.Size([4096]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01480, (torch.Size([151, 200]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01381, (torch.Size([1024]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01226, (torch.Size([128]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01074, (torch.Size([2048, 512]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01073, (torch.Size([512]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00834, (torch.Size([256]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00793, (torch.Size([2048, 512]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00729, (torch.Size([512, 32]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00719, (torch.Size([2048]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00719, (torch.Size([2048]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00673, (torch.Size([128]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00637, (torch.Size([4096]))
2020-07-08 13:25:49,125 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00614, (torch.Size([256]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00589, (torch.Size([4096]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00563, (torch.Size([128]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00517, (torch.Size([2048]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00517, (torch.Size([2048]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00415, (torch.Size([4096]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00395, (torch.Size([22801, 51]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00366, (torch.Size([256]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00340, (torch.Size([51]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00294, (torch.Size([51]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00228, (torch.Size([512]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00195, (torch.Size([4096]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00137, (torch.Size([4096]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00121, (torch.Size([256]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00062, (torch.Size([512, 1024]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00055, (torch.Size([512]))
2020-07-08 13:25:49,126 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00036, (torch.Size([2048, 4424]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00035, (torch.Size([2048, 4424]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00005, (torch.Size([2048]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00005, (torch.Size([2048]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00005, (torch.Size([2048]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00005, (torch.Size([2048]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00004, (torch.Size([2048, 512]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00003, (torch.Size([2048, 512]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 13:25:49,127 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 13:25:49,130 maskrcnn_benchmark INFO: eta: 8:10:18  iter: 16000  loss: 3.3960 (3.4346)  auxiliary_ctx: 0.1158 (0.1275)  auxiliary_frq: 0.1905 (0.1882)  auxiliary_vis: 0.1140 (0.1386)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9773 (2.9803)  time: 1.1273 (1.2258)  data: 0.0247 (0.1117)  lr: 0.056000  max mem: 6681
2020-07-08 13:25:49,133 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0016000.pth
2020-07-08 13:25:51,563 maskrcnn_benchmark INFO: Start validating
2020-07-08 13:25:51,592 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 18:06:36,018 maskrcnn_benchmark INFO: Using 7 GPUs
2020-07-08 18:06:36,019 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'mfb', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '56', 'TEST.IMS_PER_BATCH', '7', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE'], skip_test=False)
2020-07-08 18:06:36,019 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-07-08 18:06:40,614 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-07-08 18:06:40,615 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-07-08 18:06:40,615 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate', 'dist'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-07-08 18:06:40,618 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: TDE
      FUSION_TYPE: mfb
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 56
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 7
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-07-08 18:06:40,619 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/config.yml
2020-07-08 18:06:40,655 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-07-08 18:06:43,886 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-07-08 18:06:43,886 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-07-08 18:06:43,888 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-07-08 18:06:43,888 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-07-08 18:06:45,096 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-07-08 18:06:45,393 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-07-08 18:06:45,424 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-07-08 18:06:45,425 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0016000.pth
2020-07-08 18:06:47,530 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0016000.pth
2020-07-08 18:06:48,079 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-07-08 18:06:48,079 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-07-08 18:06:50,788 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/labels.json
2020-07-08 18:06:52,015 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-07-08 18:06:52,015 maskrcnn_benchmark INFO: Validate before training
2020-07-08 18:06:52,017 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 18:08:35,635 maskrcnn_benchmark INFO: Total run time: 0:01:43.617369 (0.14506431684494017 s / img per device, on 7 devices)
2020-07-08 18:08:35,635 maskrcnn_benchmark INFO: Model inference time: 0:01:22.089198 (0.1149248770236969 s / img per device, on 7 devices)
2020-07-08 18:10:14,866 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.3767;   R @ 50: 0.4675;   R @ 100: 0.4853;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.5044; ngR @ 50: 0.7160; ngR @ 100: 0.7778;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1222;  zR @ 50: 0.1911;  zR @ 100: 0.2185;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1571;  mR @ 50: 0.1868;  mR @ 100: 0.1999;  for mode=predcls, type=Mean Recall.
(above:0.4232) (across:0.0000) (against:0.0000) (along:0.0385) (and:0.0000) (at:0.3529) (attached to:0.0088) (behind:0.4309) (belonging to:0.0000) (between:0.0000) (carrying:0.4605) (covered in:0.1071) (covering:0.0898) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0662) (has:0.4762) (holding:0.5431) (in:0.4362) (in front of:0.2704) (laying on:0.0476) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3595) (of:0.5467) (on:0.5084) (on back of:0.0455) (over:0.1423) (painted on:0.0000) (parked on:0.4453) (part of:0.0000) (playing:0.0000) (riding:0.8527) (says:0.0000) (sitting on:0.3223) (standing on:0.1591) (to:0.0000) (under:0.3648) (using:0.0769) (walking in:0.0000) (walking on:0.5293) (watching:0.3529) (wearing:0.9586) (wears:0.0000) (with:0.3562) 
SGG eval:   A @ 20: 0.5241;   A @ 50: 0.5288;   A @ 100: 0.5288;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 18:10:15,647 maskrcnn_benchmark INFO: Start training
2020-07-08 18:10:17,531 maskrcnn_benchmark INFO: ---Total norm 0.70260 clip coef 7.11637-----------------
2020-07-08 18:10:17,541 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.49440, (torch.Size([4096, 12544]))
2020-07-08 18:10:17,541 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.39814, (torch.Size([4096, 12544]))
2020-07-08 18:10:17,541 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.17519, (torch.Size([4096, 4096]))
2020-07-08 18:10:17,541 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.16371, (torch.Size([256, 1024, 3, 3]))
2020-07-08 18:10:17,541 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.10258, (torch.Size([4096, 4096]))
2020-07-08 18:10:17,541 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.06557, (torch.Size([256, 128, 3, 3]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.05578, (torch.Size([2048, 4808]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05572, (torch.Size([51, 4096]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.05092, (torch.Size([4096, 1024]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.05052, (torch.Size([2048, 4808]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.04060, (torch.Size([128, 2, 7, 7]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03450, (torch.Size([51, 4096]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02797, (torch.Size([4096, 512]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02711, (torch.Size([1024, 512]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02698, (torch.Size([512, 1024]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01704, (torch.Size([128]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01665, (torch.Size([151, 200]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01516, (torch.Size([4096]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01329, (torch.Size([2048, 512]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01214, (torch.Size([512, 32]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01201, (torch.Size([1024]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01027, (torch.Size([512]))
2020-07-08 18:10:17,542 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00961, (torch.Size([2048, 512]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00914, (torch.Size([256]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00620, (torch.Size([256]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00606, (torch.Size([128]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00605, (torch.Size([4096]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00588, (torch.Size([2048]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00588, (torch.Size([2048]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00566, (torch.Size([2048]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00566, (torch.Size([2048]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00559, (torch.Size([256]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00505, (torch.Size([128]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00494, (torch.Size([4096]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00452, (torch.Size([4096]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00418, (torch.Size([22801, 51]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00363, (torch.Size([512]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00354, (torch.Size([51]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00246, (torch.Size([51]))
2020-07-08 18:10:17,543 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00216, (torch.Size([4096]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00195, (torch.Size([4096]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00150, (torch.Size([256]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00035, (torch.Size([512, 1024]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00034, (torch.Size([512]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00024, (torch.Size([2048, 4424]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00023, (torch.Size([2048, 4424]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00003, (torch.Size([2048]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00003, (torch.Size([2048]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00003, (torch.Size([2048]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00003, (torch.Size([2048]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00001, (torch.Size([2048, 512]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00001, (torch.Size([2048, 512]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-08 18:10:17,544 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-08 18:10:17,545 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-08 18:10:17,545 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 18:10:17,545 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 18:14:02,549 maskrcnn_benchmark INFO: eta: 7:30:01  iter: 16200  loss: 3.5614 (7.6112)  auxiliary_ctx: 0.2484 (4.2193)  auxiliary_frq: 0.1848 (0.1839)  auxiliary_vis: 0.1494 (0.1538)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9843 (3.0542)  time: 1.1252 (1.1345)  data: 0.0198 (0.0271)  lr: 0.560000  max mem: 6042
2020-07-08 18:17:49,004 maskrcnn_benchmark INFO: eta: 7:25:48  iter: 16400  loss: 3.5697 (5.5910)  auxiliary_ctx: 0.2453 (2.2341)  auxiliary_frq: 0.1853 (0.1844)  auxiliary_vis: 0.1540 (0.1535)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9832 (3.0190)  time: 1.1264 (1.1334)  data: 0.0196 (0.0254)  lr: 0.560000  max mem: 6042
2020-07-08 18:21:35,321 maskrcnn_benchmark INFO: eta: 7:21:47  iter: 16600  loss: 3.5404 (4.9144)  auxiliary_ctx: 0.2372 (1.5708)  auxiliary_frq: 0.1788 (0.1840)  auxiliary_vis: 0.1457 (0.1525)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9827 (3.0071)  time: 1.1272 (1.1328)  data: 0.0248 (0.0250)  lr: 0.560000  max mem: 6052
2020-07-08 18:25:21,236 maskrcnn_benchmark INFO: eta: 7:17:42  iter: 16800  loss: 3.5631 (4.5764)  auxiliary_ctx: 0.2411 (1.2393)  auxiliary_frq: 0.1823 (0.1837)  auxiliary_vis: 0.1524 (0.1523)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9836 (3.0011)  time: 1.1242 (1.1320)  data: 0.0233 (0.0245)  lr: 0.560000  max mem: 6579
2020-07-08 18:29:07,719 maskrcnn_benchmark INFO: eta: 7:13:57  iter: 17000  loss: 3.5435 (4.3729)  auxiliary_ctx: 0.2321 (1.0399)  auxiliary_frq: 0.1766 (0.1835)  auxiliary_vis: 0.1479 (0.1520)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9821 (2.9976)  time: 1.1293 (1.1321)  data: 0.0250 (0.0245)  lr: 0.560000  max mem: 6579
2020-07-08 18:32:53,212 maskrcnn_benchmark INFO: eta: 7:09:53  iter: 17200  loss: 3.5710 (4.2373)  auxiliary_ctx: 0.2585 (0.9075)  auxiliary_frq: 0.1843 (0.1834)  auxiliary_vis: 0.1483 (0.1513)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9826 (2.9951)  time: 1.1253 (1.1313)  data: 0.0240 (0.0244)  lr: 0.560000  max mem: 6579
2020-07-08 18:36:39,417 maskrcnn_benchmark INFO: eta: 7:06:06  iter: 17400  loss: 3.5412 (4.1409)  auxiliary_ctx: 0.2391 (0.8131)  auxiliary_frq: 0.1793 (0.1835)  auxiliary_vis: 0.1404 (0.1510)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9822 (2.9934)  time: 1.1388 (1.1313)  data: 0.0265 (0.0246)  lr: 0.560000  max mem: 6579
2020-07-08 18:40:26,023 maskrcnn_benchmark INFO: eta: 7:02:25  iter: 17600  loss: 3.5370 (4.0674)  auxiliary_ctx: 0.2342 (0.7417)  auxiliary_frq: 0.1779 (0.1831)  auxiliary_vis: 0.1466 (0.1505)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9830 (2.9920)  time: 1.1375 (1.1315)  data: 0.0199 (0.0246)  lr: 0.560000  max mem: 6579
2020-07-08 18:44:12,482 maskrcnn_benchmark INFO: eta: 6:58:40  iter: 17800  loss: 3.5594 (4.0112)  auxiliary_ctx: 0.2424 (0.6866)  auxiliary_frq: 0.1836 (0.1831)  auxiliary_vis: 0.1481 (0.1505)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9828 (2.9910)  time: 1.1289 (1.1316)  data: 0.0253 (0.0246)  lr: 0.560000  max mem: 6579
2020-07-08 18:47:58,780 maskrcnn_benchmark INFO: eta: 6:54:54  iter: 18000  loss: 3.5352 (3.9653)  auxiliary_ctx: 0.2309 (0.6420)  auxiliary_frq: 0.1742 (0.1828)  auxiliary_vis: 0.1463 (0.1503)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9820 (2.9902)  time: 1.1262 (1.1316)  data: 0.0184 (0.0245)  lr: 0.560000  max mem: 6579
2020-07-08 18:47:58,783 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0018000.pth
2020-07-08 18:48:01,276 maskrcnn_benchmark INFO: Start validating
2020-07-08 18:48:01,308 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 19:41:39,828 maskrcnn_benchmark INFO: Using 8 GPUs
2020-07-08 19:41:39,828 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'mfb', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '56', 'TEST.IMS_PER_BATCH', '7', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE'], skip_test=False)
2020-07-08 19:41:39,828 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-07-08 19:41:44,370 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-07-08 19:41:44,370 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-07-08 19:41:44,371 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate', 'dist'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-07-08 19:41:44,373 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: TDE
      FUSION_TYPE: mfb
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 56
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 7
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-07-08 19:41:44,374 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/config.yml
2020-07-08 19:41:44,411 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-07-08 19:41:47,654 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-07-08 19:41:47,654 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-07-08 19:41:47,655 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-07-08 19:41:47,655 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-07-08 19:41:48,894 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-07-08 19:41:49,711 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-07-08 19:41:49,743 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-07-08 19:41:49,744 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0018000.pth
2020-07-08 19:41:51,966 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0018000.pth
2020-07-08 19:41:52,597 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-07-08 19:41:52,597 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-07-08 19:41:55,265 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/labels.json
2020-07-08 19:42:56,064 maskrcnn_benchmark INFO: Using 8 GPUs
2020-07-08 19:42:56,064 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'mfb', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE'], skip_test=False)
2020-07-08 19:42:56,064 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-07-08 19:42:59,946 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-07-08 19:42:59,946 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-07-08 19:42:59,947 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate', 'dist'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-07-08 19:42:59,949 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: TDE
      FUSION_TYPE: mfb
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 64
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-07-08 19:42:59,950 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/config.yml
2020-07-08 19:42:59,985 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-07-08 19:43:03,229 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-07-08 19:43:03,229 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-07-08 19:43:03,230 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-07-08 19:43:03,230 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-07-08 19:43:04,445 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-07-08 19:43:04,733 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-07-08 19:43:04,765 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-07-08 19:43:04,766 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0018000.pth
2020-07-08 19:43:06,882 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0018000.pth
2020-07-08 19:43:07,443 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-07-08 19:43:07,444 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-07-08 19:43:10,215 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/labels.json
2020-07-08 19:43:11,481 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-07-08 19:43:11,482 maskrcnn_benchmark INFO: Validate before training
2020-07-08 19:43:11,484 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 19:44:44,128 maskrcnn_benchmark INFO: Total run time: 0:01:32.644181 (0.1482306896209717 s / img per device, on 8 devices)
2020-07-08 19:44:44,129 maskrcnn_benchmark INFO: Model inference time: 0:01:10.072386 (0.11211581764221192 s / img per device, on 8 devices)
2020-07-08 19:45:51,540 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.0077;   R @ 50: 0.0135;   R @ 100: 0.0182;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.0065; ngR @ 50: 0.0284; ngR @ 100: 0.0642;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0311;  zR @ 50: 0.0422;  zR @ 100: 0.0556;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0059;  mR @ 50: 0.0100;  mR @ 100: 0.0138;  for mode=predcls, type=Mean Recall.
(above:0.6880) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0000) (attached to:0.0000) (behind:0.0000) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.0000) (holding:0.0000) (in:0.0000) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0000) (of:0.0000) (on:0.0000) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0000) (standing on:0.0000) (to:0.0000) (under:0.0000) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.0000) (wears:0.0000) (with:0.0000) 
SGG eval:   A @ 20: 0.0242;   A @ 50: 0.0242;   A @ 100: 0.0242;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 19:45:52,259 maskrcnn_benchmark INFO: Start training
2020-07-08 19:45:54,174 maskrcnn_benchmark INFO: ---Total norm 0.14433 clip coef 34.64183-----------------
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.11086, (torch.Size([4096, 12544]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.06077, (torch.Size([256, 1024, 3, 3]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.04503, (torch.Size([4096, 4096]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03968, (torch.Size([51, 4096]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02443, (torch.Size([256, 128, 3, 3]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01940, (torch.Size([128, 2, 7, 7]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00899, (torch.Size([51]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00840, (torch.Size([128]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00623, (torch.Size([51]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00445, (torch.Size([256]))
2020-07-08 19:45:54,184 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00396, (torch.Size([22801, 51]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00349, (torch.Size([256]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00343, (torch.Size([128]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00312, (torch.Size([4096]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00248, (torch.Size([256]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00244, (torch.Size([128]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00136, (torch.Size([4096]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00057, (torch.Size([256]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.00011, (torch.Size([51, 4096]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00005, (torch.Size([4096]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.00002, (torch.Size([4096, 1024]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4808]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.00000, (torch.Size([4096, 512]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4808]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00000, (torch.Size([1024, 512]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.00000, (torch.Size([512, 1024]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00000, (torch.Size([4096]))
2020-07-08 19:45:54,185 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00000, (torch.Size([512, 32]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.00000, (torch.Size([4096, 4096]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00000, (torch.Size([512]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.00000, (torch.Size([4096, 12544]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00000, (torch.Size([512]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00000, (torch.Size([1024]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00000, (torch.Size([4096]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00000, (torch.Size([4096]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00000, (torch.Size([512, 1024]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00000, (torch.Size([512]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 19:45:54,186 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-08 19:45:54,187 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 19:49:41,215 maskrcnn_benchmark INFO: eta: 6:55:55  iter: 18200  loss: 3.5564 (3.5550)  auxiliary_ctx: 0.2401 (0.2445)  auxiliary_frq: 0.1815 (0.1817)  auxiliary_vis: 0.1494 (0.1463)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9825 (2.9826)  time: 1.1348 (1.1448)  data: 0.0251 (0.0290)  lr: 0.640000  max mem: 6103
2020-07-08 19:53:29,444 maskrcnn_benchmark INFO: eta: 6:51:27  iter: 18400  loss: 3.5481 (3.5542)  auxiliary_ctx: 0.2400 (0.2434)  auxiliary_frq: 0.1788 (0.1811)  auxiliary_vis: 0.1479 (0.1470)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9827 (2.9827)  time: 1.1456 (1.1430)  data: 0.0248 (0.0270)  lr: 0.640000  max mem: 6103
2020-07-08 19:57:18,130 maskrcnn_benchmark INFO: eta: 6:47:42  iter: 18600  loss: 3.5640 (3.5549)  auxiliary_ctx: 0.2444 (0.2432)  auxiliary_frq: 0.1793 (0.1811)  auxiliary_vis: 0.1540 (0.1479)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9834 (2.9827)  time: 1.1393 (1.1431)  data: 0.0265 (0.0260)  lr: 0.640000  max mem: 6161
2020-07-08 20:01:06,711 maskrcnn_benchmark INFO: eta: 6:43:52  iter: 18800  loss: 3.5509 (3.5565)  auxiliary_ctx: 0.2434 (0.2437)  auxiliary_frq: 0.1782 (0.1813)  auxiliary_vis: 0.1488 (0.1487)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9828 (2.9828)  time: 1.1443 (1.1431)  data: 0.0267 (0.0263)  lr: 0.640000  max mem: 6161
2020-07-08 20:04:55,223 maskrcnn_benchmark INFO: eta: 6:40:02  iter: 19000  loss: 3.5158 (3.5557)  auxiliary_ctx: 0.2267 (0.2434)  auxiliary_frq: 0.1733 (0.1811)  auxiliary_vis: 0.1372 (0.1485)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9815 (2.9828)  time: 1.1399 (1.1430)  data: 0.0263 (0.0259)  lr: 0.640000  max mem: 6215
2020-07-08 20:08:43,367 maskrcnn_benchmark INFO: eta: 6:36:05  iter: 19200  loss: 3.5574 (3.5563)  auxiliary_ctx: 0.2424 (0.2446)  auxiliary_frq: 0.1831 (0.1809)  auxiliary_vis: 0.1491 (0.1481)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9831 (2.9827)  time: 1.1298 (1.1426)  data: 0.0259 (0.0257)  lr: 0.640000  max mem: 6215
2020-07-08 20:12:31,988 maskrcnn_benchmark INFO: eta: 6:32:18  iter: 19400  loss: 3.5553 (3.5571)  auxiliary_ctx: 0.2428 (0.2451)  auxiliary_frq: 0.1782 (0.1809)  auxiliary_vis: 0.1489 (0.1483)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9826 (2.9827)  time: 1.1450 (1.1427)  data: 0.0259 (0.0258)  lr: 0.640000  max mem: 6215
2020-07-08 20:16:20,879 maskrcnn_benchmark INFO: eta: 6:28:34  iter: 19600  loss: 3.5163 (3.5535)  auxiliary_ctx: 0.2094 (0.2417)  auxiliary_frq: 0.1762 (0.1808)  auxiliary_vis: 0.1488 (0.1483)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9829 (2.9827)  time: 1.1471 (1.1429)  data: 0.0204 (0.0255)  lr: 0.640000  max mem: 6215
2020-07-08 20:20:09,581 maskrcnn_benchmark INFO: eta: 6:24:47  iter: 19800  loss: 3.5366 (3.5511)  auxiliary_ctx: 0.2190 (0.2390)  auxiliary_frq: 0.1830 (0.1807)  auxiliary_vis: 0.1515 (0.1486)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9825 (2.9828)  time: 1.1380 (1.1430)  data: 0.0271 (0.0254)  lr: 0.640000  max mem: 6285
2020-07-08 20:23:58,135 maskrcnn_benchmark INFO: ---Total norm 0.13138 clip coef 38.05711-----------------
2020-07-08 20:23:58,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.09886, (torch.Size([4096, 12544]))
2020-07-08 20:23:58,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.05336, (torch.Size([256, 1024, 3, 3]))
2020-07-08 20:23:58,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03918, (torch.Size([4096, 4096]))
2020-07-08 20:23:58,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03800, (torch.Size([51, 4096]))
2020-07-08 20:23:58,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02179, (torch.Size([256, 128, 3, 3]))
2020-07-08 20:23:58,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01748, (torch.Size([128, 2, 7, 7]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01136, (torch.Size([512, 1024]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.01044, (torch.Size([51, 4096]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.00986, (torch.Size([4096, 512]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00832, (torch.Size([1024, 512]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00830, (torch.Size([51]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.00777, (torch.Size([4096, 1024]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00758, (torch.Size([512, 32]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00740, (torch.Size([512]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00681, (torch.Size([128]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00517, (torch.Size([4096]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00431, (torch.Size([51]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00428, (torch.Size([256]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00407, (torch.Size([22801, 51]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00395, (torch.Size([1024]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00339, (torch.Size([128]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00329, (torch.Size([256]))
2020-07-08 20:23:58,146 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00282, (torch.Size([4096]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00274, (torch.Size([2048]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00274, (torch.Size([2048]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00267, (torch.Size([2048, 512]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00254, (torch.Size([2048]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00254, (torch.Size([2048]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00249, (torch.Size([128]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00241, (torch.Size([256]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00219, (torch.Size([512]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00203, (torch.Size([2048, 512]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.00145, (torch.Size([2048, 4808]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.00135, (torch.Size([2048, 4808]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00120, (torch.Size([4096]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00103, (torch.Size([4096]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.00073, (torch.Size([4096, 12544]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00054, (torch.Size([256]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.00031, (torch.Size([4096, 4096]))
2020-07-08 20:23:58,147 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00018, (torch.Size([151, 200]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00002, (torch.Size([512]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00002, (torch.Size([4096]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00001, (torch.Size([512, 1024]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00000, (torch.Size([4096]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-08 20:23:58,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-08 20:23:58,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 20:23:58,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-08 20:23:58,149 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 20:23:58,151 maskrcnn_benchmark INFO: eta: 6:20:58  iter: 20000  loss: 3.5273 (3.5485)  auxiliary_ctx: 0.2173 (0.2368)  auxiliary_frq: 0.1793 (0.1807)  auxiliary_vis: 0.1446 (0.1483)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9821 (2.9827)  time: 1.1364 (1.1429)  data: 0.0250 (0.0255)  lr: 0.640000  max mem: 6285
2020-07-08 20:23:58,154 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0020000.pth
2020-07-08 20:24:00,709 maskrcnn_benchmark INFO: Start validating
2020-07-08 20:24:00,737 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 20:25:33,003 maskrcnn_benchmark INFO: Total run time: 0:01:32.265665 (0.14762506446838378 s / img per device, on 8 devices)
2020-07-08 20:25:33,003 maskrcnn_benchmark INFO: Model inference time: 0:01:10.028356 (0.1120453701019287 s / img per device, on 8 devices)
2020-07-08 20:26:56,695 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.0753;   R @ 50: 0.1061;   R @ 100: 0.1214;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.0830; ngR @ 50: 0.1107; ngR @ 100: 0.1549;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0778;  zR @ 50: 0.1044;  zR @ 100: 0.1356;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0503;  mR @ 50: 0.0862;  mR @ 100: 0.1070;  for mode=predcls, type=Mean Recall.
(above:0.2736) (across:0.0000) (against:0.0000) (along:0.0385) (and:0.0323) (at:0.4152) (attached to:0.0067) (behind:0.1338) (belonging to:0.0107) (between:0.0000) (carrying:0.0351) (covered in:0.0357) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.2091) (holding:0.2281) (in:0.0374) (in front of:0.0434) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1617) (of:0.1276) (on:0.0512) (on back of:0.0000) (over:0.1423) (painted on:0.0000) (parked on:0.4636) (part of:0.0000) (playing:0.0000) (riding:0.4985) (says:0.0000) (sitting on:0.3935) (standing on:0.1587) (to:0.0000) (under:0.0961) (using:0.0000) (walking in:0.0000) (walking on:0.4426) (watching:0.1471) (wearing:0.1196) (wears:0.6198) (with:0.2970) 
SGG eval:   A @ 20: 0.1231;   A @ 50: 0.1238;   A @ 100: 0.1238;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 20:26:57,456 maskrcnn_benchmark INFO: Validation Result: 0.1214
2020-07-08 20:30:45,404 maskrcnn_benchmark INFO: eta: 6:43:58  iter: 20200  loss: 3.5132 (3.5463)  auxiliary_ctx: 0.2057 (0.2347)  auxiliary_frq: 0.1783 (0.1806)  auxiliary_vis: 0.1479 (0.1482)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9824 (2.9827)  time: 1.1388 (1.2242)  data: 0.0196 (0.1069)  lr: 0.640000  max mem: 6285
2020-07-08 20:34:33,646 maskrcnn_benchmark INFO: eta: 6:37:37  iter: 20400  loss: 3.4845 (3.5431)  auxiliary_ctx: 0.1875 (0.2320)  auxiliary_frq: 0.1716 (0.1804)  auxiliary_vis: 0.1411 (0.1480)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9815 (2.9827)  time: 1.1376 (1.2172)  data: 0.0236 (0.1000)  lr: 0.640000  max mem: 6285
2020-07-08 20:38:21,830 maskrcnn_benchmark INFO: eta: 6:31:40  iter: 20600  loss: 3.5114 (3.5405)  auxiliary_ctx: 0.1958 (0.2295)  auxiliary_frq: 0.1822 (0.1802)  auxiliary_vis: 0.1459 (0.1480)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9825 (2.9827)  time: 1.1421 (1.2114)  data: 0.0268 (0.0941)  lr: 0.640000  max mem: 6285
2020-07-08 20:42:09,993 maskrcnn_benchmark INFO: eta: 6:26:01  iter: 20800  loss: 3.4986 (3.5378)  auxiliary_ctx: 0.1940 (0.2271)  auxiliary_frq: 0.1768 (0.1801)  auxiliary_vis: 0.1445 (0.1479)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9825 (2.9827)  time: 1.1431 (1.2063)  data: 0.0167 (0.0890)  lr: 0.640000  max mem: 6285
2020-07-08 20:45:58,320 maskrcnn_benchmark INFO: eta: 6:20:38  iter: 21000  loss: 3.4823 (3.5349)  auxiliary_ctx: 0.1810 (0.2244)  auxiliary_frq: 0.1788 (0.1800)  auxiliary_vis: 0.1425 (0.1477)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9820 (2.9827)  time: 1.1292 (1.2020)  data: 0.0193 (0.0845)  lr: 0.640000  max mem: 6285
2020-07-08 20:49:46,917 maskrcnn_benchmark INFO: eta: 6:15:28  iter: 21200  loss: 3.4694 (3.5318)  auxiliary_ctx: 0.1755 (0.2217)  auxiliary_frq: 0.1736 (0.1799)  auxiliary_vis: 0.1377 (0.1476)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9814 (2.9826)  time: 1.1372 (1.1983)  data: 0.0214 (0.0808)  lr: 0.640000  max mem: 6285
2020-07-08 20:53:35,592 maskrcnn_benchmark INFO: eta: 6:10:28  iter: 21400  loss: 3.4910 (3.5294)  auxiliary_ctx: 0.1747 (0.2191)  auxiliary_frq: 0.1790 (0.1799)  auxiliary_vis: 0.1529 (0.1477)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9834 (2.9826)  time: 1.1335 (1.1951)  data: 0.0259 (0.0775)  lr: 0.640000  max mem: 6285
2020-07-08 20:57:23,874 maskrcnn_benchmark INFO: eta: 6:05:34  iter: 21600  loss: 3.4732 (3.5263)  auxiliary_ctx: 0.1641 (0.2162)  auxiliary_frq: 0.1789 (0.1799)  auxiliary_vis: 0.1487 (0.1476)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9824 (2.9826)  time: 1.1397 (1.1921)  data: 0.0267 (0.0745)  lr: 0.640000  max mem: 6285
2020-07-08 21:01:12,196 maskrcnn_benchmark INFO: eta: 6:00:48  iter: 21800  loss: 3.4526 (3.5230)  auxiliary_ctx: 0.1560 (0.2134)  auxiliary_frq: 0.1720 (0.1797)  auxiliary_vis: 0.1411 (0.1474)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9811 (2.9826)  time: 1.1301 (1.1895)  data: 0.0167 (0.0719)  lr: 0.640000  max mem: 6285
2020-07-08 21:05:00,567 maskrcnn_benchmark INFO: eta: 5:56:07  iter: 22000  loss: 3.4454 (3.5205)  auxiliary_ctx: 0.1520 (0.2108)  auxiliary_frq: 0.1737 (0.1796)  auxiliary_vis: 0.1373 (0.1474)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9813 (2.9826)  time: 1.1450 (1.1871)  data: 0.0179 (0.0694)  lr: 0.640000  max mem: 6285
2020-07-08 21:05:00,570 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0022000.pth
2020-07-08 21:05:02,862 maskrcnn_benchmark INFO: Start validating
2020-07-08 21:05:02,901 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 21:06:33,414 maskrcnn_benchmark INFO: Total run time: 0:01:30.512618 (0.14482018852233886 s / img per device, on 8 devices)
2020-07-08 21:06:33,415 maskrcnn_benchmark INFO: Model inference time: 0:01:10.592328 (0.11294772415161133 s / img per device, on 8 devices)
2020-07-08 21:08:04,936 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2193;   R @ 50: 0.2701;   R @ 100: 0.2922;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3001; ngR @ 50: 0.4199; ngR @ 100: 0.5020;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1007;  zR @ 50: 0.1474;  zR @ 100: 0.1741;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0913;  mR @ 50: 0.1167;  mR @ 100: 0.1290;  for mode=predcls, type=Mean Recall.
(above:0.3689) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0709) (attached to:0.0394) (behind:0.1333) (belonging to:0.0000) (between:0.0000) (carrying:0.5570) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0404) (has:0.4056) (holding:0.2360) (in:0.1960) (in front of:0.0437) (laying on:0.0476) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0725) (of:0.7856) (on:0.2205) (on back of:0.0000) (over:0.0366) (painted on:0.0000) (parked on:0.0159) (part of:0.0000) (playing:0.0000) (riding:0.3869) (says:0.0000) (sitting on:0.2635) (standing on:0.1330) (to:0.0000) (under:0.0612) (using:0.0769) (walking in:0.0000) (walking on:0.4839) (watching:0.3137) (wearing:0.9384) (wears:0.0000) (with:0.3154) 
SGG eval:   A @ 20: 0.3002;   A @ 50: 0.3027;   A @ 100: 0.3027;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 21:08:05,704 maskrcnn_benchmark INFO: Validation Result: 0.2922
2020-07-08 21:11:53,726 maskrcnn_benchmark INFO: eta: 6:04:34  iter: 22200  loss: 3.4556 (3.5176)  auxiliary_ctx: 0.1535 (0.2084)  auxiliary_frq: 0.1776 (0.1795)  auxiliary_vis: 0.1449 (0.1472)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9814 (2.9825)  time: 1.1297 (1.2289)  data: 0.0190 (0.1113)  lr: 0.640000  max mem: 6313
2020-07-08 21:15:42,457 maskrcnn_benchmark INFO: eta: 5:59:20  iter: 22400  loss: 3.4664 (3.5153)  auxiliary_ctx: 0.1599 (0.2062)  auxiliary_frq: 0.1789 (0.1794)  auxiliary_vis: 0.1474 (0.1472)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9814 (2.9825)  time: 1.1336 (1.2250)  data: 0.0264 (0.1073)  lr: 0.640000  max mem: 6313
2020-07-08 21:19:30,541 maskrcnn_benchmark INFO: eta: 5:54:11  iter: 22600  loss: 3.4655 (3.5133)  auxiliary_ctx: 0.1580 (0.2042)  auxiliary_frq: 0.1773 (0.1794)  auxiliary_vis: 0.1469 (0.1472)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9818 (2.9825)  time: 1.1320 (1.2214)  data: 0.0251 (0.1036)  lr: 0.640000  max mem: 6313
2020-07-08 21:23:19,276 maskrcnn_benchmark INFO: eta: 5:49:11  iter: 22800  loss: 3.4387 (3.5110)  auxiliary_ctx: 0.1540 (0.2022)  auxiliary_frq: 0.1684 (0.1792)  auxiliary_vis: 0.1361 (0.1471)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9809 (2.9825)  time: 1.1429 (1.2181)  data: 0.0247 (0.1003)  lr: 0.640000  max mem: 6313
2020-07-08 21:27:07,456 maskrcnn_benchmark INFO: eta: 5:44:15  iter: 23000  loss: 3.4673 (3.5091)  auxiliary_ctx: 0.1595 (0.2004)  auxiliary_frq: 0.1754 (0.1792)  auxiliary_vis: 0.1458 (0.1471)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9822 (2.9824)  time: 1.1378 (1.2150)  data: 0.0253 (0.0972)  lr: 0.640000  max mem: 6313
2020-07-08 21:30:56,402 maskrcnn_benchmark INFO: eta: 5:39:27  iter: 23200  loss: 3.4646 (3.5073)  auxiliary_ctx: 0.1528 (0.1987)  auxiliary_frq: 0.1796 (0.1791)  auxiliary_vis: 0.1464 (0.1470)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9818 (2.9824)  time: 1.1511 (1.2123)  data: 0.0253 (0.0944)  lr: 0.640000  max mem: 6313
2020-07-08 21:34:44,849 maskrcnn_benchmark INFO: eta: 5:34:41  iter: 23400  loss: 3.4409 (3.5055)  auxiliary_ctx: 0.1482 (0.1971)  auxiliary_frq: 0.1716 (0.1790)  auxiliary_vis: 0.1404 (0.1470)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9816 (2.9824)  time: 1.1389 (1.2097)  data: 0.0202 (0.0917)  lr: 0.640000  max mem: 6313
2020-07-08 21:38:32,794 maskrcnn_benchmark INFO: eta: 5:29:58  iter: 23600  loss: 3.4560 (3.5038)  auxiliary_ctx: 0.1541 (0.1956)  auxiliary_frq: 0.1770 (0.1789)  auxiliary_vis: 0.1473 (0.1469)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9809 (2.9824)  time: 1.1435 (1.2072)  data: 0.0261 (0.0894)  lr: 0.640000  max mem: 6313
2020-07-08 21:42:21,967 maskrcnn_benchmark INFO: eta: 5:25:22  iter: 23800  loss: 3.4347 (3.5023)  auxiliary_ctx: 0.1482 (0.1942)  auxiliary_frq: 0.1745 (0.1789)  auxiliary_vis: 0.1385 (0.1468)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9810 (2.9824)  time: 1.1421 (1.2051)  data: 0.0251 (0.0871)  lr: 0.640000  max mem: 6313
2020-07-08 21:46:10,755 maskrcnn_benchmark INFO: ---Total norm 0.13206 clip coef 37.85999-----------------
2020-07-08 21:46:10,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.09295, (torch.Size([4096, 12544]))
2020-07-08 21:46:10,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.04476, (torch.Size([256, 1024, 3, 3]))
2020-07-08 21:46:10,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.03774, (torch.Size([51, 4096]))
2020-07-08 21:46:10,765 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.03626, (torch.Size([4096, 12544]))
2020-07-08 21:46:10,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03217, (torch.Size([4096, 4096]))
2020-07-08 21:46:10,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.02136, (torch.Size([51, 4096]))
2020-07-08 21:46:10,765 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.02115, (torch.Size([4096, 4096]))
2020-07-08 21:46:10,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01687, (torch.Size([512, 32]))
2020-07-08 21:46:10,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01529, (torch.Size([256, 128, 3, 3]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.01489, (torch.Size([4096, 1024]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01386, (torch.Size([2048, 4808]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01380, (torch.Size([512, 1024]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01375, (torch.Size([2048, 4808]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01237, (torch.Size([128, 2, 7, 7]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01214, (torch.Size([1024, 512]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.00904, (torch.Size([4096, 512]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00842, (torch.Size([512]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00792, (torch.Size([151, 200]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00649, (torch.Size([1024]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00600, (torch.Size([4096]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00513, (torch.Size([51]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00452, (torch.Size([4096]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00444, (torch.Size([128]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00435, (torch.Size([512]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00409, (torch.Size([2048]))
2020-07-08 21:46:10,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00409, (torch.Size([2048]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00406, (torch.Size([2048]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00406, (torch.Size([2048]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00324, (torch.Size([2048, 512]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00313, (torch.Size([2048, 512]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00292, (torch.Size([22801, 51]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00247, (torch.Size([256]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00236, (torch.Size([256]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00232, (torch.Size([51]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00218, (torch.Size([128]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00196, (torch.Size([128]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00172, (torch.Size([256]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00170, (torch.Size([4096]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00095, (torch.Size([4096]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00090, (torch.Size([4096]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00052, (torch.Size([512]))
2020-07-08 21:46:10,767 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00043, (torch.Size([256]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00035, (torch.Size([512, 1024]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00021, (torch.Size([4096]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00003, (torch.Size([2048, 4424]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00003, (torch.Size([2048, 4424]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00001, (torch.Size([2048]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00001, (torch.Size([2048]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00001, (torch.Size([2048]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00001, (torch.Size([2048]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-08 21:46:10,768 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 21:46:10,771 maskrcnn_benchmark INFO: eta: 5:20:49  iter: 24000  loss: 3.4481 (3.5008)  auxiliary_ctx: 0.1449 (0.1929)  auxiliary_frq: 0.1737 (0.1788)  auxiliary_vis: 0.1455 (0.1468)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9814 (2.9823)  time: 1.1388 (1.2031)  data: 0.0263 (0.0850)  lr: 0.640000  max mem: 6313
2020-07-08 21:46:10,774 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0024000.pth
2020-07-08 21:46:12,910 maskrcnn_benchmark INFO: Start validating
2020-07-08 21:46:12,958 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 21:47:43,552 maskrcnn_benchmark INFO: Total run time: 0:01:30.594103 (0.1449505641937256 s / img per device, on 8 devices)
2020-07-08 21:47:43,553 maskrcnn_benchmark INFO: Model inference time: 0:01:10.327501 (0.11252400169372559 s / img per device, on 8 devices)
2020-07-08 21:49:16,856 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2401;   R @ 50: 0.2977;   R @ 100: 0.3165;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3465; ngR @ 50: 0.5107; ngR @ 100: 0.6183;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1119;  zR @ 50: 0.1585;  zR @ 100: 0.1837;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1201;  mR @ 50: 0.1470;  mR @ 100: 0.1600;  for mode=predcls, type=Mean Recall.
(above:0.2891) (across:0.0000) (against:0.0000) (along:0.0833) (and:0.0000) (at:0.3261) (attached to:0.0642) (behind:0.3536) (belonging to:0.0071) (between:0.0000) (carrying:0.2763) (covered in:0.0714) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0441) (has:0.3411) (holding:0.4076) (in:0.2261) (in front of:0.2183) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1974) (of:0.4956) (on:0.2664) (on back of:0.0000) (over:0.0488) (painted on:0.0000) (parked on:0.3344) (part of:0.0000) (playing:0.0000) (riding:0.8586) (says:0.0000) (sitting on:0.5053) (standing on:0.1297) (to:0.0000) (under:0.1020) (using:0.0192) (walking in:0.0000) (walking on:0.5293) (watching:0.2647) (wearing:0.8715) (wears:0.1200) (with:0.3709) 
SGG eval:   A @ 20: 0.3088;   A @ 50: 0.3119;   A @ 100: 0.3119;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 21:49:17,627 maskrcnn_benchmark INFO: Validation Result: 0.3165
2020-07-08 21:53:05,938 maskrcnn_benchmark INFO: eta: 5:24:13  iter: 24200  loss: 3.4710 (3.4994)  auxiliary_ctx: 0.1545 (0.1916)  auxiliary_frq: 0.1768 (0.1788)  auxiliary_vis: 0.1510 (0.1468)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9821 (2.9823)  time: 1.1354 (1.2312)  data: 0.0252 (0.1132)  lr: 0.640000  max mem: 6313
2020-07-08 21:56:53,867 maskrcnn_benchmark INFO: eta: 5:19:22  iter: 24400  loss: 3.4402 (3.4981)  auxiliary_ctx: 0.1457 (0.1904)  auxiliary_frq: 0.1733 (0.1787)  auxiliary_vis: 0.1395 (0.1467)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9813 (2.9823)  time: 1.1392 (1.2284)  data: 0.0179 (0.1104)  lr: 0.640000  max mem: 6313
2020-07-08 22:00:42,311 maskrcnn_benchmark INFO: eta: 5:14:36  iter: 24600  loss: 3.4607 (3.4968)  auxiliary_ctx: 0.1552 (0.1892)  auxiliary_frq: 0.1756 (0.1787)  auxiliary_vis: 0.1453 (0.1467)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9816 (2.9823)  time: 1.1326 (1.2258)  data: 0.0252 (0.1078)  lr: 0.640000  max mem: 6557
2020-07-08 22:04:30,603 maskrcnn_benchmark INFO: eta: 5:09:53  iter: 24800  loss: 3.4637 (3.4954)  auxiliary_ctx: 0.1535 (0.1880)  auxiliary_frq: 0.1787 (0.1786)  auxiliary_vis: 0.1473 (0.1466)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9816 (2.9823)  time: 1.1281 (1.2233)  data: 0.0254 (0.1053)  lr: 0.640000  max mem: 6557
2020-07-08 22:08:19,340 maskrcnn_benchmark INFO: eta: 5:05:15  iter: 25000  loss: 3.4506 (3.4942)  auxiliary_ctx: 0.1504 (0.1869)  auxiliary_frq: 0.1763 (0.1785)  auxiliary_vis: 0.1420 (0.1465)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9813 (2.9822)  time: 1.1393 (1.2210)  data: 0.0260 (0.1029)  lr: 0.640000  max mem: 6557
2020-07-08 22:12:08,007 maskrcnn_benchmark INFO: eta: 5:00:39  iter: 25200  loss: 3.4258 (3.4930)  auxiliary_ctx: 0.1406 (0.1859)  auxiliary_frq: 0.1678 (0.1784)  auxiliary_vis: 0.1374 (0.1465)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9806 (2.9822)  time: 1.1363 (1.2189)  data: 0.0255 (0.1007)  lr: 0.640000  max mem: 6557
2020-07-08 22:15:56,136 maskrcnn_benchmark INFO: eta: 4:56:04  iter: 25400  loss: 3.4363 (3.4917)  auxiliary_ctx: 0.1434 (0.1849)  auxiliary_frq: 0.1716 (0.1783)  auxiliary_vis: 0.1394 (0.1463)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9806 (2.9822)  time: 1.1392 (1.2167)  data: 0.0257 (0.0987)  lr: 0.640000  max mem: 6557
2020-07-08 22:19:44,826 maskrcnn_benchmark INFO: eta: 4:51:33  iter: 25600  loss: 3.4408 (3.4907)  auxiliary_ctx: 0.1484 (0.1840)  auxiliary_frq: 0.1710 (0.1783)  auxiliary_vis: 0.1388 (0.1463)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9811 (2.9822)  time: 1.1438 (1.2148)  data: 0.0258 (0.0967)  lr: 0.640000  max mem: 6557
2020-07-08 22:23:32,860 maskrcnn_benchmark INFO: eta: 4:47:03  iter: 25800  loss: 3.4273 (3.4897)  auxiliary_ctx: 0.1460 (0.1831)  auxiliary_frq: 0.1708 (0.1782)  auxiliary_vis: 0.1374 (0.1462)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9805 (2.9822)  time: 1.1414 (1.2129)  data: 0.0269 (0.0949)  lr: 0.640000  max mem: 6557
2020-07-08 22:27:21,478 maskrcnn_benchmark INFO: eta: 4:42:36  iter: 26000  loss: 3.4435 (3.4888)  auxiliary_ctx: 0.1490 (0.1823)  auxiliary_frq: 0.1742 (0.1781)  auxiliary_vis: 0.1446 (0.1462)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9817 (2.9821)  time: 1.1373 (1.2112)  data: 0.0258 (0.0932)  lr: 0.640000  max mem: 6557
2020-07-08 22:27:21,481 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0026000.pth
2020-07-08 22:27:23,721 maskrcnn_benchmark INFO: Start validating
2020-07-08 22:27:23,755 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 22:28:54,908 maskrcnn_benchmark INFO: Total run time: 0:01:31.152730 (0.14584436798095704 s / img per device, on 8 devices)
2020-07-08 22:28:54,909 maskrcnn_benchmark INFO: Model inference time: 0:01:10.687126 (0.11309940185546875 s / img per device, on 8 devices)
2020-07-08 22:30:31,917 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2742;   R @ 50: 0.3391;   R @ 100: 0.3611;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3891; ngR @ 50: 0.5852; ngR @ 100: 0.6958;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0985;  zR @ 50: 0.1496;  zR @ 100: 0.1896;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1192;  mR @ 50: 0.1446;  mR @ 100: 0.1585;  for mode=predcls, type=Mean Recall.
(above:0.4289) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0323) (at:0.2948) (attached to:0.0046) (behind:0.3018) (belonging to:0.0000) (between:0.0000) (carrying:0.5219) (covered in:0.0714) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0294) (has:0.2803) (holding:0.3278) (in:0.2307) (in front of:0.1880) (laying on:0.0000) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2620) (of:0.4158) (on:0.3795) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.4170) (part of:0.0000) (playing:0.0000) (riding:0.8438) (says:0.0000) (sitting on:0.3341) (standing on:0.1438) (to:0.0000) (under:0.1403) (using:0.0000) (walking in:0.0385) (walking on:0.4864) (watching:0.3824) (wearing:0.9328) (wears:0.0000) (with:0.3453) 
SGG eval:   A @ 20: 0.3595;   A @ 50: 0.3623;   A @ 100: 0.3623;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 22:30:32,683 maskrcnn_benchmark INFO: Validation Result: 0.3611
2020-07-08 22:34:20,783 maskrcnn_benchmark INFO: eta: 4:43:31  iter: 26200  loss: 3.4344 (3.4878)  auxiliary_ctx: 0.1419 (0.1815)  auxiliary_frq: 0.1717 (0.1781)  auxiliary_vis: 0.1383 (0.1461)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9807 (2.9821)  time: 1.1398 (1.2327)  data: 0.0255 (0.1148)  lr: 0.640000  max mem: 6557
2020-07-08 22:38:08,831 maskrcnn_benchmark INFO: eta: 4:38:55  iter: 26400  loss: 3.4645 (3.4867)  auxiliary_ctx: 0.1540 (0.1806)  auxiliary_frq: 0.1797 (0.1780)  auxiliary_vis: 0.1457 (0.1460)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9815 (2.9821)  time: 1.1411 (1.2305)  data: 0.0252 (0.1126)  lr: 0.640000  max mem: 6557
2020-07-08 22:41:57,545 maskrcnn_benchmark INFO: eta: 4:34:22  iter: 26600  loss: 3.4637 (3.4858)  auxiliary_ctx: 0.1533 (0.1799)  auxiliary_frq: 0.1782 (0.1779)  auxiliary_vis: 0.1486 (0.1460)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9818 (2.9821)  time: 1.1341 (1.2285)  data: 0.0266 (0.1106)  lr: 0.640000  max mem: 6557
2020-07-08 22:45:45,625 maskrcnn_benchmark INFO: eta: 4:29:50  iter: 26800  loss: 3.4479 (3.4850)  auxiliary_ctx: 0.1481 (0.1792)  auxiliary_frq: 0.1734 (0.1779)  auxiliary_vis: 0.1456 (0.1459)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9817 (2.9821)  time: 1.1337 (1.2265)  data: 0.0259 (0.1087)  lr: 0.640000  max mem: 6557
2020-07-08 22:49:33,804 maskrcnn_benchmark INFO: eta: 4:25:20  iter: 27000  loss: 3.4387 (3.4842)  auxiliary_ctx: 0.1474 (0.1784)  auxiliary_frq: 0.1744 (0.1778)  auxiliary_vis: 0.1413 (0.1459)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9811 (2.9821)  time: 1.1432 (1.2246)  data: 0.0211 (0.1067)  lr: 0.640000  max mem: 6557
2020-07-08 22:53:22,282 maskrcnn_benchmark INFO: eta: 4:20:52  iter: 27200  loss: 3.4369 (3.4834)  auxiliary_ctx: 0.1428 (0.1778)  auxiliary_frq: 0.1741 (0.1777)  auxiliary_vis: 0.1358 (0.1458)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9808 (2.9820)  time: 1.1431 (1.2228)  data: 0.0263 (0.1049)  lr: 0.640000  max mem: 6557
2020-07-08 22:57:11,430 maskrcnn_benchmark INFO: eta: 4:16:26  iter: 27400  loss: 3.4259 (3.4825)  auxiliary_ctx: 0.1416 (0.1771)  auxiliary_frq: 0.1697 (0.1776)  auxiliary_vis: 0.1375 (0.1457)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9806 (2.9820)  time: 1.1435 (1.2212)  data: 0.0170 (0.1032)  lr: 0.640000  max mem: 6557
2020-07-08 23:00:59,500 maskrcnn_benchmark INFO: eta: 4:12:01  iter: 27600  loss: 3.4329 (3.4817)  auxiliary_ctx: 0.1423 (0.1765)  auxiliary_frq: 0.1692 (0.1776)  auxiliary_vis: 0.1382 (0.1457)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9808 (2.9820)  time: 1.1414 (1.2195)  data: 0.0258 (0.1015)  lr: 0.640000  max mem: 6557
2020-07-08 23:04:47,225 maskrcnn_benchmark INFO: eta: 4:07:37  iter: 27800  loss: 3.4586 (3.4810)  auxiliary_ctx: 0.1490 (0.1759)  auxiliary_frq: 0.1779 (0.1775)  auxiliary_vis: 0.1462 (0.1456)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9815 (2.9820)  time: 1.1309 (1.2179)  data: 0.0227 (0.0999)  lr: 0.640000  max mem: 6557
2020-07-08 23:08:35,390 maskrcnn_benchmark INFO: ---Total norm 0.14351 clip coef 34.84010-----------------
2020-07-08 23:08:35,400 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.09627, (torch.Size([4096, 12544]))
2020-07-08 23:08:35,400 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.04440, (torch.Size([256, 1024, 3, 3]))
2020-07-08 23:08:35,400 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.04317, (torch.Size([4096, 12544]))
2020-07-08 23:08:35,400 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.04076, (torch.Size([51, 4096]))
2020-07-08 23:08:35,400 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03825, (torch.Size([4096, 4096]))
2020-07-08 23:08:35,400 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.02926, (torch.Size([51, 4096]))
2020-07-08 23:08:35,400 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.02741, (torch.Size([4096, 4096]))
2020-07-08 23:08:35,400 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01984, (torch.Size([2048, 4808]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.01822, (torch.Size([4096, 1024]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01645, (torch.Size([512, 1024]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01534, (torch.Size([256, 128, 3, 3]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01514, (torch.Size([2048, 4808]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01441, (torch.Size([512]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01332, (torch.Size([1024, 512]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01314, (torch.Size([128, 2, 7, 7]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01112, (torch.Size([512, 32]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00935, (torch.Size([1024]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00790, (torch.Size([151, 200]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.00751, (torch.Size([4096, 512]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00670, (torch.Size([4096]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00655, (torch.Size([2048]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00655, (torch.Size([2048]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00591, (torch.Size([256]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00545, (torch.Size([2048]))
2020-07-08 23:08:35,401 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00545, (torch.Size([2048]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00520, (torch.Size([128]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00486, (torch.Size([4096]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00469, (torch.Size([51]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00469, (torch.Size([2048, 512]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00452, (torch.Size([4096]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00424, (torch.Size([2048, 512]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00351, (torch.Size([51]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00307, (torch.Size([22801, 51]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00304, (torch.Size([512]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00250, (torch.Size([256]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00226, (torch.Size([128]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00219, (torch.Size([256]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00204, (torch.Size([128]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00128, (torch.Size([4096]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00116, (torch.Size([4096]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00049, (torch.Size([256]))
2020-07-08 23:08:35,402 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00026, (torch.Size([4096]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00006, (torch.Size([512]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00004, (torch.Size([512, 1024]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00001, (torch.Size([2048, 4424]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00001, (torch.Size([2048, 4424]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-08 23:08:35,403 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-08 23:08:35,404 maskrcnn_benchmark INFO: -------------------------------
2020-07-08 23:08:35,406 maskrcnn_benchmark INFO: eta: 4:03:15  iter: 28000  loss: 3.4258 (3.4803)  auxiliary_ctx: 0.1421 (0.1753)  auxiliary_frq: 0.1715 (0.1774)  auxiliary_vis: 0.1356 (0.1456)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9807 (2.9820)  time: 1.1389 (1.2163)  data: 0.0237 (0.0984)  lr: 0.640000  max mem: 6557
2020-07-08 23:08:35,409 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0028000.pth
2020-07-08 23:08:37,837 maskrcnn_benchmark INFO: Start validating
2020-07-08 23:08:37,869 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 23:10:08,403 maskrcnn_benchmark INFO: Total run time: 0:01:30.533537 (0.14485365867614747 s / img per device, on 8 devices)
2020-07-08 23:10:08,403 maskrcnn_benchmark INFO: Model inference time: 0:01:10.702492 (0.11312398796081544 s / img per device, on 8 devices)
2020-07-08 23:11:42,535 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2149;   R @ 50: 0.2793;   R @ 100: 0.3047;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3184; ngR @ 50: 0.4955; ngR @ 100: 0.6225;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1222;  zR @ 50: 0.1674;  zR @ 100: 0.1807;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1251;  mR @ 50: 0.1491;  mR @ 100: 0.1601;  for mode=predcls, type=Mean Recall.
(above:0.4226) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0161) (at:0.4704) (attached to:0.0459) (behind:0.3283) (belonging to:0.0000) (between:0.0000) (carrying:0.5461) (covered in:0.0714) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.2739) (holding:0.3321) (in:0.2439) (in front of:0.2838) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2634) (of:0.3868) (on:0.2427) (on back of:0.0000) (over:0.0488) (painted on:0.0000) (parked on:0.3487) (part of:0.0000) (playing:0.0000) (riding:0.8705) (says:0.0000) (sitting on:0.4936) (standing on:0.1906) (to:0.0000) (under:0.0918) (using:0.0000) (walking in:0.0000) (walking on:0.5937) (watching:0.1176) (wearing:0.8227) (wears:0.1247) (with:0.3614) 
SGG eval:   A @ 20: 0.2888;   A @ 50: 0.2916;   A @ 100: 0.2916;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 23:11:43,320 maskrcnn_benchmark INFO: Validation Result: 0.3047
2020-07-08 23:15:31,649 maskrcnn_benchmark INFO: eta: 4:02:32  iter: 28200  loss: 3.4234 (3.4796)  auxiliary_ctx: 0.1379 (0.1747)  auxiliary_frq: 0.1695 (0.1774)  auxiliary_vis: 0.1382 (0.1455)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9810 (2.9820)  time: 1.1451 (1.2333)  data: 0.0260 (0.1153)  lr: 0.640000  max mem: 6557
2020-07-08 23:19:20,429 maskrcnn_benchmark INFO: eta: 3:58:06  iter: 28400  loss: 3.4264 (3.4788)  auxiliary_ctx: 0.1440 (0.1741)  auxiliary_frq: 0.1709 (0.1773)  auxiliary_vis: 0.1370 (0.1454)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9804 (2.9819)  time: 1.1411 (1.2316)  data: 0.0258 (0.1136)  lr: 0.640000  max mem: 6557
2020-07-08 23:23:08,996 maskrcnn_benchmark INFO: eta: 3:53:40  iter: 28600  loss: 3.4323 (3.4782)  auxiliary_ctx: 0.1411 (0.1736)  auxiliary_frq: 0.1710 (0.1773)  auxiliary_vis: 0.1371 (0.1454)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9807 (2.9819)  time: 1.1380 (1.2299)  data: 0.0255 (0.1119)  lr: 0.640000  max mem: 6557
2020-07-08 23:26:57,565 maskrcnn_benchmark INFO: eta: 3:49:16  iter: 28800  loss: 3.4349 (3.4776)  auxiliary_ctx: 0.1448 (0.1731)  auxiliary_frq: 0.1733 (0.1772)  auxiliary_vis: 0.1367 (0.1454)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9806 (2.9819)  time: 1.1383 (1.2283)  data: 0.0249 (0.1103)  lr: 0.640000  max mem: 6557
2020-07-08 23:30:46,128 maskrcnn_benchmark INFO: eta: 3:44:53  iter: 29000  loss: 3.4481 (3.4770)  auxiliary_ctx: 0.1485 (0.1726)  auxiliary_frq: 0.1733 (0.1772)  auxiliary_vis: 0.1456 (0.1453)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9816 (2.9819)  time: 1.1388 (1.2267)  data: 0.0240 (0.1086)  lr: 0.640000  max mem: 6557
2020-07-08 23:34:34,557 maskrcnn_benchmark INFO: eta: 3:40:32  iter: 29200  loss: 3.4513 (3.4764)  auxiliary_ctx: 0.1479 (0.1722)  auxiliary_frq: 0.1775 (0.1771)  auxiliary_vis: 0.1473 (0.1453)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9819 (2.9819)  time: 1.1409 (1.2252)  data: 0.0253 (0.1072)  lr: 0.640000  max mem: 6557
2020-07-08 23:38:22,355 maskrcnn_benchmark INFO: eta: 3:36:11  iter: 29400  loss: 3.4532 (3.4758)  auxiliary_ctx: 0.1502 (0.1717)  auxiliary_frq: 0.1727 (0.1771)  auxiliary_vis: 0.1414 (0.1452)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9808 (2.9819)  time: 1.1376 (1.2237)  data: 0.0222 (0.1057)  lr: 0.640000  max mem: 6557
2020-07-08 23:42:10,563 maskrcnn_benchmark INFO: eta: 3:31:51  iter: 29600  loss: 3.4413 (3.4754)  auxiliary_ctx: 0.1441 (0.1712)  auxiliary_frq: 0.1733 (0.1770)  auxiliary_vis: 0.1436 (0.1452)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9816 (2.9819)  time: 1.1338 (1.2223)  data: 0.0230 (0.1043)  lr: 0.640000  max mem: 6557
2020-07-08 23:45:58,611 maskrcnn_benchmark INFO: eta: 3:27:32  iter: 29800  loss: 3.4386 (3.4748)  auxiliary_ctx: 0.1438 (0.1708)  auxiliary_frq: 0.1754 (0.1770)  auxiliary_vis: 0.1426 (0.1452)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9813 (2.9819)  time: 1.1394 (1.2209)  data: 0.0251 (0.1029)  lr: 0.640000  max mem: 6557
2020-07-08 23:49:46,737 maskrcnn_benchmark INFO: eta: 3:23:15  iter: 30000  loss: 3.4377 (3.4742)  auxiliary_ctx: 0.1435 (0.1703)  auxiliary_frq: 0.1717 (0.1769)  auxiliary_vis: 0.1448 (0.1451)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9810 (2.9818)  time: 1.1365 (1.2195)  data: 0.0212 (0.1016)  lr: 0.640000  max mem: 6557
2020-07-08 23:49:46,740 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0030000.pth
2020-07-08 23:49:48,987 maskrcnn_benchmark INFO: Start validating
2020-07-08 23:49:49,026 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-08 23:51:19,818 maskrcnn_benchmark INFO: Total run time: 0:01:30.791398 (0.14526623611450196 s / img per device, on 8 devices)
2020-07-08 23:51:19,818 maskrcnn_benchmark INFO: Model inference time: 0:01:09.901283 (0.11184205322265625 s / img per device, on 8 devices)
2020-07-08 23:52:55,556 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2507;   R @ 50: 0.3170;   R @ 100: 0.3397;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3451; ngR @ 50: 0.5249; ngR @ 100: 0.6407;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1170;  zR @ 50: 0.1607;  zR @ 100: 0.1756;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1278;  mR @ 50: 0.1527;  mR @ 100: 0.1641;  for mode=predcls, type=Mean Recall.
(above:0.4284) (across:0.0556) (against:0.0000) (along:0.0000) (and:0.0323) (at:0.4266) (attached to:0.0564) (behind:0.4005) (belonging to:0.0071) (between:0.0000) (carrying:0.6491) (covered in:0.1071) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0257) (has:0.3894) (holding:0.4261) (in:0.3305) (in front of:0.1493) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3853) (of:0.4352) (on:0.2525) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.2140) (part of:0.0000) (playing:0.0000) (riding:0.7812) (says:0.0000) (sitting on:0.3526) (standing on:0.0870) (to:0.0000) (under:0.1633) (using:0.0000) (walking in:0.0000) (walking on:0.6192) (watching:0.0000) (wearing:0.9476) (wears:0.0000) (with:0.3146) 
SGG eval:   A @ 20: 0.3394;   A @ 50: 0.3425;   A @ 100: 0.3425;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-08 23:52:56,175 maskrcnn_benchmark INFO: Validation Result: 0.3397
2020-07-08 23:52:56,176 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-07-08 23:56:43,845 maskrcnn_benchmark INFO: eta: 3:21:30  iter: 30200  loss: 3.4300 (3.4735)  auxiliary_ctx: 0.1378 (0.1698)  auxiliary_frq: 0.1768 (0.1768)  auxiliary_vis: 0.1345 (0.1450)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9805 (2.9818)  time: 1.1337 (1.2337)  data: 0.0188 (0.1158)  lr: 0.064000  max mem: 6557
2020-07-09 00:00:32,285 maskrcnn_benchmark INFO: eta: 3:17:09  iter: 30400  loss: 3.3956 (3.4726)  auxiliary_ctx: 0.1287 (0.1693)  auxiliary_frq: 0.1648 (0.1768)  auxiliary_vis: 0.1222 (0.1447)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9788 (2.9818)  time: 1.1351 (1.2323)  data: 0.0219 (0.1143)  lr: 0.064000  max mem: 6557
2020-07-09 00:04:20,825 maskrcnn_benchmark INFO: eta: 3:12:49  iter: 30600  loss: 3.4235 (3.4718)  auxiliary_ctx: 0.1376 (0.1688)  auxiliary_frq: 0.1752 (0.1767)  auxiliary_vis: 0.1268 (0.1445)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9797 (2.9818)  time: 1.1462 (1.2308)  data: 0.0263 (0.1129)  lr: 0.064000  max mem: 6557
2020-07-09 00:08:08,974 maskrcnn_benchmark INFO: eta: 3:08:30  iter: 30800  loss: 3.4049 (3.4710)  auxiliary_ctx: 0.1340 (0.1684)  auxiliary_frq: 0.1722 (0.1767)  auxiliary_vis: 0.1227 (0.1442)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9799 (2.9817)  time: 1.1365 (1.2294)  data: 0.0261 (0.1115)  lr: 0.064000  max mem: 6557
2020-07-09 00:11:57,812 maskrcnn_benchmark INFO: eta: 3:04:13  iter: 31000  loss: 3.3939 (3.4701)  auxiliary_ctx: 0.1340 (0.1679)  auxiliary_frq: 0.1677 (0.1766)  auxiliary_vis: 0.1230 (0.1439)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9789 (2.9817)  time: 1.1451 (1.2281)  data: 0.0247 (0.1101)  lr: 0.064000  max mem: 6557
2020-07-09 00:15:46,372 maskrcnn_benchmark INFO: eta: 2:59:56  iter: 31200  loss: 3.3947 (3.4692)  auxiliary_ctx: 0.1298 (0.1674)  auxiliary_frq: 0.1692 (0.1766)  auxiliary_vis: 0.1176 (0.1436)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9782 (2.9817)  time: 1.1407 (1.2268)  data: 0.0249 (0.1088)  lr: 0.064000  max mem: 6557
2020-07-09 00:19:34,885 maskrcnn_benchmark INFO: eta: 2:55:39  iter: 31400  loss: 3.4181 (3.4683)  auxiliary_ctx: 0.1390 (0.1669)  auxiliary_frq: 0.1774 (0.1765)  auxiliary_vis: 0.1240 (0.1432)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9792 (2.9816)  time: 1.1325 (1.2256)  data: 0.0250 (0.1076)  lr: 0.064000  max mem: 6557
2020-07-09 00:23:23,386 maskrcnn_benchmark INFO: eta: 2:51:24  iter: 31600  loss: 3.3911 (3.4674)  auxiliary_ctx: 0.1312 (0.1664)  auxiliary_frq: 0.1728 (0.1765)  auxiliary_vis: 0.1124 (0.1429)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9780 (2.9816)  time: 1.1366 (1.2243)  data: 0.0248 (0.1063)  lr: 0.064000  max mem: 6557
2020-07-09 00:27:11,601 maskrcnn_benchmark INFO: eta: 2:47:09  iter: 31800  loss: 3.3914 (3.4664)  auxiliary_ctx: 0.1298 (0.1660)  auxiliary_frq: 0.1662 (0.1764)  auxiliary_vis: 0.1116 (0.1425)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9777 (2.9815)  time: 1.1359 (1.2231)  data: 0.0238 (0.1051)  lr: 0.064000  max mem: 6557
2020-07-09 00:31:00,138 maskrcnn_benchmark INFO: ---Total norm 0.28288 clip coef 17.67512-----------------
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.22944, (torch.Size([4096, 12544]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.08807, (torch.Size([4096, 12544]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.07780, (torch.Size([256, 1024, 3, 3]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06264, (torch.Size([4096, 4096]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.04777, (torch.Size([4096, 4096]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.03725, (torch.Size([51, 4096]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03660, (torch.Size([51, 4096]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02746, (torch.Size([256, 128, 3, 3]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.02611, (torch.Size([4096, 1024]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02588, (torch.Size([512, 32]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02076, (torch.Size([128, 2, 7, 7]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01998, (torch.Size([2048, 4808]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01980, (torch.Size([2048, 4808]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01559, (torch.Size([4096, 512]))
2020-07-09 00:31:00,148 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01441, (torch.Size([1024, 512]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01380, (torch.Size([512, 1024]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01196, (torch.Size([151, 200]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00875, (torch.Size([128]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00851, (torch.Size([512]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00655, (torch.Size([4096]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00582, (torch.Size([512]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00572, (torch.Size([4096]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00492, (torch.Size([1024]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00465, (torch.Size([2048]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00465, (torch.Size([2048]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00455, (torch.Size([2048, 512]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00443, (torch.Size([256]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00441, (torch.Size([2048]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00441, (torch.Size([2048]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00419, (torch.Size([51]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00412, (torch.Size([2048, 512]))
2020-07-09 00:31:00,149 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00408, (torch.Size([22801, 51]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00374, (torch.Size([128]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00373, (torch.Size([51]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00356, (torch.Size([256]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00333, (torch.Size([4096]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00229, (torch.Size([256]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00216, (torch.Size([4096]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00199, (torch.Size([4096]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00161, (torch.Size([128]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00069, (torch.Size([256]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00047, (torch.Size([4096]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00008, (torch.Size([512]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00006, (torch.Size([512, 1024]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-07-09 00:31:00,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-09 00:31:00,151 maskrcnn_benchmark INFO: -------------------------------
2020-07-09 00:31:00,154 maskrcnn_benchmark INFO: eta: 2:42:55  iter: 32000  loss: 3.4033 (3.4655)  auxiliary_ctx: 0.1356 (0.1656)  auxiliary_frq: 0.1736 (0.1764)  auxiliary_vis: 0.1161 (0.1421)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9780 (2.9815)  time: 1.1362 (1.2220)  data: 0.0185 (0.1039)  lr: 0.064000  max mem: 6557
2020-07-09 00:31:00,156 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0032000.pth
2020-07-09 00:31:02,382 maskrcnn_benchmark INFO: Start validating
2020-07-09 00:31:02,418 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-09 00:32:32,424 maskrcnn_benchmark INFO: Total run time: 0:01:30.006244 (0.1440099910736084 s / img per device, on 8 devices)
2020-07-09 00:32:32,425 maskrcnn_benchmark INFO: Model inference time: 0:01:10.880240 (0.11340838394165038 s / img per device, on 8 devices)
2020-07-09 00:34:07,768 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2786;   R @ 50: 0.3461;   R @ 100: 0.3657;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3833; ngR @ 50: 0.5599; ngR @ 100: 0.6517;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1407;  zR @ 50: 0.1896;  zR @ 100: 0.1963;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1447;  mR @ 50: 0.1699;  mR @ 100: 0.1789;  for mode=predcls, type=Mean Recall.
(above:0.3417) (across:0.0556) (against:0.0000) (along:0.0000) (and:0.0323) (at:0.4332) (attached to:0.0573) (behind:0.2903) (belonging to:0.0000) (between:0.0000) (carrying:0.5329) (covered in:0.1071) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.3844) (holding:0.4077) (in:0.2848) (in front of:0.2381) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3394) (of:0.3807) (on:0.3239) (on back of:0.0227) (over:0.0732) (painted on:0.0000) (parked on:0.5941) (part of:0.0000) (playing:0.0000) (riding:0.8705) (says:0.0000) (sitting on:0.3771) (standing on:0.1743) (to:0.0000) (under:0.1352) (using:0.0000) (walking in:0.0000) (walking on:0.7504) (watching:0.2941) (wearing:0.9259) (wears:0.0000) (with:0.3244) 
SGG eval:   A @ 20: 0.3628;   A @ 50: 0.3658;   A @ 100: 0.3658;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-09 00:34:08,529 maskrcnn_benchmark INFO: Validation Result: 0.3657
2020-07-09 00:37:56,291 maskrcnn_benchmark INFO: eta: 2:40:25  iter: 32200  loss: 3.3858 (3.4646)  auxiliary_ctx: 0.1337 (0.1651)  auxiliary_frq: 0.1668 (0.1763)  auxiliary_vis: 0.1082 (0.1417)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9776 (2.9814)  time: 1.1394 (1.2341)  data: 0.0255 (0.1160)  lr: 0.064000  max mem: 6557
2020-07-09 00:41:44,978 maskrcnn_benchmark INFO: eta: 2:36:09  iter: 32400  loss: 3.3922 (3.4636)  auxiliary_ctx: 0.1314 (0.1647)  auxiliary_frq: 0.1713 (0.1763)  auxiliary_vis: 0.1121 (0.1413)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9777 (2.9814)  time: 1.1420 (1.2328)  data: 0.0259 (0.1148)  lr: 0.064000  max mem: 6557
2020-07-09 00:45:33,763 maskrcnn_benchmark INFO: eta: 2:31:53  iter: 32600  loss: 3.3841 (3.4627)  auxiliary_ctx: 0.1311 (0.1642)  auxiliary_frq: 0.1709 (0.1762)  auxiliary_vis: 0.1050 (0.1409)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9770 (2.9813)  time: 1.1366 (1.2316)  data: 0.0212 (0.1135)  lr: 0.064000  max mem: 6557
2020-07-09 00:49:22,491 maskrcnn_benchmark INFO: eta: 2:27:39  iter: 32800  loss: 3.3881 (3.4617)  auxiliary_ctx: 0.1337 (0.1638)  auxiliary_frq: 0.1732 (0.1762)  auxiliary_vis: 0.1068 (0.1404)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9779 (2.9813)  time: 1.1378 (1.2304)  data: 0.0258 (0.1123)  lr: 0.064000  max mem: 6557
2020-07-09 00:53:10,773 maskrcnn_benchmark INFO: eta: 2:23:24  iter: 33000  loss: 3.3886 (3.4608)  auxiliary_ctx: 0.1336 (0.1634)  auxiliary_frq: 0.1710 (0.1761)  auxiliary_vis: 0.1079 (0.1400)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9776 (2.9813)  time: 1.1360 (1.2292)  data: 0.0249 (0.1111)  lr: 0.064000  max mem: 6557
2020-07-09 00:56:59,119 maskrcnn_benchmark INFO: eta: 2:19:10  iter: 33200  loss: 3.3889 (3.4599)  auxiliary_ctx: 0.1344 (0.1630)  auxiliary_frq: 0.1726 (0.1761)  auxiliary_vis: 0.1072 (0.1396)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9769 (2.9812)  time: 1.1433 (1.2281)  data: 0.0257 (0.1100)  lr: 0.064000  max mem: 6557
2020-07-09 01:00:47,405 maskrcnn_benchmark INFO: eta: 2:14:57  iter: 33400  loss: 3.3652 (3.4590)  auxiliary_ctx: 0.1267 (0.1626)  auxiliary_frq: 0.1652 (0.1760)  auxiliary_vis: 0.0929 (0.1391)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9761 (2.9812)  time: 1.1341 (1.2270)  data: 0.0250 (0.1089)  lr: 0.064000  max mem: 6557
2020-07-09 01:04:36,131 maskrcnn_benchmark INFO: eta: 2:10:45  iter: 33600  loss: 3.3877 (3.4580)  auxiliary_ctx: 0.1343 (0.1622)  auxiliary_frq: 0.1734 (0.1760)  auxiliary_vis: 0.1041 (0.1386)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9771 (2.9811)  time: 1.1375 (1.2259)  data: 0.0213 (0.1078)  lr: 0.064000  max mem: 6557
2020-07-09 01:08:24,882 maskrcnn_benchmark INFO: eta: 2:06:34  iter: 33800  loss: 3.3665 (3.4570)  auxiliary_ctx: 0.1279 (0.1618)  auxiliary_frq: 0.1700 (0.1759)  auxiliary_vis: 0.0995 (0.1381)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9760 (2.9810)  time: 1.1469 (1.2248)  data: 0.0254 (0.1067)  lr: 0.064000  max mem: 6557
2020-07-09 01:12:13,359 maskrcnn_benchmark INFO: eta: 2:02:22  iter: 34000  loss: 3.3647 (3.4560)  auxiliary_ctx: 0.1257 (0.1615)  auxiliary_frq: 0.1682 (0.1759)  auxiliary_vis: 0.0934 (0.1377)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9761 (2.9810)  time: 1.1424 (1.2238)  data: 0.0255 (0.1057)  lr: 0.064000  max mem: 6557
2020-07-09 01:12:13,362 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0034000.pth
2020-07-09 01:12:15,599 maskrcnn_benchmark INFO: Start validating
2020-07-09 01:12:15,627 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-09 01:13:45,681 maskrcnn_benchmark INFO: Total run time: 0:01:30.054116 (0.14408658561706544 s / img per device, on 8 devices)
2020-07-09 01:13:45,682 maskrcnn_benchmark INFO: Model inference time: 0:01:09.813833 (0.11170213279724121 s / img per device, on 8 devices)
2020-07-09 01:15:22,426 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2864;   R @ 50: 0.3577;   R @ 100: 0.3807;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3801; ngR @ 50: 0.5386; ngR @ 100: 0.6198;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1430;  zR @ 50: 0.1852;  zR @ 100: 0.1896;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1368;  mR @ 50: 0.1632;  mR @ 100: 0.1772;  for mode=predcls, type=Mean Recall.
(above:0.3097) (across:0.0000) (against:0.0000) (along:0.0385) (and:0.1129) (at:0.4430) (attached to:0.0655) (behind:0.2679) (belonging to:0.0000) (between:0.0000) (carrying:0.5329) (covered in:0.0714) (covering:0.0286) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0667) (hanging from:0.0368) (has:0.3655) (holding:0.3647) (in:0.3130) (in front of:0.2523) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2873) (of:0.3637) (on:0.3613) (on back of:0.0682) (over:0.0366) (painted on:0.0000) (parked on:0.5199) (part of:0.0000) (playing:0.0000) (riding:0.7902) (says:0.0000) (sitting on:0.4047) (standing on:0.1522) (to:0.0000) (under:0.1777) (using:0.0000) (walking in:0.0000) (walking on:0.6760) (watching:0.3529) (wearing:0.9235) (wears:0.0000) (with:0.3350) 
SGG eval:   A @ 20: 0.3800;   A @ 50: 0.3829;   A @ 100: 0.3829;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-09 01:15:23,189 maskrcnn_benchmark INFO: Validation Result: 0.3807
2020-07-09 01:19:11,583 maskrcnn_benchmark INFO: eta: 1:59:20  iter: 34200  loss: 3.3858 (3.4551)  auxiliary_ctx: 0.1313 (0.1611)  auxiliary_frq: 0.1785 (0.1759)  auxiliary_vis: 0.0986 (0.1372)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9764 (2.9809)  time: 1.1367 (1.2345)  data: 0.0234 (0.1164)  lr: 0.064000  max mem: 6557
2020-07-09 01:22:59,819 maskrcnn_benchmark INFO: eta: 1:55:06  iter: 34400  loss: 3.3706 (3.4542)  auxiliary_ctx: 0.1293 (0.1608)  auxiliary_frq: 0.1702 (0.1759)  auxiliary_vis: 0.0952 (0.1367)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9762 (2.9809)  time: 1.1365 (1.2334)  data: 0.0260 (0.1152)  lr: 0.064000  max mem: 6557
2020-07-09 01:26:47,964 maskrcnn_benchmark INFO: eta: 1:50:54  iter: 34600  loss: 3.3657 (3.4533)  auxiliary_ctx: 0.1267 (0.1604)  auxiliary_frq: 0.1692 (0.1758)  auxiliary_vis: 0.0919 (0.1362)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9760 (2.9808)  time: 1.1467 (1.2323)  data: 0.0174 (0.1141)  lr: 0.064000  max mem: 6557
2020-07-09 01:30:36,509 maskrcnn_benchmark INFO: eta: 1:46:42  iter: 34800  loss: 3.3591 (3.4524)  auxiliary_ctx: 0.1263 (0.1601)  auxiliary_frq: 0.1692 (0.1758)  auxiliary_vis: 0.0917 (0.1357)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9756 (2.9808)  time: 1.1439 (1.2312)  data: 0.0249 (0.1130)  lr: 0.064000  max mem: 6557
2020-07-09 01:34:24,939 maskrcnn_benchmark INFO: eta: 1:42:30  iter: 35000  loss: 3.3536 (3.4515)  auxiliary_ctx: 0.1230 (0.1597)  auxiliary_frq: 0.1649 (0.1758)  auxiliary_vis: 0.0896 (0.1353)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9756 (2.9807)  time: 1.1426 (1.2302)  data: 0.0259 (0.1120)  lr: 0.064000  max mem: 6557
2020-07-09 01:38:12,771 maskrcnn_benchmark INFO: eta: 1:38:19  iter: 35200  loss: 3.3767 (3.4506)  auxiliary_ctx: 0.1331 (0.1594)  auxiliary_frq: 0.1774 (0.1758)  auxiliary_vis: 0.0915 (0.1348)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9758 (2.9807)  time: 1.1334 (1.2291)  data: 0.0211 (0.1109)  lr: 0.064000  max mem: 6557
2020-07-09 01:42:01,331 maskrcnn_benchmark INFO: eta: 1:34:09  iter: 35400  loss: 3.3736 (3.4497)  auxiliary_ctx: 0.1294 (0.1591)  auxiliary_frq: 0.1742 (0.1757)  auxiliary_vis: 0.0895 (0.1343)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9755 (2.9806)  time: 1.1321 (1.2281)  data: 0.0253 (0.1099)  lr: 0.064000  max mem: 6557
2020-07-09 01:45:49,798 maskrcnn_benchmark INFO: eta: 1:29:59  iter: 35600  loss: 3.3514 (3.4487)  auxiliary_ctx: 0.1257 (0.1587)  auxiliary_frq: 0.1711 (0.1757)  auxiliary_vis: 0.0863 (0.1338)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9753 (2.9805)  time: 1.1369 (1.2271)  data: 0.0260 (0.1089)  lr: 0.064000  max mem: 6557
2020-07-09 01:49:38,595 maskrcnn_benchmark INFO: eta: 1:25:50  iter: 35800  loss: 3.3699 (3.4478)  auxiliary_ctx: 0.1285 (0.1584)  auxiliary_frq: 0.1726 (0.1757)  auxiliary_vis: 0.0897 (0.1333)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9756 (2.9805)  time: 1.1315 (1.2262)  data: 0.0184 (0.1080)  lr: 0.064000  max mem: 6557
2020-07-09 01:53:27,103 maskrcnn_benchmark INFO: ---Total norm 0.42404 clip coef 11.79143-----------------
2020-07-09 01:53:27,112 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.35744, (torch.Size([4096, 12544]))
2020-07-09 01:53:27,112 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.14944, (torch.Size([4096, 12544]))
2020-07-09 01:53:27,112 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.09908, (torch.Size([256, 1024, 3, 3]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.07443, (torch.Size([4096, 4096]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06760, (torch.Size([4096, 4096]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05024, (torch.Size([51, 4096]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03866, (torch.Size([256, 128, 3, 3]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03525, (torch.Size([51, 4096]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03310, (torch.Size([4096, 1024]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.02372, (torch.Size([2048, 4808]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02240, (torch.Size([128, 2, 7, 7]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01910, (torch.Size([4096, 512]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01703, (torch.Size([151, 200]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01626, (torch.Size([2048, 4808]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01549, (torch.Size([512, 32]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01209, (torch.Size([1024, 512]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01185, (torch.Size([512, 1024]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01049, (torch.Size([512]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01022, (torch.Size([2048]))
2020-07-09 01:53:27,113 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01022, (torch.Size([2048]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00876, (torch.Size([1024]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00837, (torch.Size([128]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00820, (torch.Size([4096]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00676, (torch.Size([2048, 512]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00623, (torch.Size([2048]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00623, (torch.Size([2048]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00575, (torch.Size([4096]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00547, (torch.Size([256]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00527, (torch.Size([128]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00466, (torch.Size([2048, 512]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00462, (torch.Size([4096]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00447, (torch.Size([256]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00439, (torch.Size([256]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00412, (torch.Size([128]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00368, (torch.Size([512]))
2020-07-09 01:53:27,114 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00355, (torch.Size([4096]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00333, (torch.Size([51]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00328, (torch.Size([51]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00324, (torch.Size([4096]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00313, (torch.Size([22801, 51]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00094, (torch.Size([256]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00081, (torch.Size([4096]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00003, (torch.Size([512]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00003, (torch.Size([512, 1024]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-07-09 01:53:27,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-09 01:53:27,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-09 01:53:27,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-09 01:53:27,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-09 01:53:27,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-09 01:53:27,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-09 01:53:27,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-09 01:53:27,116 maskrcnn_benchmark INFO: -------------------------------
2020-07-09 01:53:27,119 maskrcnn_benchmark INFO: eta: 1:21:41  iter: 36000  loss: 3.3581 (3.4469)  auxiliary_ctx: 0.1256 (0.1581)  auxiliary_frq: 0.1689 (0.1756)  auxiliary_vis: 0.0871 (0.1328)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9751 (2.9804)  time: 1.1388 (1.2253)  data: 0.0184 (0.1070)  lr: 0.064000  max mem: 6557
2020-07-09 01:53:27,121 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0036000.pth
2020-07-09 01:53:29,387 maskrcnn_benchmark INFO: Start validating
2020-07-09 01:53:29,423 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-09 01:54:59,537 maskrcnn_benchmark INFO: Total run time: 0:01:30.114037 (0.14418245887756348 s / img per device, on 8 devices)
2020-07-09 01:54:59,538 maskrcnn_benchmark INFO: Model inference time: 0:01:10.159729 (0.11225556564331055 s / img per device, on 8 devices)
2020-07-09 01:56:35,304 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2843;   R @ 50: 0.3555;   R @ 100: 0.3773;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3778; ngR @ 50: 0.5203; ngR @ 100: 0.5880;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1385;  zR @ 50: 0.1756;  zR @ 100: 0.1881;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1377;  mR @ 50: 0.1621;  mR @ 100: 0.1723;  for mode=predcls, type=Mean Recall.
(above:0.2873) (across:0.0000) (against:0.0000) (along:0.0385) (and:0.0000) (at:0.4123) (attached to:0.0701) (behind:0.2718) (belonging to:0.0000) (between:0.0000) (carrying:0.4803) (covered in:0.0476) (covering:0.0612) (eating:0.0714) (flying in:0.0000) (for:0.0093) (from:0.0000) (growing on:0.0333) (hanging from:0.0515) (has:0.4089) (holding:0.3470) (in:0.3053) (in front of:0.3098) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2243) (of:0.2781) (on:0.4002) (on back of:0.0227) (over:0.1264) (painted on:0.0000) (parked on:0.5253) (part of:0.0208) (playing:0.0000) (riding:0.8259) (says:0.0000) (sitting on:0.3792) (standing on:0.1391) (to:0.0278) (under:0.2262) (using:0.1346) (walking in:0.0000) (walking on:0.6048) (watching:0.2353) (wearing:0.6543) (wears:0.3299) (with:0.2568) 
SGG eval:   A @ 20: 0.3862;   A @ 50: 0.3890;   A @ 100: 0.3890;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-09 01:56:36,074 maskrcnn_benchmark INFO: Validation Result: 0.3773
2020-07-09 02:00:24,412 maskrcnn_benchmark INFO: eta: 1:18:11  iter: 36200  loss: 3.3586 (3.4460)  auxiliary_ctx: 0.1283 (0.1577)  auxiliary_frq: 0.1728 (0.1756)  auxiliary_vis: 0.0836 (0.1323)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9749 (2.9804)  time: 1.1482 (1.2347)  data: 0.0259 (0.1165)  lr: 0.064000  max mem: 6557
2020-07-09 02:04:12,562 maskrcnn_benchmark INFO: eta: 1:14:01  iter: 36400  loss: 3.3644 (3.4451)  auxiliary_ctx: 0.1290 (0.1574)  auxiliary_frq: 0.1733 (0.1756)  auxiliary_vis: 0.0847 (0.1318)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9745 (2.9803)  time: 1.1363 (1.2337)  data: 0.0173 (0.1154)  lr: 0.064000  max mem: 6557
2020-07-09 02:08:00,990 maskrcnn_benchmark INFO: eta: 1:09:51  iter: 36600  loss: 3.3484 (3.4442)  auxiliary_ctx: 0.1243 (0.1571)  auxiliary_frq: 0.1637 (0.1755)  auxiliary_vis: 0.0784 (0.1313)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9743 (2.9803)  time: 1.1351 (1.2327)  data: 0.0227 (0.1144)  lr: 0.064000  max mem: 6557
2020-07-09 02:11:49,994 maskrcnn_benchmark INFO: eta: 1:05:41  iter: 36800  loss: 3.3702 (3.4433)  auxiliary_ctx: 0.1315 (0.1568)  auxiliary_frq: 0.1745 (0.1755)  auxiliary_vis: 0.0858 (0.1308)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9751 (2.9802)  time: 1.1336 (1.2318)  data: 0.0167 (0.1135)  lr: 0.064000  max mem: 6557
2020-07-09 02:15:38,801 maskrcnn_benchmark INFO: eta: 1:01:32  iter: 37000  loss: 3.3471 (3.4424)  auxiliary_ctx: 0.1238 (0.1565)  auxiliary_frq: 0.1696 (0.1755)  auxiliary_vis: 0.0785 (0.1303)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9739 (2.9802)  time: 1.1399 (1.2309)  data: 0.0251 (0.1125)  lr: 0.064000  max mem: 6557
2020-07-09 02:19:26,790 maskrcnn_benchmark INFO: eta: 0:57:23  iter: 37200  loss: 3.3540 (3.4416)  auxiliary_ctx: 0.1274 (0.1562)  auxiliary_frq: 0.1705 (0.1755)  auxiliary_vis: 0.0823 (0.1298)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9749 (2.9801)  time: 1.1351 (1.2299)  data: 0.0243 (0.1116)  lr: 0.064000  max mem: 6557
2020-07-09 02:23:14,739 maskrcnn_benchmark INFO: eta: 0:53:15  iter: 37400  loss: 3.3444 (3.4407)  auxiliary_ctx: 0.1211 (0.1559)  auxiliary_frq: 0.1684 (0.1754)  auxiliary_vis: 0.0814 (0.1293)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9743 (2.9800)  time: 1.1386 (1.2290)  data: 0.0225 (0.1106)  lr: 0.064000  max mem: 6557
2020-07-09 02:27:03,344 maskrcnn_benchmark INFO: eta: 0:49:07  iter: 37600  loss: 3.3526 (3.4399)  auxiliary_ctx: 0.1245 (0.1556)  auxiliary_frq: 0.1745 (0.1754)  auxiliary_vis: 0.0797 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9743 (2.9800)  time: 1.1380 (1.2281)  data: 0.0249 (0.1097)  lr: 0.064000  max mem: 6557
2020-07-09 02:30:51,879 maskrcnn_benchmark INFO: eta: 0:44:59  iter: 37800  loss: 3.3630 (3.4390)  auxiliary_ctx: 0.1313 (0.1554)  auxiliary_frq: 0.1762 (0.1754)  auxiliary_vis: 0.0855 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9752 (2.9799)  time: 1.1468 (1.2273)  data: 0.0261 (0.1089)  lr: 0.064000  max mem: 6557
2020-07-09 02:34:40,275 maskrcnn_benchmark INFO: eta: 0:40:52  iter: 38000  loss: 3.3606 (3.4381)  auxiliary_ctx: 0.1270 (0.1551)  auxiliary_frq: 0.1806 (0.1754)  auxiliary_vis: 0.0796 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9745 (2.9799)  time: 1.1469 (1.2264)  data: 0.0259 (0.1080)  lr: 0.064000  max mem: 6557
2020-07-09 02:34:40,278 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0038000.pth
2020-07-09 02:34:42,625 maskrcnn_benchmark INFO: Start validating
2020-07-09 02:34:42,653 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-09 02:36:13,498 maskrcnn_benchmark INFO: Total run time: 0:01:30.844582 (0.1453513313293457 s / img per device, on 8 devices)
2020-07-09 02:36:13,498 maskrcnn_benchmark INFO: Model inference time: 0:01:10.282999 (0.11245279846191407 s / img per device, on 8 devices)
2020-07-09 02:37:47,768 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2875;   R @ 50: 0.3447;   R @ 100: 0.3586;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3834; ngR @ 50: 0.4981; ngR @ 100: 0.5453;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1141;  zR @ 50: 0.1289;  zR @ 100: 0.1348;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1297;  mR @ 50: 0.1543;  mR @ 100: 0.1650;  for mode=predcls, type=Mean Recall.
(above:0.2241) (across:0.0000) (against:0.0526) (along:0.0449) (and:0.0000) (at:0.4078) (attached to:0.0550) (behind:0.1759) (belonging to:0.0012) (between:0.0000) (carrying:0.4430) (covered in:0.0119) (covering:0.0327) (eating:0.2143) (flying in:0.0000) (for:0.0093) (from:0.0000) (growing on:0.0000) (hanging from:0.0662) (has:0.4200) (holding:0.2879) (in:0.3024) (in front of:0.2761) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1538) (of:0.3697) (on:0.3915) (on back of:0.0227) (over:0.1728) (painted on:0.0000) (parked on:0.4522) (part of:0.0000) (playing:0.0000) (riding:0.8170) (says:0.0000) (sitting on:0.3545) (standing on:0.1786) (to:0.0000) (under:0.2211) (using:0.0000) (walking in:0.0000) (walking on:0.6215) (watching:0.2941) (wearing:0.6160) (wears:0.3398) (with:0.1722) 
SGG eval:   A @ 20: 0.3604;   A @ 50: 0.3620;   A @ 100: 0.3620;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-09 02:37:48,521 maskrcnn_benchmark INFO: Validation Result: 0.3586
2020-07-09 02:37:48,522 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-07-09 02:41:36,481 maskrcnn_benchmark INFO: eta: 0:37:02  iter: 38200  loss: 3.3330 (3.4372)  auxiliary_ctx: 0.1212 (0.1548)  auxiliary_frq: 0.1707 (0.1754)  auxiliary_vis: 0.0735 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9738 (2.9798)  time: 1.1320 (1.2349)  data: 0.0253 (0.1165)  lr: 0.006400  max mem: 6557
2020-07-09 02:45:24,695 maskrcnn_benchmark INFO: eta: 0:32:54  iter: 38400  loss: 3.3406 (3.4363)  auxiliary_ctx: 0.1255 (0.1544)  auxiliary_frq: 0.1723 (0.1753)  auxiliary_vis: 0.0698 (0.1268)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9734 (2.9798)  time: 1.1361 (1.2339)  data: 0.0240 (0.1156)  lr: 0.006400  max mem: 6557
2020-07-09 02:49:13,394 maskrcnn_benchmark INFO: eta: 0:28:46  iter: 38600  loss: 3.3443 (3.4354)  auxiliary_ctx: 0.1246 (0.1541)  auxiliary_frq: 0.1753 (0.1753)  auxiliary_vis: 0.0701 (0.1262)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9736 (2.9797)  time: 1.1506 (1.2331)  data: 0.0263 (0.1147)  lr: 0.006400  max mem: 6557
2020-07-09 02:53:01,915 maskrcnn_benchmark INFO: eta: 0:24:38  iter: 38800  loss: 3.3414 (3.4345)  auxiliary_ctx: 0.1238 (0.1538)  auxiliary_frq: 0.1706 (0.1753)  auxiliary_vis: 0.0699 (0.1257)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9735 (2.9796)  time: 1.1490 (1.2322)  data: 0.0232 (0.1138)  lr: 0.006400  max mem: 6557
2020-07-09 02:56:50,731 maskrcnn_benchmark INFO: eta: 0:20:31  iter: 39000  loss: 3.3355 (3.4335)  auxiliary_ctx: 0.1203 (0.1535)  auxiliary_frq: 0.1705 (0.1753)  auxiliary_vis: 0.0655 (0.1251)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9728 (2.9796)  time: 1.1353 (1.2314)  data: 0.0258 (0.1129)  lr: 0.006400  max mem: 6557
2020-07-09 03:00:39,095 maskrcnn_benchmark INFO: eta: 0:16:24  iter: 39200  loss: 3.3175 (3.4326)  auxiliary_ctx: 0.1149 (0.1532)  auxiliary_frq: 0.1663 (0.1753)  auxiliary_vis: 0.0633 (0.1246)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9729 (2.9795)  time: 1.1370 (1.2305)  data: 0.0258 (0.1121)  lr: 0.006400  max mem: 6557
2020-07-09 03:04:27,383 maskrcnn_benchmark INFO: eta: 0:12:17  iter: 39400  loss: 3.3258 (3.4316)  auxiliary_ctx: 0.1179 (0.1529)  auxiliary_frq: 0.1699 (0.1752)  auxiliary_vis: 0.0634 (0.1240)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9728 (2.9795)  time: 1.1435 (1.2297)  data: 0.0242 (0.1113)  lr: 0.006400  max mem: 6557
2020-07-09 03:08:16,031 maskrcnn_benchmark INFO: eta: 0:08:11  iter: 39600  loss: 3.3275 (3.4307)  auxiliary_ctx: 0.1186 (0.1526)  auxiliary_frq: 0.1730 (0.1752)  auxiliary_vis: 0.0635 (0.1235)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9732 (2.9794)  time: 1.1382 (1.2289)  data: 0.0261 (0.1104)  lr: 0.006400  max mem: 6557
2020-07-09 03:12:04,634 maskrcnn_benchmark INFO: eta: 0:04:05  iter: 39800  loss: 3.3192 (3.4298)  auxiliary_ctx: 0.1148 (0.1523)  auxiliary_frq: 0.1679 (0.1752)  auxiliary_vis: 0.0612 (0.1229)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9727 (2.9793)  time: 1.1378 (1.2281)  data: 0.0176 (0.1096)  lr: 0.006400  max mem: 6557
2020-07-09 03:15:53,058 maskrcnn_benchmark INFO: ---Total norm 0.49455 clip coef 10.11018-----------------
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.37438, (torch.Size([4096, 12544]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.26469, (torch.Size([4096, 12544]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.10846, (torch.Size([4096, 4096]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.09351, (torch.Size([256, 1024, 3, 3]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06856, (torch.Size([4096, 4096]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.04872, (torch.Size([51, 4096]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04127, (torch.Size([256, 128, 3, 3]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03250, (torch.Size([51, 4096]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.02709, (torch.Size([4096, 1024]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.02587, (torch.Size([2048, 4808]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02344, (torch.Size([128, 2, 7, 7]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01928, (torch.Size([2048, 4808]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01769, (torch.Size([151, 200]))
2020-07-09 03:15:53,068 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01423, (torch.Size([4096, 512]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01422, (torch.Size([512, 32]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01410, (torch.Size([1024, 512]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01151, (torch.Size([512, 1024]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00966, (torch.Size([4096]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00940, (torch.Size([128]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00790, (torch.Size([2048, 512]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00703, (torch.Size([1024]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00635, (torch.Size([512]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00584, (torch.Size([2048]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00584, (torch.Size([2048]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00520, (torch.Size([2048, 512]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00507, (torch.Size([4096]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00504, (torch.Size([4096]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00467, (torch.Size([256]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00459, (torch.Size([256]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00420, (torch.Size([128]))
2020-07-09 03:15:53,069 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00378, (torch.Size([256]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00361, (torch.Size([512]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00357, (torch.Size([22801, 51]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00311, (torch.Size([4096]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00308, (torch.Size([4096]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00307, (torch.Size([2048]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00307, (torch.Size([2048]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00283, (torch.Size([51]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00265, (torch.Size([128]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00265, (torch.Size([51]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00139, (torch.Size([4096]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00085, (torch.Size([256]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00004, (torch.Size([512]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00004, (torch.Size([512, 1024]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-09 03:15:53,070 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-07-09 03:15:53,071 maskrcnn_benchmark INFO: -------------------------------
2020-07-09 03:15:53,074 maskrcnn_benchmark INFO: eta: 0:00:00  iter: 40000  loss: 3.3149 (3.4288)  auxiliary_ctx: 0.1135 (0.1520)  auxiliary_frq: 0.1688 (0.1752)  auxiliary_vis: 0.0606 (0.1224)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.9724 (2.9793)  time: 1.1398 (1.2273)  data: 0.0174 (0.1088)  lr: 0.006400  max mem: 6557
2020-07-09 03:15:53,077 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_0040000.pth
2020-07-09 03:15:55,410 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-mfb7-TDE/model_final.pth
2020-07-09 03:15:57,610 maskrcnn_benchmark INFO: Start validating
2020-07-09 03:15:57,645 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-07-09 03:17:29,037 maskrcnn_benchmark INFO: Total run time: 0:01:31.391624 (0.14622659912109376 s / img per device, on 8 devices)
2020-07-09 03:17:29,038 maskrcnn_benchmark INFO: Model inference time: 0:01:10.766415 (0.1132262638092041 s / img per device, on 8 devices)
2020-07-09 03:19:02,387 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.3137;   R @ 50: 0.3611;   R @ 100: 0.3709;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3852; ngR @ 50: 0.4790; ngR @ 100: 0.5172;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1141;  zR @ 50: 0.1274;  zR @ 100: 0.1348;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1329;  mR @ 50: 0.1533;  mR @ 100: 0.1634;  for mode=predcls, type=Mean Recall.
(above:0.2021) (across:0.0000) (against:0.0526) (along:0.1154) (and:0.0000) (at:0.4156) (attached to:0.0644) (behind:0.1688) (belonging to:0.0000) (between:0.0000) (carrying:0.4496) (covered in:0.0476) (covering:0.0850) (eating:0.2143) (flying in:0.0000) (for:0.0278) (from:0.0000) (growing on:0.0000) (hanging from:0.0735) (has:0.3412) (holding:0.2596) (in:0.2680) (in front of:0.2183) (laying on:0.0952) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1672) (of:0.2241) (on:0.4250) (on back of:0.0682) (over:0.1606) (painted on:0.0000) (parked on:0.5487) (part of:0.0000) (playing:0.0000) (riding:0.8080) (says:0.0000) (sitting on:0.3668) (standing on:0.1252) (to:0.0000) (under:0.2185) (using:0.0000) (walking in:0.0000) (walking on:0.6190) (watching:0.2941) (wearing:0.6897) (wears:0.1954) (with:0.1613) 
SGG eval:   A @ 20: 0.3792;   A @ 50: 0.3808;   A @ 100: 0.3808;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-07-09 03:19:03,161 maskrcnn_benchmark INFO: Validation Result: 0.3709
2020-07-09 03:19:03,411 maskrcnn_benchmark INFO: Total training time: 7:33:11.151468 (0.6798 s / it)
2020-07-09 03:19:05,340 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).
2020-07-09 03:27:00,902 maskrcnn_benchmark INFO: Total run time: 0:07:55.561282 (0.14385881642481027 s / img per device, on 8 devices)
2020-07-09 03:27:00,903 maskrcnn_benchmark INFO: Model inference time: 0:06:14.924202 (0.113415776065012 s / img per device, on 8 devices)
2020-07-09 03:35:42,460 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9995
====================================================================================================
SGG eval:   R @ 20: 0.3186;   R @ 50: 0.3705;   R @ 100: 0.3785;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3899; ngR @ 50: 0.4881; ngR @ 100: 0.5236;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0963;  zR @ 50: 0.1334;  zR @ 100: 0.1467;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1298;  mR @ 50: 0.1531;  mR @ 100: 0.1627;  for mode=predcls, type=Mean Recall.
(above:0.2011) (across:0.0000) (against:0.0323) (along:0.0336) (and:0.0000) (at:0.3000) (attached to:0.0836) (behind:0.2948) (belonging to:0.0069) (between:0.0000) (carrying:0.3789) (covered in:0.2280) (covering:0.0639) (eating:0.1199) (flying in:0.0000) (for:0.0912) (from:0.0141) (growing on:0.0345) (hanging from:0.0710) (has:0.4211) (holding:0.4027) (in:0.2553) (in front of:0.1275) (laying on:0.1753) (looking at:0.0848) (lying on:0.0102) (made of:0.0625) (mounted on:0.0208) (near:0.1802) (of:0.2865) (on:0.3803) (on back of:0.0319) (over:0.1472) (painted on:0.0000) (parked on:0.3734) (part of:0.0062) (playing:0.0000) (riding:0.7621) (says:0.0000) (sitting on:0.3502) (standing on:0.1823) (to:0.0164) (under:0.2535) (using:0.0625) (walking in:0.0000) (walking on:0.3806) (watching:0.1857) (wearing:0.7040) (wears:0.1794) (with:0.1394) 
SGG eval:   A @ 20: 0.3728;   A @ 50: 0.3732;   A @ 100: 0.3732;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

