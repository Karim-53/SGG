2020-06-09 09:26:23,637 maskrcnn_benchmark INFO: Using 8 GPUs
2020-06-09 09:26:23,637 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE'], skip_test=False)
2020-06-09 09:26:23,637 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-09 09:26:28,506 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-09 09:26:28,507 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-09 09:26:28,507 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-09 09:26:28,510 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: TDE
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 64
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-09 09:26:28,510 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/config.yml
2020-06-09 09:26:28,545 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-09 09:26:31,832 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-09 09:26:31,832 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-09 09:26:59,213 maskrcnn_benchmark.data.build INFO: finish
2020-06-09 09:26:59,213 maskrcnn_benchmark.data.build INFO: Save data statistics to: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-09 09:26:59,213 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-09 09:27:00,505 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-09 09:27:01,166 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-09 09:27:01,194 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-09 09:27:01,196 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth
2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-06-09 09:27:02,105 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2020-06-09 09:27:02,105 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)
2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)
2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2020-06-09 09:27:02,530 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-06-09 09:27:02,531 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-09 09:27:05,309 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/labels.json
2020-06-09 09:27:06,520 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-06-09 09:27:06,521 maskrcnn_benchmark INFO: Validate before training
2020-06-09 09:27:06,529 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 09:28:38,354 maskrcnn_benchmark INFO: Total run time: 0:01:31.824018 (0.1469184295654297 s / img per device, on 8 devices)
2020-06-09 09:28:38,354 maskrcnn_benchmark INFO: Model inference time: 0:01:09.704013 (0.11152642021179199 s / img per device, on 8 devices)
2020-06-09 09:29:45,520 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.0033;   R @ 50: 0.0049;   R @ 100: 0.0061;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.0069; ngR @ 50: 0.0196; ngR @ 100: 0.0440;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0044;  zR @ 50: 0.0044;  zR @ 100: 0.0095;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0053;  mR @ 50: 0.0093;  mR @ 100: 0.0111;  for mode=predcls, type=Mean Recall.
(above:0.0108) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0000) (attached to:0.0000) (behind:0.0000) (belonging to:0.0000) (between:0.0962) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.0294) (holding:0.0067) (in:0.0000) (in front of:0.0235) (laying on:0.0000) (looking at:0.1739) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0000) (of:0.0016) (on:0.0014) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0159) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0000) (standing on:0.0909) (to:0.0694) (under:0.0000) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.0000) (wears:0.0000) (with:0.0004) 
SGG eval:   A @ 20: 0.0073;   A @ 50: 0.0075;   A @ 100: 0.0075;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 09:29:46,288 maskrcnn_benchmark INFO: Start training
2020-06-09 09:29:48,285 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------
2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: inf, (torch.Size([51]))
2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: inf, (torch.Size([51, 4096]))
2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: inf, (torch.Size([51]))
2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 64594.83203, (torch.Size([4096, 512]))
2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 20386.34180, (torch.Size([512, 32]))
2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 18794.22852, (torch.Size([4096]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 6352.29395, (torch.Size([512]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 670.18872, (torch.Size([22801, 51]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 20.33342, (torch.Size([4096, 4096]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 18.43250, (torch.Size([4096, 12544]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 3.79290, (torch.Size([256, 1024, 3, 3]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.63481, (torch.Size([256, 128, 3, 3]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 1.09265, (torch.Size([51, 4096]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.64679, (torch.Size([4096, 1024]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.63362, (torch.Size([512, 1024]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.49527, (torch.Size([4096, 4096]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.35582, (torch.Size([128, 2, 7, 7]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.30655, (torch.Size([2048, 4808]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.30343, (torch.Size([2048, 4808]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.24282, (torch.Size([4096, 12544]))
2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.24256, (torch.Size([512]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.21975, (torch.Size([4096]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.17784, (torch.Size([256]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.09924, (torch.Size([4096]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.09058, (torch.Size([256]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.07593, (torch.Size([128]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.06794, (torch.Size([512, 1024]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.05310, (torch.Size([2048, 512]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.05284, (torch.Size([2048, 512]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.03785, (torch.Size([4096]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.03560, (torch.Size([2048, 4424]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.03413, (torch.Size([2048, 4424]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.03335, (torch.Size([256]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.03174, (torch.Size([256]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.03166, (torch.Size([2048]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.03166, (torch.Size([2048]))
2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.03132, (torch.Size([2048]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.03132, (torch.Size([2048]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02829, (torch.Size([128]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02815, (torch.Size([1024, 512]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.02707, (torch.Size([128]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.02595, (torch.Size([512]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.02407, (torch.Size([1024]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01344, (torch.Size([4096]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00597, (torch.Size([2048, 512]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00583, (torch.Size([2048, 512]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00356, (torch.Size([2048]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00356, (torch.Size([2048]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00341, (torch.Size([2048]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00341, (torch.Size([2048]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00318, (torch.Size([4096]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00247, (torch.Size([151, 200]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00179, (torch.Size([128, 32]))
2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00102, (torch.Size([32, 9]))
2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00070, (torch.Size([128]))
2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00032, (torch.Size([32]))
2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00028, (torch.Size([151, 200]))
2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00018, (torch.Size([32]))
2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: -------------------------------
2020-06-09 09:33:37,089 maskrcnn_benchmark INFO: eta: 12:45:29  iter: 200  loss: 0.8979 (1.3697)  auxiliary_ctx: 0.1836 (0.3939)  auxiliary_frq: 0.2057 (0.2092)  auxiliary_vis: 0.1858 (0.3753)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2993 (0.3914)  time: 1.1446 (1.1540)  data: 0.0206 (0.0298)  lr: 0.293248  max mem: 6061
2020-06-09 09:37:27,522 maskrcnn_benchmark INFO: eta: 12:41:02  iter: 400  loss: 0.8389 (1.1123)  auxiliary_ctx: 0.1693 (0.2835)  auxiliary_frq: 0.2078 (0.2088)  auxiliary_vis: 0.1844 (0.2821)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2740 (0.3380)  time: 1.1383 (1.1531)  data: 0.0164 (0.0266)  lr: 0.523648  max mem: 6061
2020-06-09 09:41:17,401 maskrcnn_benchmark INFO: eta: 12:36:23  iter: 600  loss: 0.7891 (1.0206)  auxiliary_ctx: 0.1521 (0.2443)  auxiliary_frq: 0.2033 (0.2083)  auxiliary_vis: 0.1752 (0.2506)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2570 (0.3174)  time: 1.1465 (1.1519)  data: 0.0238 (0.0242)  lr: 0.640000  max mem: 6124
2020-06-09 09:45:07,793 maskrcnn_benchmark INFO: eta: 12:32:33  iter: 800  loss: 0.8228 (0.9693)  auxiliary_ctx: 0.1638 (0.2236)  auxiliary_frq: 0.2094 (0.2077)  auxiliary_vis: 0.1862 (0.2333)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2641 (0.3047)  time: 1.1481 (1.1519)  data: 0.0242 (0.0238)  lr: 0.640000  max mem: 6124
2020-06-09 09:48:57,311 maskrcnn_benchmark INFO: eta: 12:28:09  iter: 1000  loss: 0.7759 (0.9363)  auxiliary_ctx: 0.1501 (0.2104)  auxiliary_frq: 0.2010 (0.2073)  auxiliary_vis: 0.1678 (0.2225)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2548 (0.2961)  time: 1.1420 (1.1510)  data: 0.0249 (0.0238)  lr: 0.640000  max mem: 6124
2020-06-09 09:52:47,557 maskrcnn_benchmark INFO: eta: 12:24:20  iter: 1200  loss: 0.7592 (0.9119)  auxiliary_ctx: 0.1472 (0.2011)  auxiliary_frq: 0.1994 (0.2068)  auxiliary_vis: 0.1682 (0.2145)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2431 (0.2894)  time: 1.1584 (1.1511)  data: 0.0236 (0.0234)  lr: 0.640000  max mem: 6124
2020-06-09 09:56:37,402 maskrcnn_benchmark INFO: eta: 12:20:20  iter: 1400  loss: 0.7770 (0.8927)  auxiliary_ctx: 0.1502 (0.1941)  auxiliary_frq: 0.2048 (0.2061)  auxiliary_vis: 0.1760 (0.2086)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2451 (0.2840)  time: 1.1412 (1.1508)  data: 0.0246 (0.0232)  lr: 0.640000  max mem: 6124
2020-06-09 10:00:27,095 maskrcnn_benchmark INFO: eta: 12:16:19  iter: 1600  loss: 0.7829 (0.8790)  auxiliary_ctx: 0.1508 (0.1889)  auxiliary_frq: 0.2019 (0.2056)  auxiliary_vis: 0.1708 (0.2042)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2479 (0.2802)  time: 1.1467 (1.1505)  data: 0.0243 (0.0232)  lr: 0.640000  max mem: 6124
2020-06-09 10:04:17,544 maskrcnn_benchmark INFO: eta: 12:12:36  iter: 1800  loss: 0.7965 (0.8682)  auxiliary_ctx: 0.1487 (0.1849)  auxiliary_frq: 0.2032 (0.2053)  auxiliary_vis: 0.1767 (0.2008)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2481 (0.2772)  time: 1.1528 (1.1507)  data: 0.0233 (0.0230)  lr: 0.640000  max mem: 6124
2020-06-09 10:08:06,939 maskrcnn_benchmark INFO: eta: 12:08:32  iter: 2000  loss: 0.7567 (0.8587)  auxiliary_ctx: 0.1514 (0.1816)  auxiliary_frq: 0.1990 (0.2049)  auxiliary_vis: 0.1675 (0.1978)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2437 (0.2744)  time: 1.1437 (1.1503)  data: 0.0248 (0.0230)  lr: 0.640000  max mem: 6124
2020-06-09 10:08:06,942 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0002000.pth
2020-06-09 10:08:09,217 maskrcnn_benchmark INFO: Start validating
2020-06-09 10:08:09,243 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 10:09:39,769 maskrcnn_benchmark INFO: Total run time: 0:01:30.525655 (0.14484104766845704 s / img per device, on 8 devices)
2020-06-09 10:09:39,769 maskrcnn_benchmark INFO: Model inference time: 0:01:10.113488 (0.11218158073425293 s / img per device, on 8 devices)
2020-06-09 10:11:10,741 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2329;   R @ 50: 0.3147;   R @ 100: 0.3624;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2876; ngR @ 50: 0.4438; ngR @ 100: 0.5837;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1022;  zR @ 50: 0.1422;  zR @ 100: 0.1793;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1512;  mR @ 50: 0.2033;  mR @ 100: 0.2300;  for mode=predcls, type=Mean Recall.
(above:0.3151) (across:0.0000) (against:0.0000) (along:0.2308) (and:0.0000) (at:0.6978) (attached to:0.0000) (behind:0.5724) (belonging to:0.0000) (between:0.0000) (carrying:0.6711) (covered in:0.0714) (covering:0.0000) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.2132) (has:0.5954) (holding:0.3415) (in:0.3653) (in front of:0.4913) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0412) (of:0.6082) (on:0.1933) (on back of:0.0000) (over:0.0305) (painted on:0.0000) (parked on:0.9616) (part of:0.0000) (playing:0.0000) (riding:0.9464) (says:0.0000) (sitting on:0.5319) (standing on:0.0562) (to:0.0000) (under:0.1437) (using:0.0000) (walking in:0.0000) (walking on:0.9337) (watching:0.5098) (wearing:0.9401) (wears:0.0000) (with:0.2767) 
SGG eval:   A @ 20: 0.4054;   A @ 50: 0.4079;   A @ 100: 0.4079;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 10:11:11,506 maskrcnn_benchmark INFO: Validation Result: 0.3624
2020-06-09 10:15:00,990 maskrcnn_benchmark INFO: eta: 12:57:23  iter: 2200  loss: 0.7729 (0.8499)  auxiliary_ctx: 0.1487 (0.1786)  auxiliary_frq: 0.2021 (0.2044)  auxiliary_vis: 0.1699 (0.1952)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2474 (0.2717)  time: 1.1451 (1.2340)  data: 0.0238 (0.1070)  lr: 0.640000  max mem: 6124
2020-06-09 10:18:51,159 maskrcnn_benchmark INFO: eta: 12:48:56  iter: 2400  loss: 0.7678 (0.8423)  auxiliary_ctx: 0.1457 (0.1760)  auxiliary_frq: 0.2013 (0.2039)  auxiliary_vis: 0.1731 (0.1929)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2450 (0.2695)  time: 1.1449 (1.2270)  data: 0.0250 (0.1001)  lr: 0.640000  max mem: 6124
2020-06-09 10:22:41,490 maskrcnn_benchmark INFO: eta: 12:41:14  iter: 2600  loss: 0.7512 (0.8364)  auxiliary_ctx: 0.1443 (0.1740)  auxiliary_frq: 0.1975 (0.2035)  auxiliary_vis: 0.1660 (0.1911)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2488 (0.2678)  time: 1.1495 (1.2212)  data: 0.0247 (0.0943)  lr: 0.640000  max mem: 6124
2020-06-09 10:26:31,920 maskrcnn_benchmark INFO: eta: 12:34:06  iter: 2800  loss: 0.7614 (0.8304)  auxiliary_ctx: 0.1424 (0.1720)  auxiliary_frq: 0.1995 (0.2030)  auxiliary_vis: 0.1683 (0.1893)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2417 (0.2660)  time: 1.1445 (1.2163)  data: 0.0221 (0.0892)  lr: 0.640000  max mem: 6124
2020-06-09 10:30:21,992 maskrcnn_benchmark INFO: eta: 12:27:20  iter: 3000  loss: 0.7557 (0.8253)  auxiliary_ctx: 0.1470 (0.1704)  auxiliary_frq: 0.1963 (0.2027)  auxiliary_vis: 0.1664 (0.1878)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2431 (0.2645)  time: 1.1455 (1.2119)  data: 0.0205 (0.0848)  lr: 0.640000  max mem: 6124
2020-06-09 10:34:12,914 maskrcnn_benchmark INFO: eta: 12:21:06  iter: 3200  loss: 0.7645 (0.8209)  auxiliary_ctx: 0.1449 (0.1690)  auxiliary_frq: 0.1987 (0.2023)  auxiliary_vis: 0.1656 (0.1865)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2380 (0.2632)  time: 1.1521 (1.2083)  data: 0.0245 (0.0810)  lr: 0.640000  max mem: 6124
2020-06-09 10:38:03,538 maskrcnn_benchmark INFO: eta: 12:15:05  iter: 3400  loss: 0.7488 (0.8167)  auxiliary_ctx: 0.1460 (0.1677)  auxiliary_frq: 0.1983 (0.2019)  auxiliary_vis: 0.1641 (0.1852)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2445 (0.2620)  time: 1.1426 (1.2051)  data: 0.0199 (0.0775)  lr: 0.640000  max mem: 6124
2020-06-09 10:41:53,377 maskrcnn_benchmark INFO: eta: 12:09:11  iter: 3600  loss: 0.7680 (0.8133)  auxiliary_ctx: 0.1514 (0.1666)  auxiliary_frq: 0.1975 (0.2016)  auxiliary_vis: 0.1690 (0.1842)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2502 (0.2610)  time: 1.1425 (1.2020)  data: 0.0159 (0.0744)  lr: 0.640000  max mem: 6124
2020-06-09 10:45:43,133 maskrcnn_benchmark INFO: eta: 12:03:29  iter: 3800  loss: 0.7026 (0.8101)  auxiliary_ctx: 0.1378 (0.1656)  auxiliary_frq: 0.1886 (0.2013)  auxiliary_vis: 0.1559 (0.1832)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2254 (0.2600)  time: 1.1455 (1.1992)  data: 0.0182 (0.0716)  lr: 0.640000  max mem: 6124
2020-06-09 10:49:33,316 maskrcnn_benchmark INFO: ---Total norm 0.25203 clip coef 19.83860-----------------
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.13293, (torch.Size([4096, 12544]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.09491, (torch.Size([51, 4096]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.08744, (torch.Size([4096, 12544]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.08035, (torch.Size([4096, 4096]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.07343, (torch.Size([256, 1024, 3, 3]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06540, (torch.Size([4096, 4096]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05465, (torch.Size([51, 4096]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04717, (torch.Size([4096, 1024]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03975, (torch.Size([2048, 4808]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03738, (torch.Size([2048, 4808]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02796, (torch.Size([256, 128, 3, 3]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02765, (torch.Size([512, 1024]))
2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02396, (torch.Size([1024, 512]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02367, (torch.Size([51]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02287, (torch.Size([128, 2, 7, 7]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02159, (torch.Size([512, 32]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01877, (torch.Size([4096, 512]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01271, (torch.Size([256]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00929, (torch.Size([151, 200]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00879, (torch.Size([128]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00874, (torch.Size([51]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00854, (torch.Size([4096]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00808, (torch.Size([2048, 512]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00660, (torch.Size([256]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00642, (torch.Size([22801, 51]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00628, (torch.Size([2048, 512]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00623, (torch.Size([4096]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00622, (torch.Size([512]))
2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00493, (torch.Size([512]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00440, (torch.Size([128]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00425, (torch.Size([4096]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00355, (torch.Size([128]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00273, (torch.Size([1024]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00248, (torch.Size([256]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00233, (torch.Size([2048]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00233, (torch.Size([2048]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00209, (torch.Size([2048]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00209, (torch.Size([2048]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00199, (torch.Size([4096]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00151, (torch.Size([4096]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00122, (torch.Size([2048, 4424]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00097, (torch.Size([2048, 4424]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00074, (torch.Size([256]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00058, (torch.Size([512, 1024]))
2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00046, (torch.Size([4096]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00031, (torch.Size([512]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00009, (torch.Size([2048, 512]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00007, (torch.Size([2048, 512]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00007, (torch.Size([2048]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00007, (torch.Size([2048]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00007, (torch.Size([2048]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00007, (torch.Size([2048]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00002, (torch.Size([128, 32]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00002, (torch.Size([151, 200]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00002, (torch.Size([128]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: -------------------------------
2020-06-09 10:49:33,332 maskrcnn_benchmark INFO: eta: 11:58:03  iter: 4000  loss: 0.7685 (0.8071)  auxiliary_ctx: 0.1495 (0.1646)  auxiliary_frq: 0.1987 (0.2010)  auxiliary_vis: 0.1682 (0.1823)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2363 (0.2591)  time: 1.1499 (1.1968)  data: 0.0204 (0.0691)  lr: 0.640000  max mem: 6124
2020-06-09 10:49:33,335 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0004000.pth
2020-06-09 10:49:35,780 maskrcnn_benchmark INFO: Start validating
2020-06-09 10:49:35,813 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 10:51:04,088 maskrcnn_benchmark INFO: Total run time: 0:01:28.274763 (0.14123962020874023 s / img per device, on 8 devices)
2020-06-09 10:51:04,088 maskrcnn_benchmark INFO: Model inference time: 0:01:09.485233 (0.11117637252807618 s / img per device, on 8 devices)
2020-06-09 10:52:36,420 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2529;   R @ 50: 0.3411;   R @ 100: 0.3975;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2976; ngR @ 50: 0.4565; ngR @ 100: 0.5915;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1000;  zR @ 50: 0.1363;  zR @ 100: 0.1763;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1688;  mR @ 50: 0.2244;  mR @ 100: 0.2560;  for mode=predcls, type=Mean Recall.
(above:0.2174) (across:0.0000) (against:0.0000) (along:0.7821) (and:0.0000) (at:0.7892) (attached to:0.0000) (behind:0.5517) (belonging to:0.0000) (between:0.0000) (carrying:0.7281) (covered in:0.4048) (covering:0.1878) (eating:0.8571) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.1287) (has:0.5998) (holding:0.2459) (in:0.3524) (in front of:0.4943) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0666) (of:0.5740) (on:0.2657) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.7832) (part of:0.0000) (playing:0.0000) (riding:0.9286) (says:0.0000) (sitting on:0.5016) (standing on:0.0978) (to:0.0000) (under:0.2075) (using:0.1923) (walking in:0.0000) (walking on:0.9622) (watching:0.5686) (wearing:0.9716) (wears:0.0000) (with:0.2232) 
SGG eval:   A @ 20: 0.4778;   A @ 50: 0.4824;   A @ 100: 0.4824;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 10:52:37,056 maskrcnn_benchmark INFO: Validation Result: 0.3975
2020-06-09 10:56:26,698 maskrcnn_benchmark INFO: eta: 12:18:47  iter: 4200  loss: 0.7683 (0.8042)  auxiliary_ctx: 0.1480 (0.1638)  auxiliary_frq: 0.1983 (0.2007)  auxiliary_vis: 0.1732 (0.1815)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2433 (0.2583)  time: 1.1392 (1.2382)  data: 0.0251 (0.1107)  lr: 0.640000  max mem: 6124
2020-06-09 11:00:17,838 maskrcnn_benchmark INFO: eta: 12:12:26  iter: 4400  loss: 0.7238 (0.8018)  auxiliary_ctx: 0.1468 (0.1630)  auxiliary_frq: 0.1905 (0.2004)  auxiliary_vis: 0.1704 (0.1808)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2308 (0.2576)  time: 1.1541 (1.2344)  data: 0.0253 (0.1067)  lr: 0.640000  max mem: 6124
2020-06-09 11:04:08,356 maskrcnn_benchmark INFO: eta: 12:06:13  iter: 4600  loss: 0.7739 (0.8001)  auxiliary_ctx: 0.1512 (0.1624)  auxiliary_frq: 0.2007 (0.2001)  auxiliary_vis: 0.1704 (0.1804)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2558 (0.2572)  time: 1.1601 (1.2309)  data: 0.0254 (0.1031)  lr: 0.640000  max mem: 6124
2020-06-09 11:07:58,971 maskrcnn_benchmark INFO: eta: 12:00:12  iter: 4800  loss: 0.7184 (0.7975)  auxiliary_ctx: 0.1407 (0.1617)  auxiliary_frq: 0.1934 (0.1998)  auxiliary_vis: 0.1567 (0.1796)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2295 (0.2564)  time: 1.1482 (1.2276)  data: 0.0198 (0.0998)  lr: 0.640000  max mem: 6339
2020-06-09 11:13:47,066 maskrcnn_benchmark INFO: Using 8 GPUs
2020-06-09 11:13:47,066 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE'], skip_test=False)
2020-06-09 11:13:47,066 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-09 11:13:52,029 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-09 11:13:52,030 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-09 11:13:52,030 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-09 11:13:52,033 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: TDE
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 64
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-09 11:13:52,034 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/config.yml
2020-06-09 11:13:52,070 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-09 11:13:55,367 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-09 11:13:55,367 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-09 11:13:55,368 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-09 11:13:55,368 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-09 11:13:56,581 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-09 11:13:57,386 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-09 11:13:57,419 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-09 11:13:57,420 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0004000.pth
2020-06-09 11:13:59,579 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0004000.pth
2020-06-09 11:14:00,283 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-06-09 11:14:00,283 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-09 11:14:02,971 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/labels.json
2020-06-09 11:14:04,196 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-06-09 11:14:04,197 maskrcnn_benchmark INFO: Validate before training
2020-06-09 11:14:04,199 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 11:15:37,025 maskrcnn_benchmark INFO: Total run time: 0:01:32.825702 (0.14852112312316895 s / img per device, on 8 devices)
2020-06-09 11:15:37,025 maskrcnn_benchmark INFO: Model inference time: 0:01:11.770481 (0.1148327693939209 s / img per device, on 8 devices)
2020-06-09 11:17:09,780 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2520;   R @ 50: 0.3401;   R @ 100: 0.3961;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2968; ngR @ 50: 0.4558; ngR @ 100: 0.5902;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1000;  zR @ 50: 0.1363;  zR @ 100: 0.1807;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1690;  mR @ 50: 0.2244;  mR @ 100: 0.2559;  for mode=predcls, type=Mean Recall.
(above:0.2155) (across:0.0000) (against:0.0000) (along:0.7821) (and:0.0000) (at:0.7892) (attached to:0.0000) (behind:0.5517) (belonging to:0.0000) (between:0.0000) (carrying:0.7281) (covered in:0.4048) (covering:0.1878) (eating:0.8571) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.1287) (has:0.5993) (holding:0.2415) (in:0.3543) (in front of:0.4943) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0657) (of:0.5745) (on:0.2635) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.7753) (part of:0.0000) (playing:0.0000) (riding:0.9286) (says:0.0000) (sitting on:0.5016) (standing on:0.1087) (to:0.0000) (under:0.2075) (using:0.1923) (walking in:0.0000) (walking on:0.9622) (watching:0.5686) (wearing:0.9707) (wears:0.0000) (with:0.2232) 
SGG eval:   A @ 20: 0.4751;   A @ 50: 0.4794;   A @ 100: 0.4794;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 11:17:10,580 maskrcnn_benchmark INFO: Start training
2020-06-09 11:17:12,890 maskrcnn_benchmark INFO: ---Total norm 0.21389 clip coef 23.37625-----------------
2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.10699, (torch.Size([4096, 12544]))
2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.10371, (torch.Size([51, 4096]))
2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06745, (torch.Size([4096, 4096]))
2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.06372, (torch.Size([4096, 12544]))
2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.06253, (torch.Size([256, 1024, 3, 3]))
2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.04697, (torch.Size([4096, 4096]))
2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.04320, (torch.Size([51, 4096]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03704, (torch.Size([4096, 1024]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.02884, (torch.Size([2048, 4808]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.02719, (torch.Size([2048, 4808]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02711, (torch.Size([51]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02602, (torch.Size([256, 128, 3, 3]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02378, (torch.Size([512, 1024]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02034, (torch.Size([128, 2, 7, 7]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01859, (torch.Size([1024, 512]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01754, (torch.Size([512, 32]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01513, (torch.Size([4096, 512]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01452, (torch.Size([256]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00907, (torch.Size([128]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00730, (torch.Size([4096]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00698, (torch.Size([151, 200]))
2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00682, (torch.Size([4096]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00626, (torch.Size([512]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00579, (torch.Size([256]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00570, (torch.Size([51]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00552, (torch.Size([2048, 512]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00529, (torch.Size([22801, 51]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00513, (torch.Size([2048, 512]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00413, (torch.Size([512]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00388, (torch.Size([1024]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00366, (torch.Size([4096]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00357, (torch.Size([128]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00300, (torch.Size([128]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00247, (torch.Size([2048]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00247, (torch.Size([2048]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00236, (torch.Size([256]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00229, (torch.Size([2048]))
2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00229, (torch.Size([2048]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00205, (torch.Size([4096]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00129, (torch.Size([4096]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00123, (torch.Size([512, 1024]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00095, (torch.Size([2048, 4424]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00086, (torch.Size([2048, 4424]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00076, (torch.Size([256]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00069, (torch.Size([512]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00040, (torch.Size([4096]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00020, (torch.Size([2048, 512]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00015, (torch.Size([2048]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00015, (torch.Size([2048]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00014, (torch.Size([2048]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00014, (torch.Size([2048]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00014, (torch.Size([2048, 512]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00004, (torch.Size([128]))
2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00001, (torch.Size([151, 200]))
2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))
2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))
2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: -------------------------------
2020-06-09 11:21:04,667 maskrcnn_benchmark INFO: eta: 11:38:21  iter: 4200  loss: 0.7182 (0.7445)  auxiliary_ctx: 0.1454 (0.1461)  auxiliary_frq: 0.1881 (0.1942)  auxiliary_vis: 0.1576 (0.1634)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2302 (0.2407)  time: 1.1601 (1.1704)  data: 0.0302 (0.0322)  lr: 0.640000  max mem: 6018
2020-06-09 11:24:57,667 maskrcnn_benchmark INFO: eta: 11:32:50  iter: 4400  loss: 0.7432 (0.7482)  auxiliary_ctx: 0.1466 (0.1469)  auxiliary_frq: 0.1958 (0.1946)  auxiliary_vis: 0.1655 (0.1647)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2405 (0.2420)  time: 1.1634 (1.1677)  data: 0.0313 (0.0306)  lr: 0.640000  max mem: 6025
2020-06-09 11:28:50,182 maskrcnn_benchmark INFO: eta: 11:27:56  iter: 4600  loss: 0.7399 (0.7473)  auxiliary_ctx: 0.1415 (0.1468)  auxiliary_frq: 0.1929 (0.1942)  auxiliary_vis: 0.1657 (0.1647)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2358 (0.2415)  time: 1.1668 (1.1660)  data: 0.0281 (0.0296)  lr: 0.640000  max mem: 6025
2020-06-09 11:32:42,897 maskrcnn_benchmark INFO: eta: 11:23:41  iter: 4800  loss: 0.7612 (0.7501)  auxiliary_ctx: 0.1474 (0.1474)  auxiliary_frq: 0.1940 (0.1944)  auxiliary_vis: 0.1690 (0.1656)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2476 (0.2428)  time: 1.1510 (1.1654)  data: 0.0302 (0.0290)  lr: 0.640000  max mem: 6025
2020-06-09 11:36:35,175 maskrcnn_benchmark INFO: eta: 11:19:20  iter: 5000  loss: 0.7478 (0.7519)  auxiliary_ctx: 0.1505 (0.1478)  auxiliary_frq: 0.1957 (0.1946)  auxiliary_vis: 0.1673 (0.1660)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2422 (0.2435)  time: 1.1754 (1.1646)  data: 0.0240 (0.0284)  lr: 0.640000  max mem: 6045
2020-06-09 11:40:27,821 maskrcnn_benchmark INFO: eta: 11:15:19  iter: 5200  loss: 0.7314 (0.7515)  auxiliary_ctx: 0.1459 (0.1477)  auxiliary_frq: 0.1915 (0.1943)  auxiliary_vis: 0.1629 (0.1660)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2403 (0.2435)  time: 1.1558 (1.1644)  data: 0.0282 (0.0283)  lr: 0.640000  max mem: 6658
2020-06-09 11:44:20,162 maskrcnn_benchmark INFO: eta: 11:11:13  iter: 5400  loss: 0.7385 (0.7517)  auxiliary_ctx: 0.1464 (0.1478)  auxiliary_frq: 0.1915 (0.1942)  auxiliary_vis: 0.1660 (0.1661)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2345 (0.2435)  time: 1.1581 (1.1640)  data: 0.0305 (0.0281)  lr: 0.640000  max mem: 6658
2020-06-09 11:48:10,849 maskrcnn_benchmark INFO: eta: 11:06:35  iter: 5600  loss: 0.7671 (0.7508)  auxiliary_ctx: 0.1523 (0.1476)  auxiliary_frq: 0.1960 (0.1940)  auxiliary_vis: 0.1647 (0.1659)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2451 (0.2433)  time: 1.1449 (1.1627)  data: 0.0269 (0.0278)  lr: 0.640000  max mem: 6658
2020-06-09 11:52:02,712 maskrcnn_benchmark INFO: eta: 11:02:30  iter: 5800  loss: 0.7431 (0.7500)  auxiliary_ctx: 0.1473 (0.1475)  auxiliary_frq: 0.1874 (0.1936)  auxiliary_vis: 0.1672 (0.1657)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2400 (0.2431)  time: 1.1497 (1.1623)  data: 0.0204 (0.0277)  lr: 0.640000  max mem: 6658
2020-06-09 11:55:54,365 maskrcnn_benchmark INFO: eta: 10:58:24  iter: 6000  loss: 0.7142 (0.7497)  auxiliary_ctx: 0.1424 (0.1476)  auxiliary_frq: 0.1859 (0.1935)  auxiliary_vis: 0.1570 (0.1656)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2400 (0.2430)  time: 1.1630 (1.1619)  data: 0.0276 (0.0275)  lr: 0.640000  max mem: 6658
2020-06-09 11:55:54,369 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0006000.pth
2020-06-09 11:55:57,033 maskrcnn_benchmark INFO: Start validating
2020-06-09 11:55:57,070 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 11:57:29,163 maskrcnn_benchmark INFO: Total run time: 0:01:32.091941 (0.14734710540771484 s / img per device, on 8 devices)
2020-06-09 11:57:29,163 maskrcnn_benchmark INFO: Model inference time: 0:01:12.706450 (0.1163303207397461 s / img per device, on 8 devices)
2020-06-09 11:59:13,365 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2229;   R @ 50: 0.3331;   R @ 100: 0.4062;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2621; ngR @ 50: 0.4429; ngR @ 100: 0.5969;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0889;  zR @ 50: 0.1296;  zR @ 100: 0.1756;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1432;  mR @ 50: 0.2048;  mR @ 100: 0.2428;  for mode=predcls, type=Mean Recall.
(above:0.1905) (across:0.0000) (against:0.0000) (along:0.6218) (and:0.0000) (at:0.7076) (attached to:0.0000) (behind:0.6488) (belonging to:0.0000) (between:0.0000) (carrying:0.6184) (covered in:0.4405) (covering:0.1837) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.1176) (has:0.5876) (holding:0.2669) (in:0.3008) (in front of:0.3547) (laying on:0.0952) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0234) (of:0.5888) (on:0.3172) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.7830) (part of:0.0000) (playing:0.0000) (riding:0.9375) (says:0.0000) (sitting on:0.5182) (standing on:0.1322) (to:0.0000) (under:0.3023) (using:0.0000) (walking in:0.0000) (walking on:0.8572) (watching:0.6863) (wearing:0.8663) (wears:0.0000) (with:0.2134) 
SGG eval:   A @ 20: 0.4952;   A @ 50: 0.4995;   A @ 100: 0.4995;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 11:59:14,168 maskrcnn_benchmark INFO: Validation Result: 0.4062
2020-06-09 12:03:05,865 maskrcnn_benchmark INFO: eta: 11:45:31  iter: 6200  loss: 0.7287 (0.7489)  auxiliary_ctx: 0.1446 (0.1475)  auxiliary_frq: 0.1896 (0.1933)  auxiliary_vis: 0.1609 (0.1653)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2336 (0.2427)  time: 1.1565 (1.2524)  data: 0.0179 (0.1181)  lr: 0.640000  max mem: 6658
2020-06-09 12:06:57,824 maskrcnn_benchmark INFO: eta: 11:37:01  iter: 6400  loss: 0.7064 (0.7477)  auxiliary_ctx: 0.1380 (0.1473)  auxiliary_frq: 0.1847 (0.1931)  auxiliary_vis: 0.1519 (0.1650)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2254 (0.2423)  time: 1.1631 (1.2447)  data: 0.0283 (0.1106)  lr: 0.640000  max mem: 6658
2020-06-09 12:10:50,290 maskrcnn_benchmark INFO: eta: 11:29:20  iter: 6600  loss: 0.7527 (0.7472)  auxiliary_ctx: 0.1456 (0.1472)  auxiliary_frq: 0.1895 (0.1929)  auxiliary_vis: 0.1617 (0.1649)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2520 (0.2422)  time: 1.1667 (1.2383)  data: 0.0281 (0.1041)  lr: 0.640000  max mem: 6658
2020-06-09 12:14:42,917 maskrcnn_benchmark INFO: eta: 11:22:14  iter: 6800  loss: 0.7445 (0.7461)  auxiliary_ctx: 0.1448 (0.1470)  auxiliary_frq: 0.1914 (0.1927)  auxiliary_vis: 0.1598 (0.1646)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2369 (0.2418)  time: 1.1455 (1.2330)  data: 0.0246 (0.0986)  lr: 0.640000  max mem: 6658
2020-06-09 12:18:35,274 maskrcnn_benchmark INFO: eta: 11:15:31  iter: 7000  loss: 0.7307 (0.7453)  auxiliary_ctx: 0.1423 (0.1469)  auxiliary_frq: 0.1923 (0.1925)  auxiliary_vis: 0.1641 (0.1644)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2402 (0.2415)  time: 1.1515 (1.2282)  data: 0.0272 (0.0939)  lr: 0.640000  max mem: 6658
2020-06-09 13:09:41,326 maskrcnn_benchmark INFO: Using 8 GPUs
2020-06-09 13:09:41,326 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE'], skip_test=False)
2020-06-09 13:09:41,326 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-09 13:09:46,234 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-09 13:09:46,235 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-09 13:09:46,235 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-09 13:09:46,238 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: TDE
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 64
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-09 13:09:46,239 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/config.yml
2020-06-09 13:09:46,271 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-09 13:09:49,571 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-09 13:09:49,571 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-09 13:09:49,572 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-09 13:09:49,573 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-09 13:09:50,998 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-09 13:09:51,412 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-09 13:09:51,446 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-09 13:09:51,448 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0006000.pth
2020-06-09 13:09:53,583 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0006000.pth
2020-06-09 13:09:54,191 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-06-09 13:09:54,191 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-09 13:09:56,937 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/labels.json
2020-06-09 13:09:58,147 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-06-09 13:09:58,147 maskrcnn_benchmark INFO: Validate before training
2020-06-09 13:09:58,150 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 13:11:28,252 maskrcnn_benchmark INFO: Total run time: 0:01:30.102600 (0.14416416053771972 s / img per device, on 8 devices)
2020-06-09 13:11:28,253 maskrcnn_benchmark INFO: Model inference time: 0:01:09.362297 (0.11097967529296875 s / img per device, on 8 devices)
2020-06-09 13:13:00,439 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2232;   R @ 50: 0.3322;   R @ 100: 0.4054;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2625; ngR @ 50: 0.4420; ngR @ 100: 0.5965;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0889;  zR @ 50: 0.1296;  zR @ 100: 0.1756;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1435;  mR @ 50: 0.2044;  mR @ 100: 0.2426;  for mode=predcls, type=Mean Recall.
(above:0.1895) (across:0.0000) (against:0.0000) (along:0.6218) (and:0.0000) (at:0.7076) (attached to:0.0000) (behind:0.6463) (belonging to:0.0000) (between:0.0000) (carrying:0.6184) (covered in:0.4405) (covering:0.1837) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.1176) (has:0.5864) (holding:0.2647) (in:0.3012) (in front of:0.3547) (laying on:0.0952) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0239) (of:0.5870) (on:0.3162) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.7830) (part of:0.0000) (playing:0.0000) (riding:0.9375) (says:0.0000) (sitting on:0.5182) (standing on:0.1322) (to:0.0000) (under:0.3023) (using:0.0000) (walking in:0.0000) (walking on:0.8572) (watching:0.6863) (wearing:0.8667) (wears:0.0000) (with:0.2125) 
SGG eval:   A @ 20: 0.4949;   A @ 50: 0.4992;   A @ 100: 0.4992;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 13:13:01,211 maskrcnn_benchmark INFO: Start training
2020-06-09 13:13:03,228 maskrcnn_benchmark INFO: ---Total norm 0.28101 clip coef 17.79280-----------------
2020-06-09 13:13:03,238 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.15195, (torch.Size([4096, 12544]))
2020-06-09 13:13:03,238 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.09684, (torch.Size([4096, 12544]))
2020-06-09 13:13:03,238 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.08358, (torch.Size([256, 1024, 3, 3]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.08253, (torch.Size([51, 4096]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.07864, (torch.Size([51, 4096]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.07508, (torch.Size([4096, 4096]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.07111, (torch.Size([4096, 4096]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.06111, (torch.Size([4096, 1024]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.04314, (torch.Size([2048, 4808]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.04114, (torch.Size([2048, 4808]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03890, (torch.Size([1024, 512]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03783, (torch.Size([512, 1024]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03406, (torch.Size([256, 128, 3, 3]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.03289, (torch.Size([512, 32]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02817, (torch.Size([128, 2, 7, 7]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02742, (torch.Size([4096, 512]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01658, (torch.Size([51]))
2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01178, (torch.Size([4096]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01177, (torch.Size([1024]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01159, (torch.Size([256]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01141, (torch.Size([512]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01132, (torch.Size([128]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01082, (torch.Size([151, 200]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00967, (torch.Size([256]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00951, (torch.Size([51]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00942, (torch.Size([4096]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00885, (torch.Size([512]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00875, (torch.Size([2048, 512]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00811, (torch.Size([2048, 512]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00707, (torch.Size([22801, 51]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00627, (torch.Size([4096]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00566, (torch.Size([2048]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00566, (torch.Size([2048]))
2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00497, (torch.Size([2048]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00497, (torch.Size([2048]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00444, (torch.Size([128]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00295, (torch.Size([128]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00255, (torch.Size([256]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00226, (torch.Size([4096]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00209, (torch.Size([4096]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00092, (torch.Size([256]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00085, (torch.Size([2048, 4424]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00077, (torch.Size([2048, 4424]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00056, (torch.Size([4096]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00017, (torch.Size([512, 1024]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00014, (torch.Size([512]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00004, (torch.Size([2048, 512]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00003, (torch.Size([2048]))
2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00003, (torch.Size([2048]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00003, (torch.Size([2048, 512]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00002, (torch.Size([2048]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00002, (torch.Size([2048]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00001, (torch.Size([151, 200]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: -------------------------------
2020-06-09 13:16:51,725 maskrcnn_benchmark INFO: eta: 10:49:16  iter: 6200  loss: 0.7310 (0.7456)  auxiliary_ctx: 0.1449 (0.1476)  auxiliary_frq: 0.1868 (0.1923)  auxiliary_vis: 0.1581 (0.1636)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2425 (0.2421)  time: 1.1507 (1.1526)  data: 0.0274 (0.0301)  lr: 0.640000  max mem: 6316
2020-06-09 13:20:41,370 maskrcnn_benchmark INFO: eta: 10:44:13  iter: 6400  loss: 0.7262 (0.7484)  auxiliary_ctx: 0.1420 (0.1482)  auxiliary_frq: 0.1855 (0.1924)  auxiliary_vis: 0.1588 (0.1646)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2345 (0.2432)  time: 1.1427 (1.1504)  data: 0.0251 (0.0273)  lr: 0.640000  max mem: 6316
2020-06-09 13:24:31,515 maskrcnn_benchmark INFO: eta: 10:40:26  iter: 6600  loss: 0.7307 (0.7441)  auxiliary_ctx: 0.1495 (0.1471)  auxiliary_frq: 0.1906 (0.1915)  auxiliary_vis: 0.1586 (0.1639)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2377 (0.2416)  time: 1.1410 (1.1505)  data: 0.0278 (0.0268)  lr: 0.640000  max mem: 6316
2020-06-09 13:28:21,376 maskrcnn_benchmark INFO: eta: 10:36:26  iter: 6800  loss: 0.7185 (0.7435)  auxiliary_ctx: 0.1482 (0.1470)  auxiliary_frq: 0.1866 (0.1911)  auxiliary_vis: 0.1581 (0.1639)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2283 (0.2416)  time: 1.1471 (1.1502)  data: 0.0262 (0.0264)  lr: 0.640000  max mem: 6316
2020-06-09 13:32:11,333 maskrcnn_benchmark INFO: eta: 10:32:33  iter: 7000  loss: 0.7196 (0.7443)  auxiliary_ctx: 0.1404 (0.1472)  auxiliary_frq: 0.1907 (0.1912)  auxiliary_vis: 0.1575 (0.1641)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2260 (0.2418)  time: 1.1481 (1.1501)  data: 0.0252 (0.0259)  lr: 0.640000  max mem: 6316
2020-06-09 13:36:01,357 maskrcnn_benchmark INFO: eta: 10:28:43  iter: 7200  loss: 0.7269 (0.7440)  auxiliary_ctx: 0.1477 (0.1472)  auxiliary_frq: 0.1885 (0.1912)  auxiliary_vis: 0.1595 (0.1639)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2326 (0.2418)  time: 1.1626 (1.1501)  data: 0.0264 (0.0257)  lr: 0.640000  max mem: 6316
2020-06-09 13:39:51,021 maskrcnn_benchmark INFO: eta: 10:24:45  iter: 7400  loss: 0.7014 (0.7432)  auxiliary_ctx: 0.1416 (0.1470)  auxiliary_frq: 0.1838 (0.1910)  auxiliary_vis: 0.1548 (0.1638)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2234 (0.2415)  time: 1.1379 (1.1499)  data: 0.0177 (0.0252)  lr: 0.640000  max mem: 6316
2020-06-09 13:43:40,486 maskrcnn_benchmark INFO: eta: 10:20:45  iter: 7600  loss: 0.7566 (0.7430)  auxiliary_ctx: 0.1505 (0.1470)  auxiliary_frq: 0.1896 (0.1908)  auxiliary_vis: 0.1649 (0.1637)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2494 (0.2415)  time: 1.1371 (1.1495)  data: 0.0220 (0.0250)  lr: 0.640000  max mem: 6316
2020-06-09 13:47:30,518 maskrcnn_benchmark INFO: eta: 10:16:57  iter: 7800  loss: 0.7548 (0.7424)  auxiliary_ctx: 0.1553 (0.1469)  auxiliary_frq: 0.1895 (0.1906)  auxiliary_vis: 0.1685 (0.1636)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2454 (0.2413)  time: 1.1417 (1.1496)  data: 0.0241 (0.0246)  lr: 0.640000  max mem: 6316
2020-06-09 13:51:20,610 maskrcnn_benchmark INFO: ---Total norm 0.23787 clip coef 21.01965-----------------
2020-06-09 13:51:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.13979, (torch.Size([4096, 12544]))
2020-06-09 13:51:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.09050, (torch.Size([4096, 12544]))
2020-06-09 13:51:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.08111, (torch.Size([256, 1024, 3, 3]))
2020-06-09 13:51:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06818, (torch.Size([4096, 4096]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06240, (torch.Size([4096, 4096]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.05788, (torch.Size([51, 4096]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.04814, (torch.Size([51, 4096]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04050, (torch.Size([4096, 1024]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03190, (torch.Size([256, 128, 3, 3]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03124, (torch.Size([2048, 4808]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03066, (torch.Size([2048, 4808]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02691, (torch.Size([128, 2, 7, 7]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02544, (torch.Size([1024, 512]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02275, (torch.Size([512, 1024]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02068, (torch.Size([512, 32]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01482, (torch.Size([128]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01410, (torch.Size([4096, 512]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00997, (torch.Size([151, 200]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00851, (torch.Size([256]))
2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00780, (torch.Size([2048, 512]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00707, (torch.Size([2048, 512]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00700, (torch.Size([256]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00696, (torch.Size([51]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00632, (torch.Size([22801, 51]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00620, (torch.Size([512]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00602, (torch.Size([51]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00597, (torch.Size([4096]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00575, (torch.Size([4096]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00552, (torch.Size([1024]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00533, (torch.Size([128]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00531, (torch.Size([512]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00502, (torch.Size([4096]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00430, (torch.Size([2048]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00430, (torch.Size([2048]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00311, (torch.Size([128]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00286, (torch.Size([2048]))
2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00286, (torch.Size([2048]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00236, (torch.Size([256]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00196, (torch.Size([4096]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00196, (torch.Size([4096]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00094, (torch.Size([256]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00060, (torch.Size([4096]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00043, (torch.Size([512]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00042, (torch.Size([512, 1024]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00041, (torch.Size([2048, 4424]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00039, (torch.Size([2048, 4424]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00005, (torch.Size([2048]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00005, (torch.Size([2048]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00004, (torch.Size([2048, 512]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00004, (torch.Size([2048]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00004, (torch.Size([2048]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00002, (torch.Size([2048, 512]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: -------------------------------
2020-06-09 13:51:20,627 maskrcnn_benchmark INFO: eta: 10:13:10  iter: 8000  loss: 0.7197 (0.7417)  auxiliary_ctx: 0.1423 (0.1468)  auxiliary_frq: 0.1879 (0.1906)  auxiliary_vis: 0.1602 (0.1634)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2304 (0.2410)  time: 1.1401 (1.1497)  data: 0.0270 (0.0246)  lr: 0.640000  max mem: 6316
2020-06-09 13:51:20,630 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0008000.pth
2020-06-09 13:51:23,162 maskrcnn_benchmark INFO: Start validating
2020-06-09 13:51:23,194 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 13:52:54,326 maskrcnn_benchmark INFO: Total run time: 0:01:31.131692 (0.14581070671081542 s / img per device, on 8 devices)
2020-06-09 13:52:54,326 maskrcnn_benchmark INFO: Model inference time: 0:01:10.586701 (0.1129387222290039 s / img per device, on 8 devices)
2020-06-09 13:54:27,805 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2349;   R @ 50: 0.3245;   R @ 100: 0.3823;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2908; ngR @ 50: 0.4674; ngR @ 100: 0.6169;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0822;  zR @ 50: 0.1289;  zR @ 100: 0.1570;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1756;  mR @ 50: 0.2371;  mR @ 100: 0.2706;  for mode=predcls, type=Mean Recall.
(above:0.2658) (across:0.0000) (against:0.0000) (along:0.6667) (and:0.0000) (at:0.6857) (attached to:0.0229) (behind:0.5187) (belonging to:0.0000) (between:0.0000) (carrying:0.7083) (covered in:0.4405) (covering:0.2639) (eating:1.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.3603) (has:0.5211) (holding:0.4191) (in:0.3745) (in front of:0.4588) (laying on:0.0000) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0184) (of:0.4182) (on:0.3196) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.9124) (part of:0.0000) (playing:0.0000) (riding:0.9330) (says:0.0000) (sitting on:0.6511) (standing on:0.1902) (to:0.0000) (under:0.3180) (using:0.0385) (walking in:0.0000) (walking on:0.9473) (watching:0.6275) (wearing:0.5517) (wears:0.3795) (with:0.3408) 
SGG eval:   A @ 20: 0.4344;   A @ 50: 0.4382;   A @ 100: 0.4382;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 13:54:28,566 maskrcnn_benchmark INFO: Validation Result: 0.3823
2020-06-09 13:58:18,014 maskrcnn_benchmark INFO: eta: 10:54:30  iter: 8200  loss: 0.7496 (0.7411)  auxiliary_ctx: 0.1468 (0.1467)  auxiliary_frq: 0.1955 (0.1904)  auxiliary_vis: 0.1742 (0.1632)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2361 (0.2408)  time: 1.1398 (1.2349)  data: 0.0206 (0.1099)  lr: 0.640000  max mem: 6376
2020-06-09 14:02:08,076 maskrcnn_benchmark INFO: eta: 10:46:40  iter: 8400  loss: 0.7183 (0.7409)  auxiliary_ctx: 0.1429 (0.1466)  auxiliary_frq: 0.1865 (0.1903)  auxiliary_vis: 0.1573 (0.1632)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2247 (0.2407)  time: 1.1482 (1.2279)  data: 0.0234 (0.1028)  lr: 0.640000  max mem: 6376
2020-06-09 14:05:58,271 maskrcnn_benchmark INFO: eta: 10:39:29  iter: 8600  loss: 0.6910 (0.7407)  auxiliary_ctx: 0.1385 (0.1466)  auxiliary_frq: 0.1828 (0.1902)  auxiliary_vis: 0.1534 (0.1632)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2283 (0.2407)  time: 1.1463 (1.2219)  data: 0.0237 (0.0968)  lr: 0.640000  max mem: 6376
2020-06-09 14:09:48,196 maskrcnn_benchmark INFO: eta: 10:32:43  iter: 8800  loss: 0.7290 (0.7399)  auxiliary_ctx: 0.1403 (0.1464)  auxiliary_frq: 0.1866 (0.1900)  auxiliary_vis: 0.1569 (0.1630)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2346 (0.2404)  time: 1.1440 (1.2168)  data: 0.0258 (0.0915)  lr: 0.640000  max mem: 6376
2020-06-09 14:13:37,897 maskrcnn_benchmark INFO: eta: 10:26:19  iter: 9000  loss: 0.7641 (0.7392)  auxiliary_ctx: 0.1482 (0.1463)  auxiliary_frq: 0.1928 (0.1899)  auxiliary_vis: 0.1683 (0.1628)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2528 (0.2401)  time: 1.1434 (1.2122)  data: 0.0272 (0.0871)  lr: 0.640000  max mem: 6376
2020-06-09 14:17:27,724 maskrcnn_benchmark INFO: eta: 10:20:15  iter: 9200  loss: 0.7320 (0.7389)  auxiliary_ctx: 0.1473 (0.1463)  auxiliary_frq: 0.1868 (0.1898)  auxiliary_vis: 0.1576 (0.1628)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2350 (0.2400)  time: 1.1444 (1.2083)  data: 0.0259 (0.0832)  lr: 0.640000  max mem: 6376
2020-06-09 14:21:17,409 maskrcnn_benchmark INFO: eta: 10:14:25  iter: 9400  loss: 0.7119 (0.7383)  auxiliary_ctx: 0.1389 (0.1462)  auxiliary_frq: 0.1841 (0.1896)  auxiliary_vis: 0.1583 (0.1626)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2316 (0.2399)  time: 1.1439 (1.2048)  data: 0.0211 (0.0798)  lr: 0.640000  max mem: 6460
2020-06-09 14:25:07,324 maskrcnn_benchmark INFO: eta: 10:08:51  iter: 9600  loss: 0.7379 (0.7382)  auxiliary_ctx: 0.1417 (0.1462)  auxiliary_frq: 0.1858 (0.1895)  auxiliary_vis: 0.1606 (0.1626)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2312 (0.2399)  time: 1.1428 (1.2017)  data: 0.0211 (0.0766)  lr: 0.640000  max mem: 6460
2020-06-09 14:28:57,007 maskrcnn_benchmark INFO: eta: 10:03:26  iter: 9800  loss: 0.7238 (0.7379)  auxiliary_ctx: 0.1423 (0.1462)  auxiliary_frq: 0.1827 (0.1894)  auxiliary_vis: 0.1523 (0.1625)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2315 (0.2398)  time: 1.1448 (1.1989)  data: 0.0182 (0.0738)  lr: 0.640000  max mem: 6460
2020-06-09 14:32:47,243 maskrcnn_benchmark INFO: eta: 9:58:15  iter: 10000  loss: 0.6749 (0.7371)  auxiliary_ctx: 0.1352 (0.1460)  auxiliary_frq: 0.1802 (0.1893)  auxiliary_vis: 0.1490 (0.1623)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2154 (0.2395)  time: 1.1480 (1.1965)  data: 0.0228 (0.0714)  lr: 0.640000  max mem: 6460
2020-06-09 14:32:47,246 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0010000.pth
2020-06-09 14:32:49,441 maskrcnn_benchmark INFO: Start validating
2020-06-09 14:32:49,474 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 14:34:20,373 maskrcnn_benchmark INFO: Total run time: 0:01:30.898760 (0.14543801574707033 s / img per device, on 8 devices)
2020-06-09 14:34:20,374 maskrcnn_benchmark INFO: Model inference time: 0:01:10.134195 (0.11221471214294433 s / img per device, on 8 devices)
2020-06-09 14:35:55,112 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2532;   R @ 50: 0.3618;   R @ 100: 0.4269;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3114; ngR @ 50: 0.4984; ngR @ 100: 0.6415;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0756;  zR @ 50: 0.1489;  zR @ 100: 0.1785;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1706;  mR @ 50: 0.2449;  mR @ 100: 0.2799;  for mode=predcls, type=Mean Recall.
(above:0.2082) (across:0.0000) (against:0.0000) (along:0.7372) (and:0.0000) (at:0.8271) (attached to:0.0459) (behind:0.5347) (belonging to:0.0000) (between:0.0000) (carrying:0.7412) (covered in:0.5833) (covering:0.3095) (eating:0.8571) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.4044) (has:0.5941) (holding:0.2650) (in:0.3224) (in front of:0.4912) (laying on:0.0952) (looking at:0.0217) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0193) (of:0.5958) (on:0.4092) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.8806) (part of:0.0000) (playing:0.0000) (riding:0.8438) (says:0.0000) (sitting on:0.5818) (standing on:0.2261) (to:0.0000) (under:0.3227) (using:0.1923) (walking in:0.0000) (walking on:0.9283) (watching:0.6471) (wearing:0.4468) (wears:0.4175) (with:0.2986) 
SGG eval:   A @ 20: 0.4990;   A @ 50: 0.5037;   A @ 100: 0.5037;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 14:35:55,878 maskrcnn_benchmark INFO: Validation Result: 0.4269
2020-06-09 14:39:45,761 maskrcnn_benchmark INFO: eta: 10:15:27  iter: 10200  loss: 0.7203 (0.7366)  auxiliary_ctx: 0.1450 (0.1460)  auxiliary_frq: 0.1863 (0.1891)  auxiliary_vis: 0.1588 (0.1622)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2310 (0.2393)  time: 1.1421 (1.2392)  data: 0.0271 (0.1141)  lr: 0.640000  max mem: 6460
2020-06-09 14:43:35,747 maskrcnn_benchmark INFO: eta: 10:09:19  iter: 10400  loss: 0.7157 (0.7366)  auxiliary_ctx: 0.1436 (0.1460)  auxiliary_frq: 0.1823 (0.1891)  auxiliary_vis: 0.1620 (0.1622)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2362 (0.2393)  time: 1.1560 (1.2351)  data: 0.0250 (0.1101)  lr: 0.640000  max mem: 6460
2020-06-09 14:47:25,830 maskrcnn_benchmark INFO: eta: 10:03:24  iter: 10600  loss: 0.7234 (0.7362)  auxiliary_ctx: 0.1425 (0.1459)  auxiliary_frq: 0.1888 (0.1890)  auxiliary_vis: 0.1570 (0.1621)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2387 (0.2392)  time: 1.1384 (1.2314)  data: 0.0253 (0.1063)  lr: 0.640000  max mem: 6460
2020-06-09 14:51:15,505 maskrcnn_benchmark INFO: eta: 9:57:36  iter: 10800  loss: 0.7033 (0.7359)  auxiliary_ctx: 0.1371 (0.1459)  auxiliary_frq: 0.1808 (0.1889)  auxiliary_vis: 0.1559 (0.1620)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2275 (0.2391)  time: 1.1445 (1.2280)  data: 0.0180 (0.1029)  lr: 0.640000  max mem: 6460
2020-06-09 14:55:05,957 maskrcnn_benchmark INFO: eta: 9:52:03  iter: 11000  loss: 0.6908 (0.7355)  auxiliary_ctx: 0.1372 (0.1459)  auxiliary_frq: 0.1823 (0.1888)  auxiliary_vis: 0.1565 (0.1619)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2311 (0.2389)  time: 1.1466 (1.2249)  data: 0.0202 (0.0997)  lr: 0.640000  max mem: 6460
2020-06-09 14:58:55,920 maskrcnn_benchmark INFO: eta: 9:46:35  iter: 11200  loss: 0.7205 (0.7353)  auxiliary_ctx: 0.1417 (0.1459)  auxiliary_frq: 0.1852 (0.1887)  auxiliary_vis: 0.1634 (0.1619)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2485 (0.2389)  time: 1.1456 (1.2221)  data: 0.0262 (0.0969)  lr: 0.640000  max mem: 6460
2020-06-09 15:02:46,006 maskrcnn_benchmark INFO: eta: 9:41:15  iter: 11400  loss: 0.7248 (0.7353)  auxiliary_ctx: 0.1498 (0.1459)  auxiliary_frq: 0.1850 (0.1886)  auxiliary_vis: 0.1657 (0.1618)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2324 (0.2389)  time: 1.1415 (1.2194)  data: 0.0262 (0.0942)  lr: 0.640000  max mem: 6460
2020-06-09 15:06:36,143 maskrcnn_benchmark INFO: eta: 9:36:01  iter: 11600  loss: 0.7097 (0.7348)  auxiliary_ctx: 0.1421 (0.1458)  auxiliary_frq: 0.1880 (0.1886)  auxiliary_vis: 0.1585 (0.1617)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2273 (0.2387)  time: 1.1516 (1.2170)  data: 0.0250 (0.0917)  lr: 0.640000  max mem: 6460
2020-06-09 15:10:25,615 maskrcnn_benchmark INFO: eta: 9:30:50  iter: 11800  loss: 0.7244 (0.7344)  auxiliary_ctx: 0.1451 (0.1458)  auxiliary_frq: 0.1813 (0.1884)  auxiliary_vis: 0.1582 (0.1616)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2323 (0.2386)  time: 1.1492 (1.2146)  data: 0.0248 (0.0894)  lr: 0.640000  max mem: 6460
2020-06-09 15:14:16,178 maskrcnn_benchmark INFO: ---Total norm 0.26517 clip coef 18.85568-----------------
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.16787, (torch.Size([4096, 12544]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.09149, (torch.Size([4096, 12544]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.08105, (torch.Size([256, 1024, 3, 3]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.07374, (torch.Size([4096, 4096]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.07146, (torch.Size([4096, 4096]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05436, (torch.Size([51, 4096]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.05033, (torch.Size([51, 4096]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04834, (torch.Size([4096, 1024]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03785, (torch.Size([2048, 4808]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.03653, (torch.Size([512, 32]))
2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03599, (torch.Size([2048, 4808]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02932, (torch.Size([512, 1024]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02873, (torch.Size([1024, 512]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02813, (torch.Size([256, 128, 3, 3]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02580, (torch.Size([128, 2, 7, 7]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01745, (torch.Size([4096, 512]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01268, (torch.Size([512]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01052, (torch.Size([1024]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01032, (torch.Size([51]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01020, (torch.Size([151, 200]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01014, (torch.Size([128]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00966, (torch.Size([512]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00921, (torch.Size([4096]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00843, (torch.Size([4096]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00815, (torch.Size([2048, 512]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00807, (torch.Size([2048, 512]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00709, (torch.Size([51]))
2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00665, (torch.Size([22801, 51]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00647, (torch.Size([2048]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00647, (torch.Size([2048]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00554, (torch.Size([2048]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00554, (torch.Size([2048]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00496, (torch.Size([256]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00485, (torch.Size([4096]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00455, (torch.Size([128]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00445, (torch.Size([256]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00319, (torch.Size([128]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00226, (torch.Size([4096]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00225, (torch.Size([256]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00183, (torch.Size([4096]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00083, (torch.Size([256]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00059, (torch.Size([512]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00055, (torch.Size([4096]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00050, (torch.Size([512, 1024]))
2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00011, (torch.Size([2048, 4424]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00007, (torch.Size([2048, 4424]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00002, (torch.Size([2048]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00002, (torch.Size([2048]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00001, (torch.Size([2048]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00001, (torch.Size([2048]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00001, (torch.Size([2048, 512]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00001, (torch.Size([2048, 512]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: -------------------------------
2020-06-09 15:14:16,194 maskrcnn_benchmark INFO: eta: 9:25:49  iter: 12000  loss: 0.6961 (0.7339)  auxiliary_ctx: 0.1384 (0.1457)  auxiliary_frq: 0.1810 (0.1883)  auxiliary_vis: 0.1494 (0.1615)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2189 (0.2384)  time: 1.1515 (1.2125)  data: 0.0258 (0.0872)  lr: 0.640000  max mem: 6460
2020-06-09 15:14:16,197 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0012000.pth
2020-06-09 15:14:18,456 maskrcnn_benchmark INFO: Start validating
2020-06-09 15:14:18,510 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 15:15:49,236 maskrcnn_benchmark INFO: Total run time: 0:01:30.725488 (0.14516078071594238 s / img per device, on 8 devices)
2020-06-09 15:15:49,236 maskrcnn_benchmark INFO: Model inference time: 0:01:09.548147 (0.11127703552246093 s / img per device, on 8 devices)
2020-06-09 15:17:22,052 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2452;   R @ 50: 0.3504;   R @ 100: 0.4141;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2882; ngR @ 50: 0.4622; ngR @ 100: 0.6101;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0889;  zR @ 50: 0.1415;  zR @ 100: 0.1578;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1687;  mR @ 50: 0.2256;  mR @ 100: 0.2597;  for mode=predcls, type=Mean Recall.
(above:0.2432) (across:0.0000) (against:0.0000) (along:0.5000) (and:0.0000) (at:0.6561) (attached to:0.0000) (behind:0.5327) (belonging to:0.0000) (between:0.0000) (carrying:0.7741) (covered in:0.3690) (covering:0.2299) (eating:0.2857) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.7721) (has:0.5883) (holding:0.2120) (in:0.3119) (in front of:0.4917) (laying on:0.0000) (looking at:0.1087) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0285) (of:0.5246) (on:0.3655) (on back of:0.0000) (over:0.0793) (painted on:0.0000) (parked on:0.8847) (part of:0.0000) (playing:0.0000) (riding:0.9286) (says:0.0000) (sitting on:0.5991) (standing on:0.1250) (to:0.0000) (under:0.4324) (using:0.1923) (walking in:0.0000) (walking on:0.9661) (watching:0.6275) (wearing:0.5296) (wears:0.3146) (with:0.2748) 
SGG eval:   A @ 20: 0.4831;   A @ 50: 0.4875;   A @ 100: 0.4875;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 15:17:22,825 maskrcnn_benchmark INFO: Validation Result: 0.4141
2020-06-09 15:21:12,457 maskrcnn_benchmark INFO: eta: 9:34:46  iter: 12200  loss: 0.7027 (0.7336)  auxiliary_ctx: 0.1396 (0.1456)  auxiliary_frq: 0.1829 (0.1882)  auxiliary_vis: 0.1520 (0.1614)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2215 (0.2383)  time: 1.1503 (1.2405)  data: 0.0254 (0.1153)  lr: 0.640000  max mem: 6460
2020-06-09 15:25:02,102 maskrcnn_benchmark INFO: eta: 9:29:18  iter: 12400  loss: 0.7152 (0.7332)  auxiliary_ctx: 0.1405 (0.1456)  auxiliary_frq: 0.1863 (0.1881)  auxiliary_vis: 0.1546 (0.1613)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2290 (0.2382)  time: 1.1446 (1.2376)  data: 0.0256 (0.1124)  lr: 0.640000  max mem: 6460
2020-06-09 15:28:52,207 maskrcnn_benchmark INFO: eta: 9:23:58  iter: 12600  loss: 0.7331 (0.7328)  auxiliary_ctx: 0.1454 (0.1455)  auxiliary_frq: 0.1860 (0.1880)  auxiliary_vis: 0.1617 (0.1612)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2350 (0.2380)  time: 1.1527 (1.2350)  data: 0.0249 (0.1098)  lr: 0.640000  max mem: 6460
2020-06-09 15:32:41,349 maskrcnn_benchmark INFO: eta: 9:18:40  iter: 12800  loss: 0.7041 (0.7323)  auxiliary_ctx: 0.1397 (0.1455)  auxiliary_frq: 0.1835 (0.1879)  auxiliary_vis: 0.1547 (0.1611)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2177 (0.2379)  time: 1.1421 (1.2324)  data: 0.0228 (0.1072)  lr: 0.640000  max mem: 6460
2020-06-09 15:36:31,992 maskrcnn_benchmark INFO: eta: 9:13:32  iter: 13000  loss: 0.6919 (0.7320)  auxiliary_ctx: 0.1354 (0.1454)  auxiliary_frq: 0.1777 (0.1878)  auxiliary_vis: 0.1517 (0.1610)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2236 (0.2378)  time: 1.1571 (1.2301)  data: 0.0252 (0.1049)  lr: 0.640000  max mem: 6460
2020-06-09 15:40:21,918 maskrcnn_benchmark INFO: eta: 9:08:27  iter: 13200  loss: 0.6953 (0.7322)  auxiliary_ctx: 0.1436 (0.1455)  auxiliary_frq: 0.1772 (0.1878)  auxiliary_vis: 0.1567 (0.1610)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2267 (0.2379)  time: 1.1470 (1.2279)  data: 0.0255 (0.1026)  lr: 0.640000  max mem: 6460
2020-06-09 15:44:12,555 maskrcnn_benchmark INFO: eta: 9:03:27  iter: 13400  loss: 0.7165 (0.7317)  auxiliary_ctx: 0.1447 (0.1454)  auxiliary_frq: 0.1873 (0.1877)  auxiliary_vis: 0.1553 (0.1609)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2323 (0.2377)  time: 1.1504 (1.2259)  data: 0.0252 (0.1004)  lr: 0.640000  max mem: 6460
2020-06-09 15:48:02,597 maskrcnn_benchmark INFO: eta: 8:58:30  iter: 13600  loss: 0.6963 (0.7316)  auxiliary_ctx: 0.1391 (0.1454)  auxiliary_frq: 0.1810 (0.1876)  auxiliary_vis: 0.1526 (0.1609)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2232 (0.2377)  time: 1.1453 (1.2239)  data: 0.0216 (0.0984)  lr: 0.640000  max mem: 6570
2020-06-09 15:51:52,183 maskrcnn_benchmark INFO: eta: 8:53:34  iter: 13800  loss: 0.7170 (0.7314)  auxiliary_ctx: 0.1433 (0.1454)  auxiliary_frq: 0.1860 (0.1875)  auxiliary_vis: 0.1600 (0.1608)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2234 (0.2376)  time: 1.1406 (1.2219)  data: 0.0243 (0.0965)  lr: 0.640000  max mem: 6570
2020-06-09 15:55:42,232 maskrcnn_benchmark INFO: eta: 8:48:43  iter: 14000  loss: 0.7014 (0.7311)  auxiliary_ctx: 0.1420 (0.1454)  auxiliary_frq: 0.1831 (0.1874)  auxiliary_vis: 0.1537 (0.1607)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2197 (0.2375)  time: 1.1374 (1.2201)  data: 0.0263 (0.0947)  lr: 0.640000  max mem: 6570
2020-06-09 15:55:42,235 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0014000.pth
2020-06-09 15:55:44,665 maskrcnn_benchmark INFO: Start validating
2020-06-09 15:55:44,713 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 15:57:14,974 maskrcnn_benchmark INFO: Total run time: 0:01:30.260776 (0.14441724166870118 s / img per device, on 8 devices)
2020-06-09 15:57:14,974 maskrcnn_benchmark INFO: Model inference time: 0:01:09.535037 (0.11125605926513672 s / img per device, on 8 devices)
2020-06-09 15:58:51,015 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2441;   R @ 50: 0.3395;   R @ 100: 0.3954;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3063; ngR @ 50: 0.4930; ngR @ 100: 0.6367;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1059;  zR @ 50: 0.1370;  zR @ 100: 0.1674;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1900;  mR @ 50: 0.2443;  mR @ 100: 0.2765;  for mode=predcls, type=Mean Recall.
(above:0.2046) (across:0.0000) (against:0.0000) (along:0.6154) (and:0.0000) (at:0.7791) (attached to:0.0564) (behind:0.5036) (belonging to:0.0000) (between:0.0000) (carrying:0.7281) (covered in:0.2143) (covering:0.2483) (eating:1.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.6765) (has:0.5976) (holding:0.4066) (in:0.3432) (in front of:0.5064) (laying on:0.0476) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0539) (of:0.4782) (on:0.3954) (on back of:0.0000) (over:0.1098) (painted on:0.0000) (parked on:0.8681) (part of:0.0000) (playing:0.0000) (riding:0.9241) (says:0.0000) (sitting on:0.5283) (standing on:0.1424) (to:0.0000) (under:0.2679) (using:0.1923) (walking in:0.0000) (walking on:0.9554) (watching:0.6863) (wearing:0.0239) (wears:0.8873) (with:0.2801) 
SGG eval:   A @ 20: 0.4589;   A @ 50: 0.4641;   A @ 100: 0.4641;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 15:58:51,762 maskrcnn_benchmark INFO: Validation Result: 0.3954
2020-06-09 15:58:51,763 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-06-09 16:02:41,463 maskrcnn_benchmark INFO: eta: 8:53:50  iter: 14200  loss: 0.6884 (0.7302)  auxiliary_ctx: 0.1360 (0.1452)  auxiliary_frq: 0.1829 (0.1874)  auxiliary_vis: 0.1465 (0.1605)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2119 (0.2371)  time: 1.1526 (1.2415)  data: 0.0250 (0.1160)  lr: 0.064000  max mem: 6570
2020-06-09 16:06:31,136 maskrcnn_benchmark INFO: eta: 8:48:45  iter: 14400  loss: 0.6792 (0.7291)  auxiliary_ctx: 0.1355 (0.1450)  auxiliary_frq: 0.1838 (0.1873)  auxiliary_vis: 0.1457 (0.1601)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2109 (0.2367)  time: 1.1416 (1.2393)  data: 0.0256 (0.1139)  lr: 0.064000  max mem: 6570
2020-06-09 16:10:21,542 maskrcnn_benchmark INFO: eta: 8:43:46  iter: 14600  loss: 0.6602 (0.7276)  auxiliary_ctx: 0.1315 (0.1447)  auxiliary_frq: 0.1806 (0.1872)  auxiliary_vis: 0.1409 (0.1597)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2008 (0.2360)  time: 1.1352 (1.2372)  data: 0.0249 (0.1117)  lr: 0.064000  max mem: 6570
2020-06-09 16:14:11,049 maskrcnn_benchmark INFO: eta: 8:38:47  iter: 14800  loss: 0.6812 (0.7263)  auxiliary_ctx: 0.1344 (0.1444)  auxiliary_frq: 0.1847 (0.1871)  auxiliary_vis: 0.1438 (0.1593)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2154 (0.2355)  time: 1.1426 (1.2352)  data: 0.0241 (0.1097)  lr: 0.064000  max mem: 6570
2020-06-09 16:18:01,173 maskrcnn_benchmark INFO: eta: 8:33:53  iter: 15000  loss: 0.6842 (0.7250)  auxiliary_ctx: 0.1342 (0.1441)  auxiliary_frq: 0.1894 (0.1871)  auxiliary_vis: 0.1413 (0.1589)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2080 (0.2349)  time: 1.1441 (1.2333)  data: 0.0261 (0.1078)  lr: 0.064000  max mem: 6570
2020-06-09 16:21:51,010 maskrcnn_benchmark INFO: eta: 8:29:01  iter: 15200  loss: 0.6459 (0.7235)  auxiliary_ctx: 0.1293 (0.1439)  auxiliary_frq: 0.1814 (0.1870)  auxiliary_vis: 0.1329 (0.1584)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2013 (0.2342)  time: 1.1525 (1.2315)  data: 0.0191 (0.1060)  lr: 0.064000  max mem: 6570
2020-06-09 16:25:41,396 maskrcnn_benchmark INFO: eta: 8:24:13  iter: 15400  loss: 0.6511 (0.7222)  auxiliary_ctx: 0.1313 (0.1436)  auxiliary_frq: 0.1826 (0.1870)  auxiliary_vis: 0.1335 (0.1579)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1991 (0.2336)  time: 1.1484 (1.2298)  data: 0.0255 (0.1042)  lr: 0.064000  max mem: 6570
2020-06-09 16:29:32,111 maskrcnn_benchmark INFO: eta: 8:19:28  iter: 15600  loss: 0.6296 (0.7207)  auxiliary_ctx: 0.1235 (0.1433)  auxiliary_frq: 0.1790 (0.1869)  auxiliary_vis: 0.1316 (0.1575)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1901 (0.2329)  time: 1.1441 (1.2282)  data: 0.0243 (0.1026)  lr: 0.064000  max mem: 6570
2020-06-09 16:33:21,402 maskrcnn_benchmark INFO: eta: 8:14:42  iter: 15800  loss: 0.6455 (0.7193)  auxiliary_ctx: 0.1305 (0.1431)  auxiliary_frq: 0.1834 (0.1869)  auxiliary_vis: 0.1295 (0.1570)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1985 (0.2323)  time: 1.1402 (1.2265)  data: 0.0257 (0.1010)  lr: 0.064000  max mem: 6570
2020-06-09 16:37:11,194 maskrcnn_benchmark INFO: ---Total norm 0.40948 clip coef 12.21072-----------------
2020-06-09 16:37:11,203 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.29877, (torch.Size([4096, 12544]))
2020-06-09 16:37:11,203 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.14996, (torch.Size([4096, 12544]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.10378, (torch.Size([256, 1024, 3, 3]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.09945, (torch.Size([4096, 4096]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.09590, (torch.Size([4096, 4096]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.07359, (torch.Size([51, 4096]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.06515, (torch.Size([512, 32]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.04789, (torch.Size([4096, 512]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.04749, (torch.Size([2048, 4808]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04723, (torch.Size([4096, 1024]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.04554, (torch.Size([2048, 4808]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.04534, (torch.Size([51, 4096]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03487, (torch.Size([256, 128, 3, 3]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02951, (torch.Size([512, 1024]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02568, (torch.Size([1024, 512]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02037, (torch.Size([128, 2, 7, 7]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01763, (torch.Size([512]))
2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01680, (torch.Size([512]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01401, (torch.Size([51]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01260, (torch.Size([151, 200]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01200, (torch.Size([4096]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01166, (torch.Size([1024]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01095, (torch.Size([2048]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01095, (torch.Size([2048]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01094, (torch.Size([2048, 512]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01087, (torch.Size([4096]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01085, (torch.Size([2048, 512]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00975, (torch.Size([2048]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00975, (torch.Size([2048]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00845, (torch.Size([51]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00745, (torch.Size([128]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00700, (torch.Size([256]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00576, (torch.Size([4096]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00512, (torch.Size([22801, 51]))
2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00476, (torch.Size([256]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00439, (torch.Size([4096]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00371, (torch.Size([128]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00285, (torch.Size([256]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00279, (torch.Size([4096]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00273, (torch.Size([128]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00098, (torch.Size([256]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00089, (torch.Size([4096]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00081, (torch.Size([512, 1024]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00080, (torch.Size([512]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00013, (torch.Size([2048, 4424]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00010, (torch.Size([2048, 4424]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00004, (torch.Size([2048]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00004, (torch.Size([2048]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00003, (torch.Size([2048]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00003, (torch.Size([2048]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00003, (torch.Size([2048, 512]))
2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00002, (torch.Size([2048, 512]))
2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: -------------------------------
2020-06-09 16:37:11,210 maskrcnn_benchmark INFO: eta: 8:09:59  iter: 16000  loss: 0.6136 (0.7177)  auxiliary_ctx: 0.1250 (0.1428)  auxiliary_frq: 0.1815 (0.1868)  auxiliary_vis: 0.1243 (0.1565)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1855 (0.2316)  time: 1.1452 (1.2250)  data: 0.0243 (0.0994)  lr: 0.064000  max mem: 6570
2020-06-09 16:37:11,212 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0016000.pth
2020-06-09 16:37:13,509 maskrcnn_benchmark INFO: Start validating
2020-06-09 16:37:13,540 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 16:38:43,321 maskrcnn_benchmark INFO: Total run time: 0:01:29.780335 (0.1436485366821289 s / img per device, on 8 devices)
2020-06-09 16:38:43,322 maskrcnn_benchmark INFO: Model inference time: 0:01:09.708071 (0.111532914352417 s / img per device, on 8 devices)
2020-06-09 16:40:17,256 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2278;   R @ 50: 0.3229;   R @ 100: 0.3872;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2807; ngR @ 50: 0.4605; ngR @ 100: 0.6130;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0941;  zR @ 50: 0.1593;  zR @ 100: 0.1807;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1924;  mR @ 50: 0.2588;  mR @ 100: 0.2962;  for mode=predcls, type=Mean Recall.
(above:0.2380) (across:0.0000) (against:0.0000) (along:0.7051) (and:0.0323) (at:0.7758) (attached to:0.0413) (behind:0.5030) (belonging to:0.1071) (between:0.0000) (carrying:0.8333) (covered in:0.5119) (covering:0.3381) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.6103) (has:0.5807) (holding:0.3430) (in:0.3587) (in front of:0.5137) (laying on:0.0476) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0630) (of:0.5002) (on:0.3227) (on back of:0.0000) (over:0.1524) (painted on:0.0000) (parked on:0.9083) (part of:0.0000) (playing:0.0000) (riding:0.9196) (says:0.0000) (sitting on:0.6036) (standing on:0.2370) (to:0.1111) (under:0.3788) (using:0.1154) (walking in:0.0000) (walking on:0.9713) (watching:0.7451) (wearing:0.3834) (wears:0.4994) (with:0.2947) 
SGG eval:   A @ 20: 0.4654;   A @ 50: 0.4698;   A @ 100: 0.4698;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 16:40:18,021 maskrcnn_benchmark INFO: Validation Result: 0.3872
2020-06-09 16:44:07,754 maskrcnn_benchmark INFO: eta: 8:12:35  iter: 16200  loss: 0.6383 (0.7161)  auxiliary_ctx: 0.1287 (0.1425)  auxiliary_frq: 0.1858 (0.1868)  auxiliary_vis: 0.1315 (0.1560)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1940 (0.2308)  time: 1.1401 (1.2418)  data: 0.0253 (0.1162)  lr: 0.064000  max mem: 6570
2020-06-09 16:47:58,270 maskrcnn_benchmark INFO: eta: 8:07:46  iter: 16400  loss: 0.6294 (0.7144)  auxiliary_ctx: 0.1302 (0.1423)  auxiliary_frq: 0.1851 (0.1867)  auxiliary_vis: 0.1264 (0.1554)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1903 (0.2300)  time: 1.1475 (1.2401)  data: 0.0257 (0.1144)  lr: 0.064000  max mem: 6570
2020-06-09 16:51:48,338 maskrcnn_benchmark INFO: eta: 8:02:58  iter: 16600  loss: 0.6180 (0.7127)  auxiliary_ctx: 0.1247 (0.1420)  auxiliary_frq: 0.1837 (0.1867)  auxiliary_vis: 0.1251 (0.1549)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1860 (0.2292)  time: 1.1599 (1.2384)  data: 0.0251 (0.1127)  lr: 0.064000  max mem: 6570
2020-06-09 16:55:38,184 maskrcnn_benchmark INFO: eta: 7:58:12  iter: 16800  loss: 0.6044 (0.7111)  auxiliary_ctx: 0.1246 (0.1417)  auxiliary_frq: 0.1821 (0.1867)  auxiliary_vis: 0.1250 (0.1543)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1857 (0.2285)  time: 1.1480 (1.2368)  data: 0.0184 (0.1111)  lr: 0.064000  max mem: 6570
2020-06-09 16:59:27,873 maskrcnn_benchmark INFO: eta: 7:53:28  iter: 17000  loss: 0.6124 (0.7093)  auxiliary_ctx: 0.1262 (0.1414)  auxiliary_frq: 0.1859 (0.1866)  auxiliary_vis: 0.1236 (0.1537)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1779 (0.2276)  time: 1.1485 (1.2352)  data: 0.0265 (0.1095)  lr: 0.064000  max mem: 6570
2020-06-09 17:03:18,076 maskrcnn_benchmark INFO: eta: 7:48:47  iter: 17200  loss: 0.5802 (0.7076)  auxiliary_ctx: 0.1198 (0.1411)  auxiliary_frq: 0.1739 (0.1866)  auxiliary_vis: 0.1149 (0.1532)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1670 (0.2268)  time: 1.1562 (1.2336)  data: 0.0257 (0.1080)  lr: 0.064000  max mem: 6570
2020-06-09 17:07:08,079 maskrcnn_benchmark INFO: eta: 7:44:07  iter: 17400  loss: 0.6008 (0.7057)  auxiliary_ctx: 0.1249 (0.1408)  auxiliary_frq: 0.1826 (0.1865)  auxiliary_vis: 0.1178 (0.1526)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1764 (0.2259)  time: 1.1441 (1.2322)  data: 0.0252 (0.1065)  lr: 0.064000  max mem: 6570
2020-06-09 17:10:57,962 maskrcnn_benchmark INFO: eta: 7:39:28  iter: 17600  loss: 0.6128 (0.7040)  auxiliary_ctx: 0.1275 (0.1405)  auxiliary_frq: 0.1844 (0.1864)  auxiliary_vis: 0.1228 (0.1520)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1793 (0.2250)  time: 1.1481 (1.2308)  data: 0.0240 (0.1051)  lr: 0.064000  max mem: 6570
2020-06-09 17:14:47,980 maskrcnn_benchmark INFO: eta: 7:34:52  iter: 17800  loss: 0.5953 (0.7022)  auxiliary_ctx: 0.1229 (0.1402)  auxiliary_frq: 0.1863 (0.1864)  auxiliary_vis: 0.1145 (0.1514)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1664 (0.2242)  time: 1.1407 (1.2294)  data: 0.0259 (0.1037)  lr: 0.064000  max mem: 6570
2020-06-09 17:18:38,036 maskrcnn_benchmark INFO: eta: 7:30:17  iter: 18000  loss: 0.5913 (0.7004)  auxiliary_ctx: 0.1223 (0.1399)  auxiliary_frq: 0.1866 (0.1864)  auxiliary_vis: 0.1153 (0.1508)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1598 (0.2233)  time: 1.1556 (1.2281)  data: 0.0261 (0.1024)  lr: 0.064000  max mem: 6570
2020-06-09 17:18:38,039 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0018000.pth
2020-06-09 17:18:40,278 maskrcnn_benchmark INFO: Start validating
2020-06-09 17:18:40,319 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 17:20:11,020 maskrcnn_benchmark INFO: Total run time: 0:01:30.700822 (0.1451213146209717 s / img per device, on 8 devices)
2020-06-09 17:20:11,021 maskrcnn_benchmark INFO: Model inference time: 0:01:09.849605 (0.11175936775207519 s / img per device, on 8 devices)
2020-06-09 17:21:44,010 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2346;   R @ 50: 0.3335;   R @ 100: 0.3897;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2832; ngR @ 50: 0.4650; ngR @ 100: 0.6124;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1030;  zR @ 50: 0.1585;  zR @ 100: 0.1896;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.2040;  mR @ 50: 0.2676;  mR @ 100: 0.3052;  for mode=predcls, type=Mean Recall.
(above:0.2884) (across:0.0000) (against:0.0526) (along:0.7436) (and:0.0645) (at:0.7185) (attached to:0.0197) (behind:0.4954) (belonging to:0.3000) (between:0.0000) (carrying:0.7807) (covered in:0.7024) (covering:0.4095) (eating:1.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.2000) (hanging from:0.4375) (has:0.5096) (holding:0.3096) (in:0.3426) (in front of:0.5078) (laying on:0.2143) (looking at:0.0870) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0475) (of:0.2824) (on:0.3878) (on back of:0.0000) (over:0.1037) (painted on:0.0000) (parked on:0.9034) (part of:0.0000) (playing:0.0000) (riding:0.9018) (says:0.0000) (sitting on:0.5994) (standing on:0.2326) (to:0.1667) (under:0.3980) (using:0.1346) (walking in:0.0000) (walking on:0.9777) (watching:0.6863) (wearing:0.2459) (wears:0.6514) (with:0.3223) 
SGG eval:   A @ 20: 0.4567;   A @ 50: 0.4613;   A @ 100: 0.4613;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 17:21:44,780 maskrcnn_benchmark INFO: Validation Result: 0.3897
2020-06-09 17:21:44,780 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-06-09 17:25:35,095 maskrcnn_benchmark INFO: eta: 7:31:18  iter: 18200  loss: 0.5699 (0.6984)  auxiliary_ctx: 0.1146 (0.1396)  auxiliary_frq: 0.1827 (0.1863)  auxiliary_vis: 0.1082 (0.1502)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1612 (0.2223)  time: 1.1457 (1.2421)  data: 0.0256 (0.1164)  lr: 0.006400  max mem: 6570
2020-06-09 17:29:25,388 maskrcnn_benchmark INFO: eta: 7:26:38  iter: 18400  loss: 0.5958 (0.6963)  auxiliary_ctx: 0.1250 (0.1393)  auxiliary_frq: 0.1855 (0.1863)  auxiliary_vis: 0.1148 (0.1495)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1681 (0.2213)  time: 1.1441 (1.2407)  data: 0.0214 (0.1149)  lr: 0.006400  max mem: 6570
2020-06-09 17:33:15,836 maskrcnn_benchmark INFO: eta: 7:22:00  iter: 18600  loss: 0.5710 (0.6942)  auxiliary_ctx: 0.1193 (0.1389)  auxiliary_frq: 0.1873 (0.1862)  auxiliary_vis: 0.1085 (0.1488)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1528 (0.2203)  time: 1.1465 (1.2393)  data: 0.0256 (0.1135)  lr: 0.006400  max mem: 6570
2020-06-09 17:37:06,160 maskrcnn_benchmark INFO: eta: 7:17:23  iter: 18800  loss: 0.5494 (0.6921)  auxiliary_ctx: 0.1150 (0.1385)  auxiliary_frq: 0.1849 (0.1862)  auxiliary_vis: 0.1006 (0.1481)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1442 (0.2192)  time: 1.1472 (1.2379)  data: 0.0263 (0.1121)  lr: 0.006400  max mem: 6570
2020-06-09 17:40:56,168 maskrcnn_benchmark INFO: eta: 7:12:47  iter: 19000  loss: 0.5252 (0.6898)  auxiliary_ctx: 0.1099 (0.1382)  auxiliary_frq: 0.1798 (0.1861)  auxiliary_vis: 0.0950 (0.1474)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1402 (0.2181)  time: 1.1539 (1.2365)  data: 0.0243 (0.1108)  lr: 0.006400  max mem: 6570
2020-06-09 17:44:46,437 maskrcnn_benchmark INFO: eta: 7:08:13  iter: 19200  loss: 0.5501 (0.6877)  auxiliary_ctx: 0.1119 (0.1378)  auxiliary_frq: 0.1807 (0.1861)  auxiliary_vis: 0.1027 (0.1467)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1474 (0.2171)  time: 1.1504 (1.2352)  data: 0.0259 (0.1094)  lr: 0.006400  max mem: 6570
2020-06-09 17:48:36,747 maskrcnn_benchmark INFO: eta: 7:03:40  iter: 19400  loss: 0.5498 (0.6856)  auxiliary_ctx: 0.1136 (0.1374)  auxiliary_frq: 0.1843 (0.1861)  auxiliary_vis: 0.1041 (0.1460)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1449 (0.2160)  time: 1.1417 (1.2340)  data: 0.0232 (0.1081)  lr: 0.006400  max mem: 6570
2020-06-09 17:52:27,329 maskrcnn_benchmark INFO: eta: 6:59:09  iter: 19600  loss: 0.5151 (0.6834)  auxiliary_ctx: 0.1086 (0.1371)  auxiliary_frq: 0.1816 (0.1860)  auxiliary_vis: 0.0914 (0.1454)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1372 (0.2150)  time: 1.1476 (1.2328)  data: 0.0263 (0.1069)  lr: 0.006400  max mem: 6570
2020-06-09 17:56:17,131 maskrcnn_benchmark INFO: eta: 6:54:38  iter: 19800  loss: 0.5411 (0.6813)  auxiliary_ctx: 0.1163 (0.1367)  auxiliary_frq: 0.1857 (0.1860)  auxiliary_vis: 0.1002 (0.1447)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1421 (0.2139)  time: 1.1473 (1.2316)  data: 0.0201 (0.1057)  lr: 0.006400  max mem: 6570
2020-06-09 18:00:07,292 maskrcnn_benchmark INFO: ---Total norm 0.79692 clip coef 6.27412-----------------
2020-06-09 18:00:07,302 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.61810, (torch.Size([4096, 12544]))
2020-06-09 18:00:07,302 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.37834, (torch.Size([4096, 12544]))
2020-06-09 18:00:07,302 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.19996, (torch.Size([4096, 4096]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.15556, (torch.Size([256, 1024, 3, 3]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.15001, (torch.Size([4096, 4096]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.06588, (torch.Size([51, 4096]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.06041, (torch.Size([256, 128, 3, 3]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.04949, (torch.Size([2048, 4808]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04917, (torch.Size([4096, 1024]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.04883, (torch.Size([2048, 4808]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.04546, (torch.Size([51, 4096]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03981, (torch.Size([128, 2, 7, 7]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02745, (torch.Size([1024, 512]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02718, (torch.Size([4096, 512]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02345, (torch.Size([512, 1024]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01931, (torch.Size([512, 32]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01845, (torch.Size([151, 200]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01602, (torch.Size([128]))
2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01355, (torch.Size([4096]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01257, (torch.Size([2048, 512]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01134, (torch.Size([2048, 512]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00942, (torch.Size([256]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00903, (torch.Size([51]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00830, (torch.Size([512]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00726, (torch.Size([2048]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00726, (torch.Size([2048]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00709, (torch.Size([4096]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00705, (torch.Size([1024]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00701, (torch.Size([4096]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00668, (torch.Size([256]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00600, (torch.Size([2048]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00600, (torch.Size([2048]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00581, (torch.Size([4096]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00576, (torch.Size([128]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00572, (torch.Size([512]))
2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00549, (torch.Size([22801, 51]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00519, (torch.Size([256]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00487, (torch.Size([51]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00483, (torch.Size([128]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00456, (torch.Size([4096]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00206, (torch.Size([4096]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00138, (torch.Size([256]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00039, (torch.Size([512]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00037, (torch.Size([512, 1024]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00001, (torch.Size([2048, 4424]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: -------------------------------
2020-06-09 18:00:07,309 maskrcnn_benchmark INFO: eta: 6:50:08  iter: 20000  loss: 0.5278 (0.6792)  auxiliary_ctx: 0.1135 (0.1363)  auxiliary_frq: 0.1844 (0.1860)  auxiliary_vis: 0.0929 (0.1440)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1361 (0.2129)  time: 1.1516 (1.2304)  data: 0.0232 (0.1045)  lr: 0.006400  max mem: 6570
2020-06-09 18:00:07,311 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0020000.pth
2020-06-09 18:00:09,630 maskrcnn_benchmark INFO: Start validating
2020-06-09 18:00:09,659 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 18:01:39,617 maskrcnn_benchmark INFO: Total run time: 0:01:29.958360 (0.14393337631225586 s / img per device, on 8 devices)
2020-06-09 18:01:39,618 maskrcnn_benchmark INFO: Model inference time: 0:01:09.230126 (0.11076820220947266 s / img per device, on 8 devices)
2020-06-09 18:03:12,217 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2133;   R @ 50: 0.3144;   R @ 100: 0.3778;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2614; ngR @ 50: 0.4384; ngR @ 100: 0.5939;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1178;  zR @ 50: 0.1756;  zR @ 100: 0.1978;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1913;  mR @ 50: 0.2603;  mR @ 100: 0.3006;  for mode=predcls, type=Mean Recall.
(above:0.2184) (across:0.0000) (against:0.0351) (along:0.7821) (and:0.0645) (at:0.7101) (attached to:0.0380) (behind:0.5113) (belonging to:0.3917) (between:0.0000) (carrying:0.7807) (covered in:0.6310) (covering:0.3238) (eating:0.8571) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.1667) (hanging from:0.5184) (has:0.4608) (holding:0.2994) (in:0.3598) (in front of:0.5261) (laying on:0.2143) (looking at:0.1087) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0494) (of:0.1992) (on:0.3271) (on back of:0.0000) (over:0.2000) (painted on:0.0000) (parked on:0.9073) (part of:0.0000) (playing:0.0000) (riding:0.9107) (says:0.0000) (sitting on:0.5713) (standing on:0.2141) (to:0.1389) (under:0.3610) (using:0.2885) (walking in:0.0000) (walking on:0.9512) (watching:0.6863) (wearing:0.5804) (wears:0.2766) (with:0.3322) 
SGG eval:   A @ 20: 0.4512;   A @ 50: 0.4549;   A @ 100: 0.4549;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 18:03:12,962 maskrcnn_benchmark INFO: Validation Result: 0.3778
2020-06-09 18:07:02,556 maskrcnn_benchmark INFO: eta: 6:49:58  iter: 20200  loss: 0.5254 (0.6772)  auxiliary_ctx: 0.1086 (0.1360)  auxiliary_frq: 0.1819 (0.1859)  auxiliary_vis: 0.0917 (0.1434)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1396 (0.2119)  time: 1.1428 (1.2423)  data: 0.0251 (0.1164)  lr: 0.006400  max mem: 6570
2020-06-09 18:10:52,541 maskrcnn_benchmark INFO: eta: 6:45:24  iter: 20400  loss: 0.5255 (0.6751)  auxiliary_ctx: 0.1104 (0.1356)  auxiliary_frq: 0.1834 (0.1859)  auxiliary_vis: 0.0956 (0.1427)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1392 (0.2109)  time: 1.1440 (1.2411)  data: 0.0254 (0.1151)  lr: 0.006400  max mem: 6570
2020-06-09 18:14:42,800 maskrcnn_benchmark INFO: eta: 6:40:52  iter: 20600  loss: 0.5073 (0.6731)  auxiliary_ctx: 0.1046 (0.1353)  auxiliary_frq: 0.1787 (0.1859)  auxiliary_vis: 0.0911 (0.1420)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1315 (0.2099)  time: 1.1489 (1.2398)  data: 0.0259 (0.1139)  lr: 0.006400  max mem: 6570
2020-06-09 18:18:32,632 maskrcnn_benchmark INFO: eta: 6:36:21  iter: 20800  loss: 0.5010 (0.6711)  auxiliary_ctx: 0.1053 (0.1349)  auxiliary_frq: 0.1783 (0.1859)  auxiliary_vis: 0.0898 (0.1414)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1315 (0.2089)  time: 1.1469 (1.2386)  data: 0.0256 (0.1127)  lr: 0.006400  max mem: 6570
2020-06-09 18:22:23,173 maskrcnn_benchmark INFO: eta: 6:31:51  iter: 21000  loss: 0.5315 (0.6691)  auxiliary_ctx: 0.1126 (0.1346)  auxiliary_frq: 0.1846 (0.1858)  auxiliary_vis: 0.0948 (0.1407)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1394 (0.2079)  time: 1.1494 (1.2375)  data: 0.0208 (0.1115)  lr: 0.006400  max mem: 6570
2020-06-09 18:26:13,501 maskrcnn_benchmark INFO: eta: 6:27:23  iter: 21200  loss: 0.5263 (0.6671)  auxiliary_ctx: 0.1113 (0.1343)  auxiliary_frq: 0.1867 (0.1858)  auxiliary_vis: 0.0936 (0.1401)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1341 (0.2069)  time: 1.1439 (1.2363)  data: 0.0253 (0.1103)  lr: 0.006400  max mem: 6570
2020-06-09 18:30:03,302 maskrcnn_benchmark INFO: eta: 6:22:54  iter: 21400  loss: 0.5055 (0.6652)  auxiliary_ctx: 0.1044 (0.1339)  auxiliary_frq: 0.1831 (0.1858)  auxiliary_vis: 0.0891 (0.1395)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1330 (0.2060)  time: 1.1429 (1.2352)  data: 0.0255 (0.1092)  lr: 0.006400  max mem: 6570
2020-06-09 18:33:52,870 maskrcnn_benchmark INFO: eta: 6:18:27  iter: 21600  loss: 0.5005 (0.6633)  auxiliary_ctx: 0.1046 (0.1336)  auxiliary_frq: 0.1828 (0.1858)  auxiliary_vis: 0.0884 (0.1389)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1321 (0.2050)  time: 1.1497 (1.2341)  data: 0.0256 (0.1081)  lr: 0.006400  max mem: 6570
2020-06-09 18:37:43,278 maskrcnn_benchmark INFO: eta: 6:14:01  iter: 21800  loss: 0.5202 (0.6613)  auxiliary_ctx: 0.1055 (0.1333)  auxiliary_frq: 0.1852 (0.1857)  auxiliary_vis: 0.0929 (0.1382)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1296 (0.2040)  time: 1.1474 (1.2330)  data: 0.0247 (0.1071)  lr: 0.006400  max mem: 6570
2020-06-09 18:41:33,341 maskrcnn_benchmark INFO: eta: 6:09:36  iter: 22000  loss: 0.4795 (0.6593)  auxiliary_ctx: 0.1011 (0.1329)  auxiliary_frq: 0.1821 (0.1857)  auxiliary_vis: 0.0822 (0.1376)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1136 (0.2031)  time: 1.1513 (1.2320)  data: 0.0250 (0.1060)  lr: 0.006400  max mem: 6570
2020-06-09 18:41:33,344 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0022000.pth
2020-06-09 18:41:35,757 maskrcnn_benchmark INFO: Start validating
2020-06-09 18:41:35,784 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-09 18:43:06,026 maskrcnn_benchmark INFO: Total run time: 0:01:30.241856 (0.14438696899414064 s / img per device, on 8 devices)
2020-06-09 18:43:06,026 maskrcnn_benchmark INFO: Model inference time: 0:01:10.400124 (0.11264019889831543 s / img per device, on 8 devices)
2020-06-09 18:44:39,813 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2198;   R @ 50: 0.3194;   R @ 100: 0.3815;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2645; ngR @ 50: 0.4354; ngR @ 100: 0.5853;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1222;  zR @ 50: 0.1637;  zR @ 100: 0.1874;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1922;  mR @ 50: 0.2617;  mR @ 100: 0.3048;  for mode=predcls, type=Mean Recall.
(above:0.2356) (across:0.0000) (against:0.0877) (along:0.7051) (and:0.0645) (at:0.7101) (attached to:0.0564) (behind:0.5131) (belonging to:0.4321) (between:0.0000) (carrying:0.7544) (covered in:0.6667) (covering:0.3238) (eating:1.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.2333) (hanging from:0.4890) (has:0.4842) (holding:0.3162) (in:0.3477) (in front of:0.5195) (laying on:0.1667) (looking at:0.1522) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0574) (of:0.1920) (on:0.3169) (on back of:0.0000) (over:0.2000) (painted on:0.0000) (parked on:0.8994) (part of:0.0000) (playing:0.0000) (riding:0.9107) (says:0.0000) (sitting on:0.5710) (standing on:0.1938) (to:0.2500) (under:0.3686) (using:0.2115) (walking in:0.0000) (walking on:0.9382) (watching:0.6863) (wearing:0.6657) (wears:0.1934) (with:0.2896) 
SGG eval:   A @ 20: 0.4544;   A @ 50: 0.4585;   A @ 100: 0.4585;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-09 18:44:40,579 maskrcnn_benchmark INFO: Validation Result: 0.3815
2020-06-09 18:44:40,579 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-06-09 18:44:40,579 maskrcnn_benchmark INFO: Trigger MAX_DECAY_STEP at iteration 22000.
2020-06-09 18:44:40,872 maskrcnn_benchmark INFO: Total training time: 5:31:39.661527 (0.4975 s / it)
2020-06-09 18:44:42,825 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).
2020-06-09 18:52:34,686 maskrcnn_benchmark INFO: Total run time: 0:07:51.860212 (0.1427392306165905 s / img per device, on 8 devices)
2020-06-09 18:52:34,686 maskrcnn_benchmark INFO: Model inference time: 0:06:12.209526 (0.1125945778790269 s / img per device, on 8 devices)
2020-06-09 19:01:17,444 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9995
====================================================================================================
SGG eval:   R @ 20: 0.2503;   R @ 50: 0.3583;   R @ 100: 0.4147;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.2947; ngR @ 50: 0.4774; ngR @ 100: 0.6148;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0765;  zR @ 50: 0.1217;  zR @ 100: 0.1507;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1735;  mR @ 50: 0.2466;  mR @ 100: 0.2881;  for mode=predcls, type=Mean Recall.
(above:0.2126) (across:0.0000) (against:0.0645) (along:0.3731) (and:0.0651) (at:0.5288) (attached to:0.0573) (behind:0.5791) (belonging to:0.4395) (between:0.0035) (carrying:0.6556) (covered in:0.7220) (covering:0.4043) (eating:0.6625) (flying in:0.0000) (for:0.1210) (from:0.0000) (growing on:0.1897) (hanging from:0.3042) (has:0.5607) (holding:0.4697) (in:0.3309) (in front of:0.4084) (laying on:0.2849) (looking at:0.1422) (lying on:0.0102) (made of:0.0000) (mounted on:0.0104) (near:0.0484) (of:0.2657) (on:0.3058) (on back of:0.0591) (over:0.1727) (painted on:0.0216) (parked on:0.8238) (part of:0.0000) (playing:0.0000) (riding:0.8881) (says:0.0000) (sitting on:0.5616) (standing on:0.2560) (to:0.1298) (under:0.4380) (using:0.2964) (walking in:0.0070) (walking on:0.8113) (watching:0.6163) (wearing:0.7736) (wears:0.0993) (with:0.2313) 
SGG eval:   A @ 20: 0.4617;   A @ 50: 0.4634;   A @ 100: 0.4634;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

