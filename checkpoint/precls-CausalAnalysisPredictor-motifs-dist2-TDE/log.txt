2020-06-11 12:06:39,211 maskrcnn_benchmark INFO: Using 8 GPUs
2020-06-11 12:06:39,211 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'dist', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE'], skip_test=False)
2020-06-11 12:06:39,211 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-11 12:06:44,426 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-11 12:06:44,426 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-11 12:06:44,427 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate', 'dist'
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-11 12:06:44,429 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: TDE
      FUSION_TYPE: dist
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 64
  MAX_ITER: 40000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 8
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-11 12:06:44,430 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/config.yml
2020-06-11 12:06:44,463 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-11 12:06:47,738 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-11 12:06:47,738 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-11 12:07:15,050 maskrcnn_benchmark.data.build INFO: finish
2020-06-11 12:07:15,050 maskrcnn_benchmark.data.build INFO: Save data statistics to: checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-11 12:07:15,050 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-11 12:07:16,326 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-11 12:07:16,992 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-11 12:07:17,021 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-11 12:07:17,022 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth
2020-06-11 12:07:17,806 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)
2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)
2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2020-06-11 12:07:23,440 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-06-11 12:07:23,440 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-11 12:07:26,144 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/labels.json
2020-06-11 12:07:27,376 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-06-11 12:07:27,376 maskrcnn_benchmark INFO: Validate before training
2020-06-11 12:07:27,385 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 12:09:01,796 maskrcnn_benchmark INFO: Total run time: 0:01:34.410239 (0.1510563823699951 s / img per device, on 8 devices)
2020-06-11 12:09:01,796 maskrcnn_benchmark INFO: Model inference time: 0:01:12.328440 (0.11572550468444824 s / img per device, on 8 devices)
2020-06-11 12:10:10,087 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.0091;   R @ 50: 0.0125;   R @ 100: 0.0148;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.0147; ngR @ 50: 0.0313; ngR @ 100: 0.0582;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0044;  zR @ 50: 0.0044;  zR @ 100: 0.0044;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0134;  mR @ 50: 0.0164;  mR @ 100: 0.0216;  for mode=predcls, type=Mean Recall.
(above:0.0526) (across:0.0556) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1667) (attached to:0.0000) (behind:0.1286) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0714) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.0000) (holding:0.0178) (in:0.0005) (in front of:0.0000) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0145) (near:0.0087) (of:0.0016) (on:0.0086) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0079) (part of:0.0444) (playing:0.0000) (riding:0.0045) (says:0.0000) (sitting on:0.0933) (standing on:0.0000) (to:0.0833) (under:0.2134) (using:0.0192) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.0017) (wears:0.0044) (with:0.0110) 
SGG eval:   A @ 20: 0.0135;   A @ 50: 0.0135;   A @ 100: 0.0135;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 12:10:10,854 maskrcnn_benchmark INFO: Start training
2020-06-11 12:10:12,991 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------
2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: inf, (torch.Size([51]))
2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: inf, (torch.Size([51, 4096]))
2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 75856.36719, (torch.Size([4096, 512]))
2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 62804.63281, (torch.Size([51]))
2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 24718.42773, (torch.Size([4096]))
2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 23484.37891, (torch.Size([512, 32]))
2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 7341.17041, (torch.Size([512]))
2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 773.82178, (torch.Size([22801, 51]))
2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 19.48577, (torch.Size([4096, 4096]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 18.34809, (torch.Size([4096, 12544]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 3.66618, (torch.Size([256, 1024, 3, 3]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.74206, (torch.Size([256, 128, 3, 3]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 1.24670, (torch.Size([51, 4096]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.70901, (torch.Size([512, 1024]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.70414, (torch.Size([4096, 1024]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.58350, (torch.Size([4096, 4096]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.40628, (torch.Size([128, 2, 7, 7]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.36159, (torch.Size([2048, 4808]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.34821, (torch.Size([2048, 4808]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.27938, (torch.Size([4096, 12544]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.27581, (torch.Size([512]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.22798, (torch.Size([4096]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.16336, (torch.Size([256]))
2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.09734, (torch.Size([4096]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.08560, (torch.Size([256]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.07801, (torch.Size([128]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.07708, (torch.Size([512, 1024]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.06171, (torch.Size([2048, 512]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.05970, (torch.Size([2048, 512]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.04464, (torch.Size([4096]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.03948, (torch.Size([2048, 4424]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.03729, (torch.Size([2048]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.03729, (torch.Size([2048]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.03596, (torch.Size([2048]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.03596, (torch.Size([2048]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.03585, (torch.Size([2048, 4424]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.03340, (torch.Size([128]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.03339, (torch.Size([256]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.03104, (torch.Size([128]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.02973, (torch.Size([256]))
2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.02953, (torch.Size([512]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02947, (torch.Size([1024, 512]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.02745, (torch.Size([1024]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01582, (torch.Size([4096]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00651, (torch.Size([2048, 512]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00615, (torch.Size([2048, 512]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00392, (torch.Size([2048]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00392, (torch.Size([2048]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00363, (torch.Size([4096]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00355, (torch.Size([2048]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00355, (torch.Size([2048]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00275, (torch.Size([151, 200]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00202, (torch.Size([128, 32]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00133, (torch.Size([32, 9]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00084, (torch.Size([128]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00052, (torch.Size([32]))
2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00031, (torch.Size([151, 200]))
2020-06-11 12:10:13,005 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00019, (torch.Size([32]))
2020-06-11 12:10:13,005 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-11 12:10:13,005 maskrcnn_benchmark INFO: -------------------------------
2020-06-11 12:14:02,701 maskrcnn_benchmark INFO: eta: 12:48:57  iter: 200  loss: 2.7360 (3.2315)  auxiliary_ctx: 0.2188 (0.4506)  auxiliary_frq: 0.2050 (0.2088)  auxiliary_vis: 0.1915 (0.3114)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1337 (2.2606)  time: 1.1488 (1.1592)  data: 0.0258 (0.0297)  lr: 0.293248  max mem: 6059
2020-06-11 12:17:53,730 maskrcnn_benchmark INFO: eta: 12:43:44  iter: 400  loss: 2.7367 (2.9893)  auxiliary_ctx: 0.2014 (0.3341)  auxiliary_frq: 0.2056 (0.2079)  auxiliary_vis: 0.1812 (0.2491)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1353 (2.1981)  time: 1.1625 (1.1572)  data: 0.0262 (0.0276)  lr: 0.523648  max mem: 6059
2020-06-11 12:21:44,230 maskrcnn_benchmark INFO: eta: 12:38:51  iter: 600  loss: 2.6536 (2.8927)  auxiliary_ctx: 0.1730 (0.2873)  auxiliary_frq: 0.2004 (0.2070)  auxiliary_vis: 0.1653 (0.2254)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1136 (2.1730)  time: 1.1487 (1.1556)  data: 0.0268 (0.0268)  lr: 0.640000  max mem: 6119
2020-06-11 12:25:35,060 maskrcnn_benchmark INFO: eta: 12:34:46  iter: 800  loss: 2.6744 (2.8401)  auxiliary_ctx: 0.1816 (0.2619)  auxiliary_frq: 0.2061 (0.2060)  auxiliary_vis: 0.1757 (0.2126)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1182 (2.1596)  time: 1.1477 (1.1553)  data: 0.0262 (0.0266)  lr: 0.640000  max mem: 6119
2020-06-11 12:29:25,555 maskrcnn_benchmark INFO: eta: 12:30:33  iter: 1000  loss: 2.6534 (2.8060)  auxiliary_ctx: 0.1778 (0.2457)  auxiliary_frq: 0.1967 (0.2051)  auxiliary_vis: 0.1613 (0.2041)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1118 (2.1511)  time: 1.1450 (1.1547)  data: 0.0273 (0.0265)  lr: 0.640000  max mem: 6119
2020-06-11 12:33:16,521 maskrcnn_benchmark INFO: eta: 12:26:43  iter: 1200  loss: 2.6344 (2.7805)  auxiliary_ctx: 0.1596 (0.2336)  auxiliary_frq: 0.1955 (0.2042)  auxiliary_vis: 0.1592 (0.1978)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1094 (2.1448)  time: 1.1593 (1.1547)  data: 0.0254 (0.0264)  lr: 0.640000  max mem: 6119
2020-06-11 12:37:07,412 maskrcnn_benchmark INFO: eta: 12:22:50  iter: 1400  loss: 2.6578 (2.7605)  auxiliary_ctx: 0.1655 (0.2244)  auxiliary_frq: 0.1997 (0.2032)  auxiliary_vis: 0.1650 (0.1928)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1128 (2.1401)  time: 1.1432 (1.1547)  data: 0.0260 (0.0264)  lr: 0.640000  max mem: 6119
2020-06-11 12:40:57,629 maskrcnn_benchmark INFO: eta: 12:18:42  iter: 1600  loss: 2.6454 (2.7462)  auxiliary_ctx: 0.1685 (0.2177)  auxiliary_frq: 0.1961 (0.2025)  auxiliary_vis: 0.1615 (0.1892)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1112 (2.1368)  time: 1.1508 (1.1542)  data: 0.0267 (0.0262)  lr: 0.640000  max mem: 6119
2020-06-11 12:44:48,013 maskrcnn_benchmark INFO: eta: 12:14:41  iter: 1800  loss: 2.6420 (2.7347)  auxiliary_ctx: 0.1668 (0.2124)  auxiliary_frq: 0.1967 (0.2019)  auxiliary_vis: 0.1664 (0.1864)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1133 (2.1340)  time: 1.1473 (1.1540)  data: 0.0260 (0.0262)  lr: 0.640000  max mem: 6119
2020-06-11 12:48:38,293 maskrcnn_benchmark INFO: eta: 12:10:41  iter: 2000  loss: 2.6401 (2.7253)  auxiliary_ctx: 0.1730 (0.2081)  auxiliary_frq: 0.1933 (0.2013)  auxiliary_vis: 0.1670 (0.1840)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1095 (2.1319)  time: 1.1596 (1.1537)  data: 0.0273 (0.0262)  lr: 0.640000  max mem: 6119
2020-06-11 12:48:38,296 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0002000.pth
2020-06-11 12:48:40,868 maskrcnn_benchmark INFO: Start validating
2020-06-11 12:48:40,884 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 12:50:13,253 maskrcnn_benchmark INFO: Total run time: 0:01:32.368775 (0.1477900405883789 s / img per device, on 8 devices)
2020-06-11 12:50:13,254 maskrcnn_benchmark INFO: Model inference time: 0:01:12.632277 (0.1162116439819336 s / img per device, on 8 devices)
2020-06-11 12:51:48,976 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.2884;   R @ 50: 0.3548;   R @ 100: 0.3768;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.3983; ngR @ 50: 0.6042; ngR @ 100: 0.7504;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1067;  zR @ 50: 0.1563;  zR @ 100: 0.1711;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1438;  mR @ 50: 0.1800;  mR @ 100: 0.1945;  for mode=predcls, type=Mean Recall.
(above:0.5120) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2212) (attached to:0.0092) (behind:0.4655) (belonging to:0.0286) (between:0.0000) (carrying:0.1140) (covered in:0.0714) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0221) (has:0.5945) (holding:0.6073) (in:0.4204) (in front of:0.4279) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3406) (of:0.7042) (on:0.1990) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.9075) (part of:0.0000) (playing:0.0000) (riding:0.9062) (says:0.0000) (sitting on:0.3777) (standing on:0.0688) (to:0.0000) (under:0.1276) (using:0.0000) (walking in:0.0000) (walking on:0.9386) (watching:0.3333) (wearing:0.9759) (wears:0.0088) (with:0.3423) 
SGG eval:   A @ 20: 0.3840;   A @ 50: 0.3870;   A @ 100: 0.3870;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 12:51:49,763 maskrcnn_benchmark INFO: Validation Result: 0.3768
2020-06-11 12:55:40,212 maskrcnn_benchmark INFO: eta: 13:01:35  iter: 2200  loss: 2.6416 (2.7166)  auxiliary_ctx: 0.1719 (0.2042)  auxiliary_frq: 0.1955 (0.2007)  auxiliary_vis: 0.1623 (0.1818)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1094 (2.1300)  time: 1.1467 (1.2406)  data: 0.0258 (0.1131)  lr: 0.640000  max mem: 6119
2020-06-11 12:59:30,789 maskrcnn_benchmark INFO: eta: 12:52:52  iter: 2400  loss: 2.6260 (2.7090)  auxiliary_ctx: 0.1682 (0.2009)  auxiliary_frq: 0.1941 (0.2000)  auxiliary_vis: 0.1604 (0.1799)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1104 (2.1283)  time: 1.1495 (1.2333)  data: 0.0259 (0.1057)  lr: 0.640000  max mem: 6119
2020-06-11 13:03:21,876 maskrcnn_benchmark INFO: eta: 12:45:01  iter: 2600  loss: 2.6151 (2.7028)  auxiliary_ctx: 0.1637 (0.1981)  auxiliary_frq: 0.1893 (0.1994)  auxiliary_vis: 0.1564 (0.1783)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1094 (2.1270)  time: 1.1475 (1.2273)  data: 0.0280 (0.0996)  lr: 0.640000  max mem: 6119
2020-06-11 13:07:12,610 maskrcnn_benchmark INFO: eta: 12:37:40  iter: 2800  loss: 2.6230 (2.6971)  auxiliary_ctx: 0.1597 (0.1957)  auxiliary_frq: 0.1940 (0.1988)  auxiliary_vis: 0.1587 (0.1768)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1105 (2.1258)  time: 1.1495 (1.2221)  data: 0.0279 (0.0944)  lr: 0.640000  max mem: 6119
2020-06-11 13:11:03,489 maskrcnn_benchmark INFO: eta: 12:30:49  iter: 3000  loss: 2.6262 (2.6920)  auxiliary_ctx: 0.1651 (0.1935)  auxiliary_frq: 0.1897 (0.1982)  auxiliary_vis: 0.1545 (0.1755)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1106 (2.1248)  time: 1.1457 (1.2175)  data: 0.0263 (0.0899)  lr: 0.640000  max mem: 6119
2020-06-11 13:14:54,213 maskrcnn_benchmark INFO: eta: 12:24:18  iter: 3200  loss: 2.6246 (2.6875)  auxiliary_ctx: 0.1626 (0.1916)  auxiliary_frq: 0.1930 (0.1978)  auxiliary_vis: 0.1595 (0.1744)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1091 (2.1238)  time: 1.1475 (1.2135)  data: 0.0262 (0.0859)  lr: 0.640000  max mem: 6119
2020-06-11 13:18:45,068 maskrcnn_benchmark INFO: eta: 12:18:08  iter: 3400  loss: 2.6271 (2.6837)  auxiliary_ctx: 0.1660 (0.1900)  auxiliary_frq: 0.1915 (0.1973)  auxiliary_vis: 0.1547 (0.1734)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1068 (2.1231)  time: 1.1485 (1.2101)  data: 0.0260 (0.0824)  lr: 0.640000  max mem: 6119
2020-06-11 13:22:35,414 maskrcnn_benchmark INFO: eta: 12:12:08  iter: 3600  loss: 2.6362 (2.6803)  auxiliary_ctx: 0.1686 (0.1886)  auxiliary_frq: 0.1891 (0.1968)  auxiliary_vis: 0.1597 (0.1725)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1110 (2.1224)  time: 1.1497 (1.2068)  data: 0.0261 (0.0792)  lr: 0.640000  max mem: 6119
2020-06-11 13:26:25,704 maskrcnn_benchmark INFO: eta: 12:06:21  iter: 3800  loss: 2.5847 (2.6771)  auxiliary_ctx: 0.1568 (0.1873)  auxiliary_frq: 0.1817 (0.1964)  auxiliary_vis: 0.1460 (0.1717)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1060 (2.1217)  time: 1.1446 (1.2039)  data: 0.0265 (0.0763)  lr: 0.640000  max mem: 6119
2020-06-11 13:30:16,377 maskrcnn_benchmark INFO: ---Total norm 0.22674 clip coef 22.05139-----------------
2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.13920, (torch.Size([51, 4096]))
2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.08823, (torch.Size([4096, 12544]))
2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06597, (torch.Size([4096, 4096]))
2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.06126, (torch.Size([4096, 12544]))
2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.05402, (torch.Size([51, 4096]))
2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04933, (torch.Size([4096, 1024]))
2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.04232, (torch.Size([2048, 4808]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03978, (torch.Size([2048, 4808]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.03862, (torch.Size([256, 1024, 3, 3]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03561, (torch.Size([512, 1024]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03127, (torch.Size([4096, 4096]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02780, (torch.Size([512, 32]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02702, (torch.Size([1024, 512]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02070, (torch.Size([4096, 512]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01897, (torch.Size([51]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01658, (torch.Size([256, 128, 3, 3]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01489, (torch.Size([128, 2, 7, 7]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01308, (torch.Size([512]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01065, (torch.Size([51]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00848, (torch.Size([1024]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00827, (torch.Size([151, 200]))
2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00796, (torch.Size([4096]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00769, (torch.Size([2048, 512]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00757, (torch.Size([512]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00720, (torch.Size([4096]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00688, (torch.Size([2048, 512]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00578, (torch.Size([256]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00424, (torch.Size([128]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00410, (torch.Size([2048]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00410, (torch.Size([2048]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00402, (torch.Size([4096]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00400, (torch.Size([2048]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00400, (torch.Size([2048]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00367, (torch.Size([22801, 51]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00304, (torch.Size([512, 1024]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00248, (torch.Size([128]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00218, (torch.Size([2048, 4424]))
2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00213, (torch.Size([2048, 4424]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00203, (torch.Size([256]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00199, (torch.Size([128]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00192, (torch.Size([256]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00178, (torch.Size([4096]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00174, (torch.Size([512]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00115, (torch.Size([4096]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00052, (torch.Size([4096]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00049, (torch.Size([2048, 512]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00044, (torch.Size([2048, 512]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00043, (torch.Size([2048]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00043, (torch.Size([2048]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00040, (torch.Size([256]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00039, (torch.Size([2048]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00039, (torch.Size([2048]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00010, (torch.Size([128]))
2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00002, (torch.Size([151, 200]))
2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))
2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))
2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00001, (torch.Size([32]))
2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: -------------------------------
2020-06-11 13:30:16,394 maskrcnn_benchmark INFO: eta: 12:00:49  iter: 4000  loss: 2.6398 (2.6742)  auxiliary_ctx: 0.1710 (0.1861)  auxiliary_frq: 0.1935 (0.1960)  auxiliary_vis: 0.1629 (0.1709)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1124 (2.1211)  time: 1.1496 (1.2014)  data: 0.0278 (0.0738)  lr: 0.640000  max mem: 6119
2020-06-11 13:30:16,396 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0004000.pth
2020-06-11 13:30:18,995 maskrcnn_benchmark INFO: Start validating
2020-06-11 13:30:19,021 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 13:31:49,352 maskrcnn_benchmark INFO: Total run time: 0:01:30.330572 (0.14452891578674315 s / img per device, on 8 devices)
2020-06-11 13:31:49,353 maskrcnn_benchmark INFO: Model inference time: 0:01:11.800131 (0.11488020896911622 s / img per device, on 8 devices)
2020-06-11 13:33:31,216 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.3868;   R @ 50: 0.4669;   R @ 100: 0.4890;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.5406; ngR @ 50: 0.7561; ngR @ 100: 0.8450;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0844;  zR @ 50: 0.1733;  zR @ 100: 0.1859;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1447;  mR @ 50: 0.1720;  mR @ 100: 0.1810;  for mode=predcls, type=Mean Recall.
(above:0.3630) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.4182) (attached to:0.0092) (behind:0.4736) (belonging to:0.0000) (between:0.0000) (carrying:0.3816) (covered in:0.0000) (covering:0.0000) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.6650) (holding:0.5558) (in:0.4409) (in front of:0.1302) (laying on:0.0000) (looking at:0.0217) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4220) (of:0.5800) (on:0.4929) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.8839) (says:0.0000) (sitting on:0.3184) (standing on:0.0072) (to:0.0000) (under:0.1403) (using:0.0000) (walking in:0.0000) (walking on:0.5253) (watching:0.3235) (wearing:0.9636) (wears:0.0000) (with:0.2031) 
SGG eval:   A @ 20: 0.5180;   A @ 50: 0.5224;   A @ 100: 0.5224;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 13:33:31,992 maskrcnn_benchmark INFO: Validation Result: 0.4890
2020-06-11 13:37:22,444 maskrcnn_benchmark INFO: eta: 12:23:13  iter: 4200  loss: 2.6320 (2.6716)  auxiliary_ctx: 0.1669 (0.1851)  auxiliary_frq: 0.1905 (0.1956)  auxiliary_vis: 0.1640 (0.1702)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1112 (2.1207)  time: 1.1412 (1.2456)  data: 0.0278 (0.1181)  lr: 0.640000  max mem: 6119
2020-06-11 13:41:13,830 maskrcnn_benchmark INFO: eta: 12:16:40  iter: 4400  loss: 2.5950 (2.6692)  auxiliary_ctx: 0.1587 (0.1841)  auxiliary_frq: 0.1829 (0.1953)  auxiliary_vis: 0.1486 (0.1696)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1071 (2.1202)  time: 1.1472 (1.2416)  data: 0.0266 (0.1140)  lr: 0.640000  max mem: 6119
2020-06-11 13:45:04,575 maskrcnn_benchmark INFO: eta: 12:10:16  iter: 4600  loss: 2.6381 (2.6674)  auxiliary_ctx: 0.1703 (0.1835)  auxiliary_frq: 0.1925 (0.1950)  auxiliary_vis: 0.1601 (0.1692)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1129 (2.1198)  time: 1.1570 (1.2378)  data: 0.0215 (0.1100)  lr: 0.640000  max mem: 6119
2020-06-11 13:48:55,474 maskrcnn_benchmark INFO: eta: 12:04:07  iter: 4800  loss: 2.5947 (2.6650)  auxiliary_ctx: 0.1560 (0.1825)  auxiliary_frq: 0.1844 (0.1945)  auxiliary_vis: 0.1476 (0.1685)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1067 (2.1194)  time: 1.1567 (1.2343)  data: 0.0278 (0.1066)  lr: 0.640000  max mem: 6341
2020-06-11 13:52:46,492 maskrcnn_benchmark INFO: eta: 11:58:09  iter: 5000  loss: 2.6203 (2.6628)  auxiliary_ctx: 0.1588 (0.1817)  auxiliary_frq: 0.1852 (0.1942)  auxiliary_vis: 0.1557 (0.1679)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1091 (2.1190)  time: 1.1526 (1.2311)  data: 0.0260 (0.1033)  lr: 0.640000  max mem: 6341
2020-06-11 13:56:36,780 maskrcnn_benchmark INFO: eta: 11:52:16  iter: 5200  loss: 2.5950 (2.6610)  auxiliary_ctx: 0.1526 (0.1810)  auxiliary_frq: 0.1804 (0.1939)  auxiliary_vis: 0.1511 (0.1674)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1064 (2.1187)  time: 1.1414 (1.2281)  data: 0.0269 (0.1003)  lr: 0.640000  max mem: 6341
2020-06-11 14:00:27,197 maskrcnn_benchmark INFO: eta: 11:46:33  iter: 5400  loss: 2.5873 (2.6591)  auxiliary_ctx: 0.1569 (0.1803)  auxiliary_frq: 0.1798 (0.1936)  auxiliary_vis: 0.1468 (0.1670)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1077 (2.1183)  time: 1.1388 (1.2252)  data: 0.0269 (0.0976)  lr: 0.640000  max mem: 6341
2020-06-11 14:04:17,609 maskrcnn_benchmark INFO: eta: 11:40:58  iter: 5600  loss: 2.6053 (2.6573)  auxiliary_ctx: 0.1558 (0.1796)  auxiliary_frq: 0.1865 (0.1932)  auxiliary_vis: 0.1517 (0.1664)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1093 (2.1180)  time: 1.1500 (1.2226)  data: 0.0269 (0.0950)  lr: 0.640000  max mem: 6341
2020-06-11 14:08:08,325 maskrcnn_benchmark INFO: eta: 11:35:32  iter: 5800  loss: 2.6035 (2.6557)  auxiliary_ctx: 0.1577 (0.1790)  auxiliary_frq: 0.1816 (0.1929)  auxiliary_vis: 0.1508 (0.1660)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1070 (2.1177)  time: 1.1552 (1.2203)  data: 0.0276 (0.0926)  lr: 0.640000  max mem: 6341
2020-06-11 14:11:58,964 maskrcnn_benchmark INFO: eta: 11:30:12  iter: 6000  loss: 2.5881 (2.6542)  auxiliary_ctx: 0.1516 (0.1784)  auxiliary_frq: 0.1805 (0.1927)  auxiliary_vis: 0.1490 (0.1656)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1071 (2.1174)  time: 1.1547 (1.2180)  data: 0.0275 (0.0904)  lr: 0.640000  max mem: 6341
2020-06-11 14:11:58,967 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0006000.pth
2020-06-11 14:12:01,526 maskrcnn_benchmark INFO: Start validating
2020-06-11 14:12:01,549 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 14:13:33,323 maskrcnn_benchmark INFO: Total run time: 0:01:31.773652 (0.14683784255981444 s / img per device, on 8 devices)
2020-06-11 14:13:33,324 maskrcnn_benchmark INFO: Model inference time: 0:01:11.819916 (0.11491186561584472 s / img per device, on 8 devices)
2020-06-11 14:15:16,017 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.4293;   R @ 50: 0.5171;   R @ 100: 0.5378;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.5877; ngR @ 50: 0.7765; ngR @ 100: 0.8485;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0711;  zR @ 50: 0.1756;  zR @ 100: 0.1815;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1286;  mR @ 50: 0.1629;  mR @ 100: 0.1733;  for mode=predcls, type=Mean Recall.
(above:0.3636) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1928) (attached to:0.0000) (behind:0.4635) (belonging to:0.0000) (between:0.0000) (carrying:0.2763) (covered in:0.0000) (covering:0.0000) (eating:0.5238) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.6784) (holding:0.5831) (in:0.4361) (in front of:0.1578) (laying on:0.0000) (looking at:0.1087) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4162) (of:0.5709) (on:0.6026) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0587) (part of:0.0000) (playing:0.0000) (riding:0.7009) (says:0.0000) (sitting on:0.2841) (standing on:0.0145) (to:0.0000) (under:0.1820) (using:0.0385) (walking in:0.0000) (walking on:0.3993) (watching:0.4118) (wearing:0.9665) (wears:0.0000) (with:0.2186) 
SGG eval:   A @ 20: 0.5872;   A @ 50: 0.5925;   A @ 100: 0.5925;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 14:15:16,790 maskrcnn_benchmark INFO: Validation Result: 0.5378
2020-06-11 14:19:07,453 maskrcnn_benchmark INFO: eta: 11:42:56  iter: 6200  loss: 2.5938 (2.6528)  auxiliary_ctx: 0.1550 (0.1779)  auxiliary_frq: 0.1807 (0.1924)  auxiliary_vis: 0.1510 (0.1653)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1073 (2.1172)  time: 1.1474 (1.2478)  data: 0.0272 (0.1203)  lr: 0.640000  max mem: 6341
2020-06-11 14:22:58,122 maskrcnn_benchmark INFO: eta: 11:37:08  iter: 6400  loss: 2.6008 (2.6514)  auxiliary_ctx: 0.1582 (0.1774)  auxiliary_frq: 0.1791 (0.1921)  auxiliary_vis: 0.1492 (0.1649)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1104 (2.1169)  time: 1.1523 (1.2449)  data: 0.0260 (0.1173)  lr: 0.640000  max mem: 6341
2020-06-11 14:26:48,598 maskrcnn_benchmark INFO: eta: 11:31:25  iter: 6600  loss: 2.5939 (2.6501)  auxiliary_ctx: 0.1559 (0.1769)  auxiliary_frq: 0.1786 (0.1919)  auxiliary_vis: 0.1502 (0.1645)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1070 (2.1167)  time: 1.1492 (1.2421)  data: 0.0262 (0.1144)  lr: 0.640000  max mem: 6341
2020-06-11 14:30:39,127 maskrcnn_benchmark INFO: eta: 11:25:49  iter: 6800  loss: 2.6000 (2.6487)  auxiliary_ctx: 0.1602 (0.1765)  auxiliary_frq: 0.1833 (0.1916)  auxiliary_vis: 0.1538 (0.1642)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1077 (2.1165)  time: 1.1502 (1.2395)  data: 0.0220 (0.1118)  lr: 0.640000  max mem: 6341
2020-06-11 14:34:30,745 maskrcnn_benchmark INFO: eta: 11:20:25  iter: 7000  loss: 2.5933 (2.6477)  auxiliary_ctx: 0.1546 (0.1761)  auxiliary_frq: 0.1817 (0.1913)  auxiliary_vis: 0.1504 (0.1639)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1067 (2.1163)  time: 1.1451 (1.2371)  data: 0.0263 (0.1093)  lr: 0.640000  max mem: 6341
2020-06-11 14:38:21,525 maskrcnn_benchmark INFO: eta: 11:15:01  iter: 7200  loss: 2.6245 (2.6467)  auxiliary_ctx: 0.1624 (0.1758)  auxiliary_frq: 0.1849 (0.1911)  auxiliary_vis: 0.1549 (0.1636)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1098 (2.1162)  time: 1.1526 (1.2348)  data: 0.0253 (0.1070)  lr: 0.640000  max mem: 6341
2020-06-11 14:42:11,949 maskrcnn_benchmark INFO: eta: 11:09:42  iter: 7400  loss: 2.5974 (2.6454)  auxiliary_ctx: 0.1576 (0.1753)  auxiliary_frq: 0.1799 (0.1909)  auxiliary_vis: 0.1515 (0.1633)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1090 (2.1160)  time: 1.1415 (1.2326)  data: 0.0265 (0.1048)  lr: 0.640000  max mem: 6341
2020-06-11 14:46:02,823 maskrcnn_benchmark INFO: eta: 11:04:28  iter: 7600  loss: 2.6261 (2.6442)  auxiliary_ctx: 0.1621 (0.1749)  auxiliary_frq: 0.1889 (0.1906)  auxiliary_vis: 0.1575 (0.1629)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1111 (2.1158)  time: 1.1517 (1.2305)  data: 0.0236 (0.1027)  lr: 0.640000  max mem: 6341
2020-06-11 14:49:53,371 maskrcnn_benchmark INFO: eta: 10:59:18  iter: 7800  loss: 2.6015 (2.6434)  auxiliary_ctx: 0.1627 (0.1746)  auxiliary_frq: 0.1788 (0.1904)  auxiliary_vis: 0.1521 (0.1627)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1060 (2.1156)  time: 1.1588 (1.2285)  data: 0.0196 (0.1007)  lr: 0.640000  max mem: 6341
2020-06-11 14:53:43,967 maskrcnn_benchmark INFO: ---Total norm 0.17305 clip coef 28.89305-----------------
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.07706, (torch.Size([4096, 12544]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.07483, (torch.Size([4096, 12544]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06297, (torch.Size([4096, 4096]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.06097, (torch.Size([51, 4096]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.04561, (torch.Size([256, 1024, 3, 3]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03802, (torch.Size([4096, 1024]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03554, (torch.Size([2048, 4808]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03305, (torch.Size([51, 4096]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03237, (torch.Size([4096, 4096]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03082, (torch.Size([2048, 4808]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02595, (torch.Size([1024, 512]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02575, (torch.Size([512, 1024]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01928, (torch.Size([256, 128, 3, 3]))
2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01573, (torch.Size([4096, 512]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01472, (torch.Size([128, 2, 7, 7]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01355, (torch.Size([512, 32]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00865, (torch.Size([151, 200]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00715, (torch.Size([2048, 512]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00688, (torch.Size([1024]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00650, (torch.Size([512]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00608, (torch.Size([128]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00597, (torch.Size([4096]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00574, (torch.Size([2048, 512]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00459, (torch.Size([22801, 51]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00429, (torch.Size([51]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00423, (torch.Size([256]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00360, (torch.Size([51]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00354, (torch.Size([256]))
2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00332, (torch.Size([512]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00327, (torch.Size([2048]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00327, (torch.Size([2048]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00298, (torch.Size([4096]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00294, (torch.Size([4096]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00267, (torch.Size([2048]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00267, (torch.Size([2048]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00224, (torch.Size([128]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00197, (torch.Size([256]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00161, (torch.Size([128]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00157, (torch.Size([4096]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00146, (torch.Size([512, 1024]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00146, (torch.Size([512]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00113, (torch.Size([4096]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00086, (torch.Size([2048, 4424]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00076, (torch.Size([2048, 4424]))
2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00044, (torch.Size([4096]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00043, (torch.Size([256]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00020, (torch.Size([2048]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00020, (torch.Size([2048]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00019, (torch.Size([2048]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00019, (torch.Size([2048]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00015, (torch.Size([2048, 512]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00013, (torch.Size([2048, 512]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00002, (torch.Size([128]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: -------------------------------
2020-06-11 14:53:43,984 maskrcnn_benchmark INFO: eta: 10:54:12  iter: 8000  loss: 2.6026 (2.6423)  auxiliary_ctx: 0.1643 (0.1742)  auxiliary_frq: 0.1804 (0.1902)  auxiliary_vis: 0.1515 (0.1624)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1068 (2.1154)  time: 1.1544 (1.2266)  data: 0.0279 (0.0988)  lr: 0.640000  max mem: 6341
2020-06-11 14:53:43,987 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0008000.pth
2020-06-11 14:53:46,557 maskrcnn_benchmark INFO: Start validating
2020-06-11 14:53:46,600 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 14:55:18,176 maskrcnn_benchmark INFO: Total run time: 0:01:31.576112 (0.14652177848815917 s / img per device, on 8 devices)
2020-06-11 14:55:18,177 maskrcnn_benchmark INFO: Model inference time: 0:01:11.464407 (0.11434305152893066 s / img per device, on 8 devices)
2020-06-11 14:57:00,058 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.4208;   R @ 50: 0.4995;   R @ 100: 0.5224;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.5689; ngR @ 50: 0.7592; ngR @ 100: 0.8400;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0822;  zR @ 50: 0.1600;  zR @ 100: 0.1911;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1238;  mR @ 50: 0.1559;  mR @ 100: 0.1662;  for mode=predcls, type=Mean Recall.
(above:0.2523) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0648) (attached to:0.0000) (behind:0.5139) (belonging to:0.0000) (between:0.0000) (carrying:0.1689) (covered in:0.1429) (covering:0.0000) (eating:0.4286) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.7073) (holding:0.5401) (in:0.4285) (in front of:0.1330) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3831) (of:0.6395) (on:0.5784) (on back of:0.0000) (over:0.0061) (painted on:0.0000) (parked on:0.0294) (part of:0.0000) (playing:0.0000) (riding:0.7366) (says:0.0000) (sitting on:0.4479) (standing on:0.0370) (to:0.0000) (under:0.1667) (using:0.0000) (walking in:0.0000) (walking on:0.3745) (watching:0.3922) (wearing:0.9745) (wears:0.0000) (with:0.1507) 
SGG eval:   A @ 20: 0.5651;   A @ 50: 0.5698;   A @ 100: 0.5698;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 14:57:00,836 maskrcnn_benchmark INFO: Validation Result: 0.5224
2020-06-11 15:00:51,177 maskrcnn_benchmark INFO: eta: 11:01:52  iter: 8200  loss: 2.5819 (2.6414)  auxiliary_ctx: 0.1536 (0.1739)  auxiliary_frq: 0.1783 (0.1900)  auxiliary_vis: 0.1417 (0.1622)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1074 (2.1153)  time: 1.1598 (1.2488)  data: 0.0273 (0.1210)  lr: 0.640000  max mem: 6341
2020-06-11 15:04:40,983 maskrcnn_benchmark INFO: eta: 10:56:27  iter: 8400  loss: 2.5806 (2.6404)  auxiliary_ctx: 0.1587 (0.1736)  auxiliary_frq: 0.1774 (0.1898)  auxiliary_vis: 0.1437 (0.1619)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1068 (2.1151)  time: 1.1514 (1.2464)  data: 0.0274 (0.1187)  lr: 0.640000  max mem: 6341
2020-06-11 15:08:31,693 maskrcnn_benchmark INFO: eta: 10:51:10  iter: 8600  loss: 2.5972 (2.6395)  auxiliary_ctx: 0.1664 (0.1733)  auxiliary_frq: 0.1787 (0.1896)  auxiliary_vis: 0.1478 (0.1616)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1078 (2.1150)  time: 1.1448 (1.2443)  data: 0.0267 (0.1166)  lr: 0.640000  max mem: 6341
2020-06-11 15:12:23,021 maskrcnn_benchmark INFO: eta: 10:45:59  iter: 8800  loss: 2.5990 (2.6388)  auxiliary_ctx: 0.1627 (0.1731)  auxiliary_frq: 0.1775 (0.1894)  auxiliary_vis: 0.1507 (0.1614)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1076 (2.1149)  time: 1.1569 (1.2423)  data: 0.0271 (0.1145)  lr: 0.640000  max mem: 6361
2020-06-11 15:16:13,887 maskrcnn_benchmark INFO: eta: 10:40:50  iter: 9000  loss: 2.6393 (2.6381)  auxiliary_ctx: 0.1681 (0.1728)  auxiliary_frq: 0.1875 (0.1892)  auxiliary_vis: 0.1599 (0.1612)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1116 (2.1148)  time: 1.1412 (1.2403)  data: 0.0267 (0.1125)  lr: 0.640000  max mem: 6361
2020-06-11 15:20:04,665 maskrcnn_benchmark INFO: eta: 10:35:44  iter: 9200  loss: 2.6212 (2.6372)  auxiliary_ctx: 0.1595 (0.1726)  auxiliary_frq: 0.1889 (0.1890)  auxiliary_vis: 0.1552 (0.1610)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1095 (2.1146)  time: 1.1517 (1.2385)  data: 0.0260 (0.1107)  lr: 0.640000  max mem: 6361
2020-06-11 15:23:55,466 maskrcnn_benchmark INFO: eta: 10:30:41  iter: 9400  loss: 2.5993 (2.6363)  auxiliary_ctx: 0.1573 (0.1723)  auxiliary_frq: 0.1815 (0.1888)  auxiliary_vis: 0.1496 (0.1608)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1059 (2.1145)  time: 1.1477 (1.2367)  data: 0.0266 (0.1089)  lr: 0.640000  max mem: 6361
2020-06-11 15:27:46,395 maskrcnn_benchmark INFO: eta: 10:25:42  iter: 9600  loss: 2.6148 (2.6356)  auxiliary_ctx: 0.1648 (0.1721)  auxiliary_frq: 0.1837 (0.1886)  auxiliary_vis: 0.1558 (0.1606)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1093 (2.1144)  time: 1.1494 (1.2350)  data: 0.0275 (0.1072)  lr: 0.640000  max mem: 6361
2020-06-11 15:31:37,987 maskrcnn_benchmark INFO: eta: 10:20:48  iter: 9800  loss: 2.5792 (2.6349)  auxiliary_ctx: 0.1581 (0.1718)  auxiliary_frq: 0.1762 (0.1884)  auxiliary_vis: 0.1470 (0.1604)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1066 (2.1143)  time: 1.1522 (1.2334)  data: 0.0275 (0.1055)  lr: 0.640000  max mem: 6361
2020-06-11 15:35:28,838 maskrcnn_benchmark INFO: eta: 10:15:53  iter: 10000  loss: 2.5719 (2.6342)  auxiliary_ctx: 0.1512 (0.1716)  auxiliary_frq: 0.1751 (0.1882)  auxiliary_vis: 0.1478 (0.1602)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1042 (2.1142)  time: 1.1527 (1.2318)  data: 0.0280 (0.1039)  lr: 0.640000  max mem: 6377
2020-06-11 15:35:28,841 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0010000.pth
2020-06-11 15:35:31,426 maskrcnn_benchmark INFO: Start validating
2020-06-11 15:35:31,456 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 15:37:02,232 maskrcnn_benchmark INFO: Total run time: 0:01:30.774738 (0.14523958129882814 s / img per device, on 8 devices)
2020-06-11 15:37:02,232 maskrcnn_benchmark INFO: Model inference time: 0:01:10.712922 (0.11314067573547364 s / img per device, on 8 devices)
2020-06-11 15:38:44,600 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.4049;   R @ 50: 0.4879;   R @ 100: 0.5094;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.5557; ngR @ 50: 0.7589; ngR @ 100: 0.8379;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0844;  zR @ 50: 0.1630;  zR @ 100: 0.1867;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1199;  mR @ 50: 0.1475;  mR @ 100: 0.1559;  for mode=predcls, type=Mean Recall.
(above:0.2835) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1747) (attached to:0.0106) (behind:0.5046) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0714) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0625) (has:0.6940) (holding:0.6136) (in:0.4857) (in front of:0.1006) (laying on:0.0000) (looking at:0.0217) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5158) (of:0.6101) (on:0.5236) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.1455) (part of:0.0000) (playing:0.0000) (riding:0.7991) (says:0.0000) (sitting on:0.2446) (standing on:0.0011) (to:0.0000) (under:0.2628) (using:0.0000) (walking in:0.0000) (walking on:0.3545) (watching:0.1765) (wearing:0.9668) (wears:0.0000) (with:0.1577) 
SGG eval:   A @ 20: 0.5444;   A @ 50: 0.5492;   A @ 100: 0.5492;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 15:38:45,369 maskrcnn_benchmark INFO: Validation Result: 0.5094
2020-06-11 15:38:45,369 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-06-11 15:42:36,145 maskrcnn_benchmark INFO: eta: 10:20:36  iter: 10200  loss: 2.5577 (2.6332)  auxiliary_ctx: 0.1455 (0.1712)  auxiliary_frq: 0.1767 (0.1881)  auxiliary_vis: 0.1398 (0.1599)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1009 (2.1140)  time: 1.1537 (1.2495)  data: 0.0265 (0.1217)  lr: 0.064000  max mem: 6377
2020-06-11 15:46:27,104 maskrcnn_benchmark INFO: eta: 10:15:32  iter: 10400  loss: 2.5618 (2.6319)  auxiliary_ctx: 0.1448 (0.1707)  auxiliary_frq: 0.1770 (0.1879)  auxiliary_vis: 0.1407 (0.1595)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1016 (2.1138)  time: 1.1462 (1.2477)  data: 0.0269 (0.1198)  lr: 0.064000  max mem: 6377
2020-06-11 15:50:17,652 maskrcnn_benchmark INFO: eta: 10:10:30  iter: 10600  loss: 2.5567 (2.6307)  auxiliary_ctx: 0.1437 (0.1702)  auxiliary_frq: 0.1772 (0.1878)  auxiliary_vis: 0.1354 (0.1591)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1022 (2.1136)  time: 1.1459 (1.2459)  data: 0.0275 (0.1180)  lr: 0.064000  max mem: 6377
2020-06-11 15:54:08,348 maskrcnn_benchmark INFO: eta: 10:05:30  iter: 10800  loss: 2.5667 (2.6295)  auxiliary_ctx: 0.1458 (0.1698)  auxiliary_frq: 0.1800 (0.1876)  auxiliary_vis: 0.1379 (0.1588)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1026 (2.1134)  time: 1.1501 (1.2442)  data: 0.0200 (0.1163)  lr: 0.064000  max mem: 6377
2020-06-11 15:57:59,430 maskrcnn_benchmark INFO: eta: 10:00:35  iter: 11000  loss: 2.5558 (2.6282)  auxiliary_ctx: 0.1424 (0.1693)  auxiliary_frq: 0.1783 (0.1874)  auxiliary_vis: 0.1351 (0.1584)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1012 (2.1132)  time: 1.1491 (1.2426)  data: 0.0278 (0.1147)  lr: 0.064000  max mem: 6377
2020-06-11 16:01:49,989 maskrcnn_benchmark INFO: eta: 9:55:40  iter: 11200  loss: 2.5785 (2.6271)  auxiliary_ctx: 0.1460 (0.1688)  auxiliary_frq: 0.1876 (0.1873)  auxiliary_vis: 0.1417 (0.1580)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1023 (2.1130)  time: 1.1537 (1.2410)  data: 0.0250 (0.1131)  lr: 0.064000  max mem: 6377
2020-06-11 16:05:40,979 maskrcnn_benchmark INFO: eta: 9:50:49  iter: 11400  loss: 2.5454 (2.6259)  auxiliary_ctx: 0.1393 (0.1683)  auxiliary_frq: 0.1774 (0.1872)  auxiliary_vis: 0.1325 (0.1576)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0991 (2.1128)  time: 1.1501 (1.2395)  data: 0.0273 (0.1116)  lr: 0.064000  max mem: 6377
2020-06-11 16:09:31,723 maskrcnn_benchmark INFO: eta: 9:45:59  iter: 11600  loss: 2.5371 (2.6247)  auxiliary_ctx: 0.1371 (0.1679)  auxiliary_frq: 0.1733 (0.1870)  auxiliary_vis: 0.1294 (0.1572)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0990 (2.1126)  time: 1.1556 (1.2380)  data: 0.0279 (0.1101)  lr: 0.064000  max mem: 6386
2020-06-11 16:13:22,941 maskrcnn_benchmark INFO: eta: 9:41:12  iter: 11800  loss: 2.5439 (2.6234)  auxiliary_ctx: 0.1410 (0.1674)  auxiliary_frq: 0.1742 (0.1869)  auxiliary_vis: 0.1320 (0.1568)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0997 (2.1123)  time: 1.1480 (1.2366)  data: 0.0268 (0.1087)  lr: 0.064000  max mem: 6386
2020-06-11 16:17:13,868 maskrcnn_benchmark INFO: ---Total norm 0.23831 clip coef 20.98071-----------------
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.13686, (torch.Size([4096, 12544]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.13019, (torch.Size([4096, 12544]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.08380, (torch.Size([4096, 4096]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.05651, (torch.Size([256, 1024, 3, 3]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05038, (torch.Size([51, 4096]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03953, (torch.Size([4096, 4096]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03924, (torch.Size([4096, 1024]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03401, (torch.Size([2048, 4808]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03127, (torch.Size([2048, 4808]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02443, (torch.Size([1024, 512]))
2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02209, (torch.Size([256, 128, 3, 3]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.02186, (torch.Size([51, 4096]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02179, (torch.Size([512, 1024]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01680, (torch.Size([4096, 512]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01608, (torch.Size([128, 2, 7, 7]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01029, (torch.Size([151, 200]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00736, (torch.Size([2048, 512]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00704, (torch.Size([2048, 512]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00676, (torch.Size([1024]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00666, (torch.Size([512, 32]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00632, (torch.Size([4096]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00627, (torch.Size([512]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00606, (torch.Size([128]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00390, (torch.Size([2048]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00390, (torch.Size([2048]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00316, (torch.Size([22801, 51]))
2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00309, (torch.Size([2048]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00309, (torch.Size([2048]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00289, (torch.Size([51]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00278, (torch.Size([512]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00256, (torch.Size([4096]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00248, (torch.Size([256]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00243, (torch.Size([256]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00237, (torch.Size([256]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00229, (torch.Size([4096]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00227, (torch.Size([128]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00214, (torch.Size([128]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00201, (torch.Size([51]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00196, (torch.Size([4096]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00133, (torch.Size([4096]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00075, (torch.Size([4096]))
2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00069, (torch.Size([512, 1024]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00057, (torch.Size([512]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00049, (torch.Size([256]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00036, (torch.Size([2048, 4424]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00035, (torch.Size([2048, 4424]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00007, (torch.Size([2048]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00007, (torch.Size([2048]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00006, (torch.Size([2048, 512]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00005, (torch.Size([2048]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00005, (torch.Size([2048]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00003, (torch.Size([2048, 512]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-11 16:17:13,883 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-11 16:17:13,883 maskrcnn_benchmark INFO: -------------------------------
2020-06-11 16:17:13,885 maskrcnn_benchmark INFO: eta: 9:36:27  iter: 12000  loss: 2.5327 (2.6222)  auxiliary_ctx: 0.1360 (0.1669)  auxiliary_frq: 0.1743 (0.1867)  auxiliary_vis: 0.1276 (0.1564)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0976 (2.1121)  time: 1.1570 (1.2353)  data: 0.0266 (0.1073)  lr: 0.064000  max mem: 6386
2020-06-11 16:17:13,888 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0012000.pth
2020-06-11 16:17:16,615 maskrcnn_benchmark INFO: Start validating
2020-06-11 16:17:16,641 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 16:18:48,335 maskrcnn_benchmark INFO: Total run time: 0:01:31.693489 (0.1467095821380615 s / img per device, on 8 devices)
2020-06-11 16:18:48,335 maskrcnn_benchmark INFO: Model inference time: 0:01:11.526382 (0.1144422119140625 s / img per device, on 8 devices)
2020-06-11 16:20:31,366 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5217;   R @ 50: 0.5939;   R @ 100: 0.6095;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6457; ngR @ 50: 0.7933; ngR @ 100: 0.8586;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1111;  zR @ 50: 0.1756;  zR @ 100: 0.1978;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1298;  mR @ 50: 0.1613;  mR @ 100: 0.1712;  for mode=predcls, type=Mean Recall.
(above:0.2011) (across:0.0000) (against:0.0000) (along:0.0385) (and:0.0000) (at:0.2083) (attached to:0.0000) (behind:0.5168) (belonging to:0.0000) (between:0.0000) (carrying:0.4781) (covered in:0.0000) (covering:0.0000) (eating:0.5714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0294) (has:0.7668) (holding:0.6050) (in:0.3816) (in front of:0.1753) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4280) (of:0.5305) (on:0.7594) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.1163) (part of:0.0000) (playing:0.0000) (riding:0.5818) (says:0.0000) (sitting on:0.2765) (standing on:0.0065) (to:0.0000) (under:0.3193) (using:0.0385) (walking in:0.0000) (walking on:0.2093) (watching:0.2059) (wearing:0.9675) (wears:0.0000) (with:0.1251) 
SGG eval:   A @ 20: 0.6522;   A @ 50: 0.6572;   A @ 100: 0.6572;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 16:20:32,130 maskrcnn_benchmark INFO: Validation Result: 0.6095
2020-06-11 16:24:22,645 maskrcnn_benchmark INFO: eta: 9:39:14  iter: 12200  loss: 2.5338 (2.6210)  auxiliary_ctx: 0.1368 (0.1664)  auxiliary_frq: 0.1747 (0.1866)  auxiliary_vis: 0.1290 (0.1560)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0987 (2.1119)  time: 1.1464 (1.2501)  data: 0.0249 (0.1222)  lr: 0.064000  max mem: 6386
2020-06-11 16:28:13,475 maskrcnn_benchmark INFO: eta: 9:34:21  iter: 12400  loss: 2.5475 (2.6199)  auxiliary_ctx: 0.1348 (0.1660)  auxiliary_frq: 0.1791 (0.1865)  auxiliary_vis: 0.1329 (0.1556)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1002 (2.1117)  time: 1.1429 (1.2486)  data: 0.0272 (0.1206)  lr: 0.064000  max mem: 6386
2020-06-11 16:32:04,443 maskrcnn_benchmark INFO: eta: 9:29:30  iter: 12600  loss: 2.5423 (2.6187)  auxiliary_ctx: 0.1357 (0.1655)  auxiliary_frq: 0.1773 (0.1864)  auxiliary_vis: 0.1309 (0.1552)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0996 (2.1115)  time: 1.1446 (1.2471)  data: 0.0232 (0.1191)  lr: 0.064000  max mem: 6386
2020-06-11 16:35:55,086 maskrcnn_benchmark INFO: eta: 9:24:41  iter: 12800  loss: 2.5314 (2.6175)  auxiliary_ctx: 0.1321 (0.1651)  auxiliary_frq: 0.1750 (0.1863)  auxiliary_vis: 0.1284 (0.1549)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0987 (2.1113)  time: 1.1493 (1.2456)  data: 0.0261 (0.1177)  lr: 0.064000  max mem: 6386
2020-06-11 16:39:46,098 maskrcnn_benchmark INFO: eta: 9:19:54  iter: 13000  loss: 2.5461 (2.6164)  auxiliary_ctx: 0.1383 (0.1646)  auxiliary_frq: 0.1796 (0.1862)  auxiliary_vis: 0.1290 (0.1544)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0988 (2.1111)  time: 1.1510 (1.2442)  data: 0.0274 (0.1163)  lr: 0.064000  max mem: 6386
2020-06-11 16:43:37,496 maskrcnn_benchmark INFO: eta: 9:15:10  iter: 13200  loss: 2.5397 (2.6152)  auxiliary_ctx: 0.1338 (0.1641)  auxiliary_frq: 0.1815 (0.1860)  auxiliary_vis: 0.1284 (0.1540)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0982 (2.1110)  time: 1.1497 (1.2429)  data: 0.0280 (0.1149)  lr: 0.064000  max mem: 6386
2020-06-11 16:47:28,498 maskrcnn_benchmark INFO: eta: 9:10:26  iter: 13400  loss: 2.5195 (2.6141)  auxiliary_ctx: 0.1271 (0.1637)  auxiliary_frq: 0.1709 (0.1860)  auxiliary_vis: 0.1232 (0.1537)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0965 (2.1108)  time: 1.1526 (1.2416)  data: 0.0268 (0.1136)  lr: 0.064000  max mem: 6386
2020-06-11 16:51:19,974 maskrcnn_benchmark INFO: eta: 9:05:45  iter: 13600  loss: 2.5255 (2.6130)  auxiliary_ctx: 0.1319 (0.1633)  auxiliary_frq: 0.1778 (0.1859)  auxiliary_vis: 0.1217 (0.1533)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0970 (2.1106)  time: 1.1489 (1.2404)  data: 0.0279 (0.1123)  lr: 0.064000  max mem: 6386
2020-06-11 16:55:11,024 maskrcnn_benchmark INFO: eta: 9:01:05  iter: 13800  loss: 2.5315 (2.6119)  auxiliary_ctx: 0.1319 (0.1628)  auxiliary_frq: 0.1780 (0.1858)  auxiliary_vis: 0.1243 (0.1529)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0975 (2.1104)  time: 1.1547 (1.2391)  data: 0.0266 (0.1110)  lr: 0.064000  max mem: 6395
2020-06-11 16:59:02,165 maskrcnn_benchmark INFO: eta: 8:56:26  iter: 14000  loss: 2.5291 (2.6108)  auxiliary_ctx: 0.1270 (0.1624)  auxiliary_frq: 0.1734 (0.1857)  auxiliary_vis: 0.1221 (0.1525)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0965 (2.1102)  time: 1.1536 (1.2380)  data: 0.0274 (0.1098)  lr: 0.064000  max mem: 6395
2020-06-11 16:59:02,168 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0014000.pth
2020-06-11 16:59:04,846 maskrcnn_benchmark INFO: Start validating
2020-06-11 16:59:04,869 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 17:00:36,923 maskrcnn_benchmark INFO: Total run time: 0:01:32.053613 (0.1472857810974121 s / img per device, on 8 devices)
2020-06-11 17:00:36,924 maskrcnn_benchmark INFO: Model inference time: 0:01:12.098281 (0.11535724983215331 s / img per device, on 8 devices)
2020-06-11 17:02:22,792 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5455;   R @ 50: 0.6111;   R @ 100: 0.6259;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6546; ngR @ 50: 0.7940; ngR @ 100: 0.8562;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0933;  zR @ 50: 0.1778;  zR @ 100: 0.1867;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1281;  mR @ 50: 0.1584;  mR @ 100: 0.1698;  for mode=predcls, type=Mean Recall.
(above:0.2442) (across:0.0000) (against:0.0000) (along:0.1154) (and:0.0000) (at:0.2059) (attached to:0.0092) (behind:0.4003) (belonging to:0.0000) (between:0.0000) (carrying:0.2741) (covered in:0.0714) (covering:0.0000) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0221) (has:0.7653) (holding:0.6073) (in:0.3827) (in front of:0.0886) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5063) (of:0.4609) (on:0.7875) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.1411) (part of:0.0000) (playing:0.0000) (riding:0.5015) (says:0.0000) (sitting on:0.2494) (standing on:0.0101) (to:0.0000) (under:0.1786) (using:0.0577) (walking in:0.0000) (walking on:0.3175) (watching:0.1765) (wearing:0.9732) (wears:0.0000) (with:0.1535) 
SGG eval:   A @ 20: 0.6592;   A @ 50: 0.6639;   A @ 100: 0.6639;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 17:02:23,566 maskrcnn_benchmark INFO: Validation Result: 0.6259
2020-06-11 17:06:14,742 maskrcnn_benchmark INFO: eta: 8:57:55  iter: 14200  loss: 2.5356 (2.6097)  auxiliary_ctx: 0.1319 (0.1620)  auxiliary_frq: 0.1817 (0.1856)  auxiliary_vis: 0.1268 (0.1521)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0973 (2.1100)  time: 1.1620 (1.2510)  data: 0.0273 (0.1228)  lr: 0.064000  max mem: 6395
2020-06-11 17:10:04,910 maskrcnn_benchmark INFO: eta: 8:53:09  iter: 14400  loss: 2.5163 (2.6085)  auxiliary_ctx: 0.1258 (0.1615)  auxiliary_frq: 0.1749 (0.1855)  auxiliary_vis: 0.1188 (0.1517)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0950 (2.1099)  time: 1.1530 (1.2496)  data: 0.0249 (0.1215)  lr: 0.064000  max mem: 6395
2020-06-11 17:13:55,377 maskrcnn_benchmark INFO: eta: 8:48:25  iter: 14600  loss: 2.5136 (2.6074)  auxiliary_ctx: 0.1247 (0.1611)  auxiliary_frq: 0.1744 (0.1854)  auxiliary_vis: 0.1210 (0.1512)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0948 (2.1097)  time: 1.1460 (1.2483)  data: 0.0205 (0.1201)  lr: 0.064000  max mem: 6395
2020-06-11 17:17:46,411 maskrcnn_benchmark INFO: eta: 8:43:44  iter: 14800  loss: 2.5187 (2.6063)  auxiliary_ctx: 0.1240 (0.1606)  auxiliary_frq: 0.1781 (0.1853)  auxiliary_vis: 0.1199 (0.1508)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0965 (2.1095)  time: 1.1610 (1.2470)  data: 0.0269 (0.1188)  lr: 0.064000  max mem: 6395
2020-06-11 17:21:37,304 maskrcnn_benchmark INFO: eta: 8:39:04  iter: 15000  loss: 2.5095 (2.6052)  auxiliary_ctx: 0.1240 (0.1602)  auxiliary_frq: 0.1710 (0.1852)  auxiliary_vis: 0.1156 (0.1504)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0962 (2.1093)  time: 1.1423 (1.2458)  data: 0.0264 (0.1176)  lr: 0.064000  max mem: 6395
2020-06-11 17:25:27,984 maskrcnn_benchmark INFO: eta: 8:34:24  iter: 15200  loss: 2.4948 (2.6041)  auxiliary_ctx: 0.1235 (0.1598)  auxiliary_frq: 0.1690 (0.1851)  auxiliary_vis: 0.1117 (0.1500)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0956 (2.1091)  time: 1.1646 (1.2445)  data: 0.0271 (0.1164)  lr: 0.064000  max mem: 6395
2020-06-11 17:29:18,915 maskrcnn_benchmark INFO: eta: 8:29:47  iter: 15400  loss: 2.4882 (2.6030)  auxiliary_ctx: 0.1181 (0.1594)  auxiliary_frq: 0.1706 (0.1850)  auxiliary_vis: 0.1079 (0.1496)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0932 (2.1090)  time: 1.1508 (1.2434)  data: 0.0268 (0.1152)  lr: 0.064000  max mem: 6395
2020-06-11 17:33:09,819 maskrcnn_benchmark INFO: eta: 8:25:10  iter: 15600  loss: 2.4824 (2.6019)  auxiliary_ctx: 0.1141 (0.1589)  auxiliary_frq: 0.1707 (0.1849)  auxiliary_vis: 0.1067 (0.1492)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0927 (2.1088)  time: 1.1471 (1.2422)  data: 0.0272 (0.1141)  lr: 0.064000  max mem: 6395
2020-06-11 17:37:00,881 maskrcnn_benchmark INFO: eta: 8:20:35  iter: 15800  loss: 2.4990 (2.6007)  auxiliary_ctx: 0.1199 (0.1585)  auxiliary_frq: 0.1764 (0.1849)  auxiliary_vis: 0.1126 (0.1488)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0936 (2.1086)  time: 1.1513 (1.2411)  data: 0.0197 (0.1130)  lr: 0.064000  max mem: 6395
2020-06-11 17:40:51,447 maskrcnn_benchmark INFO: ---Total norm 0.51895 clip coef 9.63475-----------------
2020-06-11 17:40:51,457 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.30468, (torch.Size([4096, 12544]))
2020-06-11 17:40:51,457 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.29325, (torch.Size([4096, 12544]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.17126, (torch.Size([4096, 4096]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.16163, (torch.Size([51, 4096]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.09965, (torch.Size([256, 1024, 3, 3]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06590, (torch.Size([4096, 4096]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.05743, (torch.Size([4096, 1024]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.05739, (torch.Size([2048, 4808]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.05195, (torch.Size([2048, 4808]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.04770, (torch.Size([51, 4096]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.04665, (torch.Size([4096, 512]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04240, (torch.Size([256, 128, 3, 3]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03190, (torch.Size([1024, 512]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02835, (torch.Size([512, 32]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02805, (torch.Size([512, 1024]))
2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02722, (torch.Size([128, 2, 7, 7]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01751, (torch.Size([151, 200]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01413, (torch.Size([2048, 512]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01237, (torch.Size([512]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01193, (torch.Size([2048, 512]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01142, (torch.Size([4096]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01050, (torch.Size([128]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00986, (torch.Size([2048]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00986, (torch.Size([2048]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00951, (torch.Size([1024]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00944, (torch.Size([51]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00896, (torch.Size([2048]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00896, (torch.Size([2048]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00697, (torch.Size([4096]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00682, (torch.Size([512]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00618, (torch.Size([4096]))
2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00598, (torch.Size([256]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00515, (torch.Size([51]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00428, (torch.Size([256]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00421, (torch.Size([128]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00381, (torch.Size([22801, 51]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00360, (torch.Size([4096]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00327, (torch.Size([256]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00309, (torch.Size([4096]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00280, (torch.Size([128]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00180, (torch.Size([4096]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00097, (torch.Size([256]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00082, (torch.Size([512, 1024]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00074, (torch.Size([512]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00055, (torch.Size([2048, 4424]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00053, (torch.Size([2048, 4424]))
2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00012, (torch.Size([2048]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00012, (torch.Size([2048]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00011, (torch.Size([2048, 512]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00010, (torch.Size([2048]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00010, (torch.Size([2048]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00003, (torch.Size([2048, 512]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: -------------------------------
2020-06-11 17:40:51,464 maskrcnn_benchmark INFO: eta: 8:16:00  iter: 16000  loss: 2.5115 (2.5997)  auxiliary_ctx: 0.1250 (0.1581)  auxiliary_frq: 0.1765 (0.1848)  auxiliary_vis: 0.1144 (0.1484)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0951 (2.1085)  time: 1.1517 (1.2400)  data: 0.0238 (0.1119)  lr: 0.064000  max mem: 6395
2020-06-11 17:40:51,467 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0016000.pth
2020-06-11 17:40:54,151 maskrcnn_benchmark INFO: Start validating
2020-06-11 17:40:54,174 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 17:42:24,749 maskrcnn_benchmark INFO: Total run time: 0:01:30.574017 (0.14491842727661133 s / img per device, on 8 devices)
2020-06-11 17:42:24,749 maskrcnn_benchmark INFO: Model inference time: 0:01:11.607731 (0.11457237014770508 s / img per device, on 8 devices)
2020-06-11 17:44:08,442 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5405;   R @ 50: 0.6083;   R @ 100: 0.6237;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6454; ngR @ 50: 0.7806; ngR @ 100: 0.8434;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0956;  zR @ 50: 0.1874;  zR @ 100: 0.1985;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1236;  mR @ 50: 0.1562;  mR @ 100: 0.1653;  for mode=predcls, type=Mean Recall.
(above:0.2216) (across:0.0000) (against:0.0000) (along:0.0769) (and:0.0000) (at:0.1574) (attached to:0.0000) (behind:0.3889) (belonging to:0.0000) (between:0.0000) (carrying:0.3158) (covered in:0.0714) (covering:0.0000) (eating:0.5714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.7721) (holding:0.5845) (in:0.3865) (in front of:0.0636) (laying on:0.0476) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4661) (of:0.4773) (on:0.7896) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.0198) (part of:0.0000) (playing:0.0000) (riding:0.3795) (says:0.0000) (sitting on:0.2501) (standing on:0.0370) (to:0.0000) (under:0.2389) (using:0.0385) (walking in:0.0000) (walking on:0.3990) (watching:0.3235) (wearing:0.9695) (wears:0.0000) (with:0.1502) 
SGG eval:   A @ 20: 0.6559;   A @ 50: 0.6610;   A @ 100: 0.6610;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 17:44:09,227 maskrcnn_benchmark INFO: Validation Result: 0.6237
2020-06-11 17:48:00,070 maskrcnn_benchmark INFO: eta: 8:16:18  iter: 16200  loss: 2.5277 (2.5987)  auxiliary_ctx: 0.1342 (0.1577)  auxiliary_frq: 0.1762 (0.1848)  auxiliary_vis: 0.1187 (0.1480)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0972 (2.1083)  time: 1.1542 (1.2512)  data: 0.0262 (0.1230)  lr: 0.064000  max mem: 6395
2020-06-11 17:51:51,267 maskrcnn_benchmark INFO: eta: 8:11:40  iter: 16400  loss: 2.5268 (2.5977)  auxiliary_ctx: 0.1293 (0.1573)  auxiliary_frq: 0.1867 (0.1847)  auxiliary_vis: 0.1154 (0.1476)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0942 (2.1081)  time: 1.1528 (1.2500)  data: 0.0255 (0.1218)  lr: 0.064000  max mem: 6395
2020-06-11 17:55:42,183 maskrcnn_benchmark INFO: eta: 8:07:03  iter: 16600  loss: 2.5069 (2.5967)  auxiliary_ctx: 0.1206 (0.1569)  auxiliary_frq: 0.1778 (0.1846)  auxiliary_vis: 0.1108 (0.1471)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0935 (2.1080)  time: 1.1530 (1.2489)  data: 0.0265 (0.1207)  lr: 0.064000  max mem: 6423
2020-06-11 17:59:32,798 maskrcnn_benchmark INFO: eta: 8:02:27  iter: 16800  loss: 2.5072 (2.5956)  auxiliary_ctx: 0.1216 (0.1565)  auxiliary_frq: 0.1793 (0.1846)  auxiliary_vis: 0.1079 (0.1467)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0934 (2.1078)  time: 1.1445 (1.2477)  data: 0.0278 (0.1195)  lr: 0.064000  max mem: 6423
2020-06-11 18:03:23,952 maskrcnn_benchmark INFO: eta: 7:57:53  iter: 17000  loss: 2.4962 (2.5946)  auxiliary_ctx: 0.1170 (0.1561)  auxiliary_frq: 0.1736 (0.1845)  auxiliary_vis: 0.1075 (0.1463)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0917 (2.1077)  time: 1.1460 (1.2467)  data: 0.0271 (0.1184)  lr: 0.064000  max mem: 6423
2020-06-11 18:07:14,789 maskrcnn_benchmark INFO: eta: 7:53:19  iter: 17200  loss: 2.5008 (2.5936)  auxiliary_ctx: 0.1208 (0.1557)  auxiliary_frq: 0.1795 (0.1844)  auxiliary_vis: 0.1059 (0.1459)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0934 (2.1075)  time: 1.1459 (1.2456)  data: 0.0263 (0.1174)  lr: 0.064000  max mem: 6423
2020-06-11 18:11:06,308 maskrcnn_benchmark INFO: eta: 7:48:47  iter: 17400  loss: 2.4774 (2.5925)  auxiliary_ctx: 0.1138 (0.1553)  auxiliary_frq: 0.1707 (0.1844)  auxiliary_vis: 0.1024 (0.1455)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0909 (2.1073)  time: 1.1537 (1.2446)  data: 0.0264 (0.1163)  lr: 0.064000  max mem: 6423
2020-06-11 18:14:57,283 maskrcnn_benchmark INFO: eta: 7:44:15  iter: 17600  loss: 2.5063 (2.5915)  auxiliary_ctx: 0.1211 (0.1550)  auxiliary_frq: 0.1810 (0.1843)  auxiliary_vis: 0.1098 (0.1451)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0937 (2.1072)  time: 1.1521 (1.2435)  data: 0.0266 (0.1153)  lr: 0.064000  max mem: 6423
2020-06-11 18:18:47,937 maskrcnn_benchmark INFO: eta: 7:39:44  iter: 17800  loss: 2.4945 (2.5905)  auxiliary_ctx: 0.1170 (0.1546)  auxiliary_frq: 0.1749 (0.1842)  auxiliary_vis: 0.1051 (0.1446)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0926 (2.1070)  time: 1.1496 (1.2425)  data: 0.0250 (0.1143)  lr: 0.064000  max mem: 6423
2020-06-11 18:22:39,509 maskrcnn_benchmark INFO: eta: 7:35:15  iter: 18000  loss: 2.5201 (2.5895)  auxiliary_ctx: 0.1245 (0.1542)  auxiliary_frq: 0.1873 (0.1842)  auxiliary_vis: 0.1128 (0.1442)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0946 (2.1069)  time: 1.1478 (1.2416)  data: 0.0265 (0.1133)  lr: 0.064000  max mem: 6423
2020-06-11 18:22:39,512 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0018000.pth
2020-06-11 18:22:42,050 maskrcnn_benchmark INFO: Start validating
2020-06-11 18:22:42,082 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 18:24:13,070 maskrcnn_benchmark INFO: Total run time: 0:01:30.988130 (0.14558100814819336 s / img per device, on 8 devices)
2020-06-11 18:24:13,071 maskrcnn_benchmark INFO: Model inference time: 0:01:10.669924 (0.11307187843322754 s / img per device, on 8 devices)
2020-06-11 18:25:56,887 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5388;   R @ 50: 0.6023;   R @ 100: 0.6172;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6309; ngR @ 50: 0.7621; ngR @ 100: 0.8316;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.1000;  zR @ 50: 0.1956;  zR @ 100: 0.2200;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1351;  mR @ 50: 0.1693;  mR @ 100: 0.1786;  for mode=predcls, type=Mean Recall.
(above:0.2508) (across:0.0000) (against:0.0000) (along:0.0385) (and:0.0000) (at:0.3806) (attached to:0.0183) (behind:0.3851) (belonging to:0.0000) (between:0.0000) (carrying:0.5000) (covered in:0.0714) (covering:0.0000) (eating:0.5714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0588) (has:0.7698) (holding:0.5233) (in:0.3485) (in front of:0.0957) (laying on:0.0952) (looking at:0.0870) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4827) (of:0.5065) (on:0.7707) (on back of:0.0000) (over:0.0427) (painted on:0.0000) (parked on:0.0111) (part of:0.0000) (playing:0.0000) (riding:0.5074) (says:0.0000) (sitting on:0.2750) (standing on:0.0380) (to:0.0000) (under:0.2861) (using:0.2115) (walking in:0.0000) (walking on:0.2804) (watching:0.2549) (wearing:0.9706) (wears:0.0000) (with:0.0975) 
SGG eval:   A @ 20: 0.6531;   A @ 50: 0.6573;   A @ 100: 0.6573;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 18:25:57,664 maskrcnn_benchmark INFO: Validation Result: 0.6172
2020-06-11 18:25:57,664 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-06-11 18:29:47,983 maskrcnn_benchmark INFO: eta: 7:34:42  iter: 18200  loss: 2.4606 (2.5883)  auxiliary_ctx: 0.1050 (0.1537)  auxiliary_frq: 0.1729 (0.1841)  auxiliary_vis: 0.0951 (0.1438)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0880 (2.1067)  time: 1.1420 (1.2515)  data: 0.0257 (0.1232)  lr: 0.006400  max mem: 6423
2020-06-11 18:33:38,789 maskrcnn_benchmark INFO: eta: 7:30:09  iter: 18400  loss: 2.4679 (2.5870)  auxiliary_ctx: 0.1036 (0.1532)  auxiliary_frq: 0.1802 (0.1840)  auxiliary_vis: 0.0970 (0.1433)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0880 (2.1065)  time: 1.1432 (1.2504)  data: 0.0255 (0.1222)  lr: 0.006400  max mem: 6423
2020-06-11 18:37:29,880 maskrcnn_benchmark INFO: eta: 7:25:37  iter: 18600  loss: 2.4689 (2.5858)  auxiliary_ctx: 0.1053 (0.1527)  auxiliary_frq: 0.1788 (0.1840)  auxiliary_vis: 0.0959 (0.1428)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0883 (2.1063)  time: 1.1492 (1.2494)  data: 0.0252 (0.1211)  lr: 0.006400  max mem: 6423
2020-06-11 18:41:20,947 maskrcnn_benchmark INFO: eta: 7:21:06  iter: 18800  loss: 2.4578 (2.5846)  auxiliary_ctx: 0.1043 (0.1522)  auxiliary_frq: 0.1758 (0.1839)  auxiliary_vis: 0.0962 (0.1423)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0877 (2.1061)  time: 1.1484 (1.2484)  data: 0.0256 (0.1201)  lr: 0.006400  max mem: 6423
2020-06-11 18:45:11,917 maskrcnn_benchmark INFO: eta: 7:16:35  iter: 19000  loss: 2.4407 (2.5834)  auxiliary_ctx: 0.0939 (0.1517)  auxiliary_frq: 0.1719 (0.1839)  auxiliary_vis: 0.0881 (0.1418)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0850 (2.1059)  time: 1.1513 (1.2474)  data: 0.0269 (0.1191)  lr: 0.006400  max mem: 6423
2020-06-11 18:49:02,653 maskrcnn_benchmark INFO: eta: 7:12:06  iter: 19200  loss: 2.4665 (2.5821)  auxiliary_ctx: 0.1017 (0.1512)  auxiliary_frq: 0.1802 (0.1839)  auxiliary_vis: 0.0951 (0.1413)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0865 (2.1057)  time: 1.1465 (1.2464)  data: 0.0261 (0.1181)  lr: 0.006400  max mem: 6535
2020-06-11 18:52:54,114 maskrcnn_benchmark INFO: eta: 7:07:37  iter: 19400  loss: 2.4694 (2.5809)  auxiliary_ctx: 0.1064 (0.1507)  auxiliary_frq: 0.1839 (0.1838)  auxiliary_vis: 0.0961 (0.1409)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0874 (2.1055)  time: 1.1516 (1.2455)  data: 0.0263 (0.1172)  lr: 0.006400  max mem: 6535
2020-06-11 18:56:45,134 maskrcnn_benchmark INFO: eta: 7:03:09  iter: 19600  loss: 2.4476 (2.5796)  auxiliary_ctx: 0.0957 (0.1502)  auxiliary_frq: 0.1716 (0.1837)  auxiliary_vis: 0.0910 (0.1404)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0857 (2.1053)  time: 1.1583 (1.2446)  data: 0.0265 (0.1163)  lr: 0.006400  max mem: 6535
2020-06-11 19:00:35,741 maskrcnn_benchmark INFO: eta: 6:58:42  iter: 19800  loss: 2.4603 (2.5784)  auxiliary_ctx: 0.1019 (0.1497)  auxiliary_frq: 0.1827 (0.1837)  auxiliary_vis: 0.0910 (0.1399)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0860 (2.1051)  time: 1.1459 (1.2437)  data: 0.0252 (0.1153)  lr: 0.006400  max mem: 6535
2020-06-11 19:04:27,241 maskrcnn_benchmark INFO: ---Total norm 0.71894 clip coef 6.95464-----------------
2020-06-11 19:04:27,251 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.50864, (torch.Size([4096, 12544]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.35261, (torch.Size([4096, 12544]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.28404, (torch.Size([4096, 4096]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.10166, (torch.Size([51, 4096]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.09526, (torch.Size([256, 1024, 3, 3]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.08010, (torch.Size([2048, 4808]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.07788, (torch.Size([2048, 4808]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.07304, (torch.Size([4096, 1024]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06780, (torch.Size([4096, 4096]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04900, (torch.Size([256, 128, 3, 3]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.04290, (torch.Size([51, 4096]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.04061, (torch.Size([512, 1024]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03938, (torch.Size([1024, 512]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02441, (torch.Size([128, 2, 7, 7]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02301, (torch.Size([151, 200]))
2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02227, (torch.Size([4096, 512]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01801, (torch.Size([2048, 512]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01684, (torch.Size([512]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01671, (torch.Size([2048, 512]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01508, (torch.Size([1024]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01448, (torch.Size([4096]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01127, (torch.Size([4096]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01127, (torch.Size([2048]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01127, (torch.Size([2048]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01016, (torch.Size([2048]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01016, (torch.Size([2048]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00894, (torch.Size([128]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00710, (torch.Size([256]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00690, (torch.Size([4096]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00484, (torch.Size([512, 32]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00483, (torch.Size([51]))
2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00478, (torch.Size([128]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00452, (torch.Size([256]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00436, (torch.Size([256]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00382, (torch.Size([22801, 51]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00381, (torch.Size([128]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00363, (torch.Size([4096]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00318, (torch.Size([51]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00294, (torch.Size([4096]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00158, (torch.Size([4096]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00092, (torch.Size([256]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00088, (torch.Size([512]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00059, (torch.Size([2048, 4424]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00052, (torch.Size([2048, 4424]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00038, (torch.Size([512, 1024]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00035, (torch.Size([512]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00006, (torch.Size([2048]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00006, (torch.Size([2048]))
2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00006, (torch.Size([2048]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00006, (torch.Size([2048]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00006, (torch.Size([2048, 512]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00003, (torch.Size([2048, 512]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: -------------------------------
2020-06-11 19:04:27,258 maskrcnn_benchmark INFO: eta: 6:54:16  iter: 20000  loss: 2.4252 (2.5771)  auxiliary_ctx: 0.0924 (0.1492)  auxiliary_frq: 0.1673 (0.1837)  auxiliary_vis: 0.0828 (0.1394)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0828 (2.1049)  time: 1.1519 (1.2428)  data: 0.0274 (0.1144)  lr: 0.006400  max mem: 6535
2020-06-11 19:04:27,261 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0020000.pth
2020-06-11 19:04:29,422 maskrcnn_benchmark INFO: Start validating
2020-06-11 19:04:29,450 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 19:06:00,838 maskrcnn_benchmark INFO: Total run time: 0:01:31.387657 (0.1462202507019043 s / img per device, on 8 devices)
2020-06-11 19:06:00,839 maskrcnn_benchmark INFO: Model inference time: 0:01:10.976703 (0.1135627254486084 s / img per device, on 8 devices)
2020-06-11 19:07:46,543 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5594;   R @ 50: 0.6136;   R @ 100: 0.6293;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6404; ngR @ 50: 0.7584; ngR @ 100: 0.8203;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0763;  zR @ 50: 0.1689;  zR @ 100: 0.2044;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1229;  mR @ 50: 0.1534;  mR @ 100: 0.1650;  for mode=predcls, type=Mean Recall.
(above:0.1466) (across:0.0000) (against:0.0000) (along:0.1923) (and:0.0000) (at:0.2152) (attached to:0.0092) (behind:0.3842) (belonging to:0.0000) (between:0.0000) (carrying:0.4825) (covered in:0.1071) (covering:0.0000) (eating:0.4286) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0441) (has:0.7475) (holding:0.5296) (in:0.3579) (in front of:0.1069) (laying on:0.0476) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4111) (of:0.4369) (on:0.8271) (on back of:0.0000) (over:0.0467) (painted on:0.0000) (parked on:0.0190) (part of:0.0000) (playing:0.0000) (riding:0.4598) (says:0.0000) (sitting on:0.2501) (standing on:0.0272) (to:0.0000) (under:0.2219) (using:0.1346) (walking in:0.0000) (walking on:0.2567) (watching:0.2255) (wearing:0.9620) (wears:0.0000) (with:0.1305) 
SGG eval:   A @ 20: 0.6564;   A @ 50: 0.6600;   A @ 100: 0.6600;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 19:07:47,439 maskrcnn_benchmark INFO: Validation Result: 0.6293
2020-06-11 19:11:37,705 maskrcnn_benchmark INFO: eta: 6:53:06  iter: 20200  loss: 2.4378 (2.5759)  auxiliary_ctx: 0.0932 (0.1486)  auxiliary_frq: 0.1727 (0.1836)  auxiliary_vis: 0.0854 (0.1389)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0844 (2.1047)  time: 1.1560 (1.2518)  data: 0.0235 (0.1235)  lr: 0.006400  max mem: 6535
2020-06-11 19:15:28,513 maskrcnn_benchmark INFO: eta: 6:48:36  iter: 20400  loss: 2.4447 (2.5747)  auxiliary_ctx: 0.0955 (0.1481)  auxiliary_frq: 0.1750 (0.1836)  auxiliary_vis: 0.0895 (0.1384)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0841 (2.1045)  time: 1.1514 (1.2509)  data: 0.0240 (0.1225)  lr: 0.006400  max mem: 6535
2020-06-11 19:19:19,447 maskrcnn_benchmark INFO: eta: 6:44:08  iter: 20600  loss: 2.4546 (2.5735)  auxiliary_ctx: 0.0965 (0.1476)  auxiliary_frq: 0.1812 (0.1835)  auxiliary_vis: 0.0893 (0.1380)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0851 (2.1044)  time: 1.1468 (1.2499)  data: 0.0266 (0.1216)  lr: 0.006400  max mem: 6535
2020-06-11 19:23:10,562 maskrcnn_benchmark INFO: eta: 6:39:41  iter: 20800  loss: 2.4397 (2.5723)  auxiliary_ctx: 0.0932 (0.1472)  auxiliary_frq: 0.1785 (0.1835)  auxiliary_vis: 0.0869 (0.1375)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0836 (2.1042)  time: 1.1519 (1.2490)  data: 0.0242 (0.1206)  lr: 0.006400  max mem: 6535
2020-06-11 19:27:01,452 maskrcnn_benchmark INFO: eta: 6:35:14  iter: 21000  loss: 2.4491 (2.5711)  auxiliary_ctx: 0.0956 (0.1466)  auxiliary_frq: 0.1814 (0.1834)  auxiliary_vis: 0.0886 (0.1370)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0841 (2.1040)  time: 1.1573 (1.2481)  data: 0.0261 (0.1197)  lr: 0.006400  max mem: 6535
2020-06-11 19:30:51,553 maskrcnn_benchmark INFO: eta: 6:30:47  iter: 21200  loss: 2.4503 (2.5699)  auxiliary_ctx: 0.0986 (0.1462)  auxiliary_frq: 0.1808 (0.1834)  auxiliary_vis: 0.0904 (0.1366)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0844 (2.1038)  time: 1.1379 (1.2472)  data: 0.0264 (0.1188)  lr: 0.006400  max mem: 6535
2020-06-11 19:34:42,459 maskrcnn_benchmark INFO: eta: 6:26:21  iter: 21400  loss: 2.4271 (2.5687)  auxiliary_ctx: 0.0875 (0.1457)  auxiliary_frq: 0.1704 (0.1834)  auxiliary_vis: 0.0842 (0.1361)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0823 (2.1036)  time: 1.1516 (1.2463)  data: 0.0220 (0.1179)  lr: 0.006400  max mem: 6535
2020-06-11 19:38:33,688 maskrcnn_benchmark INFO: eta: 6:21:57  iter: 21600  loss: 2.4275 (2.5675)  auxiliary_ctx: 0.0907 (0.1452)  auxiliary_frq: 0.1747 (0.1833)  auxiliary_vis: 0.0854 (0.1356)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0825 (2.1034)  time: 1.1599 (1.2455)  data: 0.0255 (0.1171)  lr: 0.006400  max mem: 6535
2020-06-11 19:42:24,639 maskrcnn_benchmark INFO: eta: 6:17:32  iter: 21800  loss: 2.4382 (2.5664)  auxiliary_ctx: 0.0883 (0.1447)  auxiliary_frq: 0.1788 (0.1833)  auxiliary_vis: 0.0868 (0.1352)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0834 (2.1032)  time: 1.1490 (1.2447)  data: 0.0256 (0.1162)  lr: 0.006400  max mem: 6535
2020-06-11 19:46:15,216 maskrcnn_benchmark INFO: eta: 6:13:09  iter: 22000  loss: 2.3989 (2.5652)  auxiliary_ctx: 0.0815 (0.1442)  auxiliary_frq: 0.1697 (0.1832)  auxiliary_vis: 0.0761 (0.1347)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0791 (2.1030)  time: 1.1634 (1.2438)  data: 0.0262 (0.1154)  lr: 0.006400  max mem: 6535
2020-06-11 19:46:15,219 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0022000.pth
2020-06-11 19:46:17,603 maskrcnn_benchmark INFO: Start validating
2020-06-11 19:46:17,632 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 19:47:48,887 maskrcnn_benchmark INFO: Total run time: 0:01:31.254602 (0.1460073631286621 s / img per device, on 8 devices)
2020-06-11 19:47:48,888 maskrcnn_benchmark INFO: Model inference time: 0:01:11.992720 (0.11518835144042969 s / img per device, on 8 devices)
2020-06-11 19:49:32,212 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5544;   R @ 50: 0.6088;   R @ 100: 0.6249;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6305; ngR @ 50: 0.7446; ngR @ 100: 0.8085;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0778;  zR @ 50: 0.1667;  zR @ 100: 0.1911;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1226;  mR @ 50: 0.1513;  mR @ 100: 0.1642;  for mode=predcls, type=Mean Recall.
(above:0.1446) (across:0.0000) (against:0.0000) (along:0.0769) (and:0.0323) (at:0.1978) (attached to:0.0367) (behind:0.3780) (belonging to:0.0000) (between:0.0000) (carrying:0.4342) (covered in:0.0714) (covering:0.0000) (eating:0.5000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0588) (has:0.7528) (holding:0.5389) (in:0.3481) (in front of:0.1496) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3915) (of:0.4581) (on:0.8149) (on back of:0.0000) (over:0.0467) (painted on:0.0000) (parked on:0.0345) (part of:0.0000) (playing:0.0000) (riding:0.4955) (says:0.0000) (sitting on:0.2435) (standing on:0.0163) (to:0.0000) (under:0.1981) (using:0.1346) (walking in:0.0000) (walking on:0.2963) (watching:0.2353) (wearing:0.9503) (wears:0.0000) (with:0.1278) 
SGG eval:   A @ 20: 0.6536;   A @ 50: 0.6578;   A @ 100: 0.6578;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 19:49:32,999 maskrcnn_benchmark INFO: Validation Result: 0.6249
2020-06-11 19:53:23,950 maskrcnn_benchmark INFO: eta: 6:11:24  iter: 22200  loss: 2.4304 (2.5640)  auxiliary_ctx: 0.0898 (0.1437)  auxiliary_frq: 0.1753 (0.1832)  auxiliary_vis: 0.0832 (0.1343)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0817 (2.1029)  time: 1.1539 (1.2519)  data: 0.0264 (0.1235)  lr: 0.006400  max mem: 6535
2020-06-11 19:57:15,003 maskrcnn_benchmark INFO: eta: 6:06:58  iter: 22400  loss: 2.4318 (2.5628)  auxiliary_ctx: 0.0878 (0.1432)  auxiliary_frq: 0.1808 (0.1832)  auxiliary_vis: 0.0849 (0.1338)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0814 (2.1027)  time: 1.1565 (1.2511)  data: 0.0264 (0.1226)  lr: 0.006400  max mem: 6535
2020-06-11 20:01:06,688 maskrcnn_benchmark INFO: eta: 6:02:34  iter: 22600  loss: 2.4225 (2.5617)  auxiliary_ctx: 0.0841 (0.1427)  auxiliary_frq: 0.1773 (0.1831)  auxiliary_vis: 0.0834 (0.1334)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0815 (2.1025)  time: 1.1636 (1.2503)  data: 0.0285 (0.1218)  lr: 0.006400  max mem: 6535
2020-06-11 20:04:57,990 maskrcnn_benchmark INFO: eta: 5:58:10  iter: 22800  loss: 2.4172 (2.5605)  auxiliary_ctx: 0.0861 (0.1422)  auxiliary_frq: 0.1766 (0.1831)  auxiliary_vis: 0.0792 (0.1329)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0811 (2.1023)  time: 1.1455 (1.2494)  data: 0.0265 (0.1209)  lr: 0.006400  max mem: 6535
2020-06-11 20:08:48,601 maskrcnn_benchmark INFO: eta: 5:53:46  iter: 23000  loss: 2.4201 (2.5594)  auxiliary_ctx: 0.0846 (0.1417)  auxiliary_frq: 0.1747 (0.1831)  auxiliary_vis: 0.0799 (0.1325)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0809 (2.1021)  time: 1.1469 (1.2486)  data: 0.0269 (0.1201)  lr: 0.006400  max mem: 6535
2020-06-11 20:12:39,796 maskrcnn_benchmark INFO: eta: 5:49:23  iter: 23200  loss: 2.4221 (2.5583)  auxiliary_ctx: 0.0834 (0.1413)  auxiliary_frq: 0.1813 (0.1830)  auxiliary_vis: 0.0811 (0.1320)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0808 (2.1019)  time: 1.1608 (1.2478)  data: 0.0252 (0.1193)  lr: 0.006400  max mem: 6535
2020-06-11 20:16:30,192 maskrcnn_benchmark INFO: eta: 5:44:59  iter: 23400  loss: 2.4230 (2.5572)  auxiliary_ctx: 0.0846 (0.1408)  auxiliary_frq: 0.1783 (0.1830)  auxiliary_vis: 0.0801 (0.1316)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0798 (2.1018)  time: 1.1479 (1.2470)  data: 0.0266 (0.1185)  lr: 0.006400  max mem: 6535
2020-06-11 20:20:21,163 maskrcnn_benchmark INFO: eta: 5:40:37  iter: 23600  loss: 2.4345 (2.5560)  auxiliary_ctx: 0.0878 (0.1403)  auxiliary_frq: 0.1809 (0.1830)  auxiliary_vis: 0.0798 (0.1312)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0802 (2.1016)  time: 1.1446 (1.2462)  data: 0.0210 (0.1177)  lr: 0.006400  max mem: 6535
2020-06-11 20:24:12,115 maskrcnn_benchmark INFO: eta: 5:36:15  iter: 23800  loss: 2.4218 (2.5549)  auxiliary_ctx: 0.0860 (0.1398)  auxiliary_frq: 0.1767 (0.1829)  auxiliary_vis: 0.0793 (0.1307)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0809 (2.1014)  time: 1.1541 (1.2454)  data: 0.0257 (0.1169)  lr: 0.006400  max mem: 6535
2020-06-11 20:28:02,523 maskrcnn_benchmark INFO: ---Total norm 0.81789 clip coef 6.11331-----------------
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.59716, (torch.Size([4096, 12544]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.40959, (torch.Size([4096, 12544]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.32027, (torch.Size([4096, 4096]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.10014, (torch.Size([256, 1024, 3, 3]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.07434, (torch.Size([51, 4096]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.07134, (torch.Size([2048, 4808]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.07061, (torch.Size([2048, 4808]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06120, (torch.Size([4096, 4096]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.06070, (torch.Size([4096, 1024]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.05633, (torch.Size([256, 128, 3, 3]))
2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03298, (torch.Size([1024, 512]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03117, (torch.Size([128, 2, 7, 7]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02859, (torch.Size([512, 1024]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02326, (torch.Size([151, 200]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02197, (torch.Size([4096, 512]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01846, (torch.Size([2048, 512]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.01748, (torch.Size([51, 4096]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01583, (torch.Size([2048, 512]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01034, (torch.Size([4096]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01017, (torch.Size([128]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00981, (torch.Size([4096]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00930, (torch.Size([512]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00854, (torch.Size([512, 32]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00835, (torch.Size([2048]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00835, (torch.Size([2048]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00788, (torch.Size([2048]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00788, (torch.Size([2048]))
2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00770, (torch.Size([1024]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00746, (torch.Size([256]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00495, (torch.Size([128]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00437, (torch.Size([128]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00374, (torch.Size([256]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00340, (torch.Size([22801, 51]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00326, (torch.Size([4096]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00322, (torch.Size([256]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00318, (torch.Size([4096]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00276, (torch.Size([4096]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00237, (torch.Size([51]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00186, (torch.Size([512]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00140, (torch.Size([4096]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00127, (torch.Size([51]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00109, (torch.Size([512, 1024]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00100, (torch.Size([2048, 4424]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00086, (torch.Size([2048, 4424]))
2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00083, (torch.Size([256]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00060, (torch.Size([512]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00016, (torch.Size([2048, 512]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00013, (torch.Size([2048, 512]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00013, (torch.Size([2048]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00013, (torch.Size([2048]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00013, (torch.Size([2048]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00013, (torch.Size([2048]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00002, (torch.Size([128]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: -------------------------------
2020-06-11 20:28:02,539 maskrcnn_benchmark INFO: eta: 5:31:54  iter: 24000  loss: 2.4206 (2.5538)  auxiliary_ctx: 0.0824 (0.1394)  auxiliary_frq: 0.1737 (0.1829)  auxiliary_vis: 0.0772 (0.1303)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0797 (2.1012)  time: 1.1427 (1.2447)  data: 0.0246 (0.1162)  lr: 0.006400  max mem: 6535
2020-06-11 20:28:02,542 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0024000.pth
2020-06-11 20:28:04,878 maskrcnn_benchmark INFO: Start validating
2020-06-11 20:28:04,907 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-11 20:29:37,336 maskrcnn_benchmark INFO: Total run time: 0:01:32.427971 (0.14788475303649903 s / img per device, on 8 devices)
2020-06-11 20:29:37,336 maskrcnn_benchmark INFO: Model inference time: 0:01:11.333352 (0.11413336372375488 s / img per device, on 8 devices)
2020-06-11 20:31:20,187 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5535;   R @ 50: 0.6057;   R @ 100: 0.6208;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6228; ngR @ 50: 0.7360; ngR @ 100: 0.7974;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0852;  zR @ 50: 0.1600;  zR @ 100: 0.1844;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1262;  mR @ 50: 0.1526;  mR @ 100: 0.1700;  for mode=predcls, type=Mean Recall.
(above:0.1218) (across:0.0556) (against:0.0000) (along:0.1667) (and:0.0323) (at:0.2057) (attached to:0.0000) (behind:0.3702) (belonging to:0.0286) (between:0.0000) (carrying:0.4956) (covered in:0.1429) (covering:0.0000) (eating:0.5000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0625) (has:0.7378) (holding:0.4911) (in:0.3435) (in front of:0.1441) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3510) (of:0.4253) (on:0.8163) (on back of:0.0000) (over:0.0467) (painted on:0.0000) (parked on:0.0511) (part of:0.0000) (playing:0.0000) (riding:0.5060) (says:0.0000) (sitting on:0.2391) (standing on:0.0322) (to:0.0000) (under:0.2092) (using:0.2115) (walking in:0.0000) (walking on:0.3292) (watching:0.2353) (wearing:0.9555) (wears:0.0000) (with:0.1102) 
SGG eval:   A @ 20: 0.6492;   A @ 50: 0.6531;   A @ 100: 0.6531;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-11 20:31:20,957 maskrcnn_benchmark INFO: Validation Result: 0.6208
2020-06-11 20:31:20,957 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-06-11 20:31:20,957 maskrcnn_benchmark INFO: Trigger MAX_DECAY_STEP at iteration 24000.
2020-06-11 20:31:21,275 maskrcnn_benchmark INFO: Total training time: 8:21:10.420090 (0.7518 s / it)
2020-06-11 20:31:23,151 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).
2020-06-11 20:39:20,338 maskrcnn_benchmark INFO: Total run time: 0:07:57.186201 (0.14435035962610593 s / img per device, on 8 devices)
2020-06-11 20:39:20,339 maskrcnn_benchmark INFO: Model inference time: 0:06:17.861666 (0.11430436843806295 s / img per device, on 8 devices)
2020-06-11 20:48:56,799 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9995
====================================================================================================
SGG eval:   R @ 20: 0.5354;   R @ 50: 0.6005;   R @ 100: 0.6206;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6042; ngR @ 50: 0.7359; ngR @ 100: 0.8031;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0624;  zR @ 50: 0.1092;  zR @ 100: 0.1362;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1093;  mR @ 50: 0.1429;  mR @ 100: 0.1612;  for mode=predcls, type=Mean Recall.
(above:0.1256) (across:0.0317) (against:0.0000) (along:0.0604) (and:0.1040) (at:0.2271) (attached to:0.0135) (behind:0.4994) (belonging to:0.0070) (between:0.0069) (carrying:0.2285) (covered in:0.2530) (covering:0.0495) (eating:0.2354) (flying in:0.0000) (for:0.0430) (from:0.0141) (growing on:0.0000) (hanging from:0.0366) (has:0.7644) (holding:0.6421) (in:0.3498) (in front of:0.1386) (laying on:0.0315) (looking at:0.0469) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3071) (of:0.5941) (on:0.7362) (on back of:0.0000) (over:0.0740) (painted on:0.0000) (parked on:0.0587) (part of:0.0000) (playing:0.0000) (riding:0.3493) (says:0.0000) (sitting on:0.2342) (standing on:0.0413) (to:0.0000) (under:0.2336) (using:0.0865) (walking in:0.0000) (walking on:0.1683) (watching:0.2184) (wearing:0.9487) (wears:0.0000) (with:0.1000) 
SGG eval:   A @ 20: 0.6391;   A @ 50: 0.6412;   A @ 100: 0.6412;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

