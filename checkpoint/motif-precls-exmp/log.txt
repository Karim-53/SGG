2020-06-06 19:03:54,762 maskrcnn_benchmark INFO: Using 2 GPUs
2020-06-06 19:03:54,762 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)
2020-06-06 19:03:54,762 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-06 19:03:59,132 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-06 19:03:59,133 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-06 19:03:59,133 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-06 19:03:59,135 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/motif-precls-exmp
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-06 19:03:59,136 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml
2020-06-06 19:03:59,169 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-06 19:04:02,233 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 19:04:02,233 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-06 19:19:50,289 maskrcnn_benchmark INFO: Using 2 GPUs
2020-06-06 19:19:50,289 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)
2020-06-06 19:19:50,289 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-06 19:19:54,613 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-06 19:19:54,613 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-06 19:19:54,614 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-06 19:19:54,616 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/motif-precls-exmp
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-06 19:19:54,617 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml
2020-06-06 19:19:54,649 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-06 19:19:57,817 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 19:19:57,818 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-06 19:52:22,857 maskrcnn_benchmark INFO: Using 2 GPUs
2020-06-06 19:52:22,857 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)
2020-06-06 19:52:22,858 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-06 19:52:27,167 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-06 19:52:27,167 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-06 19:52:27,168 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-06 19:52:27,170 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/motif-precls-exmp
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-06 19:52:27,171 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml
2020-06-06 19:52:27,204 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-06 19:52:30,378 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 19:52:30,378 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-06 19:52:56,276 maskrcnn_benchmark.data.build INFO: finish
2020-06-06 19:52:56,276 maskrcnn_benchmark.data.build INFO: Save data statistics to: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-06 19:52:56,276 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 20:00:11,383 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-06 20:00:12,179 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-06 20:00:12,208 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-06 20:00:12,209 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth
2020-06-06 20:12:15,508 maskrcnn_benchmark INFO: Using 2 GPUs
2020-06-06 20:12:15,508 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)
2020-06-06 20:12:15,508 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-06 20:12:20,001 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-06 20:12:20,001 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-06 20:12:20,002 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-06 20:12:20,004 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/motif-precls-exmp
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-06 20:12:20,005 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml
2020-06-06 20:12:20,038 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-06 20:12:23,236 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 20:12:23,236 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-06 20:12:23,237 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-06 20:12:23,237 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 20:12:24,486 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-06 20:12:24,903 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-06 20:12:24,931 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-06 20:12:24,933 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth
2020-06-06 20:29:51,547 maskrcnn_benchmark INFO: Using 2 GPUs
2020-06-06 20:29:51,547 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)
2020-06-06 20:29:51,547 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-06 20:29:55,864 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-06 20:29:55,865 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-06 20:29:55,866 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-06 20:29:55,868 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/motif-precls-exmp
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-06 20:29:55,869 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml
2020-06-06 20:29:55,895 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-06 20:29:59,199 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 20:29:59,200 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-06 20:29:59,200 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-06 20:29:59,200 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 20:30:00,351 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-06 20:30:01,042 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-06 20:30:01,073 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-06 20:30:01,075 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth
2020-06-06 20:30:01,870 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-06-06 20:30:01,870 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-06-06 20:30:01,870 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)
2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.bias of shape (4096,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.weight of shape (4096, 1024)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.rel_compress.bias of shape (51,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.rel_compress.weight of shape (51, 4096)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2020-06-06 20:30:02,167 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-06-06 20:30:02,168 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-06 20:30:04,738 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/motif-precls-exmp/labels.json
2020-06-06 20:30:05,847 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-06-06 20:30:05,847 maskrcnn_benchmark INFO: Validate before training
2020-06-06 20:30:05,856 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-06 20:34:51,927 maskrcnn_benchmark INFO: Total run time: 0:04:46.071012 (0.11442840480804443 s / img per device, on 2 devices)
2020-06-06 20:34:51,928 maskrcnn_benchmark INFO: Model inference time: 0:04:20.020102 (0.10400804090499878 s / img per device, on 2 devices)
2020-06-06 20:36:30,616 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.4903;   R @ 50: 0.5942;   R @ 100: 0.6399;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.5358; ngR @ 50: 0.6889; ngR @ 100: 0.7908;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0044;  zR @ 100: 0.0044;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0907;  mR @ 50: 0.1308;  mR @ 100: 0.1611;  for mode=predcls, type=Mean Recall.
(above:0.0387) (across:0.0556) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1217) (attached to:0.0000) (behind:0.3584) (belonging to:0.0000) (between:0.0000) (carrying:0.2259) (covered in:0.3214) (covering:0.0000) (eating:0.8571) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0368) (has:0.7741) (holding:0.4561) (in:0.3357) (in front of:0.0861) (laying on:0.0000) (looking at:0.0870) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3856) (of:0.3987) (on:0.8622) (on back of:0.0455) (over:0.0589) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6652) (says:0.0000) (sitting on:0.2866) (standing on:0.0072) (to:0.0000) (under:0.1378) (using:0.2885) (walking in:0.0000) (walking on:0.0503) (watching:0.0588) (wearing:0.9655) (wears:0.0000) (with:0.0528) 
SGG eval:   A @ 20: 0.6845;   A @ 50: 0.6897;   A @ 100: 0.6897;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-06 20:36:31,376 maskrcnn_benchmark INFO: Start training
2020-06-06 20:36:32,944 maskrcnn_benchmark INFO: ---Total norm 1.31536 clip coef 3.80123-----------------
2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.72468, (torch.Size([4096, 12544]))
2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.64445, (torch.Size([4096, 4096]))
2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.42083, (torch.Size([4096, 4096]))
2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.36141, (torch.Size([512, 1024]))
2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.33887, (torch.Size([4096, 1024]))
2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.32789, (torch.Size([4096, 12544]))
2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.30688, (torch.Size([51, 4096]))
2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.21697, (torch.Size([256, 1024, 3, 3]))
2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.20123, (torch.Size([2048, 4808]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.20000, (torch.Size([2048, 4808]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.12346, (torch.Size([256, 128, 3, 3]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.09852, (torch.Size([512]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.05440, (torch.Size([51]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.04651, (torch.Size([512, 1024]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.04630, (torch.Size([128, 2, 7, 7]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.03573, (torch.Size([2048, 512]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.03499, (torch.Size([2048, 512]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.02568, (torch.Size([2048, 4424]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.02428, (torch.Size([2048, 4424]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01546, (torch.Size([1024, 512]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.01485, (torch.Size([4096]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01431, (torch.Size([22801, 51]))
2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01418, (torch.Size([2048]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01418, (torch.Size([2048]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01370, (torch.Size([2048]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01370, (torch.Size([2048]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.01124, (torch.Size([512]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00968, (torch.Size([1024]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00769, (torch.Size([4096]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00696, (torch.Size([128]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00600, (torch.Size([4096]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00490, (torch.Size([2048, 512]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00442, (torch.Size([256]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00438, (torch.Size([2048, 512]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00359, (torch.Size([151, 200]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00306, (torch.Size([4096]))
2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00255, (torch.Size([256]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00220, (torch.Size([4096]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00201, (torch.Size([256]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00199, (torch.Size([128]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00175, (torch.Size([256]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00171, (torch.Size([2048]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00171, (torch.Size([2048]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00162, (torch.Size([2048]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00162, (torch.Size([2048]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00126, (torch.Size([128]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00118, (torch.Size([128, 32]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00083, (torch.Size([32, 9]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00042, (torch.Size([151, 200]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00040, (torch.Size([128]))
2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00019, (torch.Size([32]))
2020-06-06 20:36:32,960 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00014, (torch.Size([32]))
2020-06-06 20:36:32,960 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-06 20:36:32,960 maskrcnn_benchmark INFO: -------------------------------
2020-06-06 20:39:19,256 maskrcnn_benchmark INFO: eta: 11:36:41  iter: 200  loss: 0.1320 (0.1520)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1320 (0.1520)  time: 0.8365 (0.8394)  data: 0.0101 (0.0181)  lr: 0.054984  max mem: 5953
2020-06-06 20:42:06,471 maskrcnn_benchmark INFO: eta: 11:32:31  iter: 400  loss: 0.1435 (0.1470)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1435 (0.1470)  time: 0.8338 (0.8377)  data: 0.0155 (0.0165)  lr: 0.098184  max mem: 5953
2020-06-06 20:44:54,481 maskrcnn_benchmark INFO: eta: 11:30:22  iter: 600  loss: 0.1380 (0.1467)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1380 (0.1467)  time: 0.8304 (0.8385)  data: 0.0158 (0.0161)  lr: 0.120000  max mem: 5953
2020-06-06 20:47:41,848 maskrcnn_benchmark INFO: eta: 11:27:13  iter: 800  loss: 0.1230 (0.1454)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1230 (0.1454)  time: 0.8321 (0.8381)  data: 0.0156 (0.0159)  lr: 0.120000  max mem: 5953
2020-06-06 20:50:29,783 maskrcnn_benchmark INFO: eta: 11:24:41  iter: 1000  loss: 0.1441 (0.1438)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1441 (0.1438)  time: 0.8337 (0.8384)  data: 0.0165 (0.0157)  lr: 0.120000  max mem: 5953
2020-06-06 20:53:16,451 maskrcnn_benchmark INFO: eta: 11:21:12  iter: 1200  loss: 0.1255 (0.1425)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1255 (0.1425)  time: 0.8240 (0.8376)  data: 0.0143 (0.0157)  lr: 0.120000  max mem: 5953
2020-06-06 20:56:03,399 maskrcnn_benchmark INFO: eta: 11:18:05  iter: 1400  loss: 0.1192 (0.1413)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1192 (0.1413)  time: 0.8318 (0.8372)  data: 0.0159 (0.0157)  lr: 0.120000  max mem: 5953
2020-06-06 20:58:51,271 maskrcnn_benchmark INFO: eta: 11:15:31  iter: 1600  loss: 0.1243 (0.1408)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1243 (0.1408)  time: 0.8466 (0.8374)  data: 0.0151 (0.0157)  lr: 0.120000  max mem: 5953
2020-06-06 21:01:38,481 maskrcnn_benchmark INFO: eta: 11:12:36  iter: 1800  loss: 0.1194 (0.1400)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1194 (0.1400)  time: 0.8308 (0.8373)  data: 0.0160 (0.0157)  lr: 0.120000  max mem: 5953
2020-06-06 21:04:25,529 maskrcnn_benchmark INFO: eta: 11:09:39  iter: 2000  loss: 0.1282 (0.1396)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1282 (0.1396)  time: 0.8275 (0.8371)  data: 0.0161 (0.0157)  lr: 0.120000  max mem: 5973
2020-06-06 21:04:25,532 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0002000.pth
2020-06-06 21:04:27,900 maskrcnn_benchmark INFO: Start validating
2020-06-06 21:04:27,934 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-06 21:09:14,526 maskrcnn_benchmark INFO: Total run time: 0:04:46.591597 (0.11463663864135742 s / img per device, on 2 devices)
2020-06-06 21:09:14,527 maskrcnn_benchmark INFO: Model inference time: 0:04:22.336354 (0.10493454170227051 s / img per device, on 2 devices)
2020-06-06 21:10:52,395 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6015;   R @ 50: 0.6554;   R @ 100: 0.6722;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6856; ngR @ 50: 0.8146; ngR @ 100: 0.8774;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0178;  zR @ 100: 0.0356;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1162;  mR @ 50: 0.1411;  mR @ 100: 0.1516;  for mode=predcls, type=Mean Recall.
(above:0.0430) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1389) (attached to:0.0000) (behind:0.5206) (belonging to:0.0000) (between:0.0000) (carrying:0.3509) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8046) (holding:0.5838) (in:0.3545) (in front of:0.0366) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5390) (of:0.4650) (on:0.8977) (on back of:0.0455) (over:0.0366) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.5967) (says:0.0000) (sitting on:0.3272) (standing on:0.0109) (to:0.0000) (under:0.1633) (using:0.0385) (walking in:0.0000) (walking on:0.2626) (watching:0.1961) (wearing:0.9751) (wears:0.0000) (with:0.1028) 
SGG eval:   A @ 20: 0.6970;   A @ 50: 0.7018;   A @ 100: 0.7018;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-06 21:10:53,128 maskrcnn_benchmark INFO: Validation Result: 0.6722
2020-06-06 21:13:40,040 maskrcnn_benchmark INFO: eta: 13:27:02  iter: 2200  loss: 0.1231 (0.1391)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1391)  time: 0.8406 (1.0130)  data: 0.0164 (0.1919)  lr: 0.120000  max mem: 5973
2020-06-06 21:16:26,618 maskrcnn_benchmark INFO: eta: 13:11:45  iter: 2400  loss: 0.1342 (0.1385)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1342 (0.1385)  time: 0.8310 (0.9980)  data: 0.0160 (0.1773)  lr: 0.120000  max mem: 5973
2020-06-06 21:19:13,483 maskrcnn_benchmark INFO: eta: 12:58:29  iter: 2600  loss: 0.1380 (0.1381)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1380 (0.1381)  time: 0.8336 (0.9854)  data: 0.0166 (0.1650)  lr: 0.120000  max mem: 5973
2020-06-06 21:22:01,089 maskrcnn_benchmark INFO: eta: 12:46:55  iter: 2800  loss: 0.1249 (0.1379)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1249 (0.1379)  time: 0.8374 (0.9749)  data: 0.0159 (0.1543)  lr: 0.120000  max mem: 6112
2020-06-06 21:24:48,268 maskrcnn_benchmark INFO: eta: 12:36:24  iter: 3000  loss: 0.1292 (0.1377)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1292 (0.1377)  time: 0.8260 (0.9656)  data: 0.0161 (0.1451)  lr: 0.120000  max mem: 6112
2020-06-06 21:27:35,568 maskrcnn_benchmark INFO: eta: 12:26:53  iter: 3200  loss: 0.1316 (0.1373)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1316 (0.1373)  time: 0.8351 (0.9576)  data: 0.0173 (0.1370)  lr: 0.120000  max mem: 6112
2020-06-06 21:30:23,083 maskrcnn_benchmark INFO: eta: 12:18:13  iter: 3400  loss: 0.1311 (0.1371)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1311 (0.1371)  time: 0.8343 (0.9505)  data: 0.0159 (0.1299)  lr: 0.120000  max mem: 6112
2020-06-06 21:33:10,006 maskrcnn_benchmark INFO: eta: 12:10:04  iter: 3600  loss: 0.1353 (0.1369)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1353 (0.1369)  time: 0.8289 (0.9441)  data: 0.0164 (0.1236)  lr: 0.120000  max mem: 6112
2020-06-06 21:35:57,288 maskrcnn_benchmark INFO: eta: 12:02:33  iter: 3800  loss: 0.1173 (0.1365)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1173 (0.1365)  time: 0.8291 (0.9384)  data: 0.0169 (0.1179)  lr: 0.120000  max mem: 6112
2020-06-06 21:38:44,860 maskrcnn_benchmark INFO: ---Total norm 0.14507 clip coef 34.46614-----------------
2020-06-06 21:38:44,868 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.06706, (torch.Size([4096, 12544]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.05443, (torch.Size([4096, 12544]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.04995, (torch.Size([256, 1024, 3, 3]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.04818, (torch.Size([51, 4096]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.04536, (torch.Size([4096, 4096]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03947, (torch.Size([4096, 4096]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.03178, (torch.Size([4096, 1024]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03174, (torch.Size([512, 1024]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02645, (torch.Size([256, 128, 3, 3]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.02525, (torch.Size([2048, 4808]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.02486, (torch.Size([2048, 4808]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02434, (torch.Size([128, 2, 7, 7]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.01383, (torch.Size([51]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01151, (torch.Size([512]))
2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00782, (torch.Size([22801, 51]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00539, (torch.Size([512, 1024]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00468, (torch.Size([2048, 512]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00426, (torch.Size([2048, 512]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00421, (torch.Size([128]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00399, (torch.Size([2048, 4424]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00375, (torch.Size([2048, 4424]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00356, (torch.Size([2048]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00356, (torch.Size([2048]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00319, (torch.Size([2048]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00319, (torch.Size([2048]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00271, (torch.Size([512]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00257, (torch.Size([4096]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00238, (torch.Size([256]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00235, (torch.Size([1024, 512]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00183, (torch.Size([4096]))
2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00162, (torch.Size([1024]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00122, (torch.Size([151, 200]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00120, (torch.Size([256]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00110, (torch.Size([128]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00097, (torch.Size([4096]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00075, (torch.Size([256]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00073, (torch.Size([4096]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00070, (torch.Size([2048, 512]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00067, (torch.Size([2048, 512]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00063, (torch.Size([2048]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00063, (torch.Size([2048]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00062, (torch.Size([128]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00053, (torch.Size([2048]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00053, (torch.Size([2048]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00042, (torch.Size([256]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00034, (torch.Size([128, 32]))
2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00030, (torch.Size([32, 9]))
2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00028, (torch.Size([4096]))
2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00013, (torch.Size([128]))
2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00011, (torch.Size([151, 200]))
2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00008, (torch.Size([32]))
2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00005, (torch.Size([32]))
2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: -------------------------------
2020-06-06 21:38:44,874 maskrcnn_benchmark INFO: eta: 11:55:35  iter: 4000  loss: 0.1169 (0.1362)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1169 (0.1362)  time: 0.8380 (0.9334)  data: 0.0169 (0.1129)  lr: 0.120000  max mem: 6112
2020-06-06 21:38:44,877 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0004000.pth
2020-06-06 21:38:47,108 maskrcnn_benchmark INFO: Start validating
2020-06-06 21:38:47,129 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-06 21:43:33,231 maskrcnn_benchmark INFO: Total run time: 0:04:46.102085 (0.11444083404541015 s / img per device, on 2 devices)
2020-06-06 21:43:33,232 maskrcnn_benchmark INFO: Model inference time: 0:04:20.722934 (0.104289173412323 s / img per device, on 2 devices)
2020-06-06 21:45:11,310 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6032;   R @ 50: 0.6590;   R @ 100: 0.6737;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6913; ngR @ 50: 0.8168; ngR @ 100: 0.8828;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0289;  zR @ 100: 0.0467;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1218;  mR @ 50: 0.1520;  mR @ 100: 0.1610;  for mode=predcls, type=Mean Recall.
(above:0.0723) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.4349) (attached to:0.0000) (behind:0.5148) (belonging to:0.0000) (between:0.0000) (carrying:0.1754) (covered in:0.0000) (covering:0.0000) (eating:0.2381) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8116) (holding:0.6128) (in:0.3678) (in front of:0.1040) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4648) (of:0.4305) (on:0.9065) (on back of:0.0455) (over:0.0732) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4271) (says:0.0000) (sitting on:0.2866) (standing on:0.0109) (to:0.0000) (under:0.2615) (using:0.1923) (walking in:0.0000) (walking on:0.1717) (watching:0.3039) (wearing:0.9766) (wears:0.0000) (with:0.1229) 
SGG eval:   A @ 20: 0.6985;   A @ 50: 0.7033;   A @ 100: 0.7033;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-06 21:45:12,049 maskrcnn_benchmark INFO: Validation Result: 0.6737
2020-06-06 21:47:59,091 maskrcnn_benchmark INFO: eta: 12:59:16  iter: 4200  loss: 0.1414 (0.1359)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1414 (0.1359)  time: 0.8359 (1.0209)  data: 0.0175 (0.2005)  lr: 0.120000  max mem: 6112
2020-06-06 21:50:46,509 maskrcnn_benchmark INFO: eta: 12:49:31  iter: 4400  loss: 0.1218 (0.1357)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1218 (0.1357)  time: 0.8262 (1.0125)  data: 0.0163 (0.1921)  lr: 0.120000  max mem: 6112
2020-06-06 21:53:33,524 maskrcnn_benchmark INFO: eta: 12:40:18  iter: 4600  loss: 0.1307 (0.1355)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1307 (0.1355)  time: 0.8315 (1.0048)  data: 0.0167 (0.1845)  lr: 0.120000  max mem: 6112
2020-06-06 21:56:21,204 maskrcnn_benchmark INFO: eta: 12:31:44  iter: 4800  loss: 0.1232 (0.1355)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1232 (0.1355)  time: 0.8394 (0.9979)  data: 0.0161 (0.1775)  lr: 0.120000  max mem: 6112
2020-06-06 21:59:07,104 maskrcnn_benchmark INFO: eta: 12:23:21  iter: 5000  loss: 0.1226 (0.1353)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1226 (0.1353)  time: 0.8378 (0.9911)  data: 0.0165 (0.1710)  lr: 0.120000  max mem: 6112
2020-06-06 22:01:54,107 maskrcnn_benchmark INFO: eta: 12:15:34  iter: 5200  loss: 0.1343 (0.1350)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1343 (0.1350)  time: 0.8276 (0.9851)  data: 0.0167 (0.1651)  lr: 0.120000  max mem: 6112
2020-06-06 22:04:40,134 maskrcnn_benchmark INFO: eta: 12:08:01  iter: 5400  loss: 0.1379 (0.1349)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1379 (0.1349)  time: 0.8364 (0.9794)  data: 0.0161 (0.1596)  lr: 0.120000  max mem: 6112
2020-06-06 22:07:26,783 maskrcnn_benchmark INFO: eta: 12:00:53  iter: 5600  loss: 0.1395 (0.1347)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1395 (0.1347)  time: 0.8261 (0.9742)  data: 0.0167 (0.1545)  lr: 0.120000  max mem: 6112
2020-06-06 22:10:13,418 maskrcnn_benchmark INFO: eta: 11:54:03  iter: 5800  loss: 0.1371 (0.1346)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1371 (0.1346)  time: 0.8344 (0.9693)  data: 0.0153 (0.1497)  lr: 0.120000  max mem: 6112
2020-06-06 22:12:59,923 maskrcnn_benchmark INFO: eta: 11:47:29  iter: 6000  loss: 0.1283 (0.1345)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1283 (0.1345)  time: 0.8294 (0.9648)  data: 0.0169 (0.1452)  lr: 0.120000  max mem: 6112
2020-06-06 22:12:59,926 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0006000.pth
2020-06-06 22:13:02,649 maskrcnn_benchmark INFO: Start validating
2020-06-06 22:13:02,693 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-06 22:17:49,348 maskrcnn_benchmark INFO: Total run time: 0:04:46.654371 (0.11466174840927124 s / img per device, on 2 devices)
2020-06-06 22:17:49,348 maskrcnn_benchmark INFO: Model inference time: 0:04:18.928373 (0.10357134904861451 s / img per device, on 2 devices)
2020-06-06 22:19:28,313 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6023;   R @ 50: 0.6577;   R @ 100: 0.6736;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6929; ngR @ 50: 0.8186; ngR @ 100: 0.8849;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0089;  zR @ 50: 0.0222;  zR @ 100: 0.0267;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1286;  mR @ 50: 0.1578;  mR @ 100: 0.1680;  for mode=predcls, type=Mean Recall.
(above:0.1433) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1524) (attached to:0.0000) (behind:0.4792) (belonging to:0.0000) (between:0.0000) (carrying:0.6228) (covered in:0.0000) (covering:0.0000) (eating:0.3810) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8130) (holding:0.5321) (in:0.3623) (in front of:0.0644) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5649) (of:0.4582) (on:0.8821) (on back of:0.0455) (over:0.1057) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3467) (says:0.0000) (sitting on:0.3351) (standing on:0.0152) (to:0.0000) (under:0.2538) (using:0.0385) (walking in:0.0000) (walking on:0.5199) (watching:0.1275) (wearing:0.9692) (wears:0.0000) (with:0.1055) 
SGG eval:   A @ 20: 0.7001;   A @ 50: 0.7047;   A @ 100: 0.7047;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-06 22:19:29,046 maskrcnn_benchmark INFO: Validation Result: 0.6736
2020-06-06 22:22:15,750 maskrcnn_benchmark INFO: eta: 12:26:59  iter: 6200  loss: 0.1153 (0.1343)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1153 (0.1343)  time: 0.8311 (1.0233)  data: 0.0171 (0.2038)  lr: 0.120000  max mem: 6146
2020-06-06 22:25:02,615 maskrcnn_benchmark INFO: eta: 12:19:17  iter: 6400  loss: 0.1229 (0.1343)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1229 (0.1343)  time: 0.8282 (1.0174)  data: 0.0164 (0.1980)  lr: 0.120000  max mem: 6146
2020-06-06 22:27:50,451 maskrcnn_benchmark INFO: eta: 12:11:59  iter: 6600  loss: 0.1160 (0.1341)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1160 (0.1341)  time: 0.8316 (1.0120)  data: 0.0159 (0.1925)  lr: 0.120000  max mem: 6146
2020-06-06 22:30:37,732 maskrcnn_benchmark INFO: eta: 12:04:54  iter: 6800  loss: 0.1134 (0.1339)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1134 (0.1339)  time: 0.8408 (1.0068)  data: 0.0171 (0.1873)  lr: 0.120000  max mem: 6146
2020-06-06 22:33:25,064 maskrcnn_benchmark INFO: eta: 11:58:04  iter: 7000  loss: 0.1153 (0.1337)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1153 (0.1337)  time: 0.8248 (1.0020)  data: 0.0158 (0.1824)  lr: 0.120000  max mem: 6146
2020-06-06 22:36:12,312 maskrcnn_benchmark INFO: eta: 11:51:26  iter: 7200  loss: 0.1288 (0.1337)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1288 (0.1337)  time: 0.8260 (0.9974)  data: 0.0162 (0.1778)  lr: 0.120000  max mem: 6146
2020-06-06 22:38:59,877 maskrcnn_benchmark INFO: eta: 11:45:03  iter: 7400  loss: 0.1245 (0.1335)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1245 (0.1335)  time: 0.8206 (0.9930)  data: 0.0148 (0.1734)  lr: 0.120000  max mem: 6146
2020-06-06 22:41:48,110 maskrcnn_benchmark INFO: eta: 11:38:55  iter: 7600  loss: 0.1283 (0.1334)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1283 (0.1334)  time: 0.8364 (0.9890)  data: 0.0164 (0.1693)  lr: 0.120000  max mem: 6146
2020-06-06 22:44:35,178 maskrcnn_benchmark INFO: eta: 11:32:51  iter: 7800  loss: 0.1144 (0.1333)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1144 (0.1333)  time: 0.8383 (0.9851)  data: 0.0156 (0.1654)  lr: 0.120000  max mem: 6146
2020-06-06 22:47:22,106 maskrcnn_benchmark INFO: ---Total norm 0.07148 clip coef 69.95044-----------------
2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.03135, (torch.Size([4096, 12544]))
2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.02887, (torch.Size([4096, 12544]))
2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02535, (torch.Size([51, 4096]))
2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.02411, (torch.Size([256, 1024, 3, 3]))
2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01982, (torch.Size([4096, 4096]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01834, (torch.Size([4096, 4096]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01772, (torch.Size([4096, 1024]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01580, (torch.Size([512, 1024]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01489, (torch.Size([256, 128, 3, 3]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01279, (torch.Size([128, 2, 7, 7]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01272, (torch.Size([2048, 4808]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01233, (torch.Size([2048, 4808]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00441, (torch.Size([22801, 51]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00362, (torch.Size([51]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00298, (torch.Size([512]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00230, (torch.Size([2048, 512]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00208, (torch.Size([2048, 512]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00208, (torch.Size([128]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00192, (torch.Size([1024, 512]))
2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00165, (torch.Size([256]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00132, (torch.Size([4096]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00131, (torch.Size([2048, 4424]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00127, (torch.Size([2048, 4424]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00127, (torch.Size([512, 1024]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00123, (torch.Size([256]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00121, (torch.Size([128]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00107, (torch.Size([4096]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00082, (torch.Size([2048]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00082, (torch.Size([2048]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00076, (torch.Size([2048]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00076, (torch.Size([2048]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00074, (torch.Size([151, 200]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00068, (torch.Size([1024]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00062, (torch.Size([256]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00053, (torch.Size([4096]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00048, (torch.Size([4096]))
2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00045, (torch.Size([128]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00029, (torch.Size([512]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00024, (torch.Size([256]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00016, (torch.Size([4096]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00014, (torch.Size([2048, 512]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00014, (torch.Size([2048, 512]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00007, (torch.Size([32, 9]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00006, (torch.Size([128, 32]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00004, (torch.Size([2048]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00004, (torch.Size([2048]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00004, (torch.Size([2048]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00004, (torch.Size([2048]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00003, (torch.Size([151, 200]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00001, (torch.Size([32]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: -------------------------------
2020-06-06 22:47:22,120 maskrcnn_benchmark INFO: eta: 11:26:56  iter: 8000  loss: 0.1250 (0.1332)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1250 (0.1332)  time: 0.8329 (0.9813)  data: 0.0173 (0.1616)  lr: 0.120000  max mem: 6146
2020-06-06 22:47:22,122 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0008000.pth
2020-06-06 22:47:24,646 maskrcnn_benchmark INFO: Start validating
2020-06-06 22:47:24,670 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-06 22:52:09,321 maskrcnn_benchmark INFO: Total run time: 0:04:44.650700 (0.11386027994155884 s / img per device, on 2 devices)
2020-06-06 22:52:09,321 maskrcnn_benchmark INFO: Model inference time: 0:04:20.262586 (0.10410503435134888 s / img per device, on 2 devices)
2020-06-06 22:54:11,138 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6083;   R @ 50: 0.6601;   R @ 100: 0.6759;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6957; ngR @ 50: 0.8224; ngR @ 100: 0.8873;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0267;  zR @ 100: 0.0400;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1140;  mR @ 50: 0.1395;  mR @ 100: 0.1489;  for mode=predcls, type=Mean Recall.
(above:0.0865) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1389) (attached to:0.0000) (behind:0.4310) (belonging to:0.0000) (between:0.0000) (carrying:0.5768) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8197) (holding:0.5501) (in:0.3751) (in front of:0.1420) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5191) (of:0.3947) (on:0.9155) (on back of:0.0455) (over:0.0976) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1830) (says:0.0000) (sitting on:0.2526) (standing on:0.0130) (to:0.0000) (under:0.2538) (using:0.1923) (walking in:0.0000) (walking on:0.0473) (watching:0.2941) (wearing:0.9718) (wears:0.0000) (with:0.0987) 
SGG eval:   A @ 20: 0.7014;   A @ 50: 0.7062;   A @ 100: 0.7062;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-06 22:54:11,882 maskrcnn_benchmark INFO: Validation Result: 0.6759
2020-06-06 22:56:59,227 maskrcnn_benchmark INFO: eta: 11:56:01  iter: 8200  loss: 0.1405 (0.1331)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1405 (0.1331)  time: 0.8383 (1.0278)  data: 0.0169 (0.2081)  lr: 0.120000  max mem: 6146
2020-06-06 22:59:48,083 maskrcnn_benchmark INFO: eta: 11:49:34  iter: 8400  loss: 0.1108 (0.1329)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1108 (0.1329)  time: 0.8421 (1.0234)  data: 0.0162 (0.2035)  lr: 0.120000  max mem: 6146
2020-06-06 23:02:36,522 maskrcnn_benchmark INFO: eta: 11:43:14  iter: 8600  loss: 0.1344 (0.1328)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1344 (0.1328)  time: 0.8420 (1.0192)  data: 0.0166 (0.1992)  lr: 0.120000  max mem: 6146
2020-06-06 23:05:24,869 maskrcnn_benchmark INFO: eta: 11:37:04  iter: 8800  loss: 0.1360 (0.1327)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1360 (0.1327)  time: 0.8467 (1.0152)  data: 0.0156 (0.1950)  lr: 0.120000  max mem: 6146
2020-06-06 23:08:13,820 maskrcnn_benchmark INFO: eta: 11:31:06  iter: 9000  loss: 0.1178 (0.1326)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1178 (0.1326)  time: 0.8245 (1.0114)  data: 0.0166 (0.1910)  lr: 0.120000  max mem: 6146
2020-06-06 23:11:02,009 maskrcnn_benchmark INFO: eta: 11:25:13  iter: 9200  loss: 0.1231 (0.1325)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1325)  time: 0.8477 (1.0077)  data: 0.0133 (0.1872)  lr: 0.120000  max mem: 6146
2020-06-06 23:13:50,129 maskrcnn_benchmark INFO: eta: 11:19:27  iter: 9400  loss: 0.1281 (0.1326)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1281 (0.1326)  time: 0.8459 (1.0041)  data: 0.0157 (0.1836)  lr: 0.120000  max mem: 6146
2020-06-06 23:16:37,289 maskrcnn_benchmark INFO: eta: 11:13:44  iter: 9600  loss: 0.1307 (0.1326)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1307 (0.1326)  time: 0.8309 (1.0006)  data: 0.0150 (0.1801)  lr: 0.120000  max mem: 6146
2020-06-06 23:19:09,515 maskrcnn_benchmark INFO: Using 8 GPUs
2020-06-06 23:19:09,515 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '30000', 'SOLVER.VAL_PERIOD', '5000', 'SOLVER.CHECKPOINT_PERIOD', '5000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)
2020-06-06 23:19:09,515 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-06 23:19:14,252 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-06 23:19:14,253 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-06 23:19:14,253 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-06 23:19:14,256 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/motif-precls-exmp
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 5000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 30000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 5000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-06 23:19:14,256 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml
2020-06-06 23:19:14,284 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-06 23:19:17,528 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 23:19:17,528 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-06 23:19:17,529 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-06 23:19:17,529 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 23:19:18,763 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-06 23:19:19,343 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-06 23:19:19,372 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-06 23:19:19,374 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/motif-precls-exmp/model_0008000.pth
2020-06-06 23:19:21,456 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/motif-precls-exmp/model_0008000.pth
2020-06-06 23:19:22,125 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-06-06 23:21:30,919 maskrcnn_benchmark INFO: Using 8 GPUs
2020-06-06 23:21:30,919 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '48', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '30000', 'SOLVER.VAL_PERIOD', '5000', 'SOLVER.CHECKPOINT_PERIOD', '5000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)
2020-06-06 23:21:30,919 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-06 23:21:35,925 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-06 23:21:35,925 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-06 23:21:35,926 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-06 23:21:35,928 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/motif-precls-exmp
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 5000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 48
  MAX_ITER: 30000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 5000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-06 23:21:35,929 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml
2020-06-06 23:21:35,954 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-06 23:21:39,326 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 23:21:39,327 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-06 23:21:39,327 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-06 23:21:39,328 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 23:21:40,567 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-06 23:21:41,577 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-06 23:21:41,616 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-06 23:21:41,618 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/motif-precls-exmp/model_0008000.pth
2020-06-06 23:21:43,705 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/motif-precls-exmp/model_0008000.pth
2020-06-06 23:21:44,323 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-06-06 23:21:44,323 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-06 23:21:46,955 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/motif-precls-exmp/labels.json
2020-06-06 23:23:04,887 maskrcnn_benchmark INFO: Using 8 GPUs
2020-06-06 23:23:04,888 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '48', 'TEST.IMS_PER_BATCH', '16', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '30000', 'SOLVER.VAL_PERIOD', '5000', 'SOLVER.CHECKPOINT_PERIOD', '5000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)
2020-06-06 23:23:04,888 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-06 23:23:09,961 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-06 23:23:09,962 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-06 23:23:09,962 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-06 23:23:09,965 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/motif-precls-exmp
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 5000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 48
  MAX_ITER: 30000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 5000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 16
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-06 23:23:09,966 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml
2020-06-06 23:23:09,999 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-06 23:23:13,299 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 23:23:13,300 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-06 23:23:13,300 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-06 23:23:13,301 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-06 23:23:14,493 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-06 23:23:15,182 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-06 23:23:15,216 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-06 23:23:15,218 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/motif-precls-exmp/model_0008000.pth
2020-06-06 23:23:17,295 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/motif-precls-exmp/model_0008000.pth
2020-06-06 23:23:17,912 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-06-06 23:23:17,912 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-06 23:23:20,709 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/motif-precls-exmp/labels.json
2020-06-06 23:23:20,757 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-06 23:23:21,988 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-06-06 23:23:21,989 maskrcnn_benchmark INFO: Validate before training
2020-06-06 23:23:21,991 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-06 23:24:31,490 maskrcnn_benchmark INFO: Total run time: 0:01:09.498150 (0.1111970401763916 s / img per device, on 8 devices)
2020-06-06 23:24:31,490 maskrcnn_benchmark INFO: Model inference time: 0:00:56.009438 (0.08961510086059571 s / img per device, on 8 devices)
2020-06-07 09:28:55,274 maskrcnn_benchmark INFO: Using 8 GPUs
2020-06-07 09:28:55,274 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '48', 'TEST.IMS_PER_BATCH', '16', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '30000', 'SOLVER.VAL_PERIOD', '5000', 'SOLVER.CHECKPOINT_PERIOD', '5000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)
2020-06-07 09:28:55,274 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-06-07 09:28:59,747 maskrcnn_benchmark INFO: 
PyTorch version: 1.5.0+cu101
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.4 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.105
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti
GPU 4: GeForce RTX 2080 Ti
GPU 5: GeForce RTX 2080 Ti
GPU 6: GeForce RTX 2080 Ti
GPU 7: GeForce RTX 2080 Ti

Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] torch==1.5.0+cu101
[pip3] torchvision==0.6.0+cu101
[conda] mkl                       2018.0.1             h19d6760_4  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] torch                     1.5.0+cu101              pypi_0    pypi
[conda] torchvision               0.6.0+cu101              pypi_0    pypi
        Pillow (7.1.2)
2020-06-07 09:28:59,748 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-06-07 09:28:59,748 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-06-07 09:28:59,751 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: glove/
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: checkpoint/motif-precls-exmp
PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 5000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 48
  MAX_ITER: 30000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 5000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 16
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-06-07 09:28:59,752 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml
2020-06-07 09:28:59,784 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-06-07 09:29:03,024 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-07 09:29:03,024 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-06-07 09:29:03,025 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-06-07 09:29:03,025 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-06-07 09:29:04,233 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-06-07 09:29:04,643 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-06-07 09:29:04,714 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-06-07 09:29:04,717 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/motif-precls-exmp/model_0008000.pth
2020-06-07 09:29:06,815 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/motif-precls-exmp/model_0008000.pth
2020-06-07 09:29:07,471 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-06-07 09:29:07,471 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-07 09:29:10,118 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/motif-precls-exmp/labels.json
2020-06-07 09:29:10,166 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-07 09:29:11,292 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-06-07 09:29:11,292 maskrcnn_benchmark INFO: Validate before training
2020-06-07 09:29:11,295 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-07 09:30:22,887 maskrcnn_benchmark INFO: Total run time: 0:01:11.592203 (0.11454752540588378 s / img per device, on 8 devices)
2020-06-07 09:30:22,888 maskrcnn_benchmark INFO: Model inference time: 0:00:56.318217 (0.09010914726257324 s / img per device, on 8 devices)
2020-06-07 09:32:07,844 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6082;   R @ 50: 0.6603;   R @ 100: 0.6760;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6954; ngR @ 50: 0.8225; ngR @ 100: 0.8873;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0267;  zR @ 100: 0.0400;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1140;  mR @ 50: 0.1396;  mR @ 100: 0.1486;  for mode=predcls, type=Mean Recall.
(above:0.0865) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1389) (attached to:0.0000) (behind:0.4310) (belonging to:0.0000) (between:0.0000) (carrying:0.5636) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8206) (holding:0.5501) (in:0.3751) (in front of:0.1374) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5191) (of:0.3947) (on:0.9157) (on back of:0.0455) (over:0.0976) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1830) (says:0.0000) (sitting on:0.2526) (standing on:0.0130) (to:0.0000) (under:0.2538) (using:0.1923) (walking in:0.0000) (walking on:0.0485) (watching:0.2941) (wearing:0.9718) (wears:0.0000) (with:0.1006) 
SGG eval:   A @ 20: 0.7016;   A @ 50: 0.7063;   A @ 100: 0.7063;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-07 09:32:08,493 maskrcnn_benchmark INFO: Start training
2020-06-07 09:32:10,316 maskrcnn_benchmark INFO: ---Total norm 0.05643 clip coef 88.60008-----------------
2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.02425, (torch.Size([4096, 12544]))
2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.02289, (torch.Size([4096, 12544]))
2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02120, (torch.Size([51, 4096]))
2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.02110, (torch.Size([256, 1024, 3, 3]))
2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01560, (torch.Size([4096, 4096]))
2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01476, (torch.Size([4096, 4096]))
2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01305, (torch.Size([4096, 1024]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01134, (torch.Size([256, 128, 3, 3]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01128, (torch.Size([128, 2, 7, 7]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01069, (torch.Size([512, 1024]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.00741, (torch.Size([2048, 4808]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.00721, (torch.Size([2048, 4808]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00432, (torch.Size([51]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00379, (torch.Size([512]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00379, (torch.Size([22801, 51]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00162, (torch.Size([1024, 512]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00158, (torch.Size([128]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00154, (torch.Size([2048, 512]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00139, (torch.Size([256]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00135, (torch.Size([4096]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00123, (torch.Size([2048, 512]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00097, (torch.Size([256]))
2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00095, (torch.Size([4096]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00093, (torch.Size([2048]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00093, (torch.Size([2048]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00092, (torch.Size([1024]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00090, (torch.Size([128]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00079, (torch.Size([2048]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00079, (torch.Size([2048]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00059, (torch.Size([2048, 4424]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00059, (torch.Size([512, 1024]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00058, (torch.Size([2048, 4424]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00054, (torch.Size([151, 200]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00050, (torch.Size([256]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00048, (torch.Size([4096]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00042, (torch.Size([4096]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00037, (torch.Size([128]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00032, (torch.Size([512]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00019, (torch.Size([256]))
2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00014, (torch.Size([4096]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00007, (torch.Size([2048, 512]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00006, (torch.Size([2048, 512]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00005, (torch.Size([2048]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00005, (torch.Size([2048]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00004, (torch.Size([128, 32]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00003, (torch.Size([2048]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00003, (torch.Size([2048]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00003, (torch.Size([32, 9]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00002, (torch.Size([151, 200]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00001, (torch.Size([32]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: -------------------------------
2020-06-07 09:35:16,944 maskrcnn_benchmark INFO: eta: 5:42:21  iter: 8200  loss: 0.1226 (0.1285)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1226 (0.1285)  time: 0.9399 (0.9422)  data: 0.0215 (0.0240)  lr: 0.480000  max mem: 5820
2020-06-07 09:38:25,069 maskrcnn_benchmark INFO: eta: 5:38:55  iter: 8400  loss: 0.1248 (0.1287)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1248 (0.1287)  time: 0.9379 (0.9414)  data: 0.0210 (0.0223)  lr: 0.480000  max mem: 5943
2020-06-07 09:41:32,638 maskrcnn_benchmark INFO: eta: 5:35:21  iter: 8600  loss: 0.1252 (0.1292)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1252 (0.1292)  time: 0.9337 (0.9402)  data: 0.0218 (0.0215)  lr: 0.480000  max mem: 6096
2020-06-07 09:44:40,807 maskrcnn_benchmark INFO: eta: 5:32:16  iter: 8800  loss: 0.1240 (0.1293)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1240 (0.1293)  time: 0.9424 (0.9404)  data: 0.0203 (0.0213)  lr: 0.480000  max mem: 6096
2020-06-07 09:47:48,586 maskrcnn_benchmark INFO: eta: 5:29:01  iter: 9000  loss: 0.1340 (0.1291)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1340 (0.1291)  time: 0.9352 (0.9401)  data: 0.0225 (0.0213)  lr: 0.480000  max mem: 6096
2020-06-07 09:50:56,721 maskrcnn_benchmark INFO: eta: 5:25:55  iter: 9200  loss: 0.1292 (0.1290)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1292 (0.1290)  time: 0.9370 (0.9402)  data: 0.0189 (0.0211)  lr: 0.480000  max mem: 6096
2020-06-07 09:54:04,367 maskrcnn_benchmark INFO: eta: 5:22:42  iter: 9400  loss: 0.1269 (0.1291)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1269 (0.1291)  time: 0.9367 (0.9399)  data: 0.0205 (0.0209)  lr: 0.480000  max mem: 6096
2020-06-07 09:57:12,187 maskrcnn_benchmark INFO: eta: 5:19:32  iter: 9600  loss: 0.1235 (0.1292)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1235 (0.1292)  time: 0.9303 (0.9398)  data: 0.0209 (0.0210)  lr: 0.480000  max mem: 6096
2020-06-07 10:00:19,764 maskrcnn_benchmark INFO: eta: 5:16:19  iter: 9800  loss: 0.1231 (0.1290)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1290)  time: 0.9318 (0.9396)  data: 0.0211 (0.0209)  lr: 0.480000  max mem: 6096
2020-06-07 10:03:27,953 maskrcnn_benchmark INFO: eta: 5:13:14  iter: 10000  loss: 0.1314 (0.1290)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1314 (0.1290)  time: 0.9378 (0.9397)  data: 0.0213 (0.0208)  lr: 0.480000  max mem: 6096
2020-06-07 10:03:27,956 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0010000.pth
2020-06-07 10:03:30,426 maskrcnn_benchmark INFO: Start validating
2020-06-07 10:03:30,455 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-07 10:04:40,750 maskrcnn_benchmark INFO: Total run time: 0:01:10.293523 (0.11246963729858399 s / img per device, on 8 devices)
2020-06-07 10:04:40,750 maskrcnn_benchmark INFO: Model inference time: 0:00:56.796546 (0.09087447395324708 s / img per device, on 8 devices)
2020-06-07 10:06:29,598 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6004;   R @ 50: 0.6576;   R @ 100: 0.6735;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6891; ngR @ 50: 0.8209; ngR @ 100: 0.8870;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0356;  zR @ 100: 0.0533;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1058;  mR @ 50: 0.1302;  mR @ 100: 0.1408;  for mode=predcls, type=Mean Recall.
(above:0.2127) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1237) (attached to:0.0000) (behind:0.4773) (belonging to:0.0000) (between:0.0000) (carrying:0.1425) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8294) (holding:0.5773) (in:0.3578) (in front of:0.0787) (laying on:0.0000) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5812) (of:0.4709) (on:0.8928) (on back of:0.0455) (over:0.0610) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1696) (says:0.0000) (sitting on:0.2068) (standing on:0.0109) (to:0.0000) (under:0.2398) (using:0.1154) (walking in:0.0000) (walking on:0.0000) (watching:0.2843) (wearing:0.9730) (wears:0.0000) (with:0.0797) 
SGG eval:   A @ 20: 0.6979;   A @ 50: 0.7026;   A @ 100: 0.7026;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-07 10:06:30,385 maskrcnn_benchmark INFO: Validation Result: 0.6735
2020-06-07 10:09:38,228 maskrcnn_benchmark INFO: eta: 5:37:27  iter: 10200  loss: 0.1252 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1252 (0.1288)  time: 0.9439 (1.0226)  data: 0.0206 (0.1035)  lr: 0.480000  max mem: 6096
2020-06-07 10:12:46,214 maskrcnn_benchmark INFO: eta: 5:31:48  iter: 10400  loss: 0.1361 (0.1289)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1361 (0.1289)  time: 0.9355 (1.0157)  data: 0.0212 (0.0967)  lr: 0.480000  max mem: 6096
2020-06-07 10:15:53,955 maskrcnn_benchmark INFO: eta: 5:26:29  iter: 10600  loss: 0.1219 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1219 (0.1288)  time: 0.9357 (1.0098)  data: 0.0209 (0.0908)  lr: 0.480000  max mem: 6096
2020-06-07 10:19:01,456 maskrcnn_benchmark INFO: eta: 5:21:28  iter: 10800  loss: 0.1223 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1223 (0.1288)  time: 0.9394 (1.0046)  data: 0.0191 (0.0857)  lr: 0.480000  max mem: 6096
2020-06-07 10:22:09,694 maskrcnn_benchmark INFO: eta: 5:16:47  iter: 11000  loss: 0.1202 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1202 (0.1288)  time: 0.9410 (1.0004)  data: 0.0206 (0.0814)  lr: 0.480000  max mem: 6096
2020-06-07 10:25:17,366 maskrcnn_benchmark INFO: eta: 5:12:14  iter: 11200  loss: 0.1270 (0.1289)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1270 (0.1289)  time: 0.9378 (0.9965)  data: 0.0220 (0.0775)  lr: 0.480000  max mem: 6096
2020-06-07 10:28:24,817 maskrcnn_benchmark INFO: eta: 5:07:50  iter: 11400  loss: 0.1260 (0.1289)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1260 (0.1289)  time: 0.9352 (0.9930)  data: 0.0203 (0.0741)  lr: 0.480000  max mem: 6096
2020-06-07 10:31:32,804 maskrcnn_benchmark INFO: eta: 5:03:37  iter: 11600  loss: 0.1302 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1302 (0.1288)  time: 0.9409 (0.9901)  data: 0.0210 (0.0712)  lr: 0.480000  max mem: 6096
2020-06-07 10:34:40,676 maskrcnn_benchmark INFO: eta: 4:59:30  iter: 11800  loss: 0.1373 (0.1289)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1373 (0.1289)  time: 0.9307 (0.9874)  data: 0.0200 (0.0684)  lr: 0.480000  max mem: 6096
2020-06-07 10:37:48,742 maskrcnn_benchmark INFO: ---Total norm 0.08505 clip coef 58.78942-----------------
2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.04588, (torch.Size([4096, 12544]))
2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.03735, (torch.Size([256, 1024, 3, 3]))
2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.03207, (torch.Size([4096, 12544]))
2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02796, (torch.Size([51, 4096]))
2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01836, (torch.Size([4096, 4096]))
2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01533, (torch.Size([4096, 4096]))
2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01473, (torch.Size([2048, 4808]))
2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01442, (torch.Size([512, 1024]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01399, (torch.Size([128, 2, 7, 7]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01399, (torch.Size([4096, 1024]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01330, (torch.Size([256, 128, 3, 3]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01197, (torch.Size([2048, 4808]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00766, (torch.Size([1024, 512]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00665, (torch.Size([51]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00482, (torch.Size([22801, 51]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00420, (torch.Size([128]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00364, (torch.Size([4096]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00330, (torch.Size([512]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00270, (torch.Size([1024]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00262, (torch.Size([128]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00232, (torch.Size([256]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00228, (torch.Size([2048, 512]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00210, (torch.Size([2048, 512]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00207, (torch.Size([256]))
2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00185, (torch.Size([256]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00161, (torch.Size([128]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00108, (torch.Size([2048]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00108, (torch.Size([2048]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00104, (torch.Size([4096]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00102, (torch.Size([2048]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00102, (torch.Size([2048]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00065, (torch.Size([4096]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00052, (torch.Size([4096]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00030, (torch.Size([256]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00028, (torch.Size([4096]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00023, (torch.Size([151, 200]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00014, (torch.Size([512]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00014, (torch.Size([512, 1024]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00009, (torch.Size([2048, 4424]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00008, (torch.Size([2048, 4424]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00001, (torch.Size([2048]))
2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00001, (torch.Size([2048]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00001, (torch.Size([2048]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00001, (torch.Size([2048]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00001, (torch.Size([2048, 512]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: -------------------------------
2020-06-07 10:37:48,757 maskrcnn_benchmark INFO: eta: 4:55:31  iter: 12000  loss: 0.1270 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1270 (0.1288)  time: 0.9319 (0.9851)  data: 0.0212 (0.0660)  lr: 0.480000  max mem: 6096
2020-06-07 10:40:56,564 maskrcnn_benchmark INFO: eta: 4:51:35  iter: 12200  loss: 0.1206 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1206 (0.1288)  time: 0.9360 (0.9829)  data: 0.0188 (0.0638)  lr: 0.480000  max mem: 6096
2020-06-07 10:44:05,119 maskrcnn_benchmark INFO: eta: 4:47:46  iter: 12400  loss: 0.1265 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1265 (0.1288)  time: 0.9357 (0.9811)  data: 0.0198 (0.0618)  lr: 0.480000  max mem: 6348
2020-06-07 10:47:13,270 maskrcnn_benchmark INFO: eta: 4:43:59  iter: 12600  loss: 0.1222 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1222 (0.1288)  time: 0.9465 (0.9793)  data: 0.0207 (0.0600)  lr: 0.480000  max mem: 6348
2020-06-07 10:50:21,516 maskrcnn_benchmark INFO: eta: 4:40:16  iter: 12800  loss: 0.1214 (0.1287)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1214 (0.1287)  time: 0.9373 (0.9777)  data: 0.0216 (0.0583)  lr: 0.480000  max mem: 6348
2020-06-07 10:53:29,257 maskrcnn_benchmark INFO: eta: 4:36:34  iter: 13000  loss: 0.1263 (0.1287)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1263 (0.1287)  time: 0.9365 (0.9762)  data: 0.0196 (0.0568)  lr: 0.480000  max mem: 6348
2020-06-07 10:56:37,549 maskrcnn_benchmark INFO: eta: 4:32:56  iter: 13200  loss: 0.1324 (0.1287)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1324 (0.1287)  time: 0.9389 (0.9748)  data: 0.0182 (0.0553)  lr: 0.480000  max mem: 6348
2020-06-07 10:59:45,724 maskrcnn_benchmark INFO: eta: 4:29:21  iter: 13400  loss: 0.1221 (0.1286)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1221 (0.1286)  time: 0.9373 (0.9736)  data: 0.0183 (0.0540)  lr: 0.480000  max mem: 6348
2020-06-07 11:02:53,419 maskrcnn_benchmark INFO: eta: 4:25:45  iter: 13600  loss: 0.1275 (0.1286)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1275 (0.1286)  time: 0.9348 (0.9723)  data: 0.0219 (0.0528)  lr: 0.480000  max mem: 6348
2020-06-07 11:06:01,420 maskrcnn_benchmark INFO: eta: 4:22:13  iter: 13800  loss: 0.1177 (0.1286)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1177 (0.1286)  time: 0.9424 (0.9712)  data: 0.0212 (0.0517)  lr: 0.480000  max mem: 6348
2020-06-07 11:09:09,495 maskrcnn_benchmark INFO: eta: 4:18:42  iter: 14000  loss: 0.1228 (0.1285)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1228 (0.1285)  time: 0.9387 (0.9702)  data: 0.0203 (0.0506)  lr: 0.480000  max mem: 6348
2020-06-07 11:12:17,800 maskrcnn_benchmark INFO: eta: 4:15:14  iter: 14200  loss: 0.1277 (0.1284)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1277 (0.1284)  time: 0.9439 (0.9692)  data: 0.0216 (0.0497)  lr: 0.480000  max mem: 6348
2020-06-07 11:15:25,731 maskrcnn_benchmark INFO: eta: 4:11:45  iter: 14400  loss: 0.1238 (0.1284)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1238 (0.1284)  time: 0.9341 (0.9683)  data: 0.0212 (0.0488)  lr: 0.480000  max mem: 6348
2020-06-07 11:18:33,749 maskrcnn_benchmark INFO: eta: 4:08:18  iter: 14600  loss: 0.1282 (0.1284)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1282 (0.1284)  time: 0.9322 (0.9675)  data: 0.0187 (0.0479)  lr: 0.480000  max mem: 6348
2020-06-07 11:21:42,047 maskrcnn_benchmark INFO: eta: 4:04:53  iter: 14800  loss: 0.1247 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1247 (0.1283)  time: 0.9423 (0.9667)  data: 0.0205 (0.0471)  lr: 0.480000  max mem: 6348
2020-06-07 11:24:49,896 maskrcnn_benchmark INFO: eta: 4:01:28  iter: 15000  loss: 0.1242 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1242 (0.1283)  time: 0.9373 (0.9659)  data: 0.0213 (0.0463)  lr: 0.480000  max mem: 6348
2020-06-07 11:24:49,899 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0015000.pth
2020-06-07 11:24:52,202 maskrcnn_benchmark INFO: Start validating
2020-06-07 11:24:52,232 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-07 11:26:02,553 maskrcnn_benchmark INFO: Total run time: 0:01:10.319793 (0.11251166915893554 s / img per device, on 8 devices)
2020-06-07 11:26:02,553 maskrcnn_benchmark INFO: Model inference time: 0:00:57.106029 (0.09136964645385742 s / img per device, on 8 devices)
2020-06-07 11:27:47,880 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6094;   R @ 50: 0.6626;   R @ 100: 0.6793;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6966; ngR @ 50: 0.8242; ngR @ 100: 0.8894;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0178;  zR @ 50: 0.0400;  zR @ 100: 0.0511;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1231;  mR @ 50: 0.1459;  mR @ 100: 0.1581;  for mode=predcls, type=Mean Recall.
(above:0.1430) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1616) (attached to:0.0000) (behind:0.4602) (belonging to:0.0000) (between:0.0000) (carrying:0.3618) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8248) (holding:0.6315) (in:0.3674) (in front of:0.1328) (laying on:0.0000) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5242) (of:0.4365) (on:0.9050) (on back of:0.0455) (over:0.1179) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.5759) (says:0.0000) (sitting on:0.3390) (standing on:0.0152) (to:0.0000) (under:0.2092) (using:0.0769) (walking in:0.0000) (walking on:0.0146) (watching:0.3333) (wearing:0.9773) (wears:0.0000) (with:0.1052) 
SGG eval:   A @ 20: 0.7017;   A @ 50: 0.7067;   A @ 100: 0.7067;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-07 11:27:48,651 maskrcnn_benchmark INFO: Validation Result: 0.6793
2020-06-07 11:30:56,284 maskrcnn_benchmark INFO: eta: 4:04:11  iter: 15200  loss: 0.1246 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1246 (0.1283)  time: 0.9387 (0.9900)  data: 0.0216 (0.0704)  lr: 0.480000  max mem: 6348
2020-06-07 11:34:04,066 maskrcnn_benchmark INFO: eta: 4:00:33  iter: 15400  loss: 0.1202 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1202 (0.1283)  time: 0.9351 (0.9886)  data: 0.0221 (0.0691)  lr: 0.480000  max mem: 6348
2020-06-07 11:37:12,219 maskrcnn_benchmark INFO: eta: 3:56:57  iter: 15600  loss: 0.1259 (0.1282)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1259 (0.1282)  time: 0.9397 (0.9873)  data: 0.0207 (0.0678)  lr: 0.480000  max mem: 6348
2020-06-07 11:40:20,368 maskrcnn_benchmark INFO: eta: 3:53:23  iter: 15800  loss: 0.1312 (0.1282)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1312 (0.1282)  time: 0.9362 (0.9861)  data: 0.0215 (0.0666)  lr: 0.480000  max mem: 6348
2020-06-07 11:43:28,561 maskrcnn_benchmark INFO: ---Total norm 0.06679 clip coef 74.86314-----------------
2020-06-07 11:43:28,570 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.02997, (torch.Size([4096, 12544]))
2020-06-07 11:43:28,570 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.02533, (torch.Size([4096, 12544]))
2020-06-07 11:43:28,570 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.02448, (torch.Size([256, 1024, 3, 3]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02440, (torch.Size([51, 4096]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01603, (torch.Size([4096, 4096]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01534, (torch.Size([2048, 4808]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01516, (torch.Size([512, 1024]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01397, (torch.Size([2048, 4808]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01277, (torch.Size([4096, 4096]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01165, (torch.Size([4096, 1024]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01005, (torch.Size([256, 128, 3, 3]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00933, (torch.Size([128, 2, 7, 7]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00902, (torch.Size([1024, 512]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00855, (torch.Size([51]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00710, (torch.Size([256]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00472, (torch.Size([4096]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00447, (torch.Size([512]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00422, (torch.Size([1024]))
2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00402, (torch.Size([128]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00304, (torch.Size([22801, 51]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00238, (torch.Size([2048, 512]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00211, (torch.Size([2048, 512]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00209, (torch.Size([256]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00188, (torch.Size([128]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00172, (torch.Size([128]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00160, (torch.Size([4096]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00142, (torch.Size([256]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00118, (torch.Size([2048]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00118, (torch.Size([2048]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00105, (torch.Size([2048]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00105, (torch.Size([2048]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00098, (torch.Size([4096]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00052, (torch.Size([4096]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00027, (torch.Size([256]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00019, (torch.Size([4096]))
2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00005, (torch.Size([512]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00004, (torch.Size([151, 200]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00003, (torch.Size([512, 1024]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-07 11:43:28,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-07 11:43:28,574 maskrcnn_benchmark INFO: -------------------------------
2020-06-07 11:43:28,576 maskrcnn_benchmark INFO: eta: 3:49:50  iter: 16000  loss: 0.1337 (0.1281)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1337 (0.1281)  time: 0.9357 (0.9850)  data: 0.0204 (0.0654)  lr: 0.480000  max mem: 6348
2020-06-07 11:46:36,549 maskrcnn_benchmark INFO: eta: 3:46:17  iter: 16200  loss: 0.1163 (0.1281)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1163 (0.1281)  time: 0.9400 (0.9839)  data: 0.0190 (0.0643)  lr: 0.480000  max mem: 6348
2020-06-07 11:49:44,244 maskrcnn_benchmark INFO: eta: 3:42:46  iter: 16400  loss: 0.1195 (0.1281)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1195 (0.1281)  time: 0.9337 (0.9828)  data: 0.0176 (0.0632)  lr: 0.480000  max mem: 6348
2020-06-07 11:52:52,147 maskrcnn_benchmark INFO: eta: 3:39:16  iter: 16600  loss: 0.1243 (0.1280)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1243 (0.1280)  time: 0.9375 (0.9818)  data: 0.0206 (0.0622)  lr: 0.480000  max mem: 6348
2020-06-07 11:56:00,434 maskrcnn_benchmark INFO: eta: 3:35:47  iter: 16800  loss: 0.1261 (0.1280)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1261 (0.1280)  time: 0.9365 (0.9809)  data: 0.0184 (0.0613)  lr: 0.480000  max mem: 6348
2020-06-07 11:59:08,273 maskrcnn_benchmark INFO: eta: 3:32:19  iter: 17000  loss: 0.1308 (0.1280)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1308 (0.1280)  time: 0.9358 (0.9800)  data: 0.0185 (0.0603)  lr: 0.480000  max mem: 6348
2020-06-07 12:02:16,656 maskrcnn_benchmark INFO: eta: 3:28:53  iter: 17200  loss: 0.1231 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1279)  time: 0.9492 (0.9791)  data: 0.0207 (0.0595)  lr: 0.480000  max mem: 6348
2020-06-07 12:05:24,277 maskrcnn_benchmark INFO: eta: 3:25:26  iter: 17400  loss: 0.1240 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1240 (0.1279)  time: 0.9397 (0.9783)  data: 0.0202 (0.0586)  lr: 0.480000  max mem: 6348
2020-06-07 12:08:31,922 maskrcnn_benchmark INFO: eta: 3:22:00  iter: 17600  loss: 0.1222 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1222 (0.1279)  time: 0.9318 (0.9774)  data: 0.0214 (0.0578)  lr: 0.480000  max mem: 6348
2020-06-07 12:11:39,412 maskrcnn_benchmark INFO: eta: 3:18:34  iter: 17800  loss: 0.1171 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1171 (0.1279)  time: 0.9383 (0.9766)  data: 0.0198 (0.0570)  lr: 0.480000  max mem: 6348
2020-06-07 12:14:47,512 maskrcnn_benchmark INFO: eta: 3:15:10  iter: 18000  loss: 0.1247 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1247 (0.1279)  time: 0.9350 (0.9759)  data: 0.0197 (0.0563)  lr: 0.480000  max mem: 6348
2020-06-07 12:17:55,661 maskrcnn_benchmark INFO: eta: 3:11:47  iter: 18200  loss: 0.1213 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1213 (0.1279)  time: 0.9410 (0.9752)  data: 0.0208 (0.0556)  lr: 0.480000  max mem: 6348
2020-06-07 12:21:03,716 maskrcnn_benchmark INFO: eta: 3:08:24  iter: 18400  loss: 0.1286 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1286 (0.1279)  time: 0.9383 (0.9745)  data: 0.0214 (0.0549)  lr: 0.480000  max mem: 6348
2020-06-07 12:24:11,537 maskrcnn_benchmark INFO: eta: 3:05:02  iter: 18600  loss: 0.1272 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1272 (0.1279)  time: 0.9336 (0.9739)  data: 0.0214 (0.0543)  lr: 0.480000  max mem: 6348
2020-06-07 12:27:19,750 maskrcnn_benchmark INFO: eta: 3:01:40  iter: 18800  loss: 0.1246 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1246 (0.1279)  time: 0.9383 (0.9733)  data: 0.0205 (0.0537)  lr: 0.480000  max mem: 6348
2020-06-07 12:30:27,876 maskrcnn_benchmark INFO: eta: 2:58:19  iter: 19000  loss: 0.1283 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1283 (0.1279)  time: 0.9421 (0.9727)  data: 0.0198 (0.0530)  lr: 0.480000  max mem: 6348
2020-06-07 12:33:35,780 maskrcnn_benchmark INFO: eta: 2:54:58  iter: 19200  loss: 0.1210 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1210 (0.1279)  time: 0.9354 (0.9721)  data: 0.0217 (0.0525)  lr: 0.480000  max mem: 6348
2020-06-07 12:36:43,717 maskrcnn_benchmark INFO: eta: 2:51:38  iter: 19400  loss: 0.1217 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1217 (0.1278)  time: 0.9433 (0.9715)  data: 0.0210 (0.0519)  lr: 0.480000  max mem: 6348
2020-06-07 12:39:51,881 maskrcnn_benchmark INFO: eta: 2:48:18  iter: 19600  loss: 0.1232 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1232 (0.1278)  time: 0.9359 (0.9710)  data: 0.0218 (0.0513)  lr: 0.480000  max mem: 6348
2020-06-07 12:42:59,852 maskrcnn_benchmark INFO: eta: 2:44:58  iter: 19800  loss: 0.1296 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1296 (0.1278)  time: 0.9308 (0.9705)  data: 0.0212 (0.0508)  lr: 0.480000  max mem: 6348
2020-06-07 12:46:07,939 maskrcnn_benchmark INFO: ---Total norm 0.04749 clip coef 105.28213-----------------
2020-06-07 12:46:07,948 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.02456, (torch.Size([4096, 12544]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.02112, (torch.Size([4096, 12544]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.01927, (torch.Size([256, 1024, 3, 3]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.01477, (torch.Size([51, 4096]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01022, (torch.Size([256, 128, 3, 3]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00995, (torch.Size([128, 2, 7, 7]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.00939, (torch.Size([4096, 4096]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.00859, (torch.Size([4096, 4096]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.00736, (torch.Size([4096, 1024]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.00725, (torch.Size([2048, 4808]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.00584, (torch.Size([512, 1024]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00499, (torch.Size([1024, 512]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.00468, (torch.Size([2048, 4808]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00412, (torch.Size([51]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00370, (torch.Size([128]))
2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00287, (torch.Size([22801, 51]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00277, (torch.Size([4096]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00167, (torch.Size([1024]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00157, (torch.Size([256]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00142, (torch.Size([256]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00137, (torch.Size([256]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00127, (torch.Size([512]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00123, (torch.Size([2048, 512]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00114, (torch.Size([128]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00112, (torch.Size([128]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00077, (torch.Size([2048, 512]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00077, (torch.Size([4096]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00052, (torch.Size([2048]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00052, (torch.Size([2048]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00036, (torch.Size([4096]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00026, (torch.Size([2048]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00026, (torch.Size([2048]))
2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00025, (torch.Size([4096]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00015, (torch.Size([256]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00013, (torch.Size([4096]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00001, (torch.Size([512]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00001, (torch.Size([151, 200]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00001, (torch.Size([512, 1024]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-07 12:46:07,952 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-07 12:46:07,952 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-07 12:46:07,952 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-07 12:46:07,952 maskrcnn_benchmark INFO: -------------------------------
2020-06-07 12:46:07,954 maskrcnn_benchmark INFO: eta: 2:41:39  iter: 20000  loss: 0.1225 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1225 (0.1278)  time: 0.9354 (0.9700)  data: 0.0177 (0.0503)  lr: 0.480000  max mem: 6348
2020-06-07 12:46:07,957 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0020000.pth
2020-06-07 12:46:10,449 maskrcnn_benchmark INFO: Start validating
2020-06-07 12:46:10,475 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-07 12:47:20,850 maskrcnn_benchmark INFO: Total run time: 0:01:10.374361 (0.11259897727966309 s / img per device, on 8 devices)
2020-06-07 12:47:20,851 maskrcnn_benchmark INFO: Model inference time: 0:00:56.837251 (0.09093960189819336 s / img per device, on 8 devices)
2020-06-07 12:49:09,149 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6015;   R @ 50: 0.6606;   R @ 100: 0.6759;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6895; ngR @ 50: 0.8207; ngR @ 100: 0.8882;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0178;  zR @ 50: 0.0444;  zR @ 100: 0.0622;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1167;  mR @ 50: 0.1445;  mR @ 100: 0.1535;  for mode=predcls, type=Mean Recall.
(above:0.1917) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1528) (attached to:0.0000) (behind:0.4743) (belonging to:0.0000) (between:0.0000) (carrying:0.2259) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8299) (holding:0.6165) (in:0.3550) (in front of:0.0573) (laying on:0.0000) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5594) (of:0.4526) (on:0.9000) (on back of:0.0455) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4241) (says:0.0000) (sitting on:0.2893) (standing on:0.0109) (to:0.0000) (under:0.2015) (using:0.1923) (walking in:0.0000) (walking on:0.0000) (watching:0.3529) (wearing:0.9757) (wears:0.0000) (with:0.0925) 
SGG eval:   A @ 20: 0.6996;   A @ 50: 0.7045;   A @ 100: 0.7045;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-07 12:49:09,920 maskrcnn_benchmark INFO: Validation Result: 0.6759
2020-06-07 12:52:17,630 maskrcnn_benchmark INFO: eta: 2:40:46  iter: 20200  loss: 0.1280 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1280 (0.1278)  time: 0.9374 (0.9844)  data: 0.0216 (0.0647)  lr: 0.480000  max mem: 6348
2020-06-07 12:55:25,640 maskrcnn_benchmark INFO: eta: 2:37:22  iter: 20400  loss: 0.1292 (0.1277)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1292 (0.1277)  time: 0.9392 (0.9836)  data: 0.0209 (0.0640)  lr: 0.480000  max mem: 6348
2020-06-07 12:58:33,556 maskrcnn_benchmark INFO: eta: 2:33:59  iter: 20600  loss: 0.1243 (0.1277)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1243 (0.1277)  time: 0.9359 (0.9829)  data: 0.0201 (0.0633)  lr: 0.480000  max mem: 6348
2020-06-07 13:01:41,668 maskrcnn_benchmark INFO: eta: 2:30:36  iter: 20800  loss: 0.1314 (0.1277)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1314 (0.1277)  time: 0.9450 (0.9823)  data: 0.0206 (0.0626)  lr: 0.480000  max mem: 6348
2020-06-07 13:04:49,805 maskrcnn_benchmark INFO: eta: 2:27:14  iter: 21000  loss: 0.1219 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1219 (0.1276)  time: 0.9337 (0.9816)  data: 0.0184 (0.0620)  lr: 0.480000  max mem: 6348
2020-06-07 13:07:58,012 maskrcnn_benchmark INFO: eta: 2:23:53  iter: 21200  loss: 0.1261 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1261 (0.1276)  time: 0.9445 (0.9810)  data: 0.0221 (0.0613)  lr: 0.480000  max mem: 6348
2020-06-07 13:11:06,523 maskrcnn_benchmark INFO: eta: 2:20:31  iter: 21400  loss: 0.1163 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1163 (0.1276)  time: 0.9423 (0.9804)  data: 0.0189 (0.0607)  lr: 0.480000  max mem: 6348
2020-06-07 13:14:14,716 maskrcnn_benchmark INFO: eta: 2:17:10  iter: 21600  loss: 0.1261 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1261 (0.1276)  time: 0.9398 (0.9799)  data: 0.0212 (0.0602)  lr: 0.480000  max mem: 6348
2020-06-07 13:17:23,132 maskrcnn_benchmark INFO: eta: 2:13:50  iter: 21800  loss: 0.1207 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1207 (0.1276)  time: 0.9328 (0.9793)  data: 0.0203 (0.0596)  lr: 0.480000  max mem: 6348
2020-06-07 13:20:31,095 maskrcnn_benchmark INFO: eta: 2:10:30  iter: 22000  loss: 0.1253 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1253 (0.1276)  time: 0.9365 (0.9788)  data: 0.0222 (0.0590)  lr: 0.480000  max mem: 6348
2020-06-07 13:23:39,444 maskrcnn_benchmark INFO: eta: 2:07:10  iter: 22200  loss: 0.1250 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1250 (0.1275)  time: 0.9355 (0.9782)  data: 0.0226 (0.0585)  lr: 0.480000  max mem: 6348
2020-06-07 13:26:47,379 maskrcnn_benchmark INFO: eta: 2:03:50  iter: 22400  loss: 0.1221 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1221 (0.1275)  time: 0.9322 (0.9777)  data: 0.0211 (0.0579)  lr: 0.480000  max mem: 6348
2020-06-07 13:29:55,207 maskrcnn_benchmark INFO: eta: 2:00:31  iter: 22600  loss: 0.1250 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1250 (0.1275)  time: 0.9407 (0.9772)  data: 0.0183 (0.0574)  lr: 0.480000  max mem: 6348
2020-06-07 13:33:03,114 maskrcnn_benchmark INFO: eta: 1:57:11  iter: 22800  loss: 0.1281 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1281 (0.1275)  time: 0.9329 (0.9767)  data: 0.0212 (0.0569)  lr: 0.480000  max mem: 6348
2020-06-07 13:36:11,307 maskrcnn_benchmark INFO: eta: 1:53:53  iter: 23000  loss: 0.1251 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1251 (0.1275)  time: 0.9391 (0.9762)  data: 0.0199 (0.0564)  lr: 0.480000  max mem: 6348
2020-06-07 13:39:18,980 maskrcnn_benchmark INFO: eta: 1:50:34  iter: 23200  loss: 0.1257 (0.1274)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1257 (0.1274)  time: 0.9276 (0.9757)  data: 0.0170 (0.0559)  lr: 0.480000  max mem: 6348
2020-06-07 13:42:26,772 maskrcnn_benchmark INFO: eta: 1:47:16  iter: 23400  loss: 0.1234 (0.1274)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1234 (0.1274)  time: 0.9328 (0.9752)  data: 0.0218 (0.0555)  lr: 0.480000  max mem: 6348
2020-06-07 13:45:34,362 maskrcnn_benchmark INFO: eta: 1:43:58  iter: 23600  loss: 0.1211 (0.1274)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1211 (0.1274)  time: 0.9253 (0.9747)  data: 0.0180 (0.0550)  lr: 0.480000  max mem: 6348
2020-06-07 13:48:42,499 maskrcnn_benchmark INFO: eta: 1:40:40  iter: 23800  loss: 0.1126 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1126 (0.1273)  time: 0.9381 (0.9743)  data: 0.0217 (0.0546)  lr: 0.480000  max mem: 6348
2020-06-07 13:51:50,859 maskrcnn_benchmark INFO: ---Total norm 0.06503 clip coef 76.88617-----------------
2020-06-07 13:51:50,868 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.03521, (torch.Size([4096, 12544]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.02866, (torch.Size([4096, 12544]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.02707, (torch.Size([256, 1024, 3, 3]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02008, (torch.Size([51, 4096]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01455, (torch.Size([4096, 4096]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01396, (torch.Size([128, 2, 7, 7]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01115, (torch.Size([256, 128, 3, 3]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01095, (torch.Size([4096, 4096]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01008, (torch.Size([4096, 1024]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.00717, (torch.Size([2048, 4808]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00700, (torch.Size([1024, 512]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.00698, (torch.Size([512, 1024]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.00650, (torch.Size([2048, 4808]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00506, (torch.Size([128]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00320, (torch.Size([4096]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00319, (torch.Size([51]))
2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00315, (torch.Size([22801, 51]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00230, (torch.Size([128]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00219, (torch.Size([1024]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00201, (torch.Size([256]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00182, (torch.Size([256]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00178, (torch.Size([256]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00163, (torch.Size([2048, 512]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00148, (torch.Size([128]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00133, (torch.Size([512]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00125, (torch.Size([4096]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00118, (torch.Size([2048, 512]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00059, (torch.Size([4096]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00053, (torch.Size([2048]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00053, (torch.Size([2048]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00045, (torch.Size([2048]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00045, (torch.Size([2048]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00025, (torch.Size([256]))
2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00025, (torch.Size([4096]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00017, (torch.Size([4096]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00001, (torch.Size([512]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00001, (torch.Size([512, 1024]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00000, (torch.Size([151, 200]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-07 13:51:50,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-07 13:51:50,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-07 13:51:50,872 maskrcnn_benchmark INFO: -------------------------------
2020-06-07 13:51:50,874 maskrcnn_benchmark INFO: eta: 1:37:23  iter: 24000  loss: 0.1266 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1266 (0.1273)  time: 0.9427 (0.9739)  data: 0.0205 (0.0541)  lr: 0.480000  max mem: 6348
2020-06-07 13:54:58,804 maskrcnn_benchmark INFO: eta: 1:34:06  iter: 24200  loss: 0.1227 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1227 (0.1273)  time: 0.9322 (0.9735)  data: 0.0190 (0.0537)  lr: 0.480000  max mem: 6348
2020-06-07 13:58:06,439 maskrcnn_benchmark INFO: eta: 1:30:49  iter: 24400  loss: 0.1317 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1317 (0.1273)  time: 0.9342 (0.9730)  data: 0.0213 (0.0533)  lr: 0.480000  max mem: 6348
2020-06-07 14:01:14,423 maskrcnn_benchmark INFO: eta: 1:27:32  iter: 24600  loss: 0.1231 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1273)  time: 0.9319 (0.9726)  data: 0.0187 (0.0529)  lr: 0.480000  max mem: 6348
2020-06-07 14:04:22,394 maskrcnn_benchmark INFO: eta: 1:24:15  iter: 24800  loss: 0.1246 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1246 (0.1273)  time: 0.9393 (0.9723)  data: 0.0209 (0.0525)  lr: 0.480000  max mem: 6348
2020-06-07 14:07:29,998 maskrcnn_benchmark INFO: eta: 1:20:59  iter: 25000  loss: 0.1242 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1242 (0.1273)  time: 0.9337 (0.9719)  data: 0.0192 (0.0521)  lr: 0.480000  max mem: 6348
2020-06-07 14:07:30,001 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0025000.pth
2020-06-07 14:07:32,358 maskrcnn_benchmark INFO: Start validating
2020-06-07 14:07:32,385 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-07 14:08:42,495 maskrcnn_benchmark INFO: Total run time: 0:01:10.110314 (0.1121765022277832 s / img per device, on 8 devices)
2020-06-07 14:08:42,496 maskrcnn_benchmark INFO: Model inference time: 0:00:56.887012 (0.0910192195892334 s / img per device, on 8 devices)
2020-06-07 14:10:26,754 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6069;   R @ 50: 0.6599;   R @ 100: 0.6751;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6963; ngR @ 50: 0.8241; ngR @ 100: 0.8911;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0089;  zR @ 50: 0.0311;  zR @ 100: 0.0400;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1181;  mR @ 50: 0.1402;  mR @ 100: 0.1530;  for mode=predcls, type=Mean Recall.
(above:0.1344) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1642) (attached to:0.0000) (behind:0.4409) (belonging to:0.0000) (between:0.0000) (carrying:0.2061) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0221) (has:0.8271) (holding:0.6293) (in:0.3907) (in front of:0.1398) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5256) (of:0.5075) (on:0.8912) (on back of:0.0455) (over:0.1057) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4390) (says:0.0000) (sitting on:0.3194) (standing on:0.0109) (to:0.0000) (under:0.2054) (using:0.0385) (walking in:0.0000) (walking on:0.0128) (watching:0.3137) (wearing:0.9766) (wears:0.0000) (with:0.0785) 
SGG eval:   A @ 20: 0.6995;   A @ 50: 0.7042;   A @ 100: 0.7042;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-07 14:10:27,520 maskrcnn_benchmark INFO: Validation Result: 0.6751
2020-06-07 14:10:27,520 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-06-07 14:13:34,821 maskrcnn_benchmark INFO: eta: 1:18:32  iter: 25200  loss: 0.1185 (0.1272)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1185 (0.1272)  time: 0.9319 (0.9818)  data: 0.0208 (0.0621)  lr: 0.048000  max mem: 6348
2020-06-07 14:16:42,682 maskrcnn_benchmark INFO: eta: 1:15:13  iter: 25400  loss: 0.1220 (0.1272)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1220 (0.1272)  time: 0.9327 (0.9813)  data: 0.0214 (0.0616)  lr: 0.048000  max mem: 6348
2020-06-07 14:19:51,192 maskrcnn_benchmark INFO: eta: 1:11:55  iter: 25600  loss: 0.1179 (0.1271)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1179 (0.1271)  time: 0.9351 (0.9808)  data: 0.0198 (0.0611)  lr: 0.048000  max mem: 6348
2020-06-07 14:22:58,836 maskrcnn_benchmark INFO: eta: 1:08:37  iter: 25800  loss: 0.1186 (0.1271)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1186 (0.1271)  time: 0.9374 (0.9804)  data: 0.0191 (0.0607)  lr: 0.048000  max mem: 6348
2020-06-07 14:26:06,225 maskrcnn_benchmark INFO: eta: 1:05:19  iter: 26000  loss: 0.1133 (0.1270)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1133 (0.1270)  time: 0.9341 (0.9799)  data: 0.0221 (0.0602)  lr: 0.048000  max mem: 6348
2020-06-07 14:29:14,046 maskrcnn_benchmark INFO: eta: 1:02:01  iter: 26200  loss: 0.1178 (0.1270)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1178 (0.1270)  time: 0.9383 (0.9794)  data: 0.0183 (0.0598)  lr: 0.048000  max mem: 6348
2020-06-07 14:32:21,786 maskrcnn_benchmark INFO: eta: 0:58:44  iter: 26400  loss: 0.1170 (0.1269)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1170 (0.1269)  time: 0.9280 (0.9790)  data: 0.0227 (0.0594)  lr: 0.048000  max mem: 6348
2020-06-07 14:35:29,597 maskrcnn_benchmark INFO: eta: 0:55:27  iter: 26600  loss: 0.1191 (0.1268)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1191 (0.1268)  time: 0.9326 (0.9786)  data: 0.0202 (0.0589)  lr: 0.048000  max mem: 6348
2020-06-07 14:38:37,211 maskrcnn_benchmark INFO: eta: 0:52:09  iter: 26800  loss: 0.1179 (0.1268)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1179 (0.1268)  time: 0.9365 (0.9781)  data: 0.0169 (0.0585)  lr: 0.048000  max mem: 6348
2020-06-07 14:41:45,145 maskrcnn_benchmark INFO: eta: 0:48:53  iter: 27000  loss: 0.1128 (0.1267)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1128 (0.1267)  time: 0.9391 (0.9777)  data: 0.0200 (0.0581)  lr: 0.048000  max mem: 6348
2020-06-07 14:44:52,670 maskrcnn_benchmark INFO: eta: 0:45:36  iter: 27200  loss: 0.1182 (0.1266)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1182 (0.1266)  time: 0.9331 (0.9773)  data: 0.0172 (0.0577)  lr: 0.048000  max mem: 6348
2020-06-07 14:48:00,420 maskrcnn_benchmark INFO: eta: 0:42:19  iter: 27400  loss: 0.1144 (0.1266)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1144 (0.1266)  time: 0.9361 (0.9769)  data: 0.0198 (0.0573)  lr: 0.048000  max mem: 6348
2020-06-07 14:51:08,454 maskrcnn_benchmark INFO: eta: 0:39:03  iter: 27600  loss: 0.1234 (0.1265)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1234 (0.1265)  time: 0.9360 (0.9765)  data: 0.0211 (0.0569)  lr: 0.048000  max mem: 6348
2020-06-07 14:54:15,996 maskrcnn_benchmark INFO: eta: 0:35:47  iter: 27800  loss: 0.1133 (0.1264)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1133 (0.1264)  time: 0.9356 (0.9761)  data: 0.0158 (0.0565)  lr: 0.048000  max mem: 6348
2020-06-07 14:57:23,634 maskrcnn_benchmark INFO: ---Total norm 0.10416 clip coef 48.00386-----------------
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.07262, (torch.Size([4096, 12544]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.04291, (torch.Size([4096, 12544]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.03709, (torch.Size([256, 1024, 3, 3]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02448, (torch.Size([51, 4096]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.02064, (torch.Size([4096, 4096]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.02000, (torch.Size([4096, 4096]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01288, (torch.Size([2048, 4808]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01267, (torch.Size([4096, 1024]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01185, (torch.Size([256, 128, 3, 3]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01138, (torch.Size([2048, 4808]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01053, (torch.Size([128, 2, 7, 7]))
2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.00809, (torch.Size([512, 1024]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00776, (torch.Size([1024, 512]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00411, (torch.Size([4096]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00396, (torch.Size([128]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00389, (torch.Size([256]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00321, (torch.Size([1024]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00282, (torch.Size([22801, 51]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00220, (torch.Size([2048, 512]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00215, (torch.Size([512]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00191, (torch.Size([256]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00190, (torch.Size([2048, 512]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00186, (torch.Size([128]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00185, (torch.Size([51]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00164, (torch.Size([256]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00144, (torch.Size([4096]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00121, (torch.Size([128]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00082, (torch.Size([2048]))
2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00082, (torch.Size([2048]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00079, (torch.Size([4096]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00072, (torch.Size([2048]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00072, (torch.Size([2048]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00068, (torch.Size([4096]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00040, (torch.Size([4096]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00037, (torch.Size([256]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00000, (torch.Size([512]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00000, (torch.Size([151, 200]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00000, (torch.Size([512, 1024]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))
2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))
2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))
2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))
2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))
2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: -------------------------------
2020-06-07 14:57:23,649 maskrcnn_benchmark INFO: eta: 0:32:31  iter: 28000  loss: 0.1215 (0.1264)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1215 (0.1264)  time: 0.9423 (0.9758)  data: 0.0169 (0.0562)  lr: 0.048000  max mem: 6348
2020-06-07 15:00:31,388 maskrcnn_benchmark INFO: eta: 0:29:15  iter: 28200  loss: 0.1089 (0.1263)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1089 (0.1263)  time: 0.9403 (0.9754)  data: 0.0207 (0.0558)  lr: 0.048000  max mem: 6348
2020-06-07 15:03:39,611 maskrcnn_benchmark INFO: eta: 0:26:00  iter: 28400  loss: 0.1158 (0.1262)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1158 (0.1262)  time: 0.9452 (0.9751)  data: 0.0209 (0.0555)  lr: 0.048000  max mem: 6348
2020-06-07 15:06:47,348 maskrcnn_benchmark INFO: eta: 0:22:44  iter: 28600  loss: 0.1196 (0.1261)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1196 (0.1261)  time: 0.9319 (0.9747)  data: 0.0187 (0.0551)  lr: 0.048000  max mem: 6348
2020-06-07 15:09:55,423 maskrcnn_benchmark INFO: eta: 0:19:29  iter: 28800  loss: 0.1151 (0.1261)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1151 (0.1261)  time: 0.9405 (0.9744)  data: 0.0191 (0.0548)  lr: 0.048000  max mem: 6348
2020-06-07 15:13:02,981 maskrcnn_benchmark INFO: eta: 0:16:14  iter: 29000  loss: 0.1162 (0.1260)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1162 (0.1260)  time: 0.9362 (0.9740)  data: 0.0205 (0.0544)  lr: 0.048000  max mem: 6348
2020-06-07 15:16:10,844 maskrcnn_benchmark INFO: eta: 0:12:58  iter: 29200  loss: 0.1175 (0.1259)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1175 (0.1259)  time: 0.9359 (0.9737)  data: 0.0222 (0.0541)  lr: 0.048000  max mem: 6348
2020-06-07 15:19:18,547 maskrcnn_benchmark INFO: eta: 0:09:44  iter: 29400  loss: 0.1148 (0.1259)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1148 (0.1259)  time: 0.9323 (0.9734)  data: 0.0198 (0.0538)  lr: 0.048000  max mem: 6348
2020-06-07 15:22:26,312 maskrcnn_benchmark INFO: eta: 0:06:29  iter: 29600  loss: 0.1138 (0.1258)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1138 (0.1258)  time: 0.9409 (0.9730)  data: 0.0166 (0.0535)  lr: 0.048000  max mem: 6348
2020-06-07 15:25:34,290 maskrcnn_benchmark INFO: eta: 0:03:14  iter: 29800  loss: 0.1080 (0.1257)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1080 (0.1257)  time: 0.9358 (0.9727)  data: 0.0209 (0.0531)  lr: 0.048000  max mem: 6348
2020-06-07 15:28:42,750 maskrcnn_benchmark INFO: eta: 0:00:00  iter: 30000  loss: 0.1104 (0.1256)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1104 (0.1256)  time: 0.9429 (0.9725)  data: 0.0213 (0.0528)  lr: 0.048000  max mem: 6348
2020-06-07 15:28:42,753 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0030000.pth
2020-06-07 15:28:45,007 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_final.pth
2020-06-07 15:28:47,139 maskrcnn_benchmark INFO: Start validating
2020-06-07 15:28:47,170 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-06-07 15:29:57,678 maskrcnn_benchmark INFO: Total run time: 0:01:10.508072 (0.1128129150390625 s / img per device, on 8 devices)
2020-06-07 15:29:57,679 maskrcnn_benchmark INFO: Model inference time: 0:00:56.813555 (0.09090168724060059 s / img per device, on 8 devices)
2020-06-07 15:31:43,694 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6110;   R @ 50: 0.6661;   R @ 100: 0.6806;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.7037; ngR @ 50: 0.8278; ngR @ 100: 0.8937;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0400;  zR @ 100: 0.0578;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1413;  mR @ 50: 0.1705;  mR @ 100: 0.1837;  for mode=predcls, type=Mean Recall.
(above:0.1562) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2191) (attached to:0.0000) (behind:0.4659) (belonging to:0.0000) (between:0.0000) (carrying:0.5482) (covered in:0.2024) (covering:0.0000) (eating:0.3810) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8105) (holding:0.5118) (in:0.3643) (in front of:0.2213) (laying on:0.0000) (looking at:0.1087) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4919) (of:0.4934) (on:0.9014) (on back of:0.0455) (over:0.0854) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4241) (says:0.0000) (sitting on:0.3120) (standing on:0.0283) (to:0.0000) (under:0.2844) (using:0.1923) (walking in:0.0000) (walking on:0.2420) (watching:0.5098) (wearing:0.9766) (wears:0.0000) (with:0.1282) 
SGG eval:   A @ 20: 0.7038;   A @ 50: 0.7089;   A @ 100: 0.7089;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-06-07 15:31:44,474 maskrcnn_benchmark INFO: Validation Result: 0.6806
2020-06-07 15:31:44,754 maskrcnn_benchmark INFO: Total training time: 5:59:36.260852 (0.7192 s / it)
2020-06-07 15:31:44,894 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-06-07 15:31:46,676 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).
2020-06-07 15:37:58,458 maskrcnn_benchmark INFO: Total run time: 0:06:11.781584 (0.11246512410933353 s / img per device, on 8 devices)
2020-06-07 15:37:58,458 maskrcnn_benchmark INFO: Model inference time: 0:05:07.227393 (0.09293727374226497 s / img per device, on 8 devices)
2020-06-07 15:37:58,466 maskrcnn_benchmark.inference WARNING: WARNING! WARNING! WARNING! WARNING! WARNING! WARNING!Number of images that were gathered from multiple processes is not a contiguous set. Some images might be missing from the evaluation
