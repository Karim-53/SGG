{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting environment information...\n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\n",
      "CMake version: Could not collect\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: Tesla K80\n",
      "GPU 1: Tesla K80\n",
      "\n",
      "Nvidia driver version: 430.26\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.4\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] numpy                     1.18.4                   pypi_0    pypi\n",
      "[conda] numpydoc                  0.7.0            py36h18f165f_0  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "! wget --quiet \"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\"\n",
    "! python collect_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#! pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#! pip install torch torchvision  # prefebly not use that one\n",
    "\n",
    "apt-get update\n",
    "pip install --upgrade pip\n",
    "\n",
    "#!apt-get install linux-headers-$(uname -r)\n",
    "apt-get -y install cmake\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pscp -P 10602 -pw rvG0FvCS C:\\Users\\Karim\\Downloads\\libcudnn7_7.6.5.32-1+cuda10.1_amd64.deb root@drogon.dimis.fim.uni-passau.de:/root/libcudnn7_7.6.5.32-1+cuda10.1_amd64.deb\n",
    "dpkg -i libcudnn7_7.6.5.32-1+cuda10.1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developer.nvidia.com/nccl/nccl-download\n",
    "wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\n",
    "dpkg -r libnccl2  # del version 9.1\n",
    "dpkg -i nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda update conda\n",
    "conda update conda-build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asn1crypto==1.3.0\r\n",
      "attrs==19.3.0\r\n",
      "backcall==0.1.0\r\n",
      "bleach==3.1.5\r\n",
      "certifi==2020.4.5.1\r\n",
      "cffi==1.14.0\r\n",
      "chardet==3.0.4\r\n",
      "conda==4.8.3\r\n",
      "conda-package-handling==1.7.0\r\n",
      "cryptography==2.3.1\r\n",
      "cycler==0.10.0\r\n",
      "Cython==0.29.19\r\n",
      "decorator==4.4.2\r\n",
      "defusedxml==0.6.0\r\n",
      "entrypoints==0.3\r\n",
      "future==0.18.2\r\n",
      "h5py==2.10.0\r\n",
      "idna==2.9\r\n",
      "importlib-metadata==1.6.0\r\n",
      "ipykernel==5.3.0\r\n",
      "ipython==7.15.0\r\n",
      "ipython-genutils==0.2.0\r\n",
      "jedi==0.17.0\r\n",
      "Jinja2==2.11.2\r\n",
      "jsonschema==3.2.0\r\n",
      "jupyter-client==6.1.3\r\n",
      "jupyter-contrib-core==0.3.3\r\n",
      "jupyter-core==4.6.3\r\n",
      "jupyter-nbextensions-configurator==0.4.1\r\n",
      "kiwisolver==1.2.0\r\n",
      "lesscpy==0.14.0\r\n",
      "MarkupSafe==1.1.1\r\n",
      "matplotlib==3.2.1\r\n",
      "mistune==0.8.4\r\n",
      "nbconvert==5.6.1\r\n",
      "nbformat==5.0.6\r\n",
      "ninja==1.9.0.post1\r\n",
      "notebook==6.0.3\r\n",
      "numpy==1.18.4\r\n",
      "opencv-python==4.2.0.34\r\n",
      "overrides==3.0.0\r\n",
      "packaging==20.4\r\n",
      "pandocfilters==1.4.2\r\n",
      "parso==0.7.0\r\n",
      "pexpect==4.8.0\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==7.1.2\r\n",
      "ply==3.11\r\n",
      "prometheus-client==0.8.0\r\n",
      "prompt-toolkit==3.0.5\r\n",
      "ptyprocess==0.6.0\r\n",
      "pycocotools==2.0\r\n",
      "pycosat==0.6.3\r\n",
      "pycparser==2.20\r\n",
      "Pygments==2.6.1\r\n",
      "pyOpenSSL==19.0.0\r\n",
      "pyparsing==2.4.7\r\n",
      "pyrsistent==0.16.0\r\n",
      "PySocks==1.7.1\r\n",
      "python-dateutil==2.8.1\r\n",
      "PyYAML==5.3.1\r\n",
      "pyzmq==19.0.1\r\n",
      "requests==2.23.0\r\n",
      "ruamel-yaml==0.15.87\r\n",
      "scipy==1.4.1\r\n",
      "Send2Trash==1.5.0\r\n",
      "six==1.14.0\r\n",
      "terminado==0.8.3\r\n",
      "testpath==0.4.4\r\n",
      "torch==1.5.0+cu101\r\n",
      "torchvision==0.6.0+cu101\r\n",
      "tornado==6.0.4\r\n",
      "tqdm==4.46.0\r\n",
      "traitlets==4.3.3\r\n",
      "urllib3==1.25.8\r\n",
      "wcwidth==0.2.2\r\n",
      "webencodings==0.5.1\r\n",
      "yacs==0.1.7\r\n",
      "zipp==3.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Nt81FY66EM3"
   },
   "source": [
    "# Requirements\n",
    "[github source](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "1Nt81FY66EM3"
   },
   "source": [
    "## hardware and OS\n",
    "* you need 1 to 4 GPU with CUDA\n",
    "* This notebook is intended to run on Colab. don't forget to activate the GPU in Goolgle Colab ([how to](https://jovianlin.io/pytorch-with-gpu-in-google-colab/))\n",
    "* If you do not enable GPU from the beggining then you will have to restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "hidden": true,
    "id": "U5vDdOhoxBtR",
    "outputId": "d5db9410-345d-423c-e7bc-91483a7f88ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Fri_Feb__8_19:08:17_PST_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.105\r\n"
     ]
    }
   ],
   "source": [
    "# this command must work otherwise check the symLink /usr/local/cuda\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.  There is NO\r\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.15.0-22-generic\r\n"
     ]
    }
   ],
   "source": [
    "!uname -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!dpkg --print-architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "hidden": true,
    "id": "fOghS1oMJIXG",
    "outputId": "3154e4d8-14eb-48e9-dd9d-280af544ca9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python 3!\n",
      "sys.version_info(major=3, minor=7, micro=0, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Using Python {}!'.format(sys.version_info[0]))\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-A87_S0JsZq"
   },
   "source": [
    "## Libraries\n",
    "Might take 5 to 10 mins to install everything. \n",
    "If using Kaggle kernel do not forget to enable internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "INHWUBycuZ0t",
    "outputId": "7369c2d8-7f2f-4715-c560-39e19dba08a8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.7/site-packages (7.15.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython) (3.0.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython) (4.3.3)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython) (0.17.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython) (46.4.0.post20200518)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython) (2.6.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython) (4.4.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scipy) (1.18.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py) (1.14.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.2)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2->ipython) (0.2.0)\n",
      "Requirement already satisfied: parso>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython) (0.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install ipython scipy h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "colab_type": "code",
    "id": "LZnxVYfKuyyg",
    "outputId": "53c433b3-7114-44fd-97d5-fa1db2ddd066",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.7/site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: yacs in /opt/conda/lib/python3.7/site-packages (0.1.7)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (0.29.19)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.46.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.2.0.34)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.7/site-packages (3.0.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from yacs) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.18.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install ninja yacs cython matplotlib tqdm opencv-python overrides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrNKakC2i839"
   },
   "source": [
    "ends with `Successfully installed ninja-1.9.0.post1 overrides-3.0.0 yacs-0.1.7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "ap0ZHXOAu1hb",
    "outputId": "fa62eb9f-bf1d-4c35-f277-61e8541fecea"
   },
   "outputs": [],
   "source": [
    "# do not work: !pip install pytorch  # cudatoolkit=10.0 -c pytorch\n",
    "# https://pytorch.org/get-started/locally/\n",
    "# !pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# Requirement already satisfied on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFWyA5T359_6"
   },
   "source": [
    "## install pycocotools (cocoapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "8c47j7kQ3EtZ",
    "outputId": "8606dbc5-5bd1-4605-fa48-001e6c1e8355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cocoapi'...\n",
      "remote: Enumerating objects: 975, done.\u001b[K\n",
      "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
      "Receiving objects: 100% (975/975), 11.72 MiB | 3.13 MiB/s, done.\n",
      "Resolving deltas: 100% (576/576), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "#% cd \"/content\" # \"./drive/My Drive/AAA/HS/3_code/2_collab\" # to change the current working directory for the notebook environment (and not just the subshell that runs your ! command).\n",
    "! git clone https://github.com/cocodataset/cocoapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MOCeqEFb5t8s",
    "outputId": "05a89365-331e-406e-b8cb-f022819d3f8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\n",
      "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /root/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'pycocotools._mask' extension\n",
      "creating build\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-3.7\n",
      "creating build/temp.linux-x86_64-3.7/pycocotools\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -I../common -I/opt/conda/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [-Wmaybe-uninitialized]\n",
      "       if(j%2==0) xp=x; else if(xp<x) { ys=0; ye=h-1; }\n",
      "\u001b[01;32m\u001b[K                               ^\u001b[m\u001b[K\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -I../common -I/opt/conda/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/pycocotools\n",
      "gcc -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating pycocotools.egg-info\n",
      "writing pycocotools.egg-info/PKG-INFO\n",
      "writing dependency_links to pycocotools.egg-info/dependency_links.txt\n",
      "writing requirements to pycocotools.egg-info/requires.txt\n",
      "writing top-level names to pycocotools.egg-info/top_level.txt\n",
      "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "reading manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying pycocotools/__init__.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
      "copying pycocotools/coco.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
      "copying pycocotools/mask.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
      "copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-37.pyc\n",
      "creating stub loader for pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "pycocotools.__pycache__._mask.cpython-37: module references __file__\n",
      "creating dist\n",
      "creating 'dist/pycocotools-2.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing pycocotools-2.0-py3.7-linux-x86_64.egg\n",
      "removing '/opt/conda/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg' (and everything under it)\n",
      "creating /opt/conda/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg\n",
      "Extracting pycocotools-2.0-py3.7-linux-x86_64.egg to /opt/conda/lib/python3.7/site-packages\n",
      "pycocotools 2.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /opt/conda/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg\n",
      "Processing dependencies for pycocotools==2.0\n",
      "Searching for matplotlib==3.2.1\n",
      "Best match: matplotlib 3.2.1\n",
      "Adding matplotlib 3.2.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for Cython==0.29.19\n",
      "Best match: Cython 0.29.19\n",
      "Adding Cython 0.29.19 to easy-install.pth file\n",
      "Installing cygdb script to /opt/conda/bin\n",
      "Installing cython script to /opt/conda/bin\n",
      "Installing cythonize script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for setuptools==46.4.0.post20200518\n",
      "Best match: setuptools 46.4.0.post20200518\n",
      "Adding setuptools 46.4.0.post20200518 to easy-install.pth file\n",
      "Installing easy_install script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for kiwisolver==1.2.0\n",
      "Best match: kiwisolver 1.2.0\n",
      "Adding kiwisolver 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for numpy==1.18.4\n",
      "Best match: numpy 1.18.4\n",
      "Adding numpy 1.18.4 to easy-install.pth file\n",
      "Installing f2py script to /opt/conda/bin\n",
      "Installing f2py3 script to /opt/conda/bin\n",
      "Installing f2py3.7 script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for pyparsing==2.4.7\n",
      "Best match: pyparsing 2.4.7\n",
      "Adding pyparsing 2.4.7 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for python-dateutil==2.8.1\n",
      "Best match: python-dateutil 2.8.1\n",
      "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for six==1.14.0\n",
      "Best match: six 1.14.0\n",
      "Adding six 1.14.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Finished processing dependencies for pycocotools==2.0\n"
     ]
    }
   ],
   "source": [
    "! cd cocoapi/PythonAPI; python setup.py build_ext install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OndJ9TRUpvm"
   },
   "source": [
    "ends with \n",
    "\n",
    "```\n",
    "Finished processing dependencies for pycocotools==2.0\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ2Eoix66NLA"
   },
   "source": [
    "## install apex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 151, done.\u001b[K\n",
      "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
      "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
      "remote: Total 7163 (delta 112), reused 86 (delta 55), pack-reused 7012\u001b[K\n",
      "Receiving objects: 100% (7163/7163), 13.83 MiB | 4.44 MiB/s, done.\n",
      "Resolving deltas: 100% (4826/4826), done.\n",
      "Checking connectivity... done.\n",
      "\n",
      "\n",
      "torch.__version__  = 1.5.0+cu101\n",
      "\n",
      "\n",
      "setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "  warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "\n",
      "Compiling cuda extensions with\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Fri_Feb__8_19:08:17_PST_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.105\n",
      "from /usr/local/cuda/bin\n",
      "\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating apex.egg-info\n",
      "writing apex.egg-info/PKG-INFO\n",
      "writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "writing top-level names to apex.egg-info/top_level.txt\n",
      "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "reading manifest file 'apex.egg-info/SOURCES.txt'\n",
      "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/apex\n",
      "copying apex/__init__.py -> build/lib.linux-x86_64-3.7/apex\n",
      "creating build/lib.linux-x86_64-3.7/apex/RNN\n",
      "copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
      "copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
      "copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
      "copying apex/RNN/models.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
      "creating build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "creating build/lib.linux-x86_64-3.7/apex/mlp\n",
      "copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
      "copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
      "creating build/lib.linux-x86_64-3.7/apex/contrib\n",
      "copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib\n",
      "creating build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
      "copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
      "copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
      "creating build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "creating build/lib.linux-x86_64-3.7/apex/reparameterization\n",
      "copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
      "copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
      "copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
      "creating build/lib.linux-x86_64-3.7/apex/normalization\n",
      "copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
      "copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
      "creating build/lib.linux-x86_64-3.7/apex/parallel\n",
      "copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "creating build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/utils.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/amp.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/handle.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/opt.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "creating build/lib.linux-x86_64-3.7/apex/pyprof\n",
      "copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof\n",
      "creating build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
      "copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
      "copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
      "creating build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
      "creating build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
      "creating build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
      "copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
      "copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
      "creating build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "creating build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
      "creating build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
      "copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
      "copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
      "copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
      "copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
      "copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
      "copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
      "creating build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
      "copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
      "copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
      "running build_ext\n",
      "building 'apex_C' extension\n",
      "creating /root/apex/build/temp.linux-x86_64-3.7\n",
      "creating /root/apex/build/temp.linux-x86_64-3.7/csrc\n",
      "Emitting ninja build file /root/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/1] c++ -MMD -MF /root/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/flatten_unflatten.cpp -o /root/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "In file included from /root/apex/csrc/flatten_unflatten.cpp:2:0:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     return tensors[0].type();\n",
      "                            ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/flatten_unflatten.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'amp_C' extension\n",
      "Emitting ninja build file /root/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_adam.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[2/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_adagrad.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[3/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_lamb_stage_2.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[4/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_lamb.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[5/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_sgd_kernel.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[6/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_novograd.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[7/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_scale_kernel.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[8/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_lamb_stage_1.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[9/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_axpby_kernel.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[10/11] c++ -MMD -MF /root/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/amp_C_frontend.cpp -o /root/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "[11/11] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/multi_tensor_l2norm_kernel.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o /root/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/amp_C.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'syncbn' extension\n",
      "Emitting ninja build file /root/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] c++ -MMD -MF /root/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/syncbn.cpp -o /root/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "[2/2] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/welford.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o /root/apex/build/temp.linux-x86_64-3.7/csrc/welford.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'fused_layer_norm_cuda' extension\n",
      "Emitting ninja build file /root/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/layer_norm_cuda_kernel.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[2/2] c++ -MMD -MF /root/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/layer_norm_cuda.cpp -o /root/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\n",
      "cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(input);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(input);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(gamma);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(beta);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(dout);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(mean);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(invvar);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(input);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(dout);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(mean);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(invvar);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(input);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(gamma);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/DeviceType.h:8:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                                          ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\r\n",
      " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\r\n",
      "                                                                 ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\r\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\r\n",
      "       ^\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\r\n",
      " #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\r\n",
      "                                ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\r\n",
      " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\r\n",
      "                       ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\r\n",
      " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\r\n",
      "                        ^\r\n",
      "/root/apex/csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\r\n",
      "   CHECK_INPUT(beta);\r\n",
      "   ^\r\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\r\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\r\n",
      "                 from /root/apex/csrc/layer_norm_cuda.cpp:1:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\r\n",
      "   DeprecatedTypeProperties & type() const {\r\n",
      "                              ^\r\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o /root/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so\r\n",
      "building 'mlp_cuda' extension\n",
      "Emitting ninja build file /root/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] c++ -MMD -MF /root/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/mlp.cpp -o /root/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "/root/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
      "/root/apex/csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "   for (int i = 0; i < num_layers; i++) {\n",
      "                     ^\n",
      "/root/apex/csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
      "                                                                             ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^\n",
      "/root/apex/csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                   ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^\n",
      "/root/apex/csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "   auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                    ^\n",
      "/root/apex/csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/root/apex/csrc/mlp.cpp: In lambda function:\n",
      "/root/apex/csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "                                                      ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "     const auto& the_type = TYPE;                                             \\\n",
      "                            ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                        ^\n",
      "/root/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "   ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                       ^\n",
      "/root/apex/csrc/mlp.cpp: In lambda function:\n",
      "/root/apex/csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "     for (int i = 0; i < num_layers; i++) {\n",
      "                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "     auto result = mlp_fp<scalar_t>(\n",
      "          ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp: In lambda function:\n",
      "/root/apex/csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "     for (int i = 0; i < num_layers; i++) {\n",
      "                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "     auto result = mlp_fp<scalar_t>(\n",
      "          ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp: In lambda function:\n",
      "/root/apex/csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "     for (int i = 0; i < num_layers; i++) {\n",
      "                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "     auto result = mlp_fp<scalar_t>(\n",
      "          ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
      "/root/apex/csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "   for (int i = 0; i < num_layers; i++) {\n",
      "                     ^\n",
      "/root/apex/csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "   for (int i = 0; i < inputs.size(); i++) {\n",
      "                     ^\n",
      "/root/apex/csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
      "                                                                   ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/root/apex/csrc/mlp.cpp: In lambda function:\n",
      "/root/apex/csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "                                                      ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "     const auto& the_type = TYPE;                                             \\\n",
      "                            ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                        ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                       ^\n",
      "/root/apex/csrc/mlp.cpp: In lambda function:\n",
      "/root/apex/csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "     for (int i = 0; i < num_layers; i++) {\n",
      "                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "     for (int i = 0; i < inputs.size(); i++) {\n",
      "                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/root/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                            ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                            ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "     auto result = mlp_bp<scalar_t>(\n",
      "          ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp: In lambda function:\n",
      "/root/apex/csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "     for (int i = 0; i < num_layers; i++) {\n",
      "                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "     for (int i = 0; i < inputs.size(); i++) {\n",
      "                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/root/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                            ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                            ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "     auto result = mlp_bp<scalar_t>(\n",
      "          ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp: In lambda function:\n",
      "/root/apex/csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "     for (int i = 0; i < num_layers; i++) {\n",
      "                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "     for (int i = 0; i < inputs.size(); i++) {\n",
      "                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /root/apex/csrc/mlp.cpp:1:\n",
      "/root/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                            ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                            ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "/root/apex/csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "     auto result = mlp_bp<scalar_t>(\n",
      "          ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "     return __VA_ARGS__();                          \\\n",
      "            ^\n",
      "/root/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "   ^\n",
      "[2/2] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/mlp_cuda.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\r\n",
      "FAILED: /root/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o \r\n",
      "/usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/apex/csrc/mlp_cuda.cu -o /root/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/enum.h(187): warning: statement is unreachable\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/enum.h(187): warning: statement is unreachable\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::CrossMapLRN2dImpl]’:\r\n",
      "/tmp/tmpxft_00000d40_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::EmbeddingBagImpl]’:\r\n",
      "/tmp/tmpxft_00000d40_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::EmbeddingImpl]’:\r\n",
      "/tmp/tmpxft_00000d40_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::SequentialImpl]’:\r\n",
      "/tmp/tmpxft_00000d40_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ModuleListImpl]’:\r\n",
      "/tmp/tmpxft_00000d40_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::GroupNormImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LocalResponseNormImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LayerNormImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::MultiheadAttentionImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ThresholdImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LogSoftmaxImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::SoftminImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::SoftmaxImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::GRUCellImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LSTMCellImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::RNNCellImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::GRUImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LSTMImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::RNNImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::FractionalMaxPool3dImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::FractionalMaxPool2dImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ZeroPad2dImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::UnfoldImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::FoldImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ConvTranspose3dImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ConvTranspose2dImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ConvTranspose1dImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::Conv3dImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::Conv2dImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::Conv1dImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::AdaptiveLogSoftmaxWithLossImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::BilinearImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LinearImpl]’:\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "ninja: build stopped: subcommand failed.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1400, in _run_ninja_build\r\n",
      "    check=True)\r\n",
      "  File \"/opt/conda/lib/python3.7/subprocess.py\", line 468, in run\r\n",
      "    output=stdout, stderr=stderr)\r\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"setup.py\", line 390, in <module>\r\n",
      "    extras_require=extras,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 144, in setup\r\n",
      "    return distutils.core.setup(**attrs)\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/core.py\", line 148, in setup\r\n",
      "    dist.run_commands()\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n",
      "    self.run_command(cmd)\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n",
      "    cmd_obj.run()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py\", line 67, in run\r\n",
      "    self.do_egg_install()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py\", line 109, in do_egg_install\r\n",
      "    self.run_command('bdist_egg')\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n",
      "    self.distribution.run_command(command)\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n",
      "    cmd_obj.run()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 173, in run\r\n",
      "    cmd = self.call_command('install_lib', warn_dir=0)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 159, in call_command\r\n",
      "    self.run_command(cmdname)\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n",
      "    self.distribution.run_command(command)\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n",
      "    cmd_obj.run()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/install_lib.py\", line 11, in run\r\n",
      "    self.build()\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/command/install_lib.py\", line 107, in build\r\n",
      "    self.run_command('build_ext')\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n",
      "    self.distribution.run_command(command)\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n",
      "    cmd_obj.run()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/build_ext.py\", line 87, in run\r\n",
      "    _build_ext.run(self)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\r\n",
      "    _build_ext.build_ext.run(self)\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/command/build_ext.py\", line 339, in run\r\n",
      "    self.build_extensions()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 580, in build_extensions\r\n",
      "    build_ext.build_extensions(self)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py\", line 195, in build_extensions\r\n",
      "    _build_ext.build_ext.build_extensions(self)\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/command/build_ext.py\", line 448, in build_extensions\r\n",
      "    self._build_extensions_serial()\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/command/build_ext.py\", line 473, in _build_extensions_serial\r\n",
      "    self.build_extension(ext)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/build_ext.py\", line 208, in build_extension\r\n",
      "    _build_ext.build_extension(self, ext)\r\n",
      "  File \"/opt/conda/lib/python3.7/distutils/command/build_ext.py\", line 533, in build_extension\r\n",
      "    depends=ext.depends)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 423, in unix_wrap_ninja_compile\r\n",
      "    with_cuda=with_cuda)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1140, in _write_ninja_file_and_compile_objects\r\n",
      "    error_prefix='Error compiling objects for extension')\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1413, in _run_ninja_build\r\n",
      "    raise RuntimeError(message)\r\n",
      "RuntimeError: Error compiling objects for extension\r\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/NVIDIA/apex.git\n",
    "! cd apex ; python setup.py install --cuda_ext --cpp_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ2Eoix66NLA"
   },
   "source": [
    "https://stackoverflow.com/questions/57284345/how-to-install-nvidia-apex-on-google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "yu08H3016Qud",
    "outputId": "54c04e0f-6f85-4c8d-81fe-e48bcd2453d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-nx74GTK6-6T",
    "outputId": "50f56b3b-6680-429b-8097-6f6f24b71cce",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'apex' already exists and is not an empty directory.\n",
      "/opt/conda/lib/python3.7/site-packages/pip/_internal/commands/install.py:244: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Non-user install because site-packages writeable\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-ye36o0xq\n",
      "Created temporary directory: /tmp/pip-req-tracker-z_k4siug\n",
      "Initialized build tracking at /tmp/pip-req-tracker-z_k4siug\n",
      "Created build tracker: /tmp/pip-req-tracker-z_k4siug\n",
      "Entered build tracker: /tmp/pip-req-tracker-z_k4siug\n",
      "Created temporary directory: /tmp/pip-install-5jkty80s\n",
      "Processing ./apex\n",
      "  Created temporary directory: /tmp/pip-req-build-bxi3wcuy\n",
      "  Added file:///root/apex to build tracker '/tmp/pip-req-tracker-z_k4siug'\n",
      "    Running setup.py (path:/tmp/pip-req-build-bxi3wcuy/setup.py) egg_info for package from file:///root/apex\n",
      "    Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.5.0+cu101\n",
      "\n",
      "\n",
      "    running egg_info\n",
      "    creating /tmp/pip-req-build-bxi3wcuy/pip-egg-info/apex.egg-info\n",
      "    writing /tmp/pip-req-build-bxi3wcuy/pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-req-build-bxi3wcuy/pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-req-build-bxi3wcuy/pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-req-build-bxi3wcuy/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    reading manifest file '/tmp/pip-req-build-bxi3wcuy/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file '/tmp/pip-req-build-bxi3wcuy/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    /tmp/pip-req-build-bxi3wcuy/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  Source in /tmp/pip-req-build-bxi3wcuy has version 0.1, which satisfies requirement apex==0.1 from file:///root/apex\n",
      "  Removed apex==0.1 from file:///root/apex from build tracker '/tmp/pip-req-tracker-z_k4siug'\n",
      "Skipping wheel build for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-qgg_jen5\n",
      "    Running command /opt/conda/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-bxi3wcuy/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-bxi3wcuy/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-qgg_jen5/install-record.txt --single-version-externally-managed --compile --install-headers /opt/conda/include/python3.7m/apex\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.5.0+cu101\n",
      "\n",
      "\n",
      "    /tmp/pip-req-build-bxi3wcuy/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "    Built on Fri_Feb__8_19:08:17_PST_2019\n",
      "    Cuda compilation tools, release 10.1, V10.1.105\n",
      "    from /usr/local/cuda/bin\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    running build_ext\n",
      "    building 'mlp_cuda' extension\n",
      "    Emitting ninja build file /tmp/pip-req-build-bxi3wcuy/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "    Compiling objects...\n",
      "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "    [1/2] c++ -MMD -MF /tmp/pip-req-build-bxi3wcuy/build/temp.linux-x86_64-3.7/csrc/mlp.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp -o /tmp/pip-req-build-bxi3wcuy/build/temp.linux-x86_64-3.7/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < num_layers; i++) {\n",
      "                         ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
      "                                                                                 ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                       ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                        ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In lambda function:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "                                                          ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "         const auto& the_type = TYPE;                                             \\\n",
      "                                ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                            ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                           ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In lambda function:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                           ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In lambda function:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                           ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In lambda function:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                           ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < num_layers; i++) {\n",
      "                         ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
      "                                                                       ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In lambda function:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "                                                          ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "         const auto& the_type = TYPE;                                             \\\n",
      "                                ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                            ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                           ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In lambda function:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                           ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                           ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In lambda function:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                           ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                           ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp: In lambda function:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                           ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                           ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^\n",
      "    In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                     from /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:1:\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^\n",
      "    /tmp/pip-req-build-bxi3wcuy/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    [2/2] /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /tmp/pip-req-build-bxi3wcuy/csrc/mlp_cuda.cu -o /tmp/pip-req-build-bxi3wcuy/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\r\n",
      "    FAILED: /tmp/pip-req-build-bxi3wcuy/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o\r\n",
      "    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /tmp/pip-req-build-bxi3wcuy/csrc/mlp_cuda.cu -o /tmp/pip-req-build-bxi3wcuy/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/enum.h(187): warning: statement is unreachable\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/enum.h(187): warning: statement is unreachable\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\r\n",
      "\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::CrossMapLRN2dImpl]’:\r\n",
      "    /tmp/tmpxft_00000dc6_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::EmbeddingBagImpl]’:\r\n",
      "    /tmp/tmpxft_00000dc6_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::EmbeddingImpl]’:\r\n",
      "    /tmp/tmpxft_00000dc6_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::SequentialImpl]’:\r\n",
      "    /tmp/tmpxft_00000dc6_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ModuleListImpl]’:\r\n",
      "    /tmp/tmpxft_00000dc6_00000000-5_mlp_cuda.cudafe1.stub.c:97:27:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::GroupNormImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LocalResponseNormImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LayerNormImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::MultiheadAttentionImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ThresholdImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LogSoftmaxImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::SoftminImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::SoftmaxImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::GRUCellImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LSTMCellImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::RNNCellImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::GRUImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LSTMImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::RNNImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::FractionalMaxPool3dImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::FractionalMaxPool2dImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ZeroPad2dImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::UnfoldImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::FoldImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ConvTranspose3dImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ConvTranspose2dImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::ConvTranspose1dImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::Conv3dImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::Conv2dImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::Conv1dImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::AdaptiveLogSoftmaxWithLossImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::BilinearImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h: In instantiation of ‘std::shared_ptr<torch::nn::Module> torch::nn::Cloneable<Derived>::clone(const c10::optional<c10::Device>&) const [with Derived = torch::nn::LinearImpl]’:\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/optim/sgd.h:48:48:   required from here\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:44:65: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:56:59: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, at::Tensor>’ to type ‘torch::OrderedDict<std::basic_string<char>, at::Tensor>&’\r\n",
      "    /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:68:61: error: invalid static_cast from type ‘const torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >’ to type ‘torch::OrderedDict<std::basic_string<char>, std::shared_ptr<torch::nn::Module> >&’\r\n",
      "    ninja: build stopped: subcommand failed.\r\n",
      "    Traceback (most recent call last):\r\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1400, in _run_ninja_build\r\n",
      "        check=True)\r\n",
      "      File \"/opt/conda/lib/python3.7/subprocess.py\", line 468, in run\r\n",
      "        output=stdout, stderr=stderr)\r\n",
      "    subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\r\n",
      "\r\n",
      "    During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "    Traceback (most recent call last):\r\n",
      "      File \"<string>\", line 1, in <module>\r\n",
      "      File \"/tmp/pip-req-build-bxi3wcuy/setup.py\", line 390, in <module>\r\n",
      "        extras_require=extras,\r\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 144, in setup\r\n",
      "        return distutils.core.setup(**attrs)\r\n",
      "      File \"/opt/conda/lib/python3.7/distutils/core.py\", line 148, in setup\r\n",
      "        dist.run_commands()\r\n",
      "      File \"/opt/conda/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n",
      "        self.run_command(cmd)\r\n",
      "      File \"/opt/conda/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n",
      "        cmd_obj.run()\r\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py\", line 61, in run\r\n",
      "        return orig.install.run(self)\r\n",
      "      File \"/opt/conda/lib/python3.7/distutils/command/install.py\", line 545, in run\r\n",
      "        self.run_command('build')\r\n",
      "      File \"/opt/conda/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n",
      "        self.distribution.run_command(command)\r\n",
      "      File \"/opt/conda/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n",
      "        cmd_obj.run()\r\n",
      "      File \"/opt/conda/lib/python3.7/distutils/command/build.py\", line 135, in run\r\n",
      "        self.run_command(cmd_name)\r\n",
      "      File \"/opt/conda/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n",
      "        self.distribution.run_command(command)\n",
      "      File \"/opt/conda/lib/python3.7/distutils/dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/build_ext.py\", line 87, in run\n",
      "        _build_ext.run(self)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
      "        _build_ext.build_ext.run(self)\n",
      "      File \"/opt/conda/lib/python3.7/distutils/command/build_ext.py\", line 339, in run\n",
      "        self.build_extensions()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 580, in build_extensions\n",
      "        build_ext.build_extensions(self)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py\", line 195, in build_extensions\n",
      "        _build_ext.build_ext.build_extensions(self)\n",
      "      File \"/opt/conda/lib/python3.7/distutils/command/build_ext.py\", line 448, in build_extensions\n",
      "        self._build_extensions_serial()\n",
      "      File \"/opt/conda/lib/python3.7/distutils/command/build_ext.py\", line 473, in _build_extensions_serial\n",
      "        self.build_extension(ext)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/command/build_ext.py\", line 208, in build_extension\n",
      "        _build_ext.build_extension(self, ext)\n",
      "      File \"/opt/conda/lib/python3.7/distutils/command/build_ext.py\", line 533, in build_extension\n",
      "        depends=ext.depends)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 423, in unix_wrap_ninja_compile\n",
      "        with_cuda=with_cuda)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1140, in _write_ninja_file_and_compile_objects\n",
      "        error_prefix='Error compiling objects for extension')\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1413, in _run_ninja_build\n",
      "        raise RuntimeError(message)\n",
      "    RuntimeError: Error compiling objects for extension\n",
      "    Running setup.py install for apex ... \u001b[?25l\u001b[?25herror\n",
      "Cleaning up...\n",
      "  Removing source in /tmp/pip-req-build-bxi3wcuy\n",
      "Removed build tracker: '/tmp/pip-req-tracker-z_k4siug'\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /opt/conda/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-bxi3wcuy/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-bxi3wcuy/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-qgg_jen5/install-record.txt --single-version-externally-managed --compile --install-headers /opt/conda/include/python3.7m/apex Check the logs for full command output.\u001b[0m\n",
      "Exception information:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 186, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_internal/commands/install.py\", line 404, in run\n",
      "    use_user_site=options.use_user_site,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_internal/req/__init__.py\", line 71, in install_given_reqs\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_internal/req/req_install.py\", line 829, in install\n",
      "    scheme=scheme,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_internal/operations/install/legacy.py\", line 72, in install\n",
      "    cwd=install_req.unpacked_source_directory,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_internal/utils/subprocess.py\", line 275, in runner\n",
      "    spinner=spinner,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_internal/utils/subprocess.py\", line 242, in call_subprocess\n",
      "    raise InstallationError(exc_msg)\n",
      "pip._internal.exceptions.InstallationError: Command errored out with exit status 1: /opt/conda/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-bxi3wcuy/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-bxi3wcuy/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-qgg_jen5/install-record.txt --single-version-externally-managed --compile --install-headers /opt/conda/include/python3.7m/apex Check the logs for full command output.\n",
      "1 location(s) to search for versions of pip:\n",
      "* https://pypi.org/simple/pip/\n",
      "Fetching project page and analyzing links: https://pypi.org/simple/pip/\n",
      "Getting page https://pypi.org/simple/pip/\n",
      "Found index url https://pypi.org/simple\n",
      "Starting new HTTPS connection (1): pypi.org:443\n",
      "https://pypi.org:443 \"GET /simple/pip/ HTTP/1.1\" 200 13603\n",
      "  Found link https://files.pythonhosted.org/packages/3d/9d/1e313763bdfb6a48977b65829c6ce2a43eaae29ea2f907c8bbef024a7219/pip-0.2.tar.gz#sha256=88bb8d029e1bf4acd0e04d300104b7440086f94cc1ce1c5c3c31e3293aee1f81 (from https://pypi.org/simple/pip/), version: 0.2\n",
      "  Found link https://files.pythonhosted.org/packages/18/ad/c0fe6cdfe1643a19ef027c7168572dac6283b80a384ddf21b75b921877da/pip-0.2.1.tar.gz#sha256=83522005c1266cc2de97e65072ff7554ac0f30ad369c3b02ff3a764b962048da (from https://pypi.org/simple/pip/), version: 0.2.1\n",
      "  Found link https://files.pythonhosted.org/packages/17/05/f66144ef69b436d07f8eeeb28b7f77137f80de4bf60349ec6f0f9509e801/pip-0.3.tar.gz#sha256=183c72455cb7f8860ac1376f8c4f14d7f545aeab8ee7c22cd4caf79f35a2ed47 (from https://pypi.org/simple/pip/), version: 0.3\n",
      "  Found link https://files.pythonhosted.org/packages/0a/bb/d087c9a1415f8726e683791c0b2943c53f2b76e69f527f2e2b2e9f9e7b5c/pip-0.3.1.tar.gz#sha256=34ce534f17065c78f980702928e988a6b6b2d8a9851aae5f1571a1feb9bb58d8 (from https://pypi.org/simple/pip/), version: 0.3.1\n",
      "  Found link https://files.pythonhosted.org/packages/cf/c3/153571aaac6cf999f4bb09c019b1ff379b7b599ea833813a41c784eec995/pip-0.4.tar.gz#sha256=28fc67558874f71fddda7168f73595f1650523dce3bc5bf189713ecdfc1e456e (from https://pypi.org/simple/pip/), version: 0.4\n",
      "  Found link https://files.pythonhosted.org/packages/8d/c7/f05c87812fa5d9562ecbc5f4f1fc1570444f53c81c834a7f662af406e3c1/pip-0.5.tar.gz#sha256=328d8412782f22568508a0d0c78a49c9920a82e44c8dfca49954fe525c152b2a (from https://pypi.org/simple/pip/), version: 0.5\n",
      "  Found link https://files.pythonhosted.org/packages/9a/aa/f536b6d14fe03343367da2ff44eee28f340ae650cd017ca088b6be13084a/pip-0.5.1.tar.gz#sha256=e27650538c41fe1007a41abd4cfd0f905b822622cbe1f8e7e09d1215af207694 (from https://pypi.org/simple/pip/), version: 0.5.1\n",
      "  Found link https://files.pythonhosted.org/packages/db/e6/fdf7be8a17b032c533d3f91e91e2c63dd81d3627cbe4113248a00c2d39d8/pip-0.6.tar.gz#sha256=4cf47db6815b2f435d1f44e1f35ff04823043f6161f7df9aec71a123b0c47f0d (from https://pypi.org/simple/pip/), version: 0.6\n",
      "  Found link https://files.pythonhosted.org/packages/91/cd/105f4d3c75d0ae18e12623acc96f42168aaba408dd6e43c4505aa21f8e37/pip-0.6.1.tar.gz#sha256=efe47e84ffeb0ea4804f9858b8a94bebd07f5452f907ebed36d03aed06a9f9ec (from https://pypi.org/simple/pip/), version: 0.6.1\n",
      "  Found link https://files.pythonhosted.org/packages/1c/c7/c0e1a9413c37828faf290f29a85a4d6034c145cc04bf1622ba8beb662ad8/pip-0.6.2.tar.gz#sha256=1c1a504d7e70d2c24246f95bd16e3d5fcec740fd144df69a407bf65a2ee67586 (from https://pypi.org/simple/pip/), version: 0.6.2\n",
      "  Found link https://files.pythonhosted.org/packages/3f/af/c4b9d49fb0f286996b28dbc0955c3ad359794697eb98e0e69863908070b0/pip-0.6.3.tar.gz#sha256=1a6df71eb29b98cba11bde6d6a0d8c6dd8b0518e74ceb71fb31ea4fbb42fd313 (from https://pypi.org/simple/pip/), version: 0.6.3\n",
      "  Found link https://files.pythonhosted.org/packages/ec/7a/6fe91ff0079ad0437830957c459d52f3923e516f5b453218f2a93d09a427/pip-0.7.tar.gz#sha256=ceaea0b9e494d893c8a191895301b79c1db33e41f14d3ad93e3d28a8b4e9bf27 (from https://pypi.org/simple/pip/), version: 0.7\n",
      "  Found link https://files.pythonhosted.org/packages/a5/63/11303863c2f5e9d9a15d89fcf7513a4b60987007d418862e0fb65c09fff7/pip-0.7.1.tar.gz#sha256=f54f05aa17edd0036de433c44892c8fedb1fd2871c97829838feb995818d24c3 (from https://pypi.org/simple/pip/), version: 0.7.1\n",
      "  Found link https://files.pythonhosted.org/packages/cd/a9/1debaa96bbc1005c1c8ad3b79fec58c198d35121546ea2e858ce0894268a/pip-0.7.2.tar.gz#sha256=98df2eb779358412bbbae75980171ae85deebc846d87e244d086520b1212da09 (from https://pypi.org/simple/pip/), version: 0.7.2\n",
      "  Found link https://files.pythonhosted.org/packages/74/54/f785c327fb3d163560a879b36edae5c78ee07806be282c9d4807f6be7dd1/pip-0.8.tar.gz#sha256=9017e4484a212dd4e1a43dd9f039dd7fc8338d4eea1c339d5ae1c80726de5b0f (from https://pypi.org/simple/pip/), version: 0.8\n",
      "  Found link https://files.pythonhosted.org/packages/5c/79/5e8381cc3078bae92166f2ba96de8355e8c181926505ba8882f7b099a500/pip-0.8.1.tar.gz#sha256=7176a87f35675f6468341212f3b959bb51d23ea66eb1c3692bf746c45c716fa2 (from https://pypi.org/simple/pip/), version: 0.8.1\n",
      "  Found link https://files.pythonhosted.org/packages/17/3e/0a98ab032991518741e7e712a719633e6ae160f51b3d3e855194530fd308/pip-0.8.2.tar.gz#sha256=f80a3549c048bc3bbcb47844826e9c7c6fcd87e77b92bef0d9e66d1b397c4962 (from https://pypi.org/simple/pip/), version: 0.8.2\n",
      "  Found link https://files.pythonhosted.org/packages/f7/9a/943fc6d879ed7220bac2e7e53096bfe78abec88d77f2f516400e0129679e/pip-0.8.3.tar.gz#sha256=1be2e18edd38aa75b5e4ef38a99ec33ba9247177cfcb4a6d2d2b3e73430e3001 (from https://pypi.org/simple/pip/), version: 0.8.3\n",
      "  Found link https://files.pythonhosted.org/packages/24/33/6eb675fb6db7b71d69d6928b33dea61b8bf5cfe1e5649be70ec84ce2fc09/pip-1.0.tar.gz#sha256=34ba07e2d14ba86d5088ba896ac80bed845a9b276ab8acb279b8d99bc77fec8e (from https://pypi.org/simple/pip/), version: 1.0\n",
      "  Found link https://files.pythonhosted.org/packages/10/d9/f584e6107ef98ad7eaaaa5d0f756bfee12561fa6a4712ffdb7209e0e1fd4/pip-1.0.1.tar.gz#sha256=37d2f18213d3845d2038dd3686bc71fc12bb41ad66c945a8b0dfec2879f3497b (from https://pypi.org/simple/pip/), version: 1.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/16/90/5e6f80364d8a656f60681dfb7330298edef292d43e1499bcb3a4c71ff0b9/pip-1.0.2.tar.gz#sha256=a6ed9b36aac2f121c01a2c9e0307a9e4d9438d100a407db701ac65479a3335d2 (from https://pypi.org/simple/pip/), version: 1.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/25/57/0d42cf5307d79913a082c5c4397d46f3793bc35e1138a694136d6e31be99/pip-1.1.tar.gz#sha256=993804bb947d18508acee02141281c77d27677f8c14eaa64d6287a1c53ef01c8 (from https://pypi.org/simple/pip/), version: 1.1\n",
      "  Found link https://files.pythonhosted.org/packages/ba/c3/4e1f892f41aaa217fe0d1f827fa05928783349c69f3cc06fdd68e112678a/pip-1.2.tar.gz#sha256=2b168f1987403f1dc6996a1f22a6f6637b751b7ab6ff27e78380b8d6e70aa314 (from https://pypi.org/simple/pip/), version: 1.2\n",
      "  Found link https://files.pythonhosted.org/packages/c3/a2/a63244da32afd9ce9a8ca1bd86e71610039adea8b8314046ebe5047527a6/pip-1.2.1.tar.gz#sha256=12a9302acfca62cdc7bc5d83386cac3e0581db61ac39acdb3a4e766a16b88eb1 (from https://pypi.org/simple/pip/), version: 1.2.1\n",
      "  Found link https://files.pythonhosted.org/packages/00/45/69d4f2602b80550bfb26cfd2f62c2f05b3b5c7352705d3766cd1e5b27648/pip-1.3.tar.gz#sha256=d6a13c5be316cb21a0243047c7f163f47e88973ebccff8d32e63ca1bf4d9321c (from https://pypi.org/simple/pip/), version: 1.3\n",
      "  Found link https://files.pythonhosted.org/packages/5b/ce/f5b98104f1c10d868936c25f7c597f492d4371aa9ad5fb61a94954ee7208/pip-1.3.1.tar.gz#sha256=145eaa5d1ea1b062663da1f3a97780d7edea4c63c68a37c463b1deedf7bb4957 (from https://pypi.org/simple/pip/), version: 1.3.1\n",
      "  Found link https://files.pythonhosted.org/packages/5f/d0/3b3958f6a58783bae44158b2c4c7827ae89abaecdd4bed12cff402620b9a/pip-1.4.tar.gz#sha256=1fd43cbf07d95ddcecbb795c97a1674b3ddb711bb4a67661284a5aa765aa1b97 (from https://pypi.org/simple/pip/), version: 1.4\n",
      "  Found link https://files.pythonhosted.org/packages/3f/f8/da390e0df72fb61d176b25a4b95262e3dcc14bda0ad25ac64d56db38b667/pip-1.4.1.tar.gz#sha256=4e7a06554711a624c35d0c646f63674b7f6bfc7f80221bf1eb1f631bd890d04e (from https://pypi.org/simple/pip/), version: 1.4.1\n",
      "  Found link https://files.pythonhosted.org/packages/4f/7d/e53bc80667378125a9e07d4929a61b0bd7128a1129dbe6f07bb3228652a3/pip-1.5.tar.gz#sha256=25f81d1a0e55d3b1709818dd57fdfb954b028f229f09bd69cb0bc80a8e03e048 (from https://pypi.org/simple/pip/), version: 1.5\n",
      "  Found link https://files.pythonhosted.org/packages/44/5d/1dca53b5de6d287e7eb99bd174bb022eb6cb0d6ca6e19ca6b16655dde8c2/pip-1.5.1-py2.py3-none-any.whl#sha256=00960db3b0b8724dd37fe37cfb9c72ecb8f59fab9db7d17c5c1e89a1adab49ce (from https://pypi.org/simple/pip/), version: 1.5.1\n",
      "  Found link https://files.pythonhosted.org/packages/21/3f/d86a600c9b2f41a75caacf768a24130f343def97652de2345da15ef7911f/pip-1.5.1.tar.gz#sha256=e60e936fbc101d56668c6134c1f2b5b40fcbec8b4fc4ca7fc34842b6b4c5c130 (from https://pypi.org/simple/pip/), version: 1.5.1\n",
      "  Found link https://files.pythonhosted.org/packages/3d/1f/227d77d5e9ed2df5162de4ba3616799a351eccb1ecd668ae824dd26153a1/pip-1.5.2-py2.py3-none-any.whl#sha256=6903909ccdcdbc3297b74118590e71344d6d262827acd1f5c0e2fcfce9807499 (from https://pypi.org/simple/pip/), version: 1.5.2\n",
      "  Found link https://files.pythonhosted.org/packages/ed/94/391a003107f6ec997c314199d03bff1c105af758ee490e3255353574487b/pip-1.5.2.tar.gz#sha256=2a8a3e08e652d3a40edbb39264bf01f8ff3c32520a79113357cca1f30533f738 (from https://pypi.org/simple/pip/), version: 1.5.2\n",
      "  Found link https://files.pythonhosted.org/packages/df/e9/bdb53d44fad1465b43edaf6bc7dd3027ed5af81405cc97603fdff0721ebb/pip-1.5.3-py2.py3-none-any.whl#sha256=f0037aed3ce6cf96b9e9117d42e967a74bea9ebe19088a2fdea5de93d5762fee (from https://pypi.org/simple/pip/), version: 1.5.3\n",
      "  Found link https://files.pythonhosted.org/packages/55/de/671a48ad313c808623041fc475f7c8f7610401d9f573f06b40eeb84e74e3/pip-1.5.3.tar.gz#sha256=dc53b4d28b88556a37cd73052b6d1d08cc644c6724e37c4d38a2e3c03c5440b2 (from https://pypi.org/simple/pip/), version: 1.5.3\n",
      "  Found link https://files.pythonhosted.org/packages/a9/9a/9aa19fe00de4c025562e5fb3796ff8520165a7dd1a5662c6ec9816e1ae99/pip-1.5.4-py2.py3-none-any.whl#sha256=fb7282556a42e84464f2e963a859ac4012d8134ba6218b70c1d82d145fcfa82f (from https://pypi.org/simple/pip/), version: 1.5.4\n",
      "  Found link https://files.pythonhosted.org/packages/78/d8/6e58a7130d457edadb753a0ea5708e411c100c7e94e72ad4802feeef735c/pip-1.5.4.tar.gz#sha256=70208a250bb4afdbbdd74c3ac35d4ab9ba1eb6852d02567a6a87f2f5104e30b9 (from https://pypi.org/simple/pip/), version: 1.5.4\n",
      "  Found link https://files.pythonhosted.org/packages/ce/c2/10d996b9c51b126a9f0bb9e14a9edcdd5c88888323c0685bb9b392b6c47c/pip-1.5.5-py2.py3-none-any.whl#sha256=fe7a5808190067b2598d85def9b83db46e5d64a00848ad843e107c36e1db4ae6 (from https://pypi.org/simple/pip/), version: 1.5.5\n",
      "  Found link https://files.pythonhosted.org/packages/88/01/a442fde40bd9aaf837612536f16ab751fac628807fd718690795b8ade77d/pip-1.5.5.tar.gz#sha256=4b7f5124364ae9b5ba833dcd8813a84c1c06fba1d7c8543323c7af4b33188eca (from https://pypi.org/simple/pip/), version: 1.5.5\n",
      "  Found link https://files.pythonhosted.org/packages/3f/08/7347ca4021e7fe0f1ab8f93cbc7d2a7a7350012300ad0e0227d55625e2b8/pip-1.5.6-py2.py3-none-any.whl#sha256=fbc1351ffedf09ca7560428758845a88d648b9730b63ce9e5df53a7c89f039a4 (from https://pypi.org/simple/pip/), version: 1.5.6\n",
      "  Found link https://files.pythonhosted.org/packages/45/db/4fb9a456b4ec4d3b701456ef562b9d72d76b6358e0c1463d17db18c5b772/pip-1.5.6.tar.gz#sha256=b1a4ae66baf21b7eb05a5e4f37c50c2706fa28ea1f8780ce8efe14dcd9f1726c (from https://pypi.org/simple/pip/), version: 1.5.6\n",
      "  Found link https://files.pythonhosted.org/packages/dc/7c/21191b5944b917b66e4e4e06d74f668d814b6e8a3ff7acd874479b6f6b3d/pip-6.0-py2.py3-none-any.whl#sha256=5ec6732505bd8be49fe1f8ad557b88253ffb085736396df4d6bea753fc2a8f2c (from https://pypi.org/simple/pip/), version: 6.0\n",
      "  Found link https://files.pythonhosted.org/packages/38/fd/065c66a88398f240e344fdf496b9707f92d75f88eedc3d10ff847b28a657/pip-6.0.tar.gz#sha256=6103897f1bb68d3f933edd60f3e3830c4ea6b8abf7a4b500db148921b11f6c9b (from https://pypi.org/simple/pip/), version: 6.0\n",
      "  Found link https://files.pythonhosted.org/packages/e9/7a/cdbc1a12ed52410d557e48d4646f4543e9e991ff32d2374dc6db849aa617/pip-6.0.1-py2.py3-none-any.whl#sha256=322aea7d1f7b9ee68ad87ac4704cad5df97f77e70668c0bd18f964c5daa78173 (from https://pypi.org/simple/pip/), version: 6.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/4d/c3/8675b90cd89b9b222062f4f6c7e9d48b0387f5b35cbf747a74403a883e56/pip-6.0.1.tar.gz#sha256=fa2f7c68da4a405d673aa38542f9df009d60026db4f532429ac9cbfbda1f959d (from https://pypi.org/simple/pip/), version: 6.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/71/3c/b5a521e5e99cfff091e282231591f21193fd80de079ec5fb8ed9c6614044/pip-6.0.2-py2.py3-none-any.whl#sha256=7d17b0f267f7c9cd17cd2924bbbe2b4a3d407322c0e09084ca3f1295c1fed50d (from https://pypi.org/simple/pip/), version: 6.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/4c/5a/f9e8e3de0153282c7cb54a9b991af225536ac914bac858ca664cf883bb3e/pip-6.0.2.tar.gz#sha256=6fa90667706a679e3dc75b27a51fddafa64401c45e96f8ae6c20978183290077 (from https://pypi.org/simple/pip/), version: 6.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/73/cb/3eebf42003791df29219a3dfa1874572aa16114b44c9b1b0ac66bf96e8c0/pip-6.0.3-py2.py3-none-any.whl#sha256=b72655b6ac6aef1c86dd07f51e8ace8d7aabd6a1c4ff88db87155276fa32a073 (from https://pypi.org/simple/pip/), version: 6.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/ce/63/8d99ae60d11ae1a65f5d4fc39a529a598bd3b8e067132210cb0c4d9e9f74/pip-6.0.3.tar.gz#sha256=b091a35f5fa0faffac0b27b97e1e1e93ffe63b463c2ea8dbde0c1fb987933614 (from https://pypi.org/simple/pip/), version: 6.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/c5/0e/c974206726542bc495fc7443dd97834a6d14c2f0cba183fcfcd01075225a/pip-6.0.4-py2.py3-none-any.whl#sha256=8dfd95de29a7a3bb1e7d368cc83d566938eb210b04d553ebfe5e3a422f4aec65 (from https://pypi.org/simple/pip/), version: 6.0.4\n",
      "  Found link https://files.pythonhosted.org/packages/02/a1/c90f19910ee153d7a0efca7216758121118d7e93084276541383fe9ca82e/pip-6.0.4.tar.gz#sha256=1dbbff9c369e510c7468ab68ba52c003f68f83c99c2f8259acd51099e8799f1e (from https://pypi.org/simple/pip/), version: 6.0.4\n",
      "  Found link https://files.pythonhosted.org/packages/e9/1b/c6a375a337fb576784cdea3700f6c3eaf1420f0a01458e6e034cc178a84a/pip-6.0.5-py2.py3-none-any.whl#sha256=b2c20e3a2a43b2bbb1d19ad98be27eccc7b0f0ece016da602ccaa757a862b0e2 (from https://pypi.org/simple/pip/), version: 6.0.5\n",
      "  Found link https://files.pythonhosted.org/packages/19/f2/58628768f618c8c9fea878e0fb97730c0b8a838d3ab3f325768bf12dac94/pip-6.0.5.tar.gz#sha256=3bf42d28be9085ab2e9aecfd69a6da2d31563fe833304bf71a620a30c38ab8a2 (from https://pypi.org/simple/pip/), version: 6.0.5\n",
      "  Found link https://files.pythonhosted.org/packages/64/fc/4a49ccb18f55a0ceeb76e8d554bd4563217117492997825d194ed0017cc1/pip-6.0.6-py2.py3-none-any.whl#sha256=fb04f8afe1ba57626783f0c8e2f3d46bbaebaa446fcf124f434e968a2fee595e (from https://pypi.org/simple/pip/), version: 6.0.6\n",
      "  Found link https://files.pythonhosted.org/packages/f6/ce/d9e4e178b66c766c117f62ddf4fece019ef9d50127a8926d2f60300d615e/pip-6.0.6.tar.gz#sha256=3a14091299dcdb9bab9e9004ae67ac401f2b1b14a7c98de074ca74fdddf4bfa0 (from https://pypi.org/simple/pip/), version: 6.0.6\n",
      "  Found link https://files.pythonhosted.org/packages/7a/8e/2bbd4fcf3ee06ee90ded5f39ec12f53165dfdb9ef25a981717ad38a16670/pip-6.0.7-py2.py3-none-any.whl#sha256=93a326304c7db749896bcef822bbbac1ab29dad5651c6d732e245975239890e6 (from https://pypi.org/simple/pip/), version: 6.0.7\n",
      "  Found link https://files.pythonhosted.org/packages/52/85/b160ebdaa84378df6bb0176d4eed9f57edca662446174eead7a9e2e566d6/pip-6.0.7.tar.gz#sha256=35a5a43ac6b7af83ed47ea5731a365f43d350a3a7267e039e5f06b61d42ab3c2 (from https://pypi.org/simple/pip/), version: 6.0.7\n",
      "  Found link https://files.pythonhosted.org/packages/63/65/55b71647adec1ad595bf0e5d76d028506dfc002df30c256f022ff7a660a5/pip-6.0.8-py2.py3-none-any.whl#sha256=3c22b0a8ff92727bd737a82f72700790591f177541df08c07bc1f90d6b72ac19 (from https://pypi.org/simple/pip/), version: 6.0.8\n",
      "  Found link https://files.pythonhosted.org/packages/ef/8a/e3a980bc0a7f791d72c1302f65763ed300f2e14c907ac033e01b44c79e5e/pip-6.0.8.tar.gz#sha256=0d58487a1b7f5be2e5e965c11afbea1dc44ecec8069de03491a4d0d6c85f4551 (from https://pypi.org/simple/pip/), version: 6.0.8\n",
      "  Found link https://files.pythonhosted.org/packages/24/fb/8a56a46243514681e569bbafd8146fa383476c4b7c725c8598c452366f31/pip-6.1.0-py2.py3-none-any.whl#sha256=435a018f6d29e34d4f901bf4e6860d8a5fa1816b68d62008c18ca062a306db31 (from https://pypi.org/simple/pip/), version: 6.1.0\n",
      "  Found link https://files.pythonhosted.org/packages/6c/84/432eb60bbcb414b9cdfcb135d5f4925e253c74e7d6916ada79990d6cc1a0/pip-6.1.0.tar.gz#sha256=89f120e2ab3d25ab70c36eb28ad4f280fc9ba71736e74d3055f609c1f9173768 (from https://pypi.org/simple/pip/), version: 6.1.0\n",
      "  Found link https://files.pythonhosted.org/packages/67/f0/ba0fb41dbdbfc4aa3e0c16b40269aca6b9e3d59cacdb646218aa2e9b1d2c/pip-6.1.1-py2.py3-none-any.whl#sha256=a67e54aa0f26b6d62ccec5cc6735eff205dd0fed075f56ac3d3111e91e4467fc (from https://pypi.org/simple/pip/), version: 6.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/bf/85/871c126b50b8ee0b9819e8a63b614aedd264577e73478caedcd447e8f28c/pip-6.1.1.tar.gz#sha256=89f3b626d225e08e7f20d85044afa40f612eb3284484169813dc2d0631f2a556 (from https://pypi.org/simple/pip/), version: 6.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/5a/9b/56d3c18d0784d5f2bbd446ea2dc7ffa7476c35e3dc223741d20cfee3b185/pip-7.0.0-py2.py3-none-any.whl#sha256=309c48399c7d68501a10ef206abd6e5c541fedbf84b95435d9063bd454b39df7 (from https://pypi.org/simple/pip/), version: 7.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/c6/16/6475b142927ca5d03e3b7968efa5b0edd103e4684ecfde181a25f6fa2505/pip-7.0.0.tar.gz#sha256=7b46bfc1b95494731de306a688e2a7bc056d7fa7ad27e026908fb2ae67fed23d (from https://pypi.org/simple/pip/), version: 7.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/5a/10/bb7a32c335bceba636aa673a4c977effa1e73a79f88856459486d8d670cf/pip-7.0.1-py2.py3-none-any.whl#sha256=d26b8573ba1ac1ec99a9bdbdffee2ff2b06c7790815211d0eb4dc1462a089705 (from https://pypi.org/simple/pip/), version: 7.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/4a/83/9ae4362a80739657e0c8bb628ea3fa0214a9aba7c8590dacc301ea293f73/pip-7.0.1.tar.gz#sha256=cfec177552fdd0b2d12b72651c8e874f955b4c62c1c2c9f2588cbdc1c0d0d416 (from https://pypi.org/simple/pip/), version: 7.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/64/7f/7107800ae0919a80afbf1ecba21b90890431c3ee79d700adac3c79cb6497/pip-7.0.2-py2.py3-none-any.whl#sha256=83c869c5ab7113866e2d69641ec470d47f0faae68ca4550a289a4d3db515ad65 (from https://pypi.org/simple/pip/), version: 7.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/75/b1/66532c273bca0133e42c3b4540a1609289f16e3046f1830f18c60794d661/pip-7.0.2.tar.gz#sha256=ba28fa60b573a9444e7b78ccb3b0f261d1f66f46d20403f9dce37b18a6aed405 (from https://pypi.org/simple/pip/), version: 7.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/96/76/33a598ae42dd0554207d83c7acc60e3b166dbde723cbf282f1f73b7a127c/pip-7.0.3-py2.py3-none-any.whl#sha256=7b1cb03e827d58d2d05e68ea96a9e27487ed4b0afcd951ac6e40847ce94f0738 (from https://pypi.org/simple/pip/), version: 7.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/35/59/5b23115758ba0f2fc465c459611865173ef006202ba83f662d1f58ed2fb8/pip-7.0.3.tar.gz#sha256=b4c598825a6f6dc2cac65968feb28e6be6c1f7f1408493c60a07eaa731a0affd (from https://pypi.org/simple/pip/), version: 7.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/f7/c0/9f8dac88326609b4b12b304e8382f64f7d5af7735a00d2fac36cf135fc30/pip-7.1.0-py2.py3-none-any.whl#sha256=80c29f899d3a00a448d65f8158544d22935baec7159af8da1a4fa1490ced481d (from https://pypi.org/simple/pip/), version: 7.1.0\n",
      "  Found link https://files.pythonhosted.org/packages/7e/71/3c6ece07a9a885650aa6607b0ebfdf6fc9a3ef8691c44b5e724e4eee7bf2/pip-7.1.0.tar.gz#sha256=d5275ba3221182a5dd1b6bcfbfc5ec277fb399dd23226d6fa018048f7e0f10f2 (from https://pypi.org/simple/pip/), version: 7.1.0\n",
      "  Found link https://files.pythonhosted.org/packages/1c/56/094d563c508917081bccff365e4f621ba33073c1c13aca9267a43cfcaf13/pip-7.1.1-py2.py3-none-any.whl#sha256=ce13000878d34c1178af76cb8cf269e232c00508c78ed46c165dd5b0881615f4 (from https://pypi.org/simple/pip/), version: 7.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/3b/bb/b3f2a95494fd3f01d3b3ae530e7c0e910dc25e88e30787b0a5e10cbc0640/pip-7.1.1.tar.gz#sha256=b22fe3c93a13fc7c04f145a42fd2ad50a9e3e1b8a7eed2e2b1c66e540a0951da (from https://pypi.org/simple/pip/), version: 7.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/b2/d0/cd115fe345dd6f07ec1c780020a7dfe74966fceeb171e0f20d1d4905b0b7/pip-7.1.2-py2.py3-none-any.whl#sha256=b9d3983b5cce04f842175e30169d2f869ef12c3546fd274083a65eada4e9708c (from https://pypi.org/simple/pip/), version: 7.1.2\n",
      "  Found link https://files.pythonhosted.org/packages/d0/92/1e8406c15d9372084a5bf79d96da3a0acc4e7fcf0b80020a4820897d2a5c/pip-7.1.2.tar.gz#sha256=ca047986f0528cfa975a14fb9f7f106271d4e0c3fe1ddced6c1db2e7ae57a477 (from https://pypi.org/simple/pip/), version: 7.1.2\n",
      "  Found link https://files.pythonhosted.org/packages/00/ae/bddef02881ee09c6a01a0d6541aa6c75a226a4e68b041be93142befa0cd6/pip-8.0.0-py2.py3-none-any.whl#sha256=262ed1823eb7fbe3f18a9bedb4800e59c4ab9a6682aff8c37b5ee83ea840910b (from https://pypi.org/simple/pip/), version: 8.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/e3/2d/03c014d11e66628abf2fda5ca00f779cbe7b5292c5cd13d42a95b94aa9b8/pip-8.0.0.tar.gz#sha256=90112b296152f270cb8dddcd19b7b87488d9e002e8cf622e14c4da9c2f6319b1 (from https://pypi.org/simple/pip/), version: 8.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/45/9c/6f9a24917c860873e2ce7bd95b8f79897524353df51d5d920cd6b6c1ec33/pip-8.0.1-py2.py3-none-any.whl#sha256=dedaac846bc74e38a3253671f51a056331ffca1da70e3f48d8128f2aa0635bba (from https://pypi.org/simple/pip/), version: 8.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/ea/66/a3d6187bd307159fedf8575c0d9ee2294d13b1cdd11673ca812e6a2dda8f/pip-8.0.1.tar.gz#sha256=477c50b3e538a7ac0fa611fb8b877b04b33fb70d325b12a81b9dbf3eb1158a4d (from https://pypi.org/simple/pip/), version: 8.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/e7/a0/bd35f5f978a5e925953ce02fa0f078a232f0f10fcbe543d8cfc043f74fda/pip-8.0.2-py2.py3-none-any.whl#sha256=249a6f3194be8c2e8cb4d4be3f6fd16a9f1e3336218caffa8e7419e3816f9988 (from https://pypi.org/simple/pip/), version: 8.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/ce/15/ee1f9a84365423e9ef03d0f9ed0eba2fb00ac1fffdd33e7b52aea914d0f8/pip-8.0.2.tar.gz#sha256=46f4bd0d8dfd51125a554568d646fe4200a3c2c6c36b9f2d06d2212148439521 (from https://pypi.org/simple/pip/), version: 8.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/ae/d4/2b127310f5364610b74c28e2e6a40bc19e2d3c9a9a4e012d3e333e767c99/pip-8.0.3-py2.py3-none-any.whl#sha256=b0335bc837f9edb5aad03bd43d0973b084a1cbe616f8188dc23ba13234dbd552 (from https://pypi.org/simple/pip/), version: 8.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/22/f3/14bc87a4f6b5ec70b682765978a6f3105bf05b6781fa97e04d30138bd264/pip-8.0.3.tar.gz#sha256=30f98b66f3fe1069c529a491597d34a1c224a68640c82caf2ade5f88aa1405e8 (from https://pypi.org/simple/pip/), version: 8.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/1e/c7/78440b3fb882ed001e6e12d8770bd45e73d6eced4e57f7c072b829ce8a3d/pip-8.1.0-py2.py3-none-any.whl#sha256=a542b99e08002ead83200198e19a3983270357e1cb4fe704247990b5b35471dc (from https://pypi.org/simple/pip/), version: 8.1.0\n",
      "  Found link https://files.pythonhosted.org/packages/3c/72/6981d5adf880adecb066a1a1a4c312a17f8d787a3b85446967964ac66d55/pip-8.1.0.tar.gz#sha256=d8faa75dd7d0737b16d50cd0a56dc91a631c79ecfd8d38b80f6ee929ec82043e (from https://pypi.org/simple/pip/), version: 8.1.0\n",
      "  Found link https://files.pythonhosted.org/packages/31/6a/0f19a7edef6c8e5065f4346137cc2a08e22e141942d66af2e1e72d851462/pip-8.1.1-py2.py3-none-any.whl#sha256=44b9c342782ab905c042c207d995aa069edc02621ddbdc2b9f25954a0fdac25c (from https://pypi.org/simple/pip/), version: 8.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/41/27/9a8d24e1b55bd8c85e4d022da2922cb206f183e2d18fee4e320c9547e751/pip-8.1.1.tar.gz#sha256=3e78d3066aaeb633d185a57afdccf700aa2e660436b4af618bcb6ff0fa511798 (from https://pypi.org/simple/pip/), version: 8.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/9c/32/004ce0852e0a127f07f358b715015763273799bd798956fa930814b60f39/pip-8.1.2-py2.py3-none-any.whl#sha256=6464dd9809fb34fc8df2bf49553bb11dac4c13d2ffa7a4f8038ad86a4ccb92a1 (from https://pypi.org/simple/pip/), version: 8.1.2\n",
      "  Found link https://files.pythonhosted.org/packages/e7/a8/7556133689add8d1a54c0b14aeff0acb03c64707ce100ecd53934da1aa13/pip-8.1.2.tar.gz#sha256=4d24b03ffa67638a3fa931c09fd9e0273ffa904e95ebebe7d4b1a54c93d7b732 (from https://pypi.org/simple/pip/), version: 8.1.2\n",
      "  Found link https://files.pythonhosted.org/packages/3f/ef/935d9296acc4f48d1791ee56a73781271dce9712b059b475d3f5fa78487b/pip-9.0.0-py2.py3-none-any.whl#sha256=c856ac18ca01e7127456f831926dc67cc7d3ab663f4c13b1ec156e36db4de574 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/5e/53/eaef47e5e2f75677c9de0737acc84b659b78a71c4086f424f55346a341b5/pip-9.0.0.tar.gz#sha256=f62fb70e7e000e46fce12aaeca752e5281a5446977fe5a75ab4189a43b3f8793 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/b6/ac/7015eb97dc749283ffdec1c3a88ddb8ae03b8fad0f0e611408f196358da3/pip-9.0.1-py2.py3-none-any.whl#sha256=690b762c0a8460c303c089d5d0be034fb15a5ea2b75bdf565f40421f542fefb0 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/11/b6/abcb525026a4be042b486df43905d6893fb04f05aac21c32c638e939e447/pip-9.0.1.tar.gz#sha256=09f243e1a7b461f654c26a725fa373211bb7ff17a9300058b205c61658ca940d (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/e7/f9/e801dcea22886cd513f6bd2e8f7e581bd6f67bb8e8f1cd8e7b92d8539280/pip-9.0.2-py2.py3-none-any.whl#sha256=b135491ddb061f39719b8472d8abb59c613816a2b86069c332db74d1cd208ab2 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/e5/8f/3fc66461992dc9e9fcf5e005687d5f676729172dda640df2fd8b597a6da7/pip-9.0.2.tar.gz#sha256=88110a224e9d30e5d76592a0b2130ef10e7e67a6426e8617bb918fffbfe91fe5 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/ac/95/a05b56bb975efa78d3557efa36acaf9cf5d2fd0ee0062060493687432e03/pip-9.0.3-py2.py3-none-any.whl#sha256=c3ede34530e0e0b2381e7363aded78e0c33291654937e7373032fda04e8803e5 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/c4/44/e6b8056b6c8f2bfd1445cc9990f478930d8e3459e9dbf5b8e2d2922d64d3/pip-9.0.3.tar.gz#sha256=7bf48f9a693be1d58f49f7af7e0ae9fe29fd671cde8a55e6edca3581c4ef5796 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/4b/5a/8544ae02a5bd28464e03af045e8aabde20a7b02db1911a9159328e1eb25a/pip-10.0.0b1-py2.py3-none-any.whl#sha256=dbd5d24cd461be23429625085a36cc8732cbcac4d2aaf673031f80f6ac07d844 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0b1\n",
      "  Found link https://files.pythonhosted.org/packages/aa/6d/ffbb86abf18b750fb26f27eda7c7732df2aacaa669c420d2eb2ad6df3458/pip-10.0.0b1.tar.gz#sha256=8d6e63d8b99752e4b53f272b66f9cd7b59e2b288e9a863a61c48d167203a2656 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0b1\n",
      "  Found link https://files.pythonhosted.org/packages/97/72/1d514201e7d7fc7fff5aac3de9c7b892cd72fb4bf23fd983630df96f7412/pip-10.0.0b2-py2.py3-none-any.whl#sha256=79f55588912f1b2b4f86f96f11e329bb01b25a484e2204f245128b927b1038a7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0b2\n",
      "  Found link https://files.pythonhosted.org/packages/32/67/572f642e6e42c580d3154964cfbab7d9322c23b0f417c6c01fdd206a2777/pip-10.0.0b2.tar.gz#sha256=ad6adec2150ce4aed8f6134d9b77d928fc848dbcb887fb1a455988cf99da5cae (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0b2\n",
      "  Found link https://files.pythonhosted.org/packages/62/a1/0d452b6901b0157a0134fd27ba89bf95a857fbda64ba52e1ca2cf61d8412/pip-10.0.0-py2.py3-none-any.whl#sha256=86a60a96d85e329962a9e6f6af612cbc11106293dbc83f119802b5bee9874cf3 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/e0/69/983a8e47d3dfb51e1463c1e962b2ccd1d74ec4e236e232625e353d830ed2/pip-10.0.0.tar.gz#sha256=f05a3eeea64bce94e85cc6671d679473d66288a4d37c3fcf983584954096b34f (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/0f/74/ecd13431bcc456ed390b44c8a6e917c1820365cbebcb6a8974d1cd045ab4/pip-10.0.1-py2.py3-none-any.whl#sha256=717cdffb2833be8409433a93746744b59505f42146e8d37de6c62b430e25d6d7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/ae/e8/2340d46ecadb1692a1e455f13f75e596d4eab3d11a57446f08259dee8f02/pip-10.0.1.tar.gz#sha256=f2bd08e0cd1b06e10218feaf6fef299f473ba706582eb3bd9d52203fdbd7ee68 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/5f/25/e52d3f31441505a5f3af41213346e5b6c221c9e086a166f3703d2ddaf940/pip-18.0-py2.py3-none-any.whl#sha256=070e4bf493c7c2c9f6a08dd797dd3c066d64074c38e9e8a0fb4e6541f266d96c (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 18.0\n",
      "  Found link https://files.pythonhosted.org/packages/69/81/52b68d0a4de760a2f1979b0931ba7889202f302072cc7a0d614211bc7579/pip-18.0.tar.gz#sha256=a0e11645ee37c90b40c46d607070c4fd583e2cd46231b1c06e389c5e814eed76 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 18.0\n",
      "  Found link https://files.pythonhosted.org/packages/c2/d7/90f34cb0d83a6c5631cf71dfe64cc1054598c843a92b400e55675cc2ac37/pip-18.1-py2.py3-none-any.whl#sha256=7909d0a0932e88ea53a7014dfd14522ffef91a464daaaf5c573343852ef98550 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 18.1\n",
      "  Found link https://files.pythonhosted.org/packages/45/ae/8a0ad77defb7cc903f09e551d88b443304a9bd6e6f124e75c0fbbf6de8f7/pip-18.1.tar.gz#sha256=c0a292bd977ef590379a3f05d7b7f65135487b67470f6281289a94e015650ea1 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 18.1\n",
      "  Found link https://files.pythonhosted.org/packages/60/64/73b729587b6b0d13e690a7c3acd2231ee561e8dd28a58ae1b0409a5a2b20/pip-19.0-py2.py3-none-any.whl#sha256=249ab0de4c1cef3dba4cf3f8cca722a07fc447b1692acd9f84e19c646db04c9a (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0\n",
      "  Found link https://files.pythonhosted.org/packages/11/31/c483614095176ddfa06ac99c2af4171375053b270842c7865ca0b4438dc1/pip-19.0.tar.gz#sha256=c82bf8bc00c5732f0dd49ac1dea79b6242a1bd42a5012e308ed4f04369b17e54 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0\n",
      "  Found link https://files.pythonhosted.org/packages/46/dc/7fd5df840efb3e56c8b4f768793a237ec4ee59891959d6a215d63f727023/pip-19.0.1-py2.py3-none-any.whl#sha256=aae79c7afe895fb986ec751564f24d97df1331bb99cdfec6f70dada2f40c0044 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/c8/89/ad7f27938e59db1f0f55ce214087460f65048626e2226531ba6cb6da15f0/pip-19.0.1.tar.gz#sha256=e81ddd35e361b630e94abeda4a1eddd36d47a90e71eb00f38f46b57f787cd1a5 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/d7/41/34dd96bd33958e52cb4da2f1bf0818e396514fd4f4725a79199564cd0c20/pip-19.0.2-py2.py3-none-any.whl#sha256=6a59f1083a63851aeef60c7d68b119b46af11d9d803ddc1cf927b58edcd0b312 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/4c/4d/88bc9413da11702cbbace3ccc51350ae099bb351febae8acc85fec34f9af/pip-19.0.2.tar.gz#sha256=f851133f8b58283fa50d8c78675eb88d4ff4cde29b6c41205cd938b06338e0e5 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/d8/f3/413bab4ff08e1fc4828dfc59996d721917df8e8583ea85385d51125dceff/pip-19.0.3-py2.py3-none-any.whl#sha256=bd812612bbd8ba84159d9ddc0266b7fbce712fc9bc98c82dee5750546ec8ec64 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/36/fa/51ca4d57392e2f69397cd6e5af23da2a8d37884a605f9e3f2d3bfdc48397/pip-19.0.3.tar.gz#sha256=6e6f197a1abfb45118dbb878b5c859a0edbdd33fd250100bc015b67fded4b9f2 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/f9/fb/863012b13912709c13cf5cfdbfb304fa6c727659d6290438e1a88df9d848/pip-19.1-py2.py3-none-any.whl#sha256=8f59b6cf84584d7962d79fd1be7a8ec0eb198aa52ea864896551736b3614eee9 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.1\n",
      "  Found link https://files.pythonhosted.org/packages/51/5f/802a04274843f634469ef299fcd273de4438386deb7b8681dd059f0ee3b7/pip-19.1.tar.gz#sha256=d9137cb543d8a4d73140a3282f6d777b2e786bb6abb8add3ac5b6539c82cd624 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.1\n",
      "  Found link https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl#sha256=993134f0475471b91452ca029d4390dc8f298ac63a712814f101cd1b6db46676 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/93/ab/f86b61bef7ab14909bd7ec3cd2178feb0a1c86d451bc9bccd5a1aedcde5f/pip-19.1.1.tar.gz#sha256=44d3d7d3d30a1eb65c7e5ff1173cdf8f7467850605ac7cc3707b6064bddd0958 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/3a/6f/35de4f49ae5c7fdb2b64097ab195020fb48faa8ad3a85386ece6953c11b1/pip-19.2-py2.py3-none-any.whl#sha256=468c67b0b1120cd0329dc72972cf0651310783a922e7609f3102bd5fb4acbf17 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2\n",
      "  Found link https://files.pythonhosted.org/packages/41/13/b6e68eae78405af6e4e9a93319ae5bb371057786f1590b157341f7542d7d/pip-19.2.tar.gz#sha256=aa6fdd80d13caac75d92b5eced06778712859b1606ba92d62389c11be12b2dad (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2\n",
      "  Found link https://files.pythonhosted.org/packages/62/ca/94d32a6516ed197a491d17d46595ce58a83cbb2fca280414e57cd86b84dc/pip-19.2.1-py2.py3-none-any.whl#sha256=80d7452630a67c1e7763b5f0a515690f2c1e9ad06dda48e0ae85b7fdf2f59d97 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.1\n",
      "  Found link https://files.pythonhosted.org/packages/8b/8a/1b2aadd922db1afe6bc107b03de41d6d37a28a5923383e60695fba24ae81/pip-19.2.1.tar.gz#sha256=258d702483dd749400aec59c23d638a5b2249ae28a0f478b6cab12ad45681a80 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.1\n",
      "  Found link https://files.pythonhosted.org/packages/8d/07/f7d7ced2f97ca3098c16565efbe6b15fafcba53e8d9bdb431e09140514b0/pip-19.2.2-py2.py3-none-any.whl#sha256=4b956bd8b7b481fc5fa222637ff6d0823a327e5118178f1ec47618a480e61997 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.2\n",
      "  Found link https://files.pythonhosted.org/packages/aa/1a/62fb0b95b1572c76dbc3cc31124a8b6866cbe9139eb7659ac7349457cf7c/pip-19.2.2.tar.gz#sha256=e05103825871e210d50a44c7e448587b0ed99dd775d3ef586304c58f40224a53 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.2\n",
      "  Found link https://files.pythonhosted.org/packages/30/db/9e38760b32e3e7f40cce46dd5fb107b8c73840df38f0046d8e6514e675a1/pip-19.2.3-py2.py3-none-any.whl#sha256=340a0ba40fdeb16413914c0fcd8e0b4ebb0bf39a900ec80e11c05d836c05103f (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.3\n",
      "  Found link https://files.pythonhosted.org/packages/00/9e/4c83a0950d8bdec0b4ca72afd2f9cea92d08eb7c1a768363f2ea458d08b4/pip-19.2.3.tar.gz#sha256=e7a31f147974362e6c82d84b91c7f2bdf57e4d3163d3d454e6c3e71944d67135 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.3\n",
      "  Found link https://files.pythonhosted.org/packages/4a/08/6ca123073af4ebc4c5488a5bc8a010ac57aa39ce4d3c8a931ad504de4185/pip-19.3-py2.py3-none-any.whl#sha256=e100a7eccf085f0720b4478d3bb838e1c179b1e128ec01c0403f84e86e0e2dfb (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.3\n",
      "  Found link https://files.pythonhosted.org/packages/af/7a/5dd1e6efc894613c432ce86f1011fcc3bbd8ac07dfeae6393b7b97f1de8b/pip-19.3.tar.gz#sha256=324d234b8f6124846b4e390df255cacbe09ce22791c3b714aa1ea6e44a4f2861 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.3\n",
      "  Found link https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl#sha256=6917c65fc3769ecdc61405d3dfd97afdedd75808d200b2838d7d961cebc0c2c7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.3.1\n",
      "  Found link https://files.pythonhosted.org/packages/ce/ea/9b445176a65ae4ba22dce1d93e4b5fe182f953df71a145f557cffaffc1bf/pip-19.3.1.tar.gz#sha256=21207d76c1031e517668898a6b46a9fb1501c7a4710ef5dfd6a40ad9e6757ea7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.3.1\n",
      "  Skipping link: yanked for reason: <none given>: https://files.pythonhosted.org/packages/60/65/16487a7c4e0f95bb3fc89c2e377be331fd496b7a9b08fd3077de7f3ae2cf/pip-20.0-py2.py3-none-any.whl#sha256=eea07b449d969dbc8c062c157852cf8ed2ad1b8b5ac965a6b819e62929e41703 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*)\n",
      "  Skipping link: yanked for reason: <none given>: https://files.pythonhosted.org/packages/8c/5c/c18d58ab5c1a702bf670e0bd6a77cd4645e4aeca021c6118ef850895cc96/pip-20.0.tar.gz#sha256=5128e9a9401f1d16c1d15b2ed766a79d7813db1538428d0b0ce74838249e3a41 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*)\n",
      "  Found link https://files.pythonhosted.org/packages/57/36/67f809c135c17ec9b8276466cc57f35b98c240f55c780689ea29fa32f512/pip-20.0.1-py2.py3-none-any.whl#sha256=b7110a319790ae17e8105ecd6fe07dbcc098a280c6d27b6dd7a20174927c24d7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/28/af/2c76c8aa46ccdf7578b83d97a11a2d1858794d4be4a1610ade0d30182e8b/pip-20.0.1.tar.gz#sha256=3cebbac2a1502e09265f94e5717408339de846b3c0f0ed086d7b817df9cab822 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl#sha256=4ae14a42d8adba3205ebeb38aa68cfc0b6c346e1ae2e699a0b3bad4da19cef5c (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/8e/76/66066b7bc71817238924c7e4b448abdb17eb0c92d645769c223f9ace478f/pip-20.0.2.tar.gz#sha256=7db0c8ea4c7ea51c8049640e8e6e7fde949de672bfa4949920675563a5a6967f (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/ec/05/82d3fababbf462d876883ebc36f030f4fa057a563a80f5a26ee63679d9ea/pip-20.1b1-py2.py3-none-any.whl#sha256=4cf0348b683937da883ccaae8c8bcfc9b4c7ba4c48b38cc2d89cd7b8d0b220d9 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1b1\n",
      "  Found link https://files.pythonhosted.org/packages/cd/81/c1184456fe506bd50992571c9f8581907976ce71502e36741f033e2da1f1/pip-20.1b1.tar.gz#sha256=699880a47f6d306f4f9a87ca151ef33d41d2223b81ff343b786d38c297923a19 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1b1\n",
      "  Found link https://files.pythonhosted.org/packages/54/2e/df11ea7e23e7e761d484ed3740285a34e38548cf2bad2bed3dd5768ec8b9/pip-20.1-py2.py3-none-any.whl#sha256=4fdc7fd2db7636777d28d2e1432e2876e30c2b790d461f135716577f73104369 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1\n",
      "  Found link https://files.pythonhosted.org/packages/d1/05/059c78cd5d740d2299266ffa15514dad6692d4694df571bf168e2cdd98fb/pip-20.1.tar.gz#sha256=572c0f25eca7c87217b21f6945b7192744103b18f4e4b16b8a83b227a811e192 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1\n",
      "  Found link https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl#sha256=b27c4dedae8c41aa59108f2fa38bf78e0890e590545bc8ece7cdceb4ba60f6e4 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/08/25/f204a6138dade2f6757b4ae99bc3994aac28a5602c97ddb2a35e0e22fbc4/pip-20.1.1.tar.gz#sha256=27f8dc29387dd83249e06e681ce087e6061826582198a425085e0bf4c1cf3a55 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/fe/3b/0fc5e63eb277d5a50a95ce5c896f742ef243be27382303a4a44dd0197e29/pip-20.2b1-py2.py3-none-any.whl#sha256=b4e230e2b8ece18c5a19b818f3c20a8d4eeac8172962779fd9898d7c4ceb1636 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.2b1\n",
      "  Found link https://files.pythonhosted.org/packages/77/3e/6a1fd8e08a06e3e0f54182c7c937bba3f4e9cf1b26f54946d3915021ea2e/pip-20.2b1.tar.gz#sha256=dbf65ecb1c30d35d72f5fda052fcd2f1ea9aca8eaf03d930846d990f51d3f6f6 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.2b1\n",
      "Given no hashes to check 139 links for project 'pip': discarding no candidates\n"
     ]
    }
   ],
   "source": [
    "!sh setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-user install because site-packages writeable\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-udpsq2ng\n",
      "Created temporary directory: /tmp/pip-req-tracker-7ul6fie4\n",
      "Initialized build tracking at /tmp/pip-req-tracker-7ul6fie4\n",
      "Created build tracker: /tmp/pip-req-tracker-7ul6fie4\n",
      "Entered build tracker: /tmp/pip-req-tracker-7ul6fie4\n",
      "Created temporary directory: /tmp/pip-install-r9ff3z72\n",
      "Processing ./apex\n",
      "  Created temporary directory: /tmp/pip-req-build-_z4pjgjj\n",
      "  Added file:///root/apex to build tracker '/tmp/pip-req-tracker-7ul6fie4'\n",
      "    Running setup.py (path:/tmp/pip-req-build-_z4pjgjj/setup.py) egg_info for package from file:///root/apex\n",
      "    Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.5.0+cu101\n",
      "\n",
      "\n",
      "    running egg_info\n",
      "    creating /tmp/pip-req-build-_z4pjgjj/pip-egg-info/apex.egg-info\n",
      "    writing /tmp/pip-req-build-_z4pjgjj/pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-req-build-_z4pjgjj/pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-req-build-_z4pjgjj/pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-req-build-_z4pjgjj/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    reading manifest file '/tmp/pip-req-build-_z4pjgjj/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file '/tmp/pip-req-build-_z4pjgjj/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    /tmp/pip-req-build-_z4pjgjj/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  Source in /tmp/pip-req-build-_z4pjgjj has version 0.1, which satisfies requirement apex==0.1 from file:///root/apex\n",
      "  Removed apex==0.1 from file:///root/apex from build tracker '/tmp/pip-req-tracker-7ul6fie4'\n",
      "Building wheels for collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-wheel-ahcbqj_2\n",
      "  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-ahcbqj_2\n",
      "  Running command /opt/conda/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-_z4pjgjj/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-_z4pjgjj/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-ahcbqj_2\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.5.0+cu101\n",
      "\n",
      "\n",
      "  /tmp/pip-req-build-_z4pjgjj/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build/lib\n",
      "  creating build/lib/apex\n",
      "  copying apex/__init__.py -> build/lib/apex\n",
      "  creating build/lib/apex/normalization\n",
      "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
      "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
      "  creating build/lib/apex/contrib\n",
      "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
      "  creating build/lib/apex/amp\n",
      "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
      "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
      "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
      "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
      "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
      "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
      "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
      "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
      "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
      "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
      "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
      "  creating build/lib/apex/parallel\n",
      "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
      "  creating build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
      "  creating build/lib/apex/optimizers\n",
      "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
      "  creating build/lib/apex/pyprof\n",
      "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
      "  creating build/lib/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
      "  creating build/lib/apex/mlp\n",
      "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
      "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
      "  creating build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
      "  creating build/lib/apex/RNN\n",
      "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
      "  creating build/lib/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
      "  creating build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "  creating build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  creating build/lib/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
      "  creating build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
      "  creating build/lib/apex/pyprof/nvtx\n",
      "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
      "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
      "  creating build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
      "  creating build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
      "  installing to build/bdist.linux-x86_64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build/bdist.linux-x86_64\n",
      "  creating build/bdist.linux-x86_64/wheel\n",
      "  creating build/bdist.linux-x86_64/wheel/apex\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\r\n",
      "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\r\n",
      "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\r\n",
      "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\r\n",
      "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\r\n",
      "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/normalization\r\n",
      "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\r\n",
      "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\r\n",
      "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\r\n",
      "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\r\n",
      "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\r\n",
      "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\r\n",
      "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/mlp\r\n",
      "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\r\n",
      "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/parallel\r\n",
      "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\r\n",
      "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\r\n",
      "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\r\n",
      "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\r\n",
      "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\r\n",
      "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\r\n",
      "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\r\n",
      "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\r\n",
      "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\r\n",
      "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\r\n",
      "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\r\n",
      "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\r\n",
      "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\r\n",
      "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\r\n",
      "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\r\n",
      "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/RNN\r\n",
      "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\r\n",
      "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\r\n",
      "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\r\n",
      "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\r\n",
      "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\r\n",
      "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\r\n",
      "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\r\n",
      "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\r\n",
      "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\r\n",
      "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\r\n",
      "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\r\n",
      "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\r\n",
      "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\r\n",
      "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\r\n",
      "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\r\n",
      "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\r\n",
      "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\r\n",
      "  running install_egg_info\r\n",
      "  running egg_info\r\n",
      "  writing apex.egg-info/PKG-INFO\r\n",
      "  writing dependency_links to apex.egg-info/dependency_links.txt\r\n",
      "  writing top-level names to apex.egg-info/top_level.txt\r\n",
      "  reading manifest file 'apex.egg-info/SOURCES.txt'\r\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\r\n",
      "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\r\n",
      "  running install_scripts\r\n",
      "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\r\n",
      "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\r\n",
      "  creating '/tmp/pip-wheel-ahcbqj_2/apex-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\r\n",
      "  adding 'apex/__init__.py'\r\n",
      "  adding 'apex/RNN/RNNBackend.py'\r\n",
      "  adding 'apex/RNN/__init__.py'\r\n",
      "  adding 'apex/RNN/cells.py'\r\n",
      "  adding 'apex/RNN/models.py'\n",
      "  adding 'apex/amp/__init__.py'\n",
      "  adding 'apex/amp/__version__.py'\n",
      "  adding 'apex/amp/_amp_state.py'\n",
      "  adding 'apex/amp/_initialize.py'\n",
      "  adding 'apex/amp/_process_optimizer.py'\n",
      "  adding 'apex/amp/amp.py'\n",
      "  adding 'apex/amp/compat.py'\n",
      "  adding 'apex/amp/frontend.py'\n",
      "  adding 'apex/amp/handle.py'\n",
      "  adding 'apex/amp/opt.py'\n",
      "  adding 'apex/amp/rnn_compat.py'\n",
      "  adding 'apex/amp/scaler.py'\n",
      "  adding 'apex/amp/utils.py'\n",
      "  adding 'apex/amp/wrap.py'\n",
      "  adding 'apex/amp/lists/__init__.py'\n",
      "  adding 'apex/amp/lists/functional_overrides.py'\n",
      "  adding 'apex/amp/lists/tensor_overrides.py'\n",
      "  adding 'apex/amp/lists/torch_overrides.py'\n",
      "  adding 'apex/contrib/__init__.py'\n",
      "  adding 'apex/contrib/groupbn/__init__.py'\n",
      "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
      "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
      "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
      "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
      "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/optimizers/__init__.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
      "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
      "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
      "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
      "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
      "  adding 'apex/contrib/xentropy/__init__.py'\n",
      "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
      "  adding 'apex/fp16_utils/__init__.py'\n",
      "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
      "  adding 'apex/fp16_utils/fp16util.py'\n",
      "  adding 'apex/fp16_utils/loss_scaler.py'\n",
      "  adding 'apex/mlp/__init__.py'\n",
      "  adding 'apex/mlp/mlp.py'\n",
      "  adding 'apex/multi_tensor_apply/__init__.py'\n",
      "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
      "  adding 'apex/normalization/__init__.py'\n",
      "  adding 'apex/normalization/fused_layer_norm.py'\n",
      "  adding 'apex/optimizers/__init__.py'\n",
      "  adding 'apex/optimizers/fused_adagrad.py'\n",
      "  adding 'apex/optimizers/fused_adam.py'\n",
      "  adding 'apex/optimizers/fused_lamb.py'\n",
      "  adding 'apex/optimizers/fused_novograd.py'\n",
      "  adding 'apex/optimizers/fused_sgd.py'\n",
      "  adding 'apex/parallel/LARC.py'\n",
      "  adding 'apex/parallel/__init__.py'\n",
      "  adding 'apex/parallel/distributed.py'\n",
      "  adding 'apex/parallel/multiproc.py'\n",
      "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
      "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
      "  adding 'apex/parallel/sync_batchnorm.py'\n",
      "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
      "  adding 'apex/pyprof/__init__.py'\n",
      "  adding 'apex/pyprof/nvtx/__init__.py'\n",
      "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
      "  adding 'apex/pyprof/parse/__init__.py'\n",
      "  adding 'apex/pyprof/parse/__main__.py'\n",
      "  adding 'apex/pyprof/parse/db.py'\n",
      "  adding 'apex/pyprof/parse/kernel.py'\n",
      "  adding 'apex/pyprof/parse/nvvp.py'\n",
      "  adding 'apex/pyprof/parse/parse.py'\n",
      "  adding 'apex/pyprof/prof/__init__.py'\n",
      "  adding 'apex/pyprof/prof/__main__.py'\n",
      "  adding 'apex/pyprof/prof/activation.py'\n",
      "  adding 'apex/pyprof/prof/base.py'\n",
      "  adding 'apex/pyprof/prof/blas.py'\n",
      "  adding 'apex/pyprof/prof/conv.py'\n",
      "  adding 'apex/pyprof/prof/convert.py'\n",
      "  adding 'apex/pyprof/prof/data.py'\n",
      "  adding 'apex/pyprof/prof/dropout.py'\n",
      "  adding 'apex/pyprof/prof/embedding.py'\n",
      "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
      "  adding 'apex/pyprof/prof/linear.py'\n",
      "  adding 'apex/pyprof/prof/loss.py'\n",
      "  adding 'apex/pyprof/prof/misc.py'\n",
      "  adding 'apex/pyprof/prof/normalization.py'\n",
      "  adding 'apex/pyprof/prof/optim.py'\n",
      "  adding 'apex/pyprof/prof/output.py'\n",
      "  adding 'apex/pyprof/prof/pointwise.py'\n",
      "  adding 'apex/pyprof/prof/pooling.py'\n",
      "  adding 'apex/pyprof/prof/prof.py'\n",
      "  adding 'apex/pyprof/prof/randomSample.py'\n",
      "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
      "  adding 'apex/pyprof/prof/reduction.py'\n",
      "  adding 'apex/pyprof/prof/softmax.py'\n",
      "  adding 'apex/pyprof/prof/usage.py'\n",
      "  adding 'apex/pyprof/prof/utility.py'\n",
      "  adding 'apex/reparameterization/__init__.py'\n",
      "  adding 'apex/reparameterization/reparameterization.py'\n",
      "  adding 'apex/reparameterization/weight_norm.py'\n",
      "  adding 'apex-0.1.dist-info/LICENSE'\n",
      "  adding 'apex-0.1.dist-info/METADATA'\n",
      "  adding 'apex-0.1.dist-info/WHEEL'\n",
      "  adding 'apex-0.1.dist-info/top_level.txt'\n",
      "  adding 'apex-0.1.dist-info/RECORD'\n",
      "  removing build/bdist.linux-x86_64/wheel\n",
      "\u001b[?25hdone\n",
      "  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=186403 sha256=80bffd4ab88dace4af6d1e63e3ef9aab311664125c60da49e92d983453c9c888\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-udpsq2ng/wheels/30/08/96/8745133aab26c6271171698ab29983a3118aee7347d3a6f538\n",
      "Successfully built apex\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-unpacked-wheel-cqvif8yn\n",
      "\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "  Removing source in /tmp/pip-req-build-_z4pjgjj\n",
      "Removed build tracker: '/tmp/pip-req-tracker-7ul6fie4'\n",
      "1 location(s) to search for versions of pip:\n",
      "* https://pypi.org/simple/pip/\n",
      "Fetching project page and analyzing links: https://pypi.org/simple/pip/\n",
      "Getting page https://pypi.org/simple/pip/\n",
      "Found index url https://pypi.org/simple\n",
      "Starting new HTTPS connection (1): pypi.org:443\n",
      "https://pypi.org:443 \"GET /simple/pip/ HTTP/1.1\" 200 13603\n",
      "  Found link https://files.pythonhosted.org/packages/3d/9d/1e313763bdfb6a48977b65829c6ce2a43eaae29ea2f907c8bbef024a7219/pip-0.2.tar.gz#sha256=88bb8d029e1bf4acd0e04d300104b7440086f94cc1ce1c5c3c31e3293aee1f81 (from https://pypi.org/simple/pip/), version: 0.2\n",
      "  Found link https://files.pythonhosted.org/packages/18/ad/c0fe6cdfe1643a19ef027c7168572dac6283b80a384ddf21b75b921877da/pip-0.2.1.tar.gz#sha256=83522005c1266cc2de97e65072ff7554ac0f30ad369c3b02ff3a764b962048da (from https://pypi.org/simple/pip/), version: 0.2.1\n",
      "  Found link https://files.pythonhosted.org/packages/17/05/f66144ef69b436d07f8eeeb28b7f77137f80de4bf60349ec6f0f9509e801/pip-0.3.tar.gz#sha256=183c72455cb7f8860ac1376f8c4f14d7f545aeab8ee7c22cd4caf79f35a2ed47 (from https://pypi.org/simple/pip/), version: 0.3\n",
      "  Found link https://files.pythonhosted.org/packages/0a/bb/d087c9a1415f8726e683791c0b2943c53f2b76e69f527f2e2b2e9f9e7b5c/pip-0.3.1.tar.gz#sha256=34ce534f17065c78f980702928e988a6b6b2d8a9851aae5f1571a1feb9bb58d8 (from https://pypi.org/simple/pip/), version: 0.3.1\n",
      "  Found link https://files.pythonhosted.org/packages/cf/c3/153571aaac6cf999f4bb09c019b1ff379b7b599ea833813a41c784eec995/pip-0.4.tar.gz#sha256=28fc67558874f71fddda7168f73595f1650523dce3bc5bf189713ecdfc1e456e (from https://pypi.org/simple/pip/), version: 0.4\n",
      "  Found link https://files.pythonhosted.org/packages/8d/c7/f05c87812fa5d9562ecbc5f4f1fc1570444f53c81c834a7f662af406e3c1/pip-0.5.tar.gz#sha256=328d8412782f22568508a0d0c78a49c9920a82e44c8dfca49954fe525c152b2a (from https://pypi.org/simple/pip/), version: 0.5\n",
      "  Found link https://files.pythonhosted.org/packages/9a/aa/f536b6d14fe03343367da2ff44eee28f340ae650cd017ca088b6be13084a/pip-0.5.1.tar.gz#sha256=e27650538c41fe1007a41abd4cfd0f905b822622cbe1f8e7e09d1215af207694 (from https://pypi.org/simple/pip/), version: 0.5.1\n",
      "  Found link https://files.pythonhosted.org/packages/db/e6/fdf7be8a17b032c533d3f91e91e2c63dd81d3627cbe4113248a00c2d39d8/pip-0.6.tar.gz#sha256=4cf47db6815b2f435d1f44e1f35ff04823043f6161f7df9aec71a123b0c47f0d (from https://pypi.org/simple/pip/), version: 0.6\n",
      "  Found link https://files.pythonhosted.org/packages/91/cd/105f4d3c75d0ae18e12623acc96f42168aaba408dd6e43c4505aa21f8e37/pip-0.6.1.tar.gz#sha256=efe47e84ffeb0ea4804f9858b8a94bebd07f5452f907ebed36d03aed06a9f9ec (from https://pypi.org/simple/pip/), version: 0.6.1\n",
      "  Found link https://files.pythonhosted.org/packages/1c/c7/c0e1a9413c37828faf290f29a85a4d6034c145cc04bf1622ba8beb662ad8/pip-0.6.2.tar.gz#sha256=1c1a504d7e70d2c24246f95bd16e3d5fcec740fd144df69a407bf65a2ee67586 (from https://pypi.org/simple/pip/), version: 0.6.2\n",
      "  Found link https://files.pythonhosted.org/packages/3f/af/c4b9d49fb0f286996b28dbc0955c3ad359794697eb98e0e69863908070b0/pip-0.6.3.tar.gz#sha256=1a6df71eb29b98cba11bde6d6a0d8c6dd8b0518e74ceb71fb31ea4fbb42fd313 (from https://pypi.org/simple/pip/), version: 0.6.3\n",
      "  Found link https://files.pythonhosted.org/packages/ec/7a/6fe91ff0079ad0437830957c459d52f3923e516f5b453218f2a93d09a427/pip-0.7.tar.gz#sha256=ceaea0b9e494d893c8a191895301b79c1db33e41f14d3ad93e3d28a8b4e9bf27 (from https://pypi.org/simple/pip/), version: 0.7\n",
      "  Found link https://files.pythonhosted.org/packages/a5/63/11303863c2f5e9d9a15d89fcf7513a4b60987007d418862e0fb65c09fff7/pip-0.7.1.tar.gz#sha256=f54f05aa17edd0036de433c44892c8fedb1fd2871c97829838feb995818d24c3 (from https://pypi.org/simple/pip/), version: 0.7.1\n",
      "  Found link https://files.pythonhosted.org/packages/cd/a9/1debaa96bbc1005c1c8ad3b79fec58c198d35121546ea2e858ce0894268a/pip-0.7.2.tar.gz#sha256=98df2eb779358412bbbae75980171ae85deebc846d87e244d086520b1212da09 (from https://pypi.org/simple/pip/), version: 0.7.2\n",
      "  Found link https://files.pythonhosted.org/packages/74/54/f785c327fb3d163560a879b36edae5c78ee07806be282c9d4807f6be7dd1/pip-0.8.tar.gz#sha256=9017e4484a212dd4e1a43dd9f039dd7fc8338d4eea1c339d5ae1c80726de5b0f (from https://pypi.org/simple/pip/), version: 0.8\n",
      "  Found link https://files.pythonhosted.org/packages/5c/79/5e8381cc3078bae92166f2ba96de8355e8c181926505ba8882f7b099a500/pip-0.8.1.tar.gz#sha256=7176a87f35675f6468341212f3b959bb51d23ea66eb1c3692bf746c45c716fa2 (from https://pypi.org/simple/pip/), version: 0.8.1\n",
      "  Found link https://files.pythonhosted.org/packages/17/3e/0a98ab032991518741e7e712a719633e6ae160f51b3d3e855194530fd308/pip-0.8.2.tar.gz#sha256=f80a3549c048bc3bbcb47844826e9c7c6fcd87e77b92bef0d9e66d1b397c4962 (from https://pypi.org/simple/pip/), version: 0.8.2\n",
      "  Found link https://files.pythonhosted.org/packages/f7/9a/943fc6d879ed7220bac2e7e53096bfe78abec88d77f2f516400e0129679e/pip-0.8.3.tar.gz#sha256=1be2e18edd38aa75b5e4ef38a99ec33ba9247177cfcb4a6d2d2b3e73430e3001 (from https://pypi.org/simple/pip/), version: 0.8.3\n",
      "  Found link https://files.pythonhosted.org/packages/24/33/6eb675fb6db7b71d69d6928b33dea61b8bf5cfe1e5649be70ec84ce2fc09/pip-1.0.tar.gz#sha256=34ba07e2d14ba86d5088ba896ac80bed845a9b276ab8acb279b8d99bc77fec8e (from https://pypi.org/simple/pip/), version: 1.0\n",
      "  Found link https://files.pythonhosted.org/packages/10/d9/f584e6107ef98ad7eaaaa5d0f756bfee12561fa6a4712ffdb7209e0e1fd4/pip-1.0.1.tar.gz#sha256=37d2f18213d3845d2038dd3686bc71fc12bb41ad66c945a8b0dfec2879f3497b (from https://pypi.org/simple/pip/), version: 1.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/16/90/5e6f80364d8a656f60681dfb7330298edef292d43e1499bcb3a4c71ff0b9/pip-1.0.2.tar.gz#sha256=a6ed9b36aac2f121c01a2c9e0307a9e4d9438d100a407db701ac65479a3335d2 (from https://pypi.org/simple/pip/), version: 1.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/25/57/0d42cf5307d79913a082c5c4397d46f3793bc35e1138a694136d6e31be99/pip-1.1.tar.gz#sha256=993804bb947d18508acee02141281c77d27677f8c14eaa64d6287a1c53ef01c8 (from https://pypi.org/simple/pip/), version: 1.1\n",
      "  Found link https://files.pythonhosted.org/packages/ba/c3/4e1f892f41aaa217fe0d1f827fa05928783349c69f3cc06fdd68e112678a/pip-1.2.tar.gz#sha256=2b168f1987403f1dc6996a1f22a6f6637b751b7ab6ff27e78380b8d6e70aa314 (from https://pypi.org/simple/pip/), version: 1.2\n",
      "  Found link https://files.pythonhosted.org/packages/c3/a2/a63244da32afd9ce9a8ca1bd86e71610039adea8b8314046ebe5047527a6/pip-1.2.1.tar.gz#sha256=12a9302acfca62cdc7bc5d83386cac3e0581db61ac39acdb3a4e766a16b88eb1 (from https://pypi.org/simple/pip/), version: 1.2.1\n",
      "  Found link https://files.pythonhosted.org/packages/00/45/69d4f2602b80550bfb26cfd2f62c2f05b3b5c7352705d3766cd1e5b27648/pip-1.3.tar.gz#sha256=d6a13c5be316cb21a0243047c7f163f47e88973ebccff8d32e63ca1bf4d9321c (from https://pypi.org/simple/pip/), version: 1.3\n",
      "  Found link https://files.pythonhosted.org/packages/5b/ce/f5b98104f1c10d868936c25f7c597f492d4371aa9ad5fb61a94954ee7208/pip-1.3.1.tar.gz#sha256=145eaa5d1ea1b062663da1f3a97780d7edea4c63c68a37c463b1deedf7bb4957 (from https://pypi.org/simple/pip/), version: 1.3.1\n",
      "  Found link https://files.pythonhosted.org/packages/5f/d0/3b3958f6a58783bae44158b2c4c7827ae89abaecdd4bed12cff402620b9a/pip-1.4.tar.gz#sha256=1fd43cbf07d95ddcecbb795c97a1674b3ddb711bb4a67661284a5aa765aa1b97 (from https://pypi.org/simple/pip/), version: 1.4\n",
      "  Found link https://files.pythonhosted.org/packages/3f/f8/da390e0df72fb61d176b25a4b95262e3dcc14bda0ad25ac64d56db38b667/pip-1.4.1.tar.gz#sha256=4e7a06554711a624c35d0c646f63674b7f6bfc7f80221bf1eb1f631bd890d04e (from https://pypi.org/simple/pip/), version: 1.4.1\n",
      "  Found link https://files.pythonhosted.org/packages/4f/7d/e53bc80667378125a9e07d4929a61b0bd7128a1129dbe6f07bb3228652a3/pip-1.5.tar.gz#sha256=25f81d1a0e55d3b1709818dd57fdfb954b028f229f09bd69cb0bc80a8e03e048 (from https://pypi.org/simple/pip/), version: 1.5\n",
      "  Found link https://files.pythonhosted.org/packages/44/5d/1dca53b5de6d287e7eb99bd174bb022eb6cb0d6ca6e19ca6b16655dde8c2/pip-1.5.1-py2.py3-none-any.whl#sha256=00960db3b0b8724dd37fe37cfb9c72ecb8f59fab9db7d17c5c1e89a1adab49ce (from https://pypi.org/simple/pip/), version: 1.5.1\n",
      "  Found link https://files.pythonhosted.org/packages/21/3f/d86a600c9b2f41a75caacf768a24130f343def97652de2345da15ef7911f/pip-1.5.1.tar.gz#sha256=e60e936fbc101d56668c6134c1f2b5b40fcbec8b4fc4ca7fc34842b6b4c5c130 (from https://pypi.org/simple/pip/), version: 1.5.1\n",
      "  Found link https://files.pythonhosted.org/packages/3d/1f/227d77d5e9ed2df5162de4ba3616799a351eccb1ecd668ae824dd26153a1/pip-1.5.2-py2.py3-none-any.whl#sha256=6903909ccdcdbc3297b74118590e71344d6d262827acd1f5c0e2fcfce9807499 (from https://pypi.org/simple/pip/), version: 1.5.2\n",
      "  Found link https://files.pythonhosted.org/packages/ed/94/391a003107f6ec997c314199d03bff1c105af758ee490e3255353574487b/pip-1.5.2.tar.gz#sha256=2a8a3e08e652d3a40edbb39264bf01f8ff3c32520a79113357cca1f30533f738 (from https://pypi.org/simple/pip/), version: 1.5.2\n",
      "  Found link https://files.pythonhosted.org/packages/df/e9/bdb53d44fad1465b43edaf6bc7dd3027ed5af81405cc97603fdff0721ebb/pip-1.5.3-py2.py3-none-any.whl#sha256=f0037aed3ce6cf96b9e9117d42e967a74bea9ebe19088a2fdea5de93d5762fee (from https://pypi.org/simple/pip/), version: 1.5.3\n",
      "  Found link https://files.pythonhosted.org/packages/55/de/671a48ad313c808623041fc475f7c8f7610401d9f573f06b40eeb84e74e3/pip-1.5.3.tar.gz#sha256=dc53b4d28b88556a37cd73052b6d1d08cc644c6724e37c4d38a2e3c03c5440b2 (from https://pypi.org/simple/pip/), version: 1.5.3\n",
      "  Found link https://files.pythonhosted.org/packages/a9/9a/9aa19fe00de4c025562e5fb3796ff8520165a7dd1a5662c6ec9816e1ae99/pip-1.5.4-py2.py3-none-any.whl#sha256=fb7282556a42e84464f2e963a859ac4012d8134ba6218b70c1d82d145fcfa82f (from https://pypi.org/simple/pip/), version: 1.5.4\n",
      "  Found link https://files.pythonhosted.org/packages/78/d8/6e58a7130d457edadb753a0ea5708e411c100c7e94e72ad4802feeef735c/pip-1.5.4.tar.gz#sha256=70208a250bb4afdbbdd74c3ac35d4ab9ba1eb6852d02567a6a87f2f5104e30b9 (from https://pypi.org/simple/pip/), version: 1.5.4\n",
      "  Found link https://files.pythonhosted.org/packages/ce/c2/10d996b9c51b126a9f0bb9e14a9edcdd5c88888323c0685bb9b392b6c47c/pip-1.5.5-py2.py3-none-any.whl#sha256=fe7a5808190067b2598d85def9b83db46e5d64a00848ad843e107c36e1db4ae6 (from https://pypi.org/simple/pip/), version: 1.5.5\n",
      "  Found link https://files.pythonhosted.org/packages/88/01/a442fde40bd9aaf837612536f16ab751fac628807fd718690795b8ade77d/pip-1.5.5.tar.gz#sha256=4b7f5124364ae9b5ba833dcd8813a84c1c06fba1d7c8543323c7af4b33188eca (from https://pypi.org/simple/pip/), version: 1.5.5\n",
      "  Found link https://files.pythonhosted.org/packages/3f/08/7347ca4021e7fe0f1ab8f93cbc7d2a7a7350012300ad0e0227d55625e2b8/pip-1.5.6-py2.py3-none-any.whl#sha256=fbc1351ffedf09ca7560428758845a88d648b9730b63ce9e5df53a7c89f039a4 (from https://pypi.org/simple/pip/), version: 1.5.6\n",
      "  Found link https://files.pythonhosted.org/packages/45/db/4fb9a456b4ec4d3b701456ef562b9d72d76b6358e0c1463d17db18c5b772/pip-1.5.6.tar.gz#sha256=b1a4ae66baf21b7eb05a5e4f37c50c2706fa28ea1f8780ce8efe14dcd9f1726c (from https://pypi.org/simple/pip/), version: 1.5.6\n",
      "  Found link https://files.pythonhosted.org/packages/dc/7c/21191b5944b917b66e4e4e06d74f668d814b6e8a3ff7acd874479b6f6b3d/pip-6.0-py2.py3-none-any.whl#sha256=5ec6732505bd8be49fe1f8ad557b88253ffb085736396df4d6bea753fc2a8f2c (from https://pypi.org/simple/pip/), version: 6.0\n",
      "  Found link https://files.pythonhosted.org/packages/38/fd/065c66a88398f240e344fdf496b9707f92d75f88eedc3d10ff847b28a657/pip-6.0.tar.gz#sha256=6103897f1bb68d3f933edd60f3e3830c4ea6b8abf7a4b500db148921b11f6c9b (from https://pypi.org/simple/pip/), version: 6.0\n",
      "  Found link https://files.pythonhosted.org/packages/e9/7a/cdbc1a12ed52410d557e48d4646f4543e9e991ff32d2374dc6db849aa617/pip-6.0.1-py2.py3-none-any.whl#sha256=322aea7d1f7b9ee68ad87ac4704cad5df97f77e70668c0bd18f964c5daa78173 (from https://pypi.org/simple/pip/), version: 6.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/4d/c3/8675b90cd89b9b222062f4f6c7e9d48b0387f5b35cbf747a74403a883e56/pip-6.0.1.tar.gz#sha256=fa2f7c68da4a405d673aa38542f9df009d60026db4f532429ac9cbfbda1f959d (from https://pypi.org/simple/pip/), version: 6.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/71/3c/b5a521e5e99cfff091e282231591f21193fd80de079ec5fb8ed9c6614044/pip-6.0.2-py2.py3-none-any.whl#sha256=7d17b0f267f7c9cd17cd2924bbbe2b4a3d407322c0e09084ca3f1295c1fed50d (from https://pypi.org/simple/pip/), version: 6.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/4c/5a/f9e8e3de0153282c7cb54a9b991af225536ac914bac858ca664cf883bb3e/pip-6.0.2.tar.gz#sha256=6fa90667706a679e3dc75b27a51fddafa64401c45e96f8ae6c20978183290077 (from https://pypi.org/simple/pip/), version: 6.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/73/cb/3eebf42003791df29219a3dfa1874572aa16114b44c9b1b0ac66bf96e8c0/pip-6.0.3-py2.py3-none-any.whl#sha256=b72655b6ac6aef1c86dd07f51e8ace8d7aabd6a1c4ff88db87155276fa32a073 (from https://pypi.org/simple/pip/), version: 6.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/ce/63/8d99ae60d11ae1a65f5d4fc39a529a598bd3b8e067132210cb0c4d9e9f74/pip-6.0.3.tar.gz#sha256=b091a35f5fa0faffac0b27b97e1e1e93ffe63b463c2ea8dbde0c1fb987933614 (from https://pypi.org/simple/pip/), version: 6.0.3\n",
      "  Found link https://files.pythonhosted.org/packages/c5/0e/c974206726542bc495fc7443dd97834a6d14c2f0cba183fcfcd01075225a/pip-6.0.4-py2.py3-none-any.whl#sha256=8dfd95de29a7a3bb1e7d368cc83d566938eb210b04d553ebfe5e3a422f4aec65 (from https://pypi.org/simple/pip/), version: 6.0.4\n",
      "  Found link https://files.pythonhosted.org/packages/02/a1/c90f19910ee153d7a0efca7216758121118d7e93084276541383fe9ca82e/pip-6.0.4.tar.gz#sha256=1dbbff9c369e510c7468ab68ba52c003f68f83c99c2f8259acd51099e8799f1e (from https://pypi.org/simple/pip/), version: 6.0.4\n",
      "  Found link https://files.pythonhosted.org/packages/e9/1b/c6a375a337fb576784cdea3700f6c3eaf1420f0a01458e6e034cc178a84a/pip-6.0.5-py2.py3-none-any.whl#sha256=b2c20e3a2a43b2bbb1d19ad98be27eccc7b0f0ece016da602ccaa757a862b0e2 (from https://pypi.org/simple/pip/), version: 6.0.5\n",
      "  Found link https://files.pythonhosted.org/packages/19/f2/58628768f618c8c9fea878e0fb97730c0b8a838d3ab3f325768bf12dac94/pip-6.0.5.tar.gz#sha256=3bf42d28be9085ab2e9aecfd69a6da2d31563fe833304bf71a620a30c38ab8a2 (from https://pypi.org/simple/pip/), version: 6.0.5\n",
      "  Found link https://files.pythonhosted.org/packages/64/fc/4a49ccb18f55a0ceeb76e8d554bd4563217117492997825d194ed0017cc1/pip-6.0.6-py2.py3-none-any.whl#sha256=fb04f8afe1ba57626783f0c8e2f3d46bbaebaa446fcf124f434e968a2fee595e (from https://pypi.org/simple/pip/), version: 6.0.6\n",
      "  Found link https://files.pythonhosted.org/packages/f6/ce/d9e4e178b66c766c117f62ddf4fece019ef9d50127a8926d2f60300d615e/pip-6.0.6.tar.gz#sha256=3a14091299dcdb9bab9e9004ae67ac401f2b1b14a7c98de074ca74fdddf4bfa0 (from https://pypi.org/simple/pip/), version: 6.0.6\n",
      "  Found link https://files.pythonhosted.org/packages/7a/8e/2bbd4fcf3ee06ee90ded5f39ec12f53165dfdb9ef25a981717ad38a16670/pip-6.0.7-py2.py3-none-any.whl#sha256=93a326304c7db749896bcef822bbbac1ab29dad5651c6d732e245975239890e6 (from https://pypi.org/simple/pip/), version: 6.0.7\n",
      "  Found link https://files.pythonhosted.org/packages/52/85/b160ebdaa84378df6bb0176d4eed9f57edca662446174eead7a9e2e566d6/pip-6.0.7.tar.gz#sha256=35a5a43ac6b7af83ed47ea5731a365f43d350a3a7267e039e5f06b61d42ab3c2 (from https://pypi.org/simple/pip/), version: 6.0.7\n",
      "  Found link https://files.pythonhosted.org/packages/63/65/55b71647adec1ad595bf0e5d76d028506dfc002df30c256f022ff7a660a5/pip-6.0.8-py2.py3-none-any.whl#sha256=3c22b0a8ff92727bd737a82f72700790591f177541df08c07bc1f90d6b72ac19 (from https://pypi.org/simple/pip/), version: 6.0.8\n",
      "  Found link https://files.pythonhosted.org/packages/ef/8a/e3a980bc0a7f791d72c1302f65763ed300f2e14c907ac033e01b44c79e5e/pip-6.0.8.tar.gz#sha256=0d58487a1b7f5be2e5e965c11afbea1dc44ecec8069de03491a4d0d6c85f4551 (from https://pypi.org/simple/pip/), version: 6.0.8\n",
      "  Found link https://files.pythonhosted.org/packages/24/fb/8a56a46243514681e569bbafd8146fa383476c4b7c725c8598c452366f31/pip-6.1.0-py2.py3-none-any.whl#sha256=435a018f6d29e34d4f901bf4e6860d8a5fa1816b68d62008c18ca062a306db31 (from https://pypi.org/simple/pip/), version: 6.1.0\n",
      "  Found link https://files.pythonhosted.org/packages/6c/84/432eb60bbcb414b9cdfcb135d5f4925e253c74e7d6916ada79990d6cc1a0/pip-6.1.0.tar.gz#sha256=89f120e2ab3d25ab70c36eb28ad4f280fc9ba71736e74d3055f609c1f9173768 (from https://pypi.org/simple/pip/), version: 6.1.0\n",
      "  Found link https://files.pythonhosted.org/packages/67/f0/ba0fb41dbdbfc4aa3e0c16b40269aca6b9e3d59cacdb646218aa2e9b1d2c/pip-6.1.1-py2.py3-none-any.whl#sha256=a67e54aa0f26b6d62ccec5cc6735eff205dd0fed075f56ac3d3111e91e4467fc (from https://pypi.org/simple/pip/), version: 6.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/bf/85/871c126b50b8ee0b9819e8a63b614aedd264577e73478caedcd447e8f28c/pip-6.1.1.tar.gz#sha256=89f3b626d225e08e7f20d85044afa40f612eb3284484169813dc2d0631f2a556 (from https://pypi.org/simple/pip/), version: 6.1.1\n",
      "  Found link https://files.pythonhosted.org/packages/5a/9b/56d3c18d0784d5f2bbd446ea2dc7ffa7476c35e3dc223741d20cfee3b185/pip-7.0.0-py2.py3-none-any.whl#sha256=309c48399c7d68501a10ef206abd6e5c541fedbf84b95435d9063bd454b39df7 (from https://pypi.org/simple/pip/), version: 7.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/c6/16/6475b142927ca5d03e3b7968efa5b0edd103e4684ecfde181a25f6fa2505/pip-7.0.0.tar.gz#sha256=7b46bfc1b95494731de306a688e2a7bc056d7fa7ad27e026908fb2ae67fed23d (from https://pypi.org/simple/pip/), version: 7.0.0\n",
      "  Found link https://files.pythonhosted.org/packages/5a/10/bb7a32c335bceba636aa673a4c977effa1e73a79f88856459486d8d670cf/pip-7.0.1-py2.py3-none-any.whl#sha256=d26b8573ba1ac1ec99a9bdbdffee2ff2b06c7790815211d0eb4dc1462a089705 (from https://pypi.org/simple/pip/), version: 7.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/4a/83/9ae4362a80739657e0c8bb628ea3fa0214a9aba7c8590dacc301ea293f73/pip-7.0.1.tar.gz#sha256=cfec177552fdd0b2d12b72651c8e874f955b4c62c1c2c9f2588cbdc1c0d0d416 (from https://pypi.org/simple/pip/), version: 7.0.1\n",
      "  Found link https://files.pythonhosted.org/packages/64/7f/7107800ae0919a80afbf1ecba21b90890431c3ee79d700adac3c79cb6497/pip-7.0.2-py2.py3-none-any.whl#sha256=83c869c5ab7113866e2d69641ec470d47f0faae68ca4550a289a4d3db515ad65 (from https://pypi.org/simple/pip/), version: 7.0.2\n",
      "  Found link https://files.pythonhosted.org/packages/75/b1/66532c273bca0133e42c3b4540a1609289f16e3046f1830f18c60794d661/pip-7.0.2.tar.gz#sha256=ba28fa60b573a9444e7b78ccb3b0f261d1f66f46d20403f9dce37b18a6aed405 (from https://pypi.org/simple/pip/), version: 7.0.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/96/76/33a598ae42dd0554207d83c7acc60e3b166dbde723cbf282f1f73b7a127c/pip-7.0.3-py2.py3-none-any.whl#sha256=7b1cb03e827d58d2d05e68ea96a9e27487ed4b0afcd951ac6e40847ce94f0738 (from https://pypi.org/simple/pip/), version: 7.0.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/35/59/5b23115758ba0f2fc465c459611865173ef006202ba83f662d1f58ed2fb8/pip-7.0.3.tar.gz#sha256=b4c598825a6f6dc2cac65968feb28e6be6c1f7f1408493c60a07eaa731a0affd (from https://pypi.org/simple/pip/), version: 7.0.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/f7/c0/9f8dac88326609b4b12b304e8382f64f7d5af7735a00d2fac36cf135fc30/pip-7.1.0-py2.py3-none-any.whl#sha256=80c29f899d3a00a448d65f8158544d22935baec7159af8da1a4fa1490ced481d (from https://pypi.org/simple/pip/), version: 7.1.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/7e/71/3c6ece07a9a885650aa6607b0ebfdf6fc9a3ef8691c44b5e724e4eee7bf2/pip-7.1.0.tar.gz#sha256=d5275ba3221182a5dd1b6bcfbfc5ec277fb399dd23226d6fa018048f7e0f10f2 (from https://pypi.org/simple/pip/), version: 7.1.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/1c/56/094d563c508917081bccff365e4f621ba33073c1c13aca9267a43cfcaf13/pip-7.1.1-py2.py3-none-any.whl#sha256=ce13000878d34c1178af76cb8cf269e232c00508c78ed46c165dd5b0881615f4 (from https://pypi.org/simple/pip/), version: 7.1.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/3b/bb/b3f2a95494fd3f01d3b3ae530e7c0e910dc25e88e30787b0a5e10cbc0640/pip-7.1.1.tar.gz#sha256=b22fe3c93a13fc7c04f145a42fd2ad50a9e3e1b8a7eed2e2b1c66e540a0951da (from https://pypi.org/simple/pip/), version: 7.1.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/b2/d0/cd115fe345dd6f07ec1c780020a7dfe74966fceeb171e0f20d1d4905b0b7/pip-7.1.2-py2.py3-none-any.whl#sha256=b9d3983b5cce04f842175e30169d2f869ef12c3546fd274083a65eada4e9708c (from https://pypi.org/simple/pip/), version: 7.1.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/d0/92/1e8406c15d9372084a5bf79d96da3a0acc4e7fcf0b80020a4820897d2a5c/pip-7.1.2.tar.gz#sha256=ca047986f0528cfa975a14fb9f7f106271d4e0c3fe1ddced6c1db2e7ae57a477 (from https://pypi.org/simple/pip/), version: 7.1.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/00/ae/bddef02881ee09c6a01a0d6541aa6c75a226a4e68b041be93142befa0cd6/pip-8.0.0-py2.py3-none-any.whl#sha256=262ed1823eb7fbe3f18a9bedb4800e59c4ab9a6682aff8c37b5ee83ea840910b (from https://pypi.org/simple/pip/), version: 8.0.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/e3/2d/03c014d11e66628abf2fda5ca00f779cbe7b5292c5cd13d42a95b94aa9b8/pip-8.0.0.tar.gz#sha256=90112b296152f270cb8dddcd19b7b87488d9e002e8cf622e14c4da9c2f6319b1 (from https://pypi.org/simple/pip/), version: 8.0.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/45/9c/6f9a24917c860873e2ce7bd95b8f79897524353df51d5d920cd6b6c1ec33/pip-8.0.1-py2.py3-none-any.whl#sha256=dedaac846bc74e38a3253671f51a056331ffca1da70e3f48d8128f2aa0635bba (from https://pypi.org/simple/pip/), version: 8.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/ea/66/a3d6187bd307159fedf8575c0d9ee2294d13b1cdd11673ca812e6a2dda8f/pip-8.0.1.tar.gz#sha256=477c50b3e538a7ac0fa611fb8b877b04b33fb70d325b12a81b9dbf3eb1158a4d (from https://pypi.org/simple/pip/), version: 8.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/e7/a0/bd35f5f978a5e925953ce02fa0f078a232f0f10fcbe543d8cfc043f74fda/pip-8.0.2-py2.py3-none-any.whl#sha256=249a6f3194be8c2e8cb4d4be3f6fd16a9f1e3336218caffa8e7419e3816f9988 (from https://pypi.org/simple/pip/), version: 8.0.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/ce/15/ee1f9a84365423e9ef03d0f9ed0eba2fb00ac1fffdd33e7b52aea914d0f8/pip-8.0.2.tar.gz#sha256=46f4bd0d8dfd51125a554568d646fe4200a3c2c6c36b9f2d06d2212148439521 (from https://pypi.org/simple/pip/), version: 8.0.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/ae/d4/2b127310f5364610b74c28e2e6a40bc19e2d3c9a9a4e012d3e333e767c99/pip-8.0.3-py2.py3-none-any.whl#sha256=b0335bc837f9edb5aad03bd43d0973b084a1cbe616f8188dc23ba13234dbd552 (from https://pypi.org/simple/pip/), version: 8.0.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/22/f3/14bc87a4f6b5ec70b682765978a6f3105bf05b6781fa97e04d30138bd264/pip-8.0.3.tar.gz#sha256=30f98b66f3fe1069c529a491597d34a1c224a68640c82caf2ade5f88aa1405e8 (from https://pypi.org/simple/pip/), version: 8.0.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/1e/c7/78440b3fb882ed001e6e12d8770bd45e73d6eced4e57f7c072b829ce8a3d/pip-8.1.0-py2.py3-none-any.whl#sha256=a542b99e08002ead83200198e19a3983270357e1cb4fe704247990b5b35471dc (from https://pypi.org/simple/pip/), version: 8.1.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/3c/72/6981d5adf880adecb066a1a1a4c312a17f8d787a3b85446967964ac66d55/pip-8.1.0.tar.gz#sha256=d8faa75dd7d0737b16d50cd0a56dc91a631c79ecfd8d38b80f6ee929ec82043e (from https://pypi.org/simple/pip/), version: 8.1.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/31/6a/0f19a7edef6c8e5065f4346137cc2a08e22e141942d66af2e1e72d851462/pip-8.1.1-py2.py3-none-any.whl#sha256=44b9c342782ab905c042c207d995aa069edc02621ddbdc2b9f25954a0fdac25c (from https://pypi.org/simple/pip/), version: 8.1.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/41/27/9a8d24e1b55bd8c85e4d022da2922cb206f183e2d18fee4e320c9547e751/pip-8.1.1.tar.gz#sha256=3e78d3066aaeb633d185a57afdccf700aa2e660436b4af618bcb6ff0fa511798 (from https://pypi.org/simple/pip/), version: 8.1.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/9c/32/004ce0852e0a127f07f358b715015763273799bd798956fa930814b60f39/pip-8.1.2-py2.py3-none-any.whl#sha256=6464dd9809fb34fc8df2bf49553bb11dac4c13d2ffa7a4f8038ad86a4ccb92a1 (from https://pypi.org/simple/pip/), version: 8.1.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/e7/a8/7556133689add8d1a54c0b14aeff0acb03c64707ce100ecd53934da1aa13/pip-8.1.2.tar.gz#sha256=4d24b03ffa67638a3fa931c09fd9e0273ffa904e95ebebe7d4b1a54c93d7b732 (from https://pypi.org/simple/pip/), version: 8.1.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/3f/ef/935d9296acc4f48d1791ee56a73781271dce9712b059b475d3f5fa78487b/pip-9.0.0-py2.py3-none-any.whl#sha256=c856ac18ca01e7127456f831926dc67cc7d3ab663f4c13b1ec156e36db4de574 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/5e/53/eaef47e5e2f75677c9de0737acc84b659b78a71c4086f424f55346a341b5/pip-9.0.0.tar.gz#sha256=f62fb70e7e000e46fce12aaeca752e5281a5446977fe5a75ab4189a43b3f8793 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/b6/ac/7015eb97dc749283ffdec1c3a88ddb8ae03b8fad0f0e611408f196358da3/pip-9.0.1-py2.py3-none-any.whl#sha256=690b762c0a8460c303c089d5d0be034fb15a5ea2b75bdf565f40421f542fefb0 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/11/b6/abcb525026a4be042b486df43905d6893fb04f05aac21c32c638e939e447/pip-9.0.1.tar.gz#sha256=09f243e1a7b461f654c26a725fa373211bb7ff17a9300058b205c61658ca940d (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/e7/f9/e801dcea22886cd513f6bd2e8f7e581bd6f67bb8e8f1cd8e7b92d8539280/pip-9.0.2-py2.py3-none-any.whl#sha256=b135491ddb061f39719b8472d8abb59c613816a2b86069c332db74d1cd208ab2 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/e5/8f/3fc66461992dc9e9fcf5e005687d5f676729172dda640df2fd8b597a6da7/pip-9.0.2.tar.gz#sha256=88110a224e9d30e5d76592a0b2130ef10e7e67a6426e8617bb918fffbfe91fe5 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/ac/95/a05b56bb975efa78d3557efa36acaf9cf5d2fd0ee0062060493687432e03/pip-9.0.3-py2.py3-none-any.whl#sha256=c3ede34530e0e0b2381e7363aded78e0c33291654937e7373032fda04e8803e5 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/c4/44/e6b8056b6c8f2bfd1445cc9990f478930d8e3459e9dbf5b8e2d2922d64d3/pip-9.0.3.tar.gz#sha256=7bf48f9a693be1d58f49f7af7e0ae9fe29fd671cde8a55e6edca3581c4ef5796 (from https://pypi.org/simple/pip/) (requires-python:>=2.6,!=3.0.*,!=3.1.*,!=3.2.*), version: 9.0.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/4b/5a/8544ae02a5bd28464e03af045e8aabde20a7b02db1911a9159328e1eb25a/pip-10.0.0b1-py2.py3-none-any.whl#sha256=dbd5d24cd461be23429625085a36cc8732cbcac4d2aaf673031f80f6ac07d844 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0b1\r\n",
      "  Found link https://files.pythonhosted.org/packages/aa/6d/ffbb86abf18b750fb26f27eda7c7732df2aacaa669c420d2eb2ad6df3458/pip-10.0.0b1.tar.gz#sha256=8d6e63d8b99752e4b53f272b66f9cd7b59e2b288e9a863a61c48d167203a2656 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0b1\r\n",
      "  Found link https://files.pythonhosted.org/packages/97/72/1d514201e7d7fc7fff5aac3de9c7b892cd72fb4bf23fd983630df96f7412/pip-10.0.0b2-py2.py3-none-any.whl#sha256=79f55588912f1b2b4f86f96f11e329bb01b25a484e2204f245128b927b1038a7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0b2\r\n",
      "  Found link https://files.pythonhosted.org/packages/32/67/572f642e6e42c580d3154964cfbab7d9322c23b0f417c6c01fdd206a2777/pip-10.0.0b2.tar.gz#sha256=ad6adec2150ce4aed8f6134d9b77d928fc848dbcb887fb1a455988cf99da5cae (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0b2\r\n",
      "  Found link https://files.pythonhosted.org/packages/62/a1/0d452b6901b0157a0134fd27ba89bf95a857fbda64ba52e1ca2cf61d8412/pip-10.0.0-py2.py3-none-any.whl#sha256=86a60a96d85e329962a9e6f6af612cbc11106293dbc83f119802b5bee9874cf3 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/e0/69/983a8e47d3dfb51e1463c1e962b2ccd1d74ec4e236e232625e353d830ed2/pip-10.0.0.tar.gz#sha256=f05a3eeea64bce94e85cc6671d679473d66288a4d37c3fcf983584954096b34f (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/0f/74/ecd13431bcc456ed390b44c8a6e917c1820365cbebcb6a8974d1cd045ab4/pip-10.0.1-py2.py3-none-any.whl#sha256=717cdffb2833be8409433a93746744b59505f42146e8d37de6c62b430e25d6d7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/ae/e8/2340d46ecadb1692a1e455f13f75e596d4eab3d11a57446f08259dee8f02/pip-10.0.1.tar.gz#sha256=f2bd08e0cd1b06e10218feaf6fef299f473ba706582eb3bd9d52203fdbd7ee68 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*), version: 10.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/5f/25/e52d3f31441505a5f3af41213346e5b6c221c9e086a166f3703d2ddaf940/pip-18.0-py2.py3-none-any.whl#sha256=070e4bf493c7c2c9f6a08dd797dd3c066d64074c38e9e8a0fb4e6541f266d96c (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 18.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/69/81/52b68d0a4de760a2f1979b0931ba7889202f302072cc7a0d614211bc7579/pip-18.0.tar.gz#sha256=a0e11645ee37c90b40c46d607070c4fd583e2cd46231b1c06e389c5e814eed76 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 18.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/c2/d7/90f34cb0d83a6c5631cf71dfe64cc1054598c843a92b400e55675cc2ac37/pip-18.1-py2.py3-none-any.whl#sha256=7909d0a0932e88ea53a7014dfd14522ffef91a464daaaf5c573343852ef98550 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 18.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/45/ae/8a0ad77defb7cc903f09e551d88b443304a9bd6e6f124e75c0fbbf6de8f7/pip-18.1.tar.gz#sha256=c0a292bd977ef590379a3f05d7b7f65135487b67470f6281289a94e015650ea1 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 18.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/60/64/73b729587b6b0d13e690a7c3acd2231ee561e8dd28a58ae1b0409a5a2b20/pip-19.0-py2.py3-none-any.whl#sha256=249ab0de4c1cef3dba4cf3f8cca722a07fc447b1692acd9f84e19c646db04c9a (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/11/31/c483614095176ddfa06ac99c2af4171375053b270842c7865ca0b4438dc1/pip-19.0.tar.gz#sha256=c82bf8bc00c5732f0dd49ac1dea79b6242a1bd42a5012e308ed4f04369b17e54 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0\r\n",
      "  Found link https://files.pythonhosted.org/packages/46/dc/7fd5df840efb3e56c8b4f768793a237ec4ee59891959d6a215d63f727023/pip-19.0.1-py2.py3-none-any.whl#sha256=aae79c7afe895fb986ec751564f24d97df1331bb99cdfec6f70dada2f40c0044 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/c8/89/ad7f27938e59db1f0f55ce214087460f65048626e2226531ba6cb6da15f0/pip-19.0.1.tar.gz#sha256=e81ddd35e361b630e94abeda4a1eddd36d47a90e71eb00f38f46b57f787cd1a5 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/d7/41/34dd96bd33958e52cb4da2f1bf0818e396514fd4f4725a79199564cd0c20/pip-19.0.2-py2.py3-none-any.whl#sha256=6a59f1083a63851aeef60c7d68b119b46af11d9d803ddc1cf927b58edcd0b312 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/4c/4d/88bc9413da11702cbbace3ccc51350ae099bb351febae8acc85fec34f9af/pip-19.0.2.tar.gz#sha256=f851133f8b58283fa50d8c78675eb88d4ff4cde29b6c41205cd938b06338e0e5 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/d8/f3/413bab4ff08e1fc4828dfc59996d721917df8e8583ea85385d51125dceff/pip-19.0.3-py2.py3-none-any.whl#sha256=bd812612bbd8ba84159d9ddc0266b7fbce712fc9bc98c82dee5750546ec8ec64 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/36/fa/51ca4d57392e2f69397cd6e5af23da2a8d37884a605f9e3f2d3bfdc48397/pip-19.0.3.tar.gz#sha256=6e6f197a1abfb45118dbb878b5c859a0edbdd33fd250100bc015b67fded4b9f2 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.0.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/f9/fb/863012b13912709c13cf5cfdbfb304fa6c727659d6290438e1a88df9d848/pip-19.1-py2.py3-none-any.whl#sha256=8f59b6cf84584d7962d79fd1be7a8ec0eb198aa52ea864896551736b3614eee9 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/51/5f/802a04274843f634469ef299fcd273de4438386deb7b8681dd059f0ee3b7/pip-19.1.tar.gz#sha256=d9137cb543d8a4d73140a3282f6d777b2e786bb6abb8add3ac5b6539c82cd624 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl#sha256=993134f0475471b91452ca029d4390dc8f298ac63a712814f101cd1b6db46676 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.1.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/93/ab/f86b61bef7ab14909bd7ec3cd2178feb0a1c86d451bc9bccd5a1aedcde5f/pip-19.1.1.tar.gz#sha256=44d3d7d3d30a1eb65c7e5ff1173cdf8f7467850605ac7cc3707b6064bddd0958 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*), version: 19.1.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/3a/6f/35de4f49ae5c7fdb2b64097ab195020fb48faa8ad3a85386ece6953c11b1/pip-19.2-py2.py3-none-any.whl#sha256=468c67b0b1120cd0329dc72972cf0651310783a922e7609f3102bd5fb4acbf17 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/41/13/b6e68eae78405af6e4e9a93319ae5bb371057786f1590b157341f7542d7d/pip-19.2.tar.gz#sha256=aa6fdd80d13caac75d92b5eced06778712859b1606ba92d62389c11be12b2dad (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/62/ca/94d32a6516ed197a491d17d46595ce58a83cbb2fca280414e57cd86b84dc/pip-19.2.1-py2.py3-none-any.whl#sha256=80d7452630a67c1e7763b5f0a515690f2c1e9ad06dda48e0ae85b7fdf2f59d97 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/8b/8a/1b2aadd922db1afe6bc107b03de41d6d37a28a5923383e60695fba24ae81/pip-19.2.1.tar.gz#sha256=258d702483dd749400aec59c23d638a5b2249ae28a0f478b6cab12ad45681a80 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/8d/07/f7d7ced2f97ca3098c16565efbe6b15fafcba53e8d9bdb431e09140514b0/pip-19.2.2-py2.py3-none-any.whl#sha256=4b956bd8b7b481fc5fa222637ff6d0823a327e5118178f1ec47618a480e61997 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/aa/1a/62fb0b95b1572c76dbc3cc31124a8b6866cbe9139eb7659ac7349457cf7c/pip-19.2.2.tar.gz#sha256=e05103825871e210d50a44c7e448587b0ed99dd775d3ef586304c58f40224a53 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/30/db/9e38760b32e3e7f40cce46dd5fb107b8c73840df38f0046d8e6514e675a1/pip-19.2.3-py2.py3-none-any.whl#sha256=340a0ba40fdeb16413914c0fcd8e0b4ebb0bf39a900ec80e11c05d836c05103f (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/00/9e/4c83a0950d8bdec0b4ca72afd2f9cea92d08eb7c1a768363f2ea458d08b4/pip-19.2.3.tar.gz#sha256=e7a31f147974362e6c82d84b91c7f2bdf57e4d3163d3d454e6c3e71944d67135 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.2.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/4a/08/6ca123073af4ebc4c5488a5bc8a010ac57aa39ce4d3c8a931ad504de4185/pip-19.3-py2.py3-none-any.whl#sha256=e100a7eccf085f0720b4478d3bb838e1c179b1e128ec01c0403f84e86e0e2dfb (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/af/7a/5dd1e6efc894613c432ce86f1011fcc3bbd8ac07dfeae6393b7b97f1de8b/pip-19.3.tar.gz#sha256=324d234b8f6124846b4e390df255cacbe09ce22791c3b714aa1ea6e44a4f2861 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.3\r\n",
      "  Found link https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl#sha256=6917c65fc3769ecdc61405d3dfd97afdedd75808d200b2838d7d961cebc0c2c7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.3.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/ce/ea/9b445176a65ae4ba22dce1d93e4b5fe182f953df71a145f557cffaffc1bf/pip-19.3.1.tar.gz#sha256=21207d76c1031e517668898a6b46a9fb1501c7a4710ef5dfd6a40ad9e6757ea7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 19.3.1\r\n",
      "  Skipping link: yanked for reason: <none given>: https://files.pythonhosted.org/packages/60/65/16487a7c4e0f95bb3fc89c2e377be331fd496b7a9b08fd3077de7f3ae2cf/pip-20.0-py2.py3-none-any.whl#sha256=eea07b449d969dbc8c062c157852cf8ed2ad1b8b5ac965a6b819e62929e41703 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*)\r\n",
      "  Skipping link: yanked for reason: <none given>: https://files.pythonhosted.org/packages/8c/5c/c18d58ab5c1a702bf670e0bd6a77cd4645e4aeca021c6118ef850895cc96/pip-20.0.tar.gz#sha256=5128e9a9401f1d16c1d15b2ed766a79d7813db1538428d0b0ce74838249e3a41 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*)\r\n",
      "  Found link https://files.pythonhosted.org/packages/57/36/67f809c135c17ec9b8276466cc57f35b98c240f55c780689ea29fa32f512/pip-20.0.1-py2.py3-none-any.whl#sha256=b7110a319790ae17e8105ecd6fe07dbcc098a280c6d27b6dd7a20174927c24d7 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/28/af/2c76c8aa46ccdf7578b83d97a11a2d1858794d4be4a1610ade0d30182e8b/pip-20.0.1.tar.gz#sha256=3cebbac2a1502e09265f94e5717408339de846b3c0f0ed086d7b817df9cab822 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.0.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl#sha256=4ae14a42d8adba3205ebeb38aa68cfc0b6c346e1ae2e699a0b3bad4da19cef5c (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.0.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/8e/76/66066b7bc71817238924c7e4b448abdb17eb0c92d645769c223f9ace478f/pip-20.0.2.tar.gz#sha256=7db0c8ea4c7ea51c8049640e8e6e7fde949de672bfa4949920675563a5a6967f (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.0.2\r\n",
      "  Found link https://files.pythonhosted.org/packages/ec/05/82d3fababbf462d876883ebc36f030f4fa057a563a80f5a26ee63679d9ea/pip-20.1b1-py2.py3-none-any.whl#sha256=4cf0348b683937da883ccaae8c8bcfc9b4c7ba4c48b38cc2d89cd7b8d0b220d9 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1b1\r\n",
      "  Found link https://files.pythonhosted.org/packages/cd/81/c1184456fe506bd50992571c9f8581907976ce71502e36741f033e2da1f1/pip-20.1b1.tar.gz#sha256=699880a47f6d306f4f9a87ca151ef33d41d2223b81ff343b786d38c297923a19 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1b1\r\n",
      "  Found link https://files.pythonhosted.org/packages/54/2e/df11ea7e23e7e761d484ed3740285a34e38548cf2bad2bed3dd5768ec8b9/pip-20.1-py2.py3-none-any.whl#sha256=4fdc7fd2db7636777d28d2e1432e2876e30c2b790d461f135716577f73104369 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/d1/05/059c78cd5d740d2299266ffa15514dad6692d4694df571bf168e2cdd98fb/pip-20.1.tar.gz#sha256=572c0f25eca7c87217b21f6945b7192744103b18f4e4b16b8a83b227a811e192 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl#sha256=b27c4dedae8c41aa59108f2fa38bf78e0890e590545bc8ece7cdceb4ba60f6e4 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/08/25/f204a6138dade2f6757b4ae99bc3994aac28a5602c97ddb2a35e0e22fbc4/pip-20.1.1.tar.gz#sha256=27f8dc29387dd83249e06e681ce087e6061826582198a425085e0bf4c1cf3a55 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.1.1\r\n",
      "  Found link https://files.pythonhosted.org/packages/fe/3b/0fc5e63eb277d5a50a95ce5c896f742ef243be27382303a4a44dd0197e29/pip-20.2b1-py2.py3-none-any.whl#sha256=b4e230e2b8ece18c5a19b818f3c20a8d4eeac8172962779fd9898d7c4ceb1636 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.2b1\r\n",
      "  Found link https://files.pythonhosted.org/packages/77/3e/6a1fd8e08a06e3e0f54182c7c937bba3f4e9cf1b26f54946d3915021ea2e/pip-20.2b1.tar.gz#sha256=dbf65ecb1c30d35d72f5fda052fcd2f1ea9aca8eaf03d930846d990f51d3f6f6 (from https://pypi.org/simple/pip/) (requires-python:>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*), version: 20.2b1\r\n",
      "Given no hashes to check 139 links for project 'pip': discarding no candidates\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -v --no-cache-dir ./apex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEuiRUr2U42g"
   },
   "source": [
    "ends with\n",
    "```\n",
    "Successfully installed apex-0.1\n",
    "Cleaning up...\n",
    "Removed build tracker '/tmp/pip-req-tracker-yl9p9317'\n",
    "```\n",
    "\n",
    "On VPN I succeeded to do only \"A Python-only build\"\n",
    "A Python-only build omits:\n",
    "* Fused kernels **required** to use apex.optimizers.FusedAdam.\n",
    "* Fused kernels **required** to use apex.normalization.FusedLayerNorm.\n",
    "* Fused kernels that improve the performance and numerical stability of apex.parallel.SyncBatchNorm.\n",
    "* Fused kernels that improve the performance of apex.parallel.DistributedDataParallel and apex.amp. DistributedDataParallel, amp, and SyncBatchNorm will still be usable, but they may be slower.\n",
    "\n",
    "AMP: Automatic Mixed Precision: https://nvidia.github.io/apex/amp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfnfJLGb7GSY"
   },
   "source": [
    "## install PyTorch Detection (Scene-Graph-Benchmark.pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "id": "QrQhyUTS7Fnj",
    "outputId": "1a77bc42-3376-4b68-d247-fccc6e4d79e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Scene-Graph-Benchmark.pytorch'...\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 462 (delta 1), reused 0 (delta 0), pack-reused 451\u001b[K\n",
      "Receiving objects: 100% (462/462), 26.17 MiB | 12.90 MiB/s, done.\n",
      "Resolving deltas: 100% (150/150), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKGMa7hOL0mx"
   },
   "source": [
    "change file name from `Scene-Graph-Benchmark.pytorch` to `Scene`\n",
    "because *ninja* can not handel certain char in the dir name\n",
    "([source](https://stackoverflow.com/questions/54569963/error-building-depfile-has-multiple-output-paths-ninja-build-stopped-subcomm ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "adnO822q8mPB",
    "outputId": "cf05fe69-e504-4bb2-c88e-291902fbbe93"
   },
   "outputs": [],
   "source": [
    "! mv Scene-Graph-Benchmark.pytorch Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B72Lk4W_86Kq",
    "outputId": "bf692be0-36e0-4110-a35e-52cb780dcd83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build\n",
      "running build_py\n",
      "running build_ext\n",
      "building 'maskrcnn_benchmark._C' extension\n",
      "Emitting ninja build file /root/Scene/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] /usr/local/cuda/bin/nvcc -DWITH_CUDA -I/root/Scene/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/Scene/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.cu -o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[2/2] /usr/local/cuda/bin/nvcc -DWITH_CUDA -I/root/Scene/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/Scene/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.cu -o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/vision.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cpu/nms_cpu.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/nms.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/maskrcnn_benchmark/_C.cpython-37m-x86_64-linux-gnu.so\n",
      "running develop\n",
      "running egg_info\n",
      "creating maskrcnn_benchmark.egg-info\n",
      "writing maskrcnn_benchmark.egg-info/PKG-INFO\n",
      "writing dependency_links to maskrcnn_benchmark.egg-info/dependency_links.txt\n",
      "writing top-level names to maskrcnn_benchmark.egg-info/top_level.txt\n",
      "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "reading manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "copying build/lib.linux-x86_64-3.7/maskrcnn_benchmark/_C.cpython-37m-x86_64-linux-gnu.so -> maskrcnn_benchmark\n",
      "Creating /opt/conda/lib/python3.7/site-packages/maskrcnn-benchmark.egg-link (link to .)\n",
      "Adding maskrcnn-benchmark 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /root/Scene\n",
      "Processing dependencies for maskrcnn-benchmark==0.1\n",
      "Finished processing dependencies for maskrcnn-benchmark==0.1\n"
     ]
    }
   ],
   "source": [
    "! cd Scene; python setup.py build develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrKqXJxATmhD"
   },
   "source": [
    "ends with:\n",
    "\n",
    "\n",
    "```\n",
    "Installed /content/Scene\n",
    "Processing dependencies for maskrcnn-benchmark==0.1\n",
    "Finished processing dependencies for maskrcnn-benchmark==0.1\n",
    "```\n",
    "otherwise you can get:\n",
    "~~~\n",
    "RuntimeError: Error compiling objects for extension\n",
    "~~~\n",
    "**I am not able to install the above cell successfully**\n",
    "\n",
    "The line above might not work for many reasons:\n",
    "* ninja is not installed\n",
    "* the folder name contains crasy characters like space, points\n",
    "* other reasons that I was not able to identify :(\n",
    "\n",
    "follow carefully the instructions above to avoid any problem :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bkpjGsSB88xK"
   },
   "source": [
    "# DATASET\n",
    "this is using files I uploaded on my persolnal drive. Therefore, it is not possible to run this part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFx_xmjPYgBw"
   },
   "source": [
    "**VG images**\n",
    "\n",
    "Download the VG images part1 (9 Gb) part2 (5 Gb).\n",
    "\n",
    "Extract these images to the file datasets/vg/VG_100K. \n",
    "\n",
    "If you want to use other directory, please link it in `DATASETS['VG_stanford_filtered']['img_dir']` of `maskrcnn_benchmark/config/paths_catelog.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-04 13:58:39--  https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5471658058 (5.1G) [application/zip]\n",
      "Saving to: ‘images2.zip’\n",
      "\n",
      "images2.zip         100%[===================>]   5.10G  4.98MB/s    in 30m 18s \n",
      "\n",
      "2020-06-04 14:28:57 (2.87 MB/s) - ‘images2.zip’ saved [5471658058/5471658058]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://cs.stanford.edu/people/rak248/VG_100K_2/images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAZMM7VGYhiV"
   },
   "source": [
    "**scene graphs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhUwA2fXfOJ2"
   },
   "source": [
    "The following code does this automatically:\n",
    "\n",
    "Download the [scene graphs](https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779871&authkey=AA33n7BRpB1xa3I) and extract them to `Scene/datasets/vg/VG-SGG-with-attri.h5`\n",
    "\n",
    "or you can edit the path in `DATASETS['VG_stanford_filtered_with_attribute']['roidb_file']` of `maskrcnn_benchmark/config/paths_catelog.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "QRTrdK72NjUP",
    "outputId": "0e0f8685-3438-4ce3-a1fa-601f058c9d65"
   },
   "outputs": [],
   "source": [
    "! ls \"/content/Scene/datasets/vg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_p1MehTKbJsY"
   },
   "outputs": [],
   "source": [
    "#! mkdir (\"/content/Scene/maskrcnn_benchmark/data/datasets/vg/\")\n",
    "#import tensorflow as tf\n",
    "# https://stackoverflow.com/questions/54172874/making-two-new-directory-in-google-colab-and-join-them/55814767#55814767\n",
    "# https://stackoverflow.com/questions/58363136/error-module-tensorflow-has-no-attribute-gfile-error-while-running-tensorfl\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.gfile.MkDir(\"/content/Scene/maskrcnn_benchmark/datasets/vg/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "it1hwPSSbWJf",
    "outputId": "658272c5-55d3-4fbb-88a6-77d34c28ff82"
   },
   "outputs": [],
   "source": [
    "! ls \"/content/Scene/maskrcnn_benchmark/data/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "7OTva0DreTzy",
    "outputId": "01c03992-8b9a-4d3b-fcd5-cdcc56aa361a"
   },
   "outputs": [],
   "source": [
    "% cd \"/content/Scene/maskrcnn_benchmark/datasets/vg\"\n",
    "#            VG-SGG-with-attri.h5    144M\n",
    "# ! wget -O \"VG-SGG-with-attri.h5\" --no-check-certificate \"https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779871&authkey=AA33n7BRpB1xa3I\"\n",
    "# if file size do not correspond then just copy it from your drive\n",
    "! cp -avr \"/content/drive/My Drive/AAA/HS/3_code/2_collab/VG-SGG-with-attri.h5\" \"/content/Scene/maskrcnn_benchmark/datasets/vg/VG-SGG-with-attri.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda toolkit:\n",
    "# https://developer.nvidia.com/cuda-10.1-download-archive-base?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=runfilelocal\n",
    "\n",
    "wget https://developer.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.105_418.39_linux.run\n",
    "sh cuda_10.1.105_418.39_linux.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "0RWl450VelIL",
    "outputId": "4208b01b-9db9-41dc-8512-3d6dadde72f9"
   },
   "outputs": [],
   "source": [
    "! ls -l --block-size=M \"/content/Scene/maskrcnn_benchmark/datasets/vg\"\n",
    "# 144M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-3.11.0.tar.gz (8.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.46.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.23.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.14.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-3.11.0-py3-none-any.whl size=9619 sha256=184ea18d44683eac553a1b7705ea72a9ec3cf61445acecbfd08fdcf3912a97bb\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/e6/10/9cbfea8dcf9fde0f406da1e4c71d5c3cf3c99e0502d7f08ac6\n",
      "Successfully built gdown\n",
      "Installing collected packages: filelock, gdown\n",
      "Successfully installed filelock-3.0.12 gdown-3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively\n",
    "gdown \"https://drive.google.com/uc?id=1h2XzeQgJNYgg3q66t1oujofbWvBIYMXG\" -O VG-SGG-with-attri.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qI9-clPcvy7u"
   },
   "source": [
    "## Pretrained models\n",
    "https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch#pretrained-models\n",
    "\n",
    "I uploaded and extracted the files manually following this: \n",
    "After you [download the Faster R-CNN model](https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779870&authkey=AH5CPVb9g5E67iQ), please extract all the files to the directory `/home/username/checkpoints/pretrained_faster_rcnn`. To train your own Faster R-CNN model, please follow the next section.\n",
    "\n",
    "In this case I extracted the files here:\n",
    "`/content/drive/My Drive/AAA/HS/3_code/2_collab/checkpoints/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 219\r\n",
      "-rw-r--r-- 1 root root 70579 Jun  4 15:09 config.yml\r\n",
      "-rw-r--r-- 1 root root 70983 Jun  4 15:09 labels.json\r\n",
      "-rw-r--r-- 1 root root 70599 Jun  4 15:09 last_checkpoint\r\n",
      "-rw-r--r-- 1 root root 71426 Jun  4 15:08 log.txt\r\n",
      "-rw-r--r-- 1 root root 70610 Jun  4 15:09 model_final.pth\r\n",
      "-rw-r--r-- 1 root root 70819 Jun  4 15:09 VG_stanford_filtered_wth_attribute_train_statistics.cache\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l checkpoint/motif-precls-exmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gdown/parse_url.py:31: UserWarning: You specified Google Drive Link but it is not the correct link to download the file. Maybe you should try: https://drive.google.com/uc?id=None\n",
      "  url=\"https://drive.google.com/uc?id={}\".format(file_id)\n",
      "Downloading...\n",
      "From: https://drive.google.com/file/d/1GoUdVlwZ8ekS7w_aWJ-tcXsx-ULCCjyI\n",
      "To: /root/checkpoints/motif-precls-exmp/log.txt\n",
      "71.4kB [00:00, 1.13MB/s]\n",
      "/opt/conda/lib/python3.7/site-packages/gdown/parse_url.py:31: UserWarning: You specified Google Drive Link but it is not the correct link to download the file. Maybe you should try: https://drive.google.com/uc?id=None\n",
      "  url=\"https://drive.google.com/uc?id={}\".format(file_id)\n",
      "Downloading...\n",
      "From: https://drive.google.com/file/d/1Pj8gfFBouqaKzJVkOV6wsY8GU60z6Nrb\n",
      "To: /root/checkpoints/motif-precls-exmp/config.yml\n",
      "70.6kB [00:00, 1.18MB/s]\n",
      "/opt/conda/lib/python3.7/site-packages/gdown/parse_url.py:31: UserWarning: You specified Google Drive Link but it is not the correct link to download the file. Maybe you should try: https://drive.google.com/uc?id=None\n",
      "  url=\"https://drive.google.com/uc?id={}\".format(file_id)\n",
      "Downloading...\n",
      "From: https://drive.google.com/file/d/1TRT3uX0tbqvIfNeL3bRGzVeqKS8SHtFa\n",
      "To: /root/checkpoints/motif-precls-exmp/model_final.pth\n",
      "70.6kB [00:00, 1.12MB/s]\n",
      "/opt/conda/lib/python3.7/site-packages/gdown/parse_url.py:31: UserWarning: You specified Google Drive Link but it is not the correct link to download the file. Maybe you should try: https://drive.google.com/uc?id=None\n",
      "  url=\"https://drive.google.com/uc?id={}\".format(file_id)\n",
      "Downloading...\n",
      "From: https://drive.google.com/file/d/1Y1SnKGeQCBqGmIpUa8izy2EvUYLyPc89\n",
      "To: /root/checkpoints/motif-precls-exmp/VG_stanford_filtered_wth_attribute_train_statistics.cache\n",
      "70.8kB [00:00, 1.19MB/s]\n",
      "/opt/conda/lib/python3.7/site-packages/gdown/parse_url.py:31: UserWarning: You specified Google Drive Link but it is not the correct link to download the file. Maybe you should try: https://drive.google.com/uc?id=None\n",
      "  url=\"https://drive.google.com/uc?id={}\".format(file_id)\n",
      "Downloading...\n",
      "From: https://drive.google.com/file/d/1_aRGThcciCvg0gFLr9EkhLIE92vEitfP\n",
      "To: /root/checkpoints/motif-precls-exmp/labels.json\n",
      "71.0kB [00:00, 823kB/s]\n",
      "/opt/conda/lib/python3.7/site-packages/gdown/parse_url.py:31: UserWarning: You specified Google Drive Link but it is not the correct link to download the file. Maybe you should try: https://drive.google.com/uc?id=None\n",
      "  url=\"https://drive.google.com/uc?id={}\".format(file_id)\n",
      "Downloading...\n",
      "From: https://drive.google.com/file/d/1q6w_tZzhKTx70hgmQ-7Rnlt4EM60MmXp\n",
      "To: /root/checkpoints/motif-precls-exmp/last_checkpoint\n",
      "70.6kB [00:00, 1.15MB/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir Scene/checkpoint/pretrained_faster_rcnn/\n",
    "cd Scene/checkpoint/pretrained_faster_rcnn/\n",
    "gdown \"https://drive.google.com/uc?id=1GoUdVlwZ8ekS7w_aWJ-tcXsx-ULCCjyI\" -O log.txt\n",
    "gdown \"https://drive.google.com/uc?id=1Pj8gfFBouqaKzJVkOV6wsY8GU60z6Nrb\" -O config.yml\n",
    "gdown \"https://drive.google.com/uc?id=1TRT3uX0tbqvIfNeL3bRGzVeqKS8SHtFa\" -O model_final.pth\n",
    "gdown \"https://drive.google.com/uc?id=1Y1SnKGeQCBqGmIpUa8izy2EvUYLyPc89\" -O VG_stanford_filtered_wth_attribute_train_statistics.cache\n",
    "gdown \"https://drive.google.com/uc?id=1_aRGThcciCvg0gFLr9EkhLIE92vEitfP\" -O labels.json\n",
    "gdown \"https://drive.google.com/uc?id=1q6w_tZzhKTx70hgmQ-7Rnlt4EM60MmXp\" -O last_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bq0NiTqbZqE6"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.gfile.MkDir(\"/content/checkpoint/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "6DNn7HmMZCk8",
    "outputId": "4af70a86-727f-4e4d-f668-50864d9cf006"
   },
   "outputs": [],
   "source": [
    "! cp -avr \"/content/drive/My Drive/AAA/HS/3_code/2_collab/checkpoints/\" \"/content/checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVH_BN5dgHkt"
   },
   "outputs": [],
   "source": [
    "# commands below did not work: wget is not stable => not able to extract the zip file\n",
    "\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.gfile.MkDir(\"/content/drive/My Drive/AAA/HS/3_code/2_collab/checkpoints/\")\n",
    "#% cd \"/content/checkpoints\"\n",
    "# pretrained_faster_rcnn.zip              1.1 Gb\n",
    "# ! wget -O \"pretrained_faster_rcnn.zip\" --no-check-certificate \"https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779870&authkey=AH5CPVb9g5E67iQ\"\n",
    "# was not able to download the file, probably because of storage limit\n",
    "# import shutil\n",
    "# shutil.unpack_archive(\"pretrained_faster_rcnn.zip\", \"/content/checkpoints/\")\n",
    "# shutil.unpack_archive(\"pretrained_faster_rcnn.gz\", \"/content/drive/My Drive/AAA/HS/3_code/2_collab/checkpoints/\")\n",
    "# !7z x \"pretrained_faster_rcnn.zip\"\n",
    "# !apt install file\n",
    "# !file \"pretrained_faster_rcnn.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gdown \"https://drive.google.com/uc?id=1w8GUUPDwfWxU-0bulyvcWS5_mfSQgaJC\" -O \"HS.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJtSgl0_AQFS"
   },
   "source": [
    "# Settings\n",
    "The default settings are under\n",
    "\n",
    "`configs/e2e_relation_X_101_32_8_FPN_1x.yaml` [git](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch/blob/db02790a60bb9b9f7c270352820968b2f2089469/configs/e2e_relation_X_101_32_8_FPN_1x.yaml#L74)\n",
    "\n",
    "and\n",
    "\n",
    " `maskrcnn_benchmark/config/defaults.py` (todo find link in github)\n",
    "\n",
    "The priority is `command > yaml > defaults.py`\n",
    "\n",
    "By Default, settings are set to the configuration below, as we can [check online](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch/blob/db02790a60bb9b9f7c270352820968b2f2089469/configs/e2e_relation_X_101_32_8_FPN_1x.yaml#L74)\n",
    "\n",
    "* For Predicate Classification (PredCls), we need to set:\n",
    "```\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True\n",
    "```\n",
    "\n",
    "\n",
    "* For Unbiased-Causal-TDE Model:\n",
    "```\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir checkpoint/pretrained_faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bRZcrKc8KOQ8"
   },
   "source": [
    "# Examples of the Training Command\n",
    "## Example 1 : (PreCls, Motif Model)\n",
    "### Train\n",
    "Training Example 1 : (PreCls, Motif Model)\n",
    "~~~\n",
    "CUDA_VISIBLE_DEVICES=0,1\n",
    "python -m torch.distributed.launch\n",
    "--master_port 10025\n",
    "--nproc_per_node=[{num_gpus}](https://docs.fast.ai/distributed.html)\n",
    "\n",
    "tools/relation_train_net.py\n",
    "--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\"\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \n",
    "SOLVER.IMS_PER_BATCH 12       **SOLVER.IMS_PER_BATCH (12) must be divisible by the number of GPUs (2) used.**\n",
    "TEST.IMS_PER_BATCH 2           **TEST.IMS_PER_BATCH (2) must be divisible by the number of GPUs (2) used.**\n",
    "DTYPE \"float16\" \n",
    "SOLVER.MAX_ITER 50000 \n",
    "SOLVER.VAL_PERIOD 2000 \n",
    "SOLVER.CHECKPOINT_PERIOD 2000 \n",
    "GLOVE_DIR /home/kaihua/glove \n",
    "MODEL.PRETRAINED_DETECTOR_CKPT /home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth \n",
    "OUTPUT_DIR /home/kaihua/checkpoints/motif-precls-exmp\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T23:17:20.248013Z",
     "start_time": "2020-06-06T20:29:36.423378Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "colab_type": "code",
    "id": "VOjDcyrBARwv",
    "outputId": "4022a460-2711-4dea-df2a-76c050e0f776",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-06 20:29:51,547 maskrcnn_benchmark INFO: Using 2 GPUs\n",
      "2020-06-06 20:29:51,547 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)\n",
      "2020-06-06 20:29:51,547 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-06 20:29:55,864 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n",
      "2020-06-06 20:29:55,865 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml\n",
      "2020-06-06 20:29:55,866 maskrcnn_benchmark INFO: \n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MAX_SIZE_TEST: 1000\n",
      "MODEL:\n",
      "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
      "  WEIGHT: \"catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\"\n",
      "  BACKBONE:\n",
      "    CONV_BODY: \"R-101-FPN\" # VGG-16\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    STRIDE_IN_1X1: False\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RELATION_ON: True\n",
      "  ATTRIBUTE_ON: False\n",
      "  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false\n",
      "  RPN:\n",
      "    USE_FPN: True\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    RPN_MID_CHANNEL: 256\n",
      "  ROI_HEADS:\n",
      "    USE_FPN: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "  ROI_BOX_HEAD:\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA\n",
      "    MLP_HEAD_DIM: 4096\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight\n",
      "    POS_WEIGHT: 50.0\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA\n",
      "    MAX_ATTRIBUTES: 10             \n",
      "    ATTRIBUTE_BGFG_SAMPLE: True    \n",
      "    ATTRIBUTE_BGFG_RATIO: 3        \n",
      "  ROI_RELATION_HEAD:\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing\n",
      "    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain \"to the left of\" & \"to the right of\")\n",
      "    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    FEATURE_EXTRACTOR: \"RelationFeatureExtractor\"\n",
      "    #################### Select Relationship Model ####################\n",
      "    #PREDICTOR: \"MotifPredictor\"\n",
      "    #PREDICTOR: \"VCTreePredictor\"\n",
      "    #PREDICTOR: \"TransformerPredictor\"\n",
      "    PREDICTOR: \"CausalAnalysisPredictor\"\n",
      "    ################# Parameters for Motif Predictor ##################\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    ############# Parameters for Causal Unbias Predictor ##############\n",
      "    ### Implementation for paper \"Unbiased Scene Graph Generation from Biased Training\"\n",
      "    CAUSAL:\n",
      "      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'\n",
      "      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         \n",
      "      SEPARATE_SPATIAL: False         # separate spatial in union feature\n",
      "      CONTEXT_LAYER: \"motifs\"         # candicates: motifs, vctree, vtranse\n",
      "      SPATIAL_FOR_VISION: True\n",
      "      EFFECT_ANALYSIS: True\n",
      "    ############### Parameters for Transformer Predictor ##############\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      NUM_HEAD: 8\n",
      "      KEY_DIM: 64\n",
      "      VAL_DIM: 64\n",
      "      INNER_DIM: 2048 \n",
      "DATASETS:\n",
      "  TRAIN: (\"VG_stanford_filtered_with_attribute_train\",)\n",
      "  VAL: (\"VG_stanford_filtered_with_attribute_val\",)\n",
      "  TEST: (\"VG_stanford_filtered_with_attribute_test\",)\n",
      "DATALOADER:\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "SOLVER:\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  BASE_LR: 0.01\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  MOMENTUM: 0.9\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  STEPS: (10000, 16000)\n",
      "  MAX_ITER: 40000\n",
      "  VAL_PERIOD: 2000\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    # the following paramters are only used for WarmupReduceLROnPlateau\n",
      "    TYPE: \"WarmupReduceLROnPlateau\"    # WarmupMultiStepLR, WarmupReduceLROnPlateau\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "OUTPUT_DIR: './output/relation_baseline'\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  RELATION:\n",
      "    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem\n",
      "    REQUIRE_OVERLAP: False\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "\n",
      "2020-06-06 20:29:55,868 maskrcnn_benchmark INFO: Running with config:\n",
      "AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: none\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: MotifPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/motif-precls-exmp\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 12\n",
      "  MAX_ITER: 50000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 2\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-06 20:29:55,869 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 20:29:55,895 maskrcnn_benchmark INFO: #################### prepare training ####################\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "2020-06-06 20:29:59,199 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-06 20:29:59,200 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2020-06-06 20:29:59,200 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-06 20:29:59,200 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-06 20:30:00,351 maskrcnn_benchmark INFO: #################### end model construction ####################\n",
      "2020-06-06 20:30:01,042 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "2020-06-06 20:30:01,073 maskrcnn_benchmark INFO: #################### end distributed ####################\n",
      "2020-06-06 20:30:01,075 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "2020-06-06 20:30:01,870 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-06 20:30:01,870 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-06 20:30:01,870 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.\n",
      "2020-06-06 20:30:01,871 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.\n",
      "2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\n",
      "2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\n",
      "2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\n",
      "2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\n",
      "2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)\n",
      "2020-06-06 20:30:01,930 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\n",
      "2020-06-06 20:30:01,931 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.bias of shape (4096,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.weight of shape (4096, 1024)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.rel_compress.bias of shape (51,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.rel_compress.weight of shape (51, 4096)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\n",
      "2020-06-06 20:30:01,932 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)\n",
      "2020-06-06 20:30:01,933 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 20:30:02,167 maskrcnn_benchmark INFO: #################### end load checkpointer ####################\n",
      "2020-06-06 20:30:02,168 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "2020-06-06 20:30:04,738 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/motif-precls-exmp/labels.json\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "2020-06-06 20:30:05,847 maskrcnn_benchmark INFO: #################### end dataloader ####################\n",
      "2020-06-06 20:30:05,847 maskrcnn_benchmark INFO: Validate before training\n",
      "2020-06-06 20:30:05,856 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "  0%|                                                  | 0/2500 [00:00<?, ?it/s][DEBUG] load_image_filenames(...) OK\n",
      "  0%|                                                  | 0/2500 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:45<00:00,  8.74it/s]\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:45<00:00,  8.74it/s]\n",
      "2020-06-06 20:34:51,927 maskrcnn_benchmark INFO: Total run time: 0:04:46.071012 (0.11442840480804443 s / img per device, on 2 devices)\n",
      "2020-06-06 20:34:51,928 maskrcnn_benchmark INFO: Model inference time: 0:04:20.020102 (0.10400804090499878 s / img per device, on 2 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.35s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.41s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-06 20:36:30,616 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.4903;   R @ 50: 0.5942;   R @ 100: 0.6399;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.5358; ngR @ 50: 0.6889; ngR @ 100: 0.7908;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0044;  zR @ 100: 0.0044;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.0907;  mR @ 50: 0.1308;  mR @ 100: 0.1611;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.0387) (across:0.0556) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1217) (attached to:0.0000) (behind:0.3584) (belonging to:0.0000) (between:0.0000) (carrying:0.2259) (covered in:0.3214) (covering:0.0000) (eating:0.8571) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0368) (has:0.7741) (holding:0.4561) (in:0.3357) (in front of:0.0861) (laying on:0.0000) (looking at:0.0870) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3856) (of:0.3987) (on:0.8622) (on back of:0.0455) (over:0.0589) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6652) (says:0.0000) (sitting on:0.2866) (standing on:0.0072) (to:0.0000) (under:0.1378) (using:0.2885) (walking in:0.0000) (walking on:0.0503) (watching:0.0588) (wearing:0.9655) (wears:0.0000) (with:0.0528) \n",
      "SGG eval:   A @ 20: 0.6845;   A @ 50: 0.6897;   A @ 100: 0.6897;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-06 20:36:31,376 maskrcnn_benchmark INFO: Start training\n",
      "2020-06-06 20:36:32,944 maskrcnn_benchmark INFO: ---Total norm 1.31536 clip coef 3.80123-----------------\n",
      "2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.72468, (torch.Size([4096, 12544]))\n",
      "2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.64445, (torch.Size([4096, 4096]))\n",
      "2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.42083, (torch.Size([4096, 4096]))\n",
      "2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.36141, (torch.Size([512, 1024]))\n",
      "2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.33887, (torch.Size([4096, 1024]))\n",
      "2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.32789, (torch.Size([4096, 12544]))\n",
      "2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.30688, (torch.Size([51, 4096]))\n",
      "2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.21697, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-06 20:36:32,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.20123, (torch.Size([2048, 4808]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.20000, (torch.Size([2048, 4808]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.12346, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.09852, (torch.Size([512]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.05440, (torch.Size([51]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.04651, (torch.Size([512, 1024]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.04630, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.03573, (torch.Size([2048, 512]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.03499, (torch.Size([2048, 512]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.02568, (torch.Size([2048, 4424]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.02428, (torch.Size([2048, 4424]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01546, (torch.Size([1024, 512]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.01485, (torch.Size([4096]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01431, (torch.Size([22801, 51]))\n",
      "2020-06-06 20:36:32,957 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01418, (torch.Size([2048]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01418, (torch.Size([2048]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01370, (torch.Size([2048]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01370, (torch.Size([2048]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.01124, (torch.Size([512]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00968, (torch.Size([1024]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00769, (torch.Size([4096]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00696, (torch.Size([128]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00600, (torch.Size([4096]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00490, (torch.Size([2048, 512]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00442, (torch.Size([256]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00438, (torch.Size([2048, 512]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00359, (torch.Size([151, 200]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00306, (torch.Size([4096]))\n",
      "2020-06-06 20:36:32,958 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00255, (torch.Size([256]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00220, (torch.Size([4096]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00201, (torch.Size([256]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00199, (torch.Size([128]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00175, (torch.Size([256]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00171, (torch.Size([2048]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00171, (torch.Size([2048]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00162, (torch.Size([2048]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00162, (torch.Size([2048]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00126, (torch.Size([128]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00118, (torch.Size([128, 32]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00083, (torch.Size([32, 9]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00042, (torch.Size([151, 200]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00040, (torch.Size([128]))\n",
      "2020-06-06 20:36:32,959 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00019, (torch.Size([32]))\n",
      "2020-06-06 20:36:32,960 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00014, (torch.Size([32]))\n",
      "2020-06-06 20:36:32,960 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-06 20:36:32,960 maskrcnn_benchmark INFO: -------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 20:39:19,256 maskrcnn_benchmark INFO: eta: 11:36:41  iter: 200  loss: 0.1320 (0.1520)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1320 (0.1520)  time: 0.8365 (0.8394)  data: 0.0101 (0.0181)  lr: 0.054984  max mem: 5953\n",
      "2020-06-06 20:42:06,471 maskrcnn_benchmark INFO: eta: 11:32:31  iter: 400  loss: 0.1435 (0.1470)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1435 (0.1470)  time: 0.8338 (0.8377)  data: 0.0155 (0.0165)  lr: 0.098184  max mem: 5953\n",
      "2020-06-06 20:44:54,481 maskrcnn_benchmark INFO: eta: 11:30:22  iter: 600  loss: 0.1380 (0.1467)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1380 (0.1467)  time: 0.8304 (0.8385)  data: 0.0158 (0.0161)  lr: 0.120000  max mem: 5953\n",
      "2020-06-06 20:47:41,848 maskrcnn_benchmark INFO: eta: 11:27:13  iter: 800  loss: 0.1230 (0.1454)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1230 (0.1454)  time: 0.8321 (0.8381)  data: 0.0156 (0.0159)  lr: 0.120000  max mem: 5953\n",
      "2020-06-06 20:50:29,783 maskrcnn_benchmark INFO: eta: 11:24:41  iter: 1000  loss: 0.1441 (0.1438)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1441 (0.1438)  time: 0.8337 (0.8384)  data: 0.0165 (0.0157)  lr: 0.120000  max mem: 5953\n",
      "2020-06-06 20:53:16,451 maskrcnn_benchmark INFO: eta: 11:21:12  iter: 1200  loss: 0.1255 (0.1425)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1255 (0.1425)  time: 0.8240 (0.8376)  data: 0.0143 (0.0157)  lr: 0.120000  max mem: 5953\n",
      "2020-06-06 20:56:03,399 maskrcnn_benchmark INFO: eta: 11:18:05  iter: 1400  loss: 0.1192 (0.1413)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1192 (0.1413)  time: 0.8318 (0.8372)  data: 0.0159 (0.0157)  lr: 0.120000  max mem: 5953\n",
      "2020-06-06 20:58:51,271 maskrcnn_benchmark INFO: eta: 11:15:31  iter: 1600  loss: 0.1243 (0.1408)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1243 (0.1408)  time: 0.8466 (0.8374)  data: 0.0151 (0.0157)  lr: 0.120000  max mem: 5953\n",
      "2020-06-06 21:01:38,481 maskrcnn_benchmark INFO: eta: 11:12:36  iter: 1800  loss: 0.1194 (0.1400)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1194 (0.1400)  time: 0.8308 (0.8373)  data: 0.0160 (0.0157)  lr: 0.120000  max mem: 5953\n",
      "2020-06-06 21:04:25,529 maskrcnn_benchmark INFO: eta: 11:09:39  iter: 2000  loss: 0.1282 (0.1396)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1282 (0.1396)  time: 0.8275 (0.8371)  data: 0.0161 (0.0157)  lr: 0.120000  max mem: 5973\n",
      "2020-06-06 21:04:25,532 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0002000.pth\n",
      "  0%|                                                  | 0/2500 [00:00<?, ?it/s]2020-06-06 21:04:27,900 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-06 21:04:27,934 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:48<00:00,  8.65it/s]\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:46<00:00,  8.72it/s]\n",
      "2020-06-06 21:09:14,526 maskrcnn_benchmark INFO: Total run time: 0:04:46.591597 (0.11463663864135742 s / img per device, on 2 devices)\n",
      "2020-06-06 21:09:14,527 maskrcnn_benchmark INFO: Model inference time: 0:04:22.336354 (0.10493454170227051 s / img per device, on 2 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=24.73s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.99s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-06 21:10:52,395 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6015;   R @ 50: 0.6554;   R @ 100: 0.6722;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6856; ngR @ 50: 0.8146; ngR @ 100: 0.8774;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0178;  zR @ 100: 0.0356;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1162;  mR @ 50: 0.1411;  mR @ 100: 0.1516;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.0430) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1389) (attached to:0.0000) (behind:0.5206) (belonging to:0.0000) (between:0.0000) (carrying:0.3509) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8046) (holding:0.5838) (in:0.3545) (in front of:0.0366) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5390) (of:0.4650) (on:0.8977) (on back of:0.0455) (over:0.0366) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.5967) (says:0.0000) (sitting on:0.3272) (standing on:0.0109) (to:0.0000) (under:0.1633) (using:0.0385) (walking in:0.0000) (walking on:0.2626) (watching:0.1961) (wearing:0.9751) (wears:0.0000) (with:0.1028) \n",
      "SGG eval:   A @ 20: 0.6970;   A @ 50: 0.7018;   A @ 100: 0.7018;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-06 21:10:53,128 maskrcnn_benchmark INFO: Validation Result: 0.6722\n",
      "2020-06-06 21:13:40,040 maskrcnn_benchmark INFO: eta: 13:27:02  iter: 2200  loss: 0.1231 (0.1391)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1391)  time: 0.8406 (1.0130)  data: 0.0164 (0.1919)  lr: 0.120000  max mem: 5973\n",
      "2020-06-06 21:16:26,618 maskrcnn_benchmark INFO: eta: 13:11:45  iter: 2400  loss: 0.1342 (0.1385)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1342 (0.1385)  time: 0.8310 (0.9980)  data: 0.0160 (0.1773)  lr: 0.120000  max mem: 5973\n",
      "2020-06-06 21:19:13,483 maskrcnn_benchmark INFO: eta: 12:58:29  iter: 2600  loss: 0.1380 (0.1381)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1380 (0.1381)  time: 0.8336 (0.9854)  data: 0.0166 (0.1650)  lr: 0.120000  max mem: 5973\n",
      "2020-06-06 21:22:01,089 maskrcnn_benchmark INFO: eta: 12:46:55  iter: 2800  loss: 0.1249 (0.1379)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1249 (0.1379)  time: 0.8374 (0.9749)  data: 0.0159 (0.1543)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 21:24:48,268 maskrcnn_benchmark INFO: eta: 12:36:24  iter: 3000  loss: 0.1292 (0.1377)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1292 (0.1377)  time: 0.8260 (0.9656)  data: 0.0161 (0.1451)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 21:27:35,568 maskrcnn_benchmark INFO: eta: 12:26:53  iter: 3200  loss: 0.1316 (0.1373)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1316 (0.1373)  time: 0.8351 (0.9576)  data: 0.0173 (0.1370)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 21:30:23,083 maskrcnn_benchmark INFO: eta: 12:18:13  iter: 3400  loss: 0.1311 (0.1371)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1311 (0.1371)  time: 0.8343 (0.9505)  data: 0.0159 (0.1299)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 21:33:10,006 maskrcnn_benchmark INFO: eta: 12:10:04  iter: 3600  loss: 0.1353 (0.1369)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1353 (0.1369)  time: 0.8289 (0.9441)  data: 0.0164 (0.1236)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 21:35:57,288 maskrcnn_benchmark INFO: eta: 12:02:33  iter: 3800  loss: 0.1173 (0.1365)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1173 (0.1365)  time: 0.8291 (0.9384)  data: 0.0169 (0.1179)  lr: 0.120000  max mem: 6112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 21:38:44,860 maskrcnn_benchmark INFO: ---Total norm 0.14507 clip coef 34.46614-----------------\r\n",
      "2020-06-06 21:38:44,868 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.06706, (torch.Size([4096, 12544]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.05443, (torch.Size([4096, 12544]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.04995, (torch.Size([256, 1024, 3, 3]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.04818, (torch.Size([51, 4096]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.04536, (torch.Size([4096, 4096]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03947, (torch.Size([4096, 4096]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.03178, (torch.Size([4096, 1024]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03174, (torch.Size([512, 1024]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02645, (torch.Size([256, 128, 3, 3]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.02525, (torch.Size([2048, 4808]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.02486, (torch.Size([2048, 4808]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02434, (torch.Size([128, 2, 7, 7]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.01383, (torch.Size([51]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01151, (torch.Size([512]))\r\n",
      "2020-06-06 21:38:44,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00782, (torch.Size([22801, 51]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00539, (torch.Size([512, 1024]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00468, (torch.Size([2048, 512]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00426, (torch.Size([2048, 512]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00421, (torch.Size([128]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00399, (torch.Size([2048, 4424]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00375, (torch.Size([2048, 4424]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00356, (torch.Size([2048]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00356, (torch.Size([2048]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00319, (torch.Size([2048]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00319, (torch.Size([2048]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00271, (torch.Size([512]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00257, (torch.Size([4096]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00238, (torch.Size([256]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00235, (torch.Size([1024, 512]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00183, (torch.Size([4096]))\r\n",
      "2020-06-06 21:38:44,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00162, (torch.Size([1024]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00122, (torch.Size([151, 200]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00120, (torch.Size([256]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00110, (torch.Size([128]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00097, (torch.Size([4096]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00075, (torch.Size([256]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00073, (torch.Size([4096]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00070, (torch.Size([2048, 512]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00067, (torch.Size([2048, 512]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00063, (torch.Size([2048]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00063, (torch.Size([2048]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00062, (torch.Size([128]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00053, (torch.Size([2048]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00053, (torch.Size([2048]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00042, (torch.Size([256]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00034, (torch.Size([128, 32]))\r\n",
      "2020-06-06 21:38:44,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00030, (torch.Size([32, 9]))\r\n",
      "2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00028, (torch.Size([4096]))\r\n",
      "2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00013, (torch.Size([128]))\r\n",
      "2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00011, (torch.Size([151, 200]))\r\n",
      "2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00008, (torch.Size([32]))\r\n",
      "2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00005, (torch.Size([32]))\r\n",
      "2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\r\n",
      "2020-06-06 21:38:44,872 maskrcnn_benchmark INFO: -------------------------------\r\n",
      "2020-06-06 21:38:44,874 maskrcnn_benchmark INFO: eta: 11:55:35  iter: 4000  loss: 0.1169 (0.1362)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1169 (0.1362)  time: 0.8380 (0.9334)  data: 0.0169 (0.1129)  lr: 0.120000  max mem: 6112\r\n",
      "2020-06-06 21:38:44,877 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0004000.pth\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2500 [00:00<?, ?it/s]2020-06-06 21:38:47,108 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-06 21:38:47,129 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:48<00:00,  8.67it/s]\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:46<00:00,  8.74it/s]\n",
      "2020-06-06 21:43:33,231 maskrcnn_benchmark INFO: Total run time: 0:04:46.102085 (0.11444083404541015 s / img per device, on 2 devices)\n",
      "2020-06-06 21:43:33,232 maskrcnn_benchmark INFO: Model inference time: 0:04:20.722934 (0.104289173412323 s / img per device, on 2 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=24.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-06 21:45:11,310 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6032;   R @ 50: 0.6590;   R @ 100: 0.6737;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6913; ngR @ 50: 0.8168; ngR @ 100: 0.8828;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0289;  zR @ 100: 0.0467;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1218;  mR @ 50: 0.1520;  mR @ 100: 0.1610;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.0723) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.4349) (attached to:0.0000) (behind:0.5148) (belonging to:0.0000) (between:0.0000) (carrying:0.1754) (covered in:0.0000) (covering:0.0000) (eating:0.2381) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8116) (holding:0.6128) (in:0.3678) (in front of:0.1040) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4648) (of:0.4305) (on:0.9065) (on back of:0.0455) (over:0.0732) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4271) (says:0.0000) (sitting on:0.2866) (standing on:0.0109) (to:0.0000) (under:0.2615) (using:0.1923) (walking in:0.0000) (walking on:0.1717) (watching:0.3039) (wearing:0.9766) (wears:0.0000) (with:0.1229) \n",
      "SGG eval:   A @ 20: 0.6985;   A @ 50: 0.7033;   A @ 100: 0.7033;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-06 21:45:12,049 maskrcnn_benchmark INFO: Validation Result: 0.6737\n",
      "2020-06-06 21:47:59,091 maskrcnn_benchmark INFO: eta: 12:59:16  iter: 4200  loss: 0.1414 (0.1359)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1414 (0.1359)  time: 0.8359 (1.0209)  data: 0.0175 (0.2005)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 21:50:46,509 maskrcnn_benchmark INFO: eta: 12:49:31  iter: 4400  loss: 0.1218 (0.1357)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1218 (0.1357)  time: 0.8262 (1.0125)  data: 0.0163 (0.1921)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 21:53:33,524 maskrcnn_benchmark INFO: eta: 12:40:18  iter: 4600  loss: 0.1307 (0.1355)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1307 (0.1355)  time: 0.8315 (1.0048)  data: 0.0167 (0.1845)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 21:56:21,204 maskrcnn_benchmark INFO: eta: 12:31:44  iter: 4800  loss: 0.1232 (0.1355)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1232 (0.1355)  time: 0.8394 (0.9979)  data: 0.0161 (0.1775)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 21:59:07,104 maskrcnn_benchmark INFO: eta: 12:23:21  iter: 5000  loss: 0.1226 (0.1353)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1226 (0.1353)  time: 0.8378 (0.9911)  data: 0.0165 (0.1710)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 22:01:54,107 maskrcnn_benchmark INFO: eta: 12:15:34  iter: 5200  loss: 0.1343 (0.1350)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1343 (0.1350)  time: 0.8276 (0.9851)  data: 0.0167 (0.1651)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 22:04:40,134 maskrcnn_benchmark INFO: eta: 12:08:01  iter: 5400  loss: 0.1379 (0.1349)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1379 (0.1349)  time: 0.8364 (0.9794)  data: 0.0161 (0.1596)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 22:07:26,783 maskrcnn_benchmark INFO: eta: 12:00:53  iter: 5600  loss: 0.1395 (0.1347)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1395 (0.1347)  time: 0.8261 (0.9742)  data: 0.0167 (0.1545)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 22:10:13,418 maskrcnn_benchmark INFO: eta: 11:54:03  iter: 5800  loss: 0.1371 (0.1346)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1371 (0.1346)  time: 0.8344 (0.9693)  data: 0.0153 (0.1497)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 22:12:59,923 maskrcnn_benchmark INFO: eta: 11:47:29  iter: 6000  loss: 0.1283 (0.1345)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1283 (0.1345)  time: 0.8294 (0.9648)  data: 0.0169 (0.1452)  lr: 0.120000  max mem: 6112\n",
      "2020-06-06 22:12:59,926 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0006000.pth\n",
      "  0%|                                                  | 0/2500 [00:00<?, ?it/s]2020-06-06 22:13:02,649 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-06 22:13:02,693 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:46<00:00,  8.72it/s]   | 1700/2500 [03:16<01:26,  9.26it/s]\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:49<00:00,  8.64it/s]\n",
      "2020-06-06 22:17:49,348 maskrcnn_benchmark INFO: Total run time: 0:04:46.654371 (0.11466174840927124 s / img per device, on 2 devices)\n",
      "2020-06-06 22:17:49,348 maskrcnn_benchmark INFO: Model inference time: 0:04:18.928373 (0.10357134904861451 s / img per device, on 2 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.48s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=24.77s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.16s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 22:19:28,313 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6023;   R @ 50: 0.6577;   R @ 100: 0.6736;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6929; ngR @ 50: 0.8186; ngR @ 100: 0.8849;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0089;  zR @ 50: 0.0222;  zR @ 100: 0.0267;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1286;  mR @ 50: 0.1578;  mR @ 100: 0.1680;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1433) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1524) (attached to:0.0000) (behind:0.4792) (belonging to:0.0000) (between:0.0000) (carrying:0.6228) (covered in:0.0000) (covering:0.0000) (eating:0.3810) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8130) (holding:0.5321) (in:0.3623) (in front of:0.0644) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5649) (of:0.4582) (on:0.8821) (on back of:0.0455) (over:0.1057) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3467) (says:0.0000) (sitting on:0.3351) (standing on:0.0152) (to:0.0000) (under:0.2538) (using:0.0385) (walking in:0.0000) (walking on:0.5199) (watching:0.1275) (wearing:0.9692) (wears:0.0000) (with:0.1055) \n",
      "SGG eval:   A @ 20: 0.7001;   A @ 50: 0.7047;   A @ 100: 0.7047;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-06 22:19:29,046 maskrcnn_benchmark INFO: Validation Result: 0.6736\n",
      "2020-06-06 22:22:15,750 maskrcnn_benchmark INFO: eta: 12:26:59  iter: 6200  loss: 0.1153 (0.1343)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1153 (0.1343)  time: 0.8311 (1.0233)  data: 0.0171 (0.2038)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:25:02,615 maskrcnn_benchmark INFO: eta: 12:19:17  iter: 6400  loss: 0.1229 (0.1343)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1229 (0.1343)  time: 0.8282 (1.0174)  data: 0.0164 (0.1980)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:27:50,451 maskrcnn_benchmark INFO: eta: 12:11:59  iter: 6600  loss: 0.1160 (0.1341)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1160 (0.1341)  time: 0.8316 (1.0120)  data: 0.0159 (0.1925)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:30:37,732 maskrcnn_benchmark INFO: eta: 12:04:54  iter: 6800  loss: 0.1134 (0.1339)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1134 (0.1339)  time: 0.8408 (1.0068)  data: 0.0171 (0.1873)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:33:25,064 maskrcnn_benchmark INFO: eta: 11:58:04  iter: 7000  loss: 0.1153 (0.1337)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1153 (0.1337)  time: 0.8248 (1.0020)  data: 0.0158 (0.1824)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:36:12,312 maskrcnn_benchmark INFO: eta: 11:51:26  iter: 7200  loss: 0.1288 (0.1337)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1288 (0.1337)  time: 0.8260 (0.9974)  data: 0.0162 (0.1778)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:38:59,877 maskrcnn_benchmark INFO: eta: 11:45:03  iter: 7400  loss: 0.1245 (0.1335)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1245 (0.1335)  time: 0.8206 (0.9930)  data: 0.0148 (0.1734)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:41:48,110 maskrcnn_benchmark INFO: eta: 11:38:55  iter: 7600  loss: 0.1283 (0.1334)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1283 (0.1334)  time: 0.8364 (0.9890)  data: 0.0164 (0.1693)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:44:35,178 maskrcnn_benchmark INFO: eta: 11:32:51  iter: 7800  loss: 0.1144 (0.1333)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1144 (0.1333)  time: 0.8383 (0.9851)  data: 0.0156 (0.1654)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:47:22,106 maskrcnn_benchmark INFO: ---Total norm 0.07148 clip coef 69.95044-----------------\n",
      "2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.03135, (torch.Size([4096, 12544]))\n",
      "2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.02887, (torch.Size([4096, 12544]))\n",
      "2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02535, (torch.Size([51, 4096]))\n",
      "2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.02411, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-06 22:47:22,114 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01982, (torch.Size([4096, 4096]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01834, (torch.Size([4096, 4096]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01772, (torch.Size([4096, 1024]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01580, (torch.Size([512, 1024]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01489, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01279, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01272, (torch.Size([2048, 4808]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01233, (torch.Size([2048, 4808]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00441, (torch.Size([22801, 51]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00362, (torch.Size([51]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00298, (torch.Size([512]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00230, (torch.Size([2048, 512]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00208, (torch.Size([2048, 512]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00208, (torch.Size([128]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00192, (torch.Size([1024, 512]))\n",
      "2020-06-06 22:47:22,115 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00165, (torch.Size([256]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00132, (torch.Size([4096]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00131, (torch.Size([2048, 4424]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00127, (torch.Size([2048, 4424]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00127, (torch.Size([512, 1024]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00123, (torch.Size([256]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00121, (torch.Size([128]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00107, (torch.Size([4096]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00082, (torch.Size([2048]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00082, (torch.Size([2048]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00076, (torch.Size([2048]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00076, (torch.Size([2048]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00074, (torch.Size([151, 200]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00068, (torch.Size([1024]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00062, (torch.Size([256]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00053, (torch.Size([4096]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00048, (torch.Size([4096]))\n",
      "2020-06-06 22:47:22,116 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00045, (torch.Size([128]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00029, (torch.Size([512]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00024, (torch.Size([256]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00016, (torch.Size([4096]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00014, (torch.Size([2048, 512]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00014, (torch.Size([2048, 512]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00007, (torch.Size([32, 9]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00006, (torch.Size([128, 32]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00004, (torch.Size([2048]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00004, (torch.Size([2048]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00004, (torch.Size([2048]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00004, (torch.Size([2048]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00003, (torch.Size([151, 200]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00001, (torch.Size([32]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-06 22:47:22,117 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-06 22:47:22,120 maskrcnn_benchmark INFO: eta: 11:26:56  iter: 8000  loss: 0.1250 (0.1332)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1250 (0.1332)  time: 0.8329 (0.9813)  data: 0.0173 (0.1616)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:47:22,122 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0008000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2500 [00:00<?, ?it/s]2020-06-06 22:47:24,646 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-06 22:47:24,670 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:44<00:00,  8.78it/s]\n",
      "100%|███████████████████████████████████████| 2500/2500 [04:47<00:00,  8.71it/s]\n",
      "2020-06-06 22:52:09,321 maskrcnn_benchmark INFO: Total run time: 0:04:44.650700 (0.11386027994155884 s / img per device, on 2 devices)\n",
      "2020-06-06 22:52:09,321 maskrcnn_benchmark INFO: Model inference time: 0:04:20.262586 (0.10410503435134888 s / img per device, on 2 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.54s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=5.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-06 22:54:11,138 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6083;   R @ 50: 0.6601;   R @ 100: 0.6759;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6957; ngR @ 50: 0.8224; ngR @ 100: 0.8873;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0267;  zR @ 100: 0.0400;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1140;  mR @ 50: 0.1395;  mR @ 100: 0.1489;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.0865) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1389) (attached to:0.0000) (behind:0.4310) (belonging to:0.0000) (between:0.0000) (carrying:0.5768) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8197) (holding:0.5501) (in:0.3751) (in front of:0.1420) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5191) (of:0.3947) (on:0.9155) (on back of:0.0455) (over:0.0976) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1830) (says:0.0000) (sitting on:0.2526) (standing on:0.0130) (to:0.0000) (under:0.2538) (using:0.1923) (walking in:0.0000) (walking on:0.0473) (watching:0.2941) (wearing:0.9718) (wears:0.0000) (with:0.0987) \n",
      "SGG eval:   A @ 20: 0.7014;   A @ 50: 0.7062;   A @ 100: 0.7062;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-06 22:54:11,882 maskrcnn_benchmark INFO: Validation Result: 0.6759\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "2020-06-06 22:56:59,227 maskrcnn_benchmark INFO: eta: 11:56:01  iter: 8200  loss: 0.1405 (0.1331)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1405 (0.1331)  time: 0.8383 (1.0278)  data: 0.0169 (0.2081)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 22:59:48,083 maskrcnn_benchmark INFO: eta: 11:49:34  iter: 8400  loss: 0.1108 (0.1329)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1108 (0.1329)  time: 0.8421 (1.0234)  data: 0.0162 (0.2035)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 23:02:36,522 maskrcnn_benchmark INFO: eta: 11:43:14  iter: 8600  loss: 0.1344 (0.1328)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1344 (0.1328)  time: 0.8420 (1.0192)  data: 0.0166 (0.1992)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 23:05:24,869 maskrcnn_benchmark INFO: eta: 11:37:04  iter: 8800  loss: 0.1360 (0.1327)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1360 (0.1327)  time: 0.8467 (1.0152)  data: 0.0156 (0.1950)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 23:08:13,820 maskrcnn_benchmark INFO: eta: 11:31:06  iter: 9000  loss: 0.1178 (0.1326)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1178 (0.1326)  time: 0.8245 (1.0114)  data: 0.0166 (0.1910)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 23:11:02,009 maskrcnn_benchmark INFO: eta: 11:25:13  iter: 9200  loss: 0.1231 (0.1325)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1325)  time: 0.8477 (1.0077)  data: 0.0133 (0.1872)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 23:13:50,129 maskrcnn_benchmark INFO: eta: 11:19:27  iter: 9400  loss: 0.1281 (0.1326)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1281 (0.1326)  time: 0.8459 (1.0041)  data: 0.0157 (0.1836)  lr: 0.120000  max mem: 6146\n",
      "2020-06-06 23:16:37,289 maskrcnn_benchmark INFO: eta: 11:13:44  iter: 9600  loss: 0.1307 (0.1326)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1307 (0.1326)  time: 0.8309 (1.0006)  data: 0.0150 (0.1801)  lr: 0.120000  max mem: 6146\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "    model = train(cfg, args.local_rank, args.distributed, logger)\n",
      "  File \"tools/relation_train_net.py\", line 147, in train\n",
      "    loss_dict = model(images, targets)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 445, in forward\n",
      "    output = self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py\", line 49, in forward\n",
      "    features = self.backbone(images.tensors)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/modeling/backbone/resnet.py\", line 149, in forward\n",
      "    x = getattr(self, stage_name)(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/modeling/backbone/resnet.py\", line 341, in forward\n",
      "    out += identity\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/wrap.py\", line 53, in wrapper\n",
      "    return orig_fn(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "    model = train(cfg, args.local_rank, args.distributed, logger)\n",
      "  File \"tools/relation_train_net.py\", line 147, in train\n",
      "    loss_dict = model(images, targets)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 445, in forward\n",
      "    output = self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py\", line 49, in forward\n",
      "    features = self.backbone(images.tensors)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/modeling/backbone/resnet.py\", line 149, in forward\n",
      "    x = getattr(self, stage_name)(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/modeling/backbone/resnet.py\", line 335, in forward\n",
      "    out = self.conv3(out)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/layers/misc.py\", line 33, in forward\n",
      "    return super(Conv2d, self).forward(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 349, in forward\n",
      "    return self._conv_forward(input, self.weight)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 346, in _conv_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/wrap.py\", line 27, in wrapper\n",
      "    kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/utils.py\", line 81, in casted_args\n",
      "    new_args.append(cast_fn(x))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/utils.py\", line 63, in maybe_half\n",
      "    return x.half()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10025 --nproc_per_node=8 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \\\n",
    "SOLVER.IMS_PER_BATCH 12 TEST.IMS_PER_BATCH 2 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/motif-precls-exmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T15:44:23.928065Z",
     "start_time": "2020-06-07T09:28:41.189854Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-07 09:28:55,274 maskrcnn_benchmark INFO: Using 8 GPUs\n",
      "2020-06-07 09:28:55,274 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '48', 'TEST.IMS_PER_BATCH', '16', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '30000', 'SOLVER.VAL_PERIOD', '5000', 'SOLVER.CHECKPOINT_PERIOD', '5000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp'], skip_test=False)\n",
      "2020-06-07 09:28:55,274 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-07 09:28:59,747 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n",
      "2020-06-07 09:28:59,748 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml\n",
      "2020-06-07 09:28:59,748 maskrcnn_benchmark INFO: \n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MAX_SIZE_TEST: 1000\n",
      "MODEL:\n",
      "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
      "  WEIGHT: \"catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\"\n",
      "  BACKBONE:\n",
      "    CONV_BODY: \"R-101-FPN\" # VGG-16\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    STRIDE_IN_1X1: False\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RELATION_ON: True\n",
      "  ATTRIBUTE_ON: False\n",
      "  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false\n",
      "  RPN:\n",
      "    USE_FPN: True\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    RPN_MID_CHANNEL: 256\n",
      "  ROI_HEADS:\n",
      "    USE_FPN: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "  ROI_BOX_HEAD:\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA\n",
      "    MLP_HEAD_DIM: 4096\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight\n",
      "    POS_WEIGHT: 50.0\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA\n",
      "    MAX_ATTRIBUTES: 10             \n",
      "    ATTRIBUTE_BGFG_SAMPLE: True    \n",
      "    ATTRIBUTE_BGFG_RATIO: 3        \n",
      "  ROI_RELATION_HEAD:\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing\n",
      "    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain \"to the left of\" & \"to the right of\")\n",
      "    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    FEATURE_EXTRACTOR: \"RelationFeatureExtractor\"\n",
      "    #################### Select Relationship Model ####################\n",
      "    #PREDICTOR: \"MotifPredictor\"\n",
      "    #PREDICTOR: \"VCTreePredictor\"\n",
      "    #PREDICTOR: \"TransformerPredictor\"\n",
      "    PREDICTOR: \"CausalAnalysisPredictor\"\n",
      "    ################# Parameters for Motif Predictor ##################\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    ############# Parameters for Causal Unbias Predictor ##############\n",
      "    ### Implementation for paper \"Unbiased Scene Graph Generation from Biased Training\"\n",
      "    CAUSAL:\n",
      "      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'\n",
      "      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         \n",
      "      SEPARATE_SPATIAL: False         # separate spatial in union feature\n",
      "      CONTEXT_LAYER: \"motifs\"         # candicates: motifs, vctree, vtranse\n",
      "      SPATIAL_FOR_VISION: True\n",
      "      EFFECT_ANALYSIS: True\n",
      "    ############### Parameters for Transformer Predictor ##############\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      NUM_HEAD: 8\n",
      "      KEY_DIM: 64\n",
      "      VAL_DIM: 64\n",
      "      INNER_DIM: 2048 \n",
      "DATASETS:\n",
      "  TRAIN: (\"VG_stanford_filtered_with_attribute_train\",)\n",
      "  VAL: (\"VG_stanford_filtered_with_attribute_val\",)\n",
      "  TEST: (\"VG_stanford_filtered_with_attribute_test\",)\n",
      "DATALOADER:\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "SOLVER:\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  BASE_LR: 0.01\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  MOMENTUM: 0.9\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  STEPS: (10000, 16000)\n",
      "  MAX_ITER: 40000\n",
      "  VAL_PERIOD: 2000\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    # the following paramters are only used for WarmupReduceLROnPlateau\n",
      "    TYPE: \"WarmupReduceLROnPlateau\"    # WarmupMultiStepLR, WarmupReduceLROnPlateau\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "OUTPUT_DIR: './output/relation_baseline'\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  RELATION:\n",
      "    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem\n",
      "    REQUIRE_OVERLAP: False\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "\n",
      "2020-06-07 09:28:59,751 maskrcnn_benchmark INFO: Running with config:\n",
      "AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: none\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: MotifPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/motif-precls-exmp\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 48\n",
      "  MAX_ITER: 30000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 5000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 16\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-07 09:28:59,752 maskrcnn_benchmark INFO: Saving config into: checkpoint/motif-precls-exmp/config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 09:28:59,784 maskrcnn_benchmark INFO: #################### prepare training ####################\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "2020-06-07 09:29:03,024 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-07 09:29:03,024 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2020-06-07 09:29:03,025 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-07 09:29:03,025 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-07 09:29:04,233 maskrcnn_benchmark INFO: #################### end model construction ####################\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-07 09:29:04,643 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "2020-06-07 09:29:04,714 maskrcnn_benchmark INFO: #################### end distributed ####################\n",
      "2020-06-07 09:29:04,717 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/motif-precls-exmp/model_0008000.pth\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-07 09:29:06,815 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/motif-precls-exmp/model_0008000.pth\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-07 09:29:07,471 maskrcnn_benchmark INFO: #################### end load checkpointer ####################\n",
      "2020-06-07 09:29:07,471 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "2020-06-07 09:29:10,118 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/motif-precls-exmp/labels.json\n",
      "2020-06-07 09:29:10,166 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]2020-06-07 09:29:11,292 maskrcnn_benchmark INFO: #################### end dataloader ####################\n",
      "2020-06-07 09:29:11,292 maskrcnn_benchmark INFO: Validate before training\n",
      "2020-06-07 09:29:11,295 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s][DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s][DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] load_image_filenames(...) OK\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.43it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:11<00:00,  4.38it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.42it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.45it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:09<00:00,  4.50it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.42it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.44it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:11<00:00,  4.38it/s]\n",
      "2020-06-07 09:30:22,887 maskrcnn_benchmark INFO: Total run time: 0:01:11.592203 (0.11454752540588378 s / img per device, on 8 devices)\n",
      "2020-06-07 09:30:22,888 maskrcnn_benchmark INFO: Model inference time: 0:00:56.318217 (0.09010914726257324 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.97s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.30s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-07 09:32:07,844 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6082;   R @ 50: 0.6603;   R @ 100: 0.6760;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6954; ngR @ 50: 0.8225; ngR @ 100: 0.8873;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0267;  zR @ 100: 0.0400;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1140;  mR @ 50: 0.1396;  mR @ 100: 0.1486;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.0865) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1389) (attached to:0.0000) (behind:0.4310) (belonging to:0.0000) (between:0.0000) (carrying:0.5636) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8206) (holding:0.5501) (in:0.3751) (in front of:0.1374) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5191) (of:0.3947) (on:0.9157) (on back of:0.0455) (over:0.0976) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1830) (says:0.0000) (sitting on:0.2526) (standing on:0.0130) (to:0.0000) (under:0.2538) (using:0.1923) (walking in:0.0000) (walking on:0.0485) (watching:0.2941) (wearing:0.9718) (wears:0.0000) (with:0.1006) \n",
      "SGG eval:   A @ 20: 0.7016;   A @ 50: 0.7063;   A @ 100: 0.7063;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-07 09:32:08,493 maskrcnn_benchmark INFO: Start training\n",
      "2020-06-07 09:32:10,316 maskrcnn_benchmark INFO: ---Total norm 0.05643 clip coef 88.60008-----------------\n",
      "2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.02425, (torch.Size([4096, 12544]))\n",
      "2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.02289, (torch.Size([4096, 12544]))\n",
      "2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02120, (torch.Size([51, 4096]))\n",
      "2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.02110, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01560, (torch.Size([4096, 4096]))\n",
      "2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01476, (torch.Size([4096, 4096]))\n",
      "2020-06-07 09:32:10,325 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01305, (torch.Size([4096, 1024]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01134, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01128, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01069, (torch.Size([512, 1024]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.00741, (torch.Size([2048, 4808]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.00721, (torch.Size([2048, 4808]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00432, (torch.Size([51]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00379, (torch.Size([512]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00379, (torch.Size([22801, 51]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00162, (torch.Size([1024, 512]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00158, (torch.Size([128]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00154, (torch.Size([2048, 512]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00139, (torch.Size([256]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00135, (torch.Size([4096]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00123, (torch.Size([2048, 512]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00097, (torch.Size([256]))\n",
      "2020-06-07 09:32:10,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00095, (torch.Size([4096]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00093, (torch.Size([2048]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00093, (torch.Size([2048]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00092, (torch.Size([1024]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00090, (torch.Size([128]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00079, (torch.Size([2048]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00079, (torch.Size([2048]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00059, (torch.Size([2048, 4424]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00059, (torch.Size([512, 1024]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00058, (torch.Size([2048, 4424]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00054, (torch.Size([151, 200]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00050, (torch.Size([256]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00048, (torch.Size([4096]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00042, (torch.Size([4096]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00037, (torch.Size([128]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00032, (torch.Size([512]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00019, (torch.Size([256]))\n",
      "2020-06-07 09:32:10,327 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00014, (torch.Size([4096]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00007, (torch.Size([2048, 512]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00006, (torch.Size([2048, 512]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00005, (torch.Size([2048]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00005, (torch.Size([2048]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00004, (torch.Size([128, 32]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00003, (torch.Size([2048]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00003, (torch.Size([2048]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00003, (torch.Size([32, 9]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00002, (torch.Size([151, 200]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00001, (torch.Size([32]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 09:32:10,328 maskrcnn_benchmark INFO: -------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 09:35:16,944 maskrcnn_benchmark INFO: eta: 5:42:21  iter: 8200  loss: 0.1226 (0.1285)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1226 (0.1285)  time: 0.9399 (0.9422)  data: 0.0215 (0.0240)  lr: 0.480000  max mem: 5820\n",
      "2020-06-07 09:38:25,069 maskrcnn_benchmark INFO: eta: 5:38:55  iter: 8400  loss: 0.1248 (0.1287)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1248 (0.1287)  time: 0.9379 (0.9414)  data: 0.0210 (0.0223)  lr: 0.480000  max mem: 5943\n",
      "2020-06-07 09:41:32,638 maskrcnn_benchmark INFO: eta: 5:35:21  iter: 8600  loss: 0.1252 (0.1292)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1252 (0.1292)  time: 0.9337 (0.9402)  data: 0.0218 (0.0215)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 09:44:40,807 maskrcnn_benchmark INFO: eta: 5:32:16  iter: 8800  loss: 0.1240 (0.1293)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1240 (0.1293)  time: 0.9424 (0.9404)  data: 0.0203 (0.0213)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 09:47:48,586 maskrcnn_benchmark INFO: eta: 5:29:01  iter: 9000  loss: 0.1340 (0.1291)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1340 (0.1291)  time: 0.9352 (0.9401)  data: 0.0225 (0.0213)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 09:50:56,721 maskrcnn_benchmark INFO: eta: 5:25:55  iter: 9200  loss: 0.1292 (0.1290)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1292 (0.1290)  time: 0.9370 (0.9402)  data: 0.0189 (0.0211)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 09:54:04,367 maskrcnn_benchmark INFO: eta: 5:22:42  iter: 9400  loss: 0.1269 (0.1291)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1269 (0.1291)  time: 0.9367 (0.9399)  data: 0.0205 (0.0209)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 09:57:12,187 maskrcnn_benchmark INFO: eta: 5:19:32  iter: 9600  loss: 0.1235 (0.1292)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1235 (0.1292)  time: 0.9303 (0.9398)  data: 0.0209 (0.0210)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:00:19,764 maskrcnn_benchmark INFO: eta: 5:16:19  iter: 9800  loss: 0.1231 (0.1290)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1290)  time: 0.9318 (0.9396)  data: 0.0211 (0.0209)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:03:27,953 maskrcnn_benchmark INFO: eta: 5:13:14  iter: 10000  loss: 0.1314 (0.1290)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1314 (0.1290)  time: 0.9378 (0.9397)  data: 0.0213 (0.0208)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:03:27,956 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0010000.pth\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]2020-06-07 10:03:30,426 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-07 10:03:30,455 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.31it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.31it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.31it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.31it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.31it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.31it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.31it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.45it/s]\n",
      "2020-06-07 10:04:40,750 maskrcnn_benchmark INFO: Total run time: 0:01:10.293523 (0.11246963729858399 s / img per device, on 8 devices)\n",
      "2020-06-07 10:04:40,750 maskrcnn_benchmark INFO: Model inference time: 0:00:56.796546 (0.09087447395324708 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.57s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=28.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-07 10:06:29,598 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6004;   R @ 50: 0.6576;   R @ 100: 0.6735;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6891; ngR @ 50: 0.8209; ngR @ 100: 0.8870;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0356;  zR @ 100: 0.0533;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1058;  mR @ 50: 0.1302;  mR @ 100: 0.1408;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2127) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1237) (attached to:0.0000) (behind:0.4773) (belonging to:0.0000) (between:0.0000) (carrying:0.1425) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8294) (holding:0.5773) (in:0.3578) (in front of:0.0787) (laying on:0.0000) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5812) (of:0.4709) (on:0.8928) (on back of:0.0455) (over:0.0610) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1696) (says:0.0000) (sitting on:0.2068) (standing on:0.0109) (to:0.0000) (under:0.2398) (using:0.1154) (walking in:0.0000) (walking on:0.0000) (watching:0.2843) (wearing:0.9730) (wears:0.0000) (with:0.0797) \n",
      "SGG eval:   A @ 20: 0.6979;   A @ 50: 0.7026;   A @ 100: 0.7026;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-07 10:06:30,385 maskrcnn_benchmark INFO: Validation Result: 0.6735\n",
      "2020-06-07 10:09:38,228 maskrcnn_benchmark INFO: eta: 5:37:27  iter: 10200  loss: 0.1252 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1252 (0.1288)  time: 0.9439 (1.0226)  data: 0.0206 (0.1035)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:12:46,214 maskrcnn_benchmark INFO: eta: 5:31:48  iter: 10400  loss: 0.1361 (0.1289)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1361 (0.1289)  time: 0.9355 (1.0157)  data: 0.0212 (0.0967)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:15:53,955 maskrcnn_benchmark INFO: eta: 5:26:29  iter: 10600  loss: 0.1219 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1219 (0.1288)  time: 0.9357 (1.0098)  data: 0.0209 (0.0908)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:19:01,456 maskrcnn_benchmark INFO: eta: 5:21:28  iter: 10800  loss: 0.1223 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1223 (0.1288)  time: 0.9394 (1.0046)  data: 0.0191 (0.0857)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:22:09,694 maskrcnn_benchmark INFO: eta: 5:16:47  iter: 11000  loss: 0.1202 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1202 (0.1288)  time: 0.9410 (1.0004)  data: 0.0206 (0.0814)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:25:17,366 maskrcnn_benchmark INFO: eta: 5:12:14  iter: 11200  loss: 0.1270 (0.1289)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1270 (0.1289)  time: 0.9378 (0.9965)  data: 0.0220 (0.0775)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:28:24,817 maskrcnn_benchmark INFO: eta: 5:07:50  iter: 11400  loss: 0.1260 (0.1289)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1260 (0.1289)  time: 0.9352 (0.9930)  data: 0.0203 (0.0741)  lr: 0.480000  max mem: 6096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 10:31:32,804 maskrcnn_benchmark INFO: eta: 5:03:37  iter: 11600  loss: 0.1302 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1302 (0.1288)  time: 0.9409 (0.9901)  data: 0.0210 (0.0712)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:34:40,676 maskrcnn_benchmark INFO: eta: 4:59:30  iter: 11800  loss: 0.1373 (0.1289)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1373 (0.1289)  time: 0.9307 (0.9874)  data: 0.0200 (0.0684)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:37:48,742 maskrcnn_benchmark INFO: ---Total norm 0.08505 clip coef 58.78942-----------------\n",
      "2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.04588, (torch.Size([4096, 12544]))\n",
      "2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.03735, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.03207, (torch.Size([4096, 12544]))\n",
      "2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02796, (torch.Size([51, 4096]))\n",
      "2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01836, (torch.Size([4096, 4096]))\n",
      "2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01533, (torch.Size([4096, 4096]))\n",
      "2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01473, (torch.Size([2048, 4808]))\n",
      "2020-06-07 10:37:48,751 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01442, (torch.Size([512, 1024]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01399, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01399, (torch.Size([4096, 1024]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01330, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01197, (torch.Size([2048, 4808]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00766, (torch.Size([1024, 512]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00665, (torch.Size([51]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00482, (torch.Size([22801, 51]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00420, (torch.Size([128]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00364, (torch.Size([4096]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00330, (torch.Size([512]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00270, (torch.Size([1024]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00262, (torch.Size([128]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00232, (torch.Size([256]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00228, (torch.Size([2048, 512]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00210, (torch.Size([2048, 512]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00207, (torch.Size([256]))\n",
      "2020-06-07 10:37:48,752 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00185, (torch.Size([256]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00161, (torch.Size([128]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00108, (torch.Size([2048]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00108, (torch.Size([2048]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00104, (torch.Size([4096]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00102, (torch.Size([2048]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00102, (torch.Size([2048]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00065, (torch.Size([4096]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00052, (torch.Size([4096]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00030, (torch.Size([256]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00028, (torch.Size([4096]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00023, (torch.Size([151, 200]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00014, (torch.Size([512]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00014, (torch.Size([512, 1024]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00009, (torch.Size([2048, 4424]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00008, (torch.Size([2048, 4424]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00001, (torch.Size([2048]))\n",
      "2020-06-07 10:37:48,753 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00001, (torch.Size([2048]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00001, (torch.Size([2048]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00001, (torch.Size([2048]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00001, (torch.Size([2048, 512]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 10:37:48,754 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-07 10:37:48,757 maskrcnn_benchmark INFO: eta: 4:55:31  iter: 12000  loss: 0.1270 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1270 (0.1288)  time: 0.9319 (0.9851)  data: 0.0212 (0.0660)  lr: 0.480000  max mem: 6096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 10:40:56,564 maskrcnn_benchmark INFO: eta: 4:51:35  iter: 12200  loss: 0.1206 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1206 (0.1288)  time: 0.9360 (0.9829)  data: 0.0188 (0.0638)  lr: 0.480000  max mem: 6096\n",
      "2020-06-07 10:44:05,119 maskrcnn_benchmark INFO: eta: 4:47:46  iter: 12400  loss: 0.1265 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1265 (0.1288)  time: 0.9357 (0.9811)  data: 0.0198 (0.0618)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 10:47:13,270 maskrcnn_benchmark INFO: eta: 4:43:59  iter: 12600  loss: 0.1222 (0.1288)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1222 (0.1288)  time: 0.9465 (0.9793)  data: 0.0207 (0.0600)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 10:50:21,516 maskrcnn_benchmark INFO: eta: 4:40:16  iter: 12800  loss: 0.1214 (0.1287)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1214 (0.1287)  time: 0.9373 (0.9777)  data: 0.0216 (0.0583)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 10:53:29,257 maskrcnn_benchmark INFO: eta: 4:36:34  iter: 13000  loss: 0.1263 (0.1287)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1263 (0.1287)  time: 0.9365 (0.9762)  data: 0.0196 (0.0568)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 10:56:37,549 maskrcnn_benchmark INFO: eta: 4:32:56  iter: 13200  loss: 0.1324 (0.1287)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1324 (0.1287)  time: 0.9389 (0.9748)  data: 0.0182 (0.0553)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 10:59:45,724 maskrcnn_benchmark INFO: eta: 4:29:21  iter: 13400  loss: 0.1221 (0.1286)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1221 (0.1286)  time: 0.9373 (0.9736)  data: 0.0183 (0.0540)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:02:53,419 maskrcnn_benchmark INFO: eta: 4:25:45  iter: 13600  loss: 0.1275 (0.1286)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1275 (0.1286)  time: 0.9348 (0.9723)  data: 0.0219 (0.0528)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:06:01,420 maskrcnn_benchmark INFO: eta: 4:22:13  iter: 13800  loss: 0.1177 (0.1286)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1177 (0.1286)  time: 0.9424 (0.9712)  data: 0.0212 (0.0517)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:09:09,495 maskrcnn_benchmark INFO: eta: 4:18:42  iter: 14000  loss: 0.1228 (0.1285)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1228 (0.1285)  time: 0.9387 (0.9702)  data: 0.0203 (0.0506)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:12:17,800 maskrcnn_benchmark INFO: eta: 4:15:14  iter: 14200  loss: 0.1277 (0.1284)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1277 (0.1284)  time: 0.9439 (0.9692)  data: 0.0216 (0.0497)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:15:25,731 maskrcnn_benchmark INFO: eta: 4:11:45  iter: 14400  loss: 0.1238 (0.1284)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1238 (0.1284)  time: 0.9341 (0.9683)  data: 0.0212 (0.0488)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:18:33,749 maskrcnn_benchmark INFO: eta: 4:08:18  iter: 14600  loss: 0.1282 (0.1284)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1282 (0.1284)  time: 0.9322 (0.9675)  data: 0.0187 (0.0479)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:21:42,047 maskrcnn_benchmark INFO: eta: 4:04:53  iter: 14800  loss: 0.1247 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1247 (0.1283)  time: 0.9423 (0.9667)  data: 0.0205 (0.0471)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:24:49,896 maskrcnn_benchmark INFO: eta: 4:01:28  iter: 15000  loss: 0.1242 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1242 (0.1283)  time: 0.9373 (0.9659)  data: 0.0213 (0.0463)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:24:49,899 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0015000.pth\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]2020-06-07 11:24:52,202 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-07 11:24:52,232 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.32it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.32it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.32it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.32it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.32it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.32it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.32it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.45it/s]\n",
      "2020-06-07 11:26:02,553 maskrcnn_benchmark INFO: Total run time: 0:01:10.319793 (0.11251166915893554 s / img per device, on 8 devices)\n",
      "2020-06-07 11:26:02,553 maskrcnn_benchmark INFO: Model inference time: 0:00:57.106029 (0.09136964645385742 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.75s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.35s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-07 11:27:47,880 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6094;   R @ 50: 0.6626;   R @ 100: 0.6793;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6966; ngR @ 50: 0.8242; ngR @ 100: 0.8894;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0178;  zR @ 50: 0.0400;  zR @ 100: 0.0511;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1231;  mR @ 50: 0.1459;  mR @ 100: 0.1581;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1430) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1616) (attached to:0.0000) (behind:0.4602) (belonging to:0.0000) (between:0.0000) (carrying:0.3618) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8248) (holding:0.6315) (in:0.3674) (in front of:0.1328) (laying on:0.0000) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5242) (of:0.4365) (on:0.9050) (on back of:0.0455) (over:0.1179) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.5759) (says:0.0000) (sitting on:0.3390) (standing on:0.0152) (to:0.0000) (under:0.2092) (using:0.0769) (walking in:0.0000) (walking on:0.0146) (watching:0.3333) (wearing:0.9773) (wears:0.0000) (with:0.1052) \n",
      "SGG eval:   A @ 20: 0.7017;   A @ 50: 0.7067;   A @ 100: 0.7067;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-07 11:27:48,651 maskrcnn_benchmark INFO: Validation Result: 0.6793\n",
      "2020-06-07 11:30:56,284 maskrcnn_benchmark INFO: eta: 4:04:11  iter: 15200  loss: 0.1246 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1246 (0.1283)  time: 0.9387 (0.9900)  data: 0.0216 (0.0704)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:34:04,066 maskrcnn_benchmark INFO: eta: 4:00:33  iter: 15400  loss: 0.1202 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1202 (0.1283)  time: 0.9351 (0.9886)  data: 0.0221 (0.0691)  lr: 0.480000  max mem: 6348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 11:37:12,219 maskrcnn_benchmark INFO: eta: 3:56:57  iter: 15600  loss: 0.1259 (0.1282)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1259 (0.1282)  time: 0.9397 (0.9873)  data: 0.0207 (0.0678)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:40:20,368 maskrcnn_benchmark INFO: eta: 3:53:23  iter: 15800  loss: 0.1312 (0.1282)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1312 (0.1282)  time: 0.9362 (0.9861)  data: 0.0215 (0.0666)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:43:28,561 maskrcnn_benchmark INFO: ---Total norm 0.06679 clip coef 74.86314-----------------\n",
      "2020-06-07 11:43:28,570 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.02997, (torch.Size([4096, 12544]))\n",
      "2020-06-07 11:43:28,570 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.02533, (torch.Size([4096, 12544]))\n",
      "2020-06-07 11:43:28,570 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.02448, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02440, (torch.Size([51, 4096]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01603, (torch.Size([4096, 4096]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01534, (torch.Size([2048, 4808]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01516, (torch.Size([512, 1024]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01397, (torch.Size([2048, 4808]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01277, (torch.Size([4096, 4096]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01165, (torch.Size([4096, 1024]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01005, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00933, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00902, (torch.Size([1024, 512]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00855, (torch.Size([51]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00710, (torch.Size([256]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00472, (torch.Size([4096]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00447, (torch.Size([512]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00422, (torch.Size([1024]))\n",
      "2020-06-07 11:43:28,571 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00402, (torch.Size([128]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00304, (torch.Size([22801, 51]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00238, (torch.Size([2048, 512]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00211, (torch.Size([2048, 512]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00209, (torch.Size([256]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00188, (torch.Size([128]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00172, (torch.Size([128]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00160, (torch.Size([4096]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00142, (torch.Size([256]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00118, (torch.Size([2048]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00118, (torch.Size([2048]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00105, (torch.Size([2048]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00105, (torch.Size([2048]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00098, (torch.Size([4096]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00052, (torch.Size([4096]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00027, (torch.Size([256]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00019, (torch.Size([4096]))\n",
      "2020-06-07 11:43:28,572 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00005, (torch.Size([512]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00004, (torch.Size([151, 200]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00003, (torch.Size([512, 1024]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 11:43:28,573 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 11:43:28,574 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 11:43:28,574 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-07 11:43:28,576 maskrcnn_benchmark INFO: eta: 3:49:50  iter: 16000  loss: 0.1337 (0.1281)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1337 (0.1281)  time: 0.9357 (0.9850)  data: 0.0204 (0.0654)  lr: 0.480000  max mem: 6348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "2020-06-07 11:46:36,549 maskrcnn_benchmark INFO: eta: 3:46:17  iter: 16200  loss: 0.1163 (0.1281)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1163 (0.1281)  time: 0.9400 (0.9839)  data: 0.0190 (0.0643)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:49:44,244 maskrcnn_benchmark INFO: eta: 3:42:46  iter: 16400  loss: 0.1195 (0.1281)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1195 (0.1281)  time: 0.9337 (0.9828)  data: 0.0176 (0.0632)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:52:52,147 maskrcnn_benchmark INFO: eta: 3:39:16  iter: 16600  loss: 0.1243 (0.1280)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1243 (0.1280)  time: 0.9375 (0.9818)  data: 0.0206 (0.0622)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:56:00,434 maskrcnn_benchmark INFO: eta: 3:35:47  iter: 16800  loss: 0.1261 (0.1280)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1261 (0.1280)  time: 0.9365 (0.9809)  data: 0.0184 (0.0613)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 11:59:08,273 maskrcnn_benchmark INFO: eta: 3:32:19  iter: 17000  loss: 0.1308 (0.1280)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1308 (0.1280)  time: 0.9358 (0.9800)  data: 0.0185 (0.0603)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:02:16,656 maskrcnn_benchmark INFO: eta: 3:28:53  iter: 17200  loss: 0.1231 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1279)  time: 0.9492 (0.9791)  data: 0.0207 (0.0595)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:05:24,277 maskrcnn_benchmark INFO: eta: 3:25:26  iter: 17400  loss: 0.1240 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1240 (0.1279)  time: 0.9397 (0.9783)  data: 0.0202 (0.0586)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:08:31,922 maskrcnn_benchmark INFO: eta: 3:22:00  iter: 17600  loss: 0.1222 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1222 (0.1279)  time: 0.9318 (0.9774)  data: 0.0214 (0.0578)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:11:39,412 maskrcnn_benchmark INFO: eta: 3:18:34  iter: 17800  loss: 0.1171 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1171 (0.1279)  time: 0.9383 (0.9766)  data: 0.0198 (0.0570)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:14:47,512 maskrcnn_benchmark INFO: eta: 3:15:10  iter: 18000  loss: 0.1247 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1247 (0.1279)  time: 0.9350 (0.9759)  data: 0.0197 (0.0563)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:17:55,661 maskrcnn_benchmark INFO: eta: 3:11:47  iter: 18200  loss: 0.1213 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1213 (0.1279)  time: 0.9410 (0.9752)  data: 0.0208 (0.0556)  lr: 0.480000  max mem: 6348\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
      "2020-06-07 12:21:03,716 maskrcnn_benchmark INFO: eta: 3:08:24  iter: 18400  loss: 0.1286 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1286 (0.1279)  time: 0.9383 (0.9745)  data: 0.0214 (0.0549)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:24:11,537 maskrcnn_benchmark INFO: eta: 3:05:02  iter: 18600  loss: 0.1272 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1272 (0.1279)  time: 0.9336 (0.9739)  data: 0.0214 (0.0543)  lr: 0.480000  max mem: 6348\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "2020-06-07 12:27:19,750 maskrcnn_benchmark INFO: eta: 3:01:40  iter: 18800  loss: 0.1246 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1246 (0.1279)  time: 0.9383 (0.9733)  data: 0.0205 (0.0537)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:30:27,876 maskrcnn_benchmark INFO: eta: 2:58:19  iter: 19000  loss: 0.1283 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1283 (0.1279)  time: 0.9421 (0.9727)  data: 0.0198 (0.0530)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:33:35,780 maskrcnn_benchmark INFO: eta: 2:54:58  iter: 19200  loss: 0.1210 (0.1279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1210 (0.1279)  time: 0.9354 (0.9721)  data: 0.0217 (0.0525)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:36:43,717 maskrcnn_benchmark INFO: eta: 2:51:38  iter: 19400  loss: 0.1217 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1217 (0.1278)  time: 0.9433 (0.9715)  data: 0.0210 (0.0519)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:39:51,881 maskrcnn_benchmark INFO: eta: 2:48:18  iter: 19600  loss: 0.1232 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1232 (0.1278)  time: 0.9359 (0.9710)  data: 0.0218 (0.0513)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:42:59,852 maskrcnn_benchmark INFO: eta: 2:44:58  iter: 19800  loss: 0.1296 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1296 (0.1278)  time: 0.9308 (0.9705)  data: 0.0212 (0.0508)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:46:07,939 maskrcnn_benchmark INFO: ---Total norm 0.04749 clip coef 105.28213-----------------\n",
      "2020-06-07 12:46:07,948 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.02456, (torch.Size([4096, 12544]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.02112, (torch.Size([4096, 12544]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.01927, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.01477, (torch.Size([51, 4096]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01022, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00995, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.00939, (torch.Size([4096, 4096]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.00859, (torch.Size([4096, 4096]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.00736, (torch.Size([4096, 1024]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.00725, (torch.Size([2048, 4808]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.00584, (torch.Size([512, 1024]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00499, (torch.Size([1024, 512]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.00468, (torch.Size([2048, 4808]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00412, (torch.Size([51]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00370, (torch.Size([128]))\n",
      "2020-06-07 12:46:07,949 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00287, (torch.Size([22801, 51]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00277, (torch.Size([4096]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00167, (torch.Size([1024]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00157, (torch.Size([256]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00142, (torch.Size([256]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00137, (torch.Size([256]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00127, (torch.Size([512]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00123, (torch.Size([2048, 512]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00114, (torch.Size([128]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00112, (torch.Size([128]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00077, (torch.Size([2048, 512]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00077, (torch.Size([4096]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00052, (torch.Size([2048]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00052, (torch.Size([2048]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00036, (torch.Size([4096]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00026, (torch.Size([2048]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00026, (torch.Size([2048]))\n",
      "2020-06-07 12:46:07,950 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00025, (torch.Size([4096]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00015, (torch.Size([256]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00013, (torch.Size([4096]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00001, (torch.Size([512]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00001, (torch.Size([151, 200]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00001, (torch.Size([512, 1024]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-07 12:46:07,951 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 12:46:07,952 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 12:46:07,952 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 12:46:07,952 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-07 12:46:07,952 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-07 12:46:07,954 maskrcnn_benchmark INFO: eta: 2:41:39  iter: 20000  loss: 0.1225 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1225 (0.1278)  time: 0.9354 (0.9700)  data: 0.0177 (0.0503)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:46:07,957 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0020000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]2020-06-07 12:46:10,449 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-07 12:46:10,475 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.30it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.30it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.30it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.30it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.30it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.30it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.30it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.45it/s]\n",
      "2020-06-07 12:47:20,850 maskrcnn_benchmark INFO: Total run time: 0:01:10.374361 (0.11259897727966309 s / img per device, on 8 devices)\n",
      "2020-06-07 12:47:20,851 maskrcnn_benchmark INFO: Model inference time: 0:00:56.837251 (0.09093960189819336 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=27.49s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-07 12:49:09,149 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6015;   R @ 50: 0.6606;   R @ 100: 0.6759;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6895; ngR @ 50: 0.8207; ngR @ 100: 0.8882;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0178;  zR @ 50: 0.0444;  zR @ 100: 0.0622;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1167;  mR @ 50: 0.1445;  mR @ 100: 0.1535;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1917) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1528) (attached to:0.0000) (behind:0.4743) (belonging to:0.0000) (between:0.0000) (carrying:0.2259) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8299) (holding:0.6165) (in:0.3550) (in front of:0.0573) (laying on:0.0000) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5594) (of:0.4526) (on:0.9000) (on back of:0.0455) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4241) (says:0.0000) (sitting on:0.2893) (standing on:0.0109) (to:0.0000) (under:0.2015) (using:0.1923) (walking in:0.0000) (walking on:0.0000) (watching:0.3529) (wearing:0.9757) (wears:0.0000) (with:0.0925) \n",
      "SGG eval:   A @ 20: 0.6996;   A @ 50: 0.7045;   A @ 100: 0.7045;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-07 12:49:09,920 maskrcnn_benchmark INFO: Validation Result: 0.6759\n",
      "2020-06-07 12:52:17,630 maskrcnn_benchmark INFO: eta: 2:40:46  iter: 20200  loss: 0.1280 (0.1278)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1280 (0.1278)  time: 0.9374 (0.9844)  data: 0.0216 (0.0647)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:55:25,640 maskrcnn_benchmark INFO: eta: 2:37:22  iter: 20400  loss: 0.1292 (0.1277)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1292 (0.1277)  time: 0.9392 (0.9836)  data: 0.0209 (0.0640)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 12:58:33,556 maskrcnn_benchmark INFO: eta: 2:33:59  iter: 20600  loss: 0.1243 (0.1277)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1243 (0.1277)  time: 0.9359 (0.9829)  data: 0.0201 (0.0633)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:01:41,668 maskrcnn_benchmark INFO: eta: 2:30:36  iter: 20800  loss: 0.1314 (0.1277)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1314 (0.1277)  time: 0.9450 (0.9823)  data: 0.0206 (0.0626)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:04:49,805 maskrcnn_benchmark INFO: eta: 2:27:14  iter: 21000  loss: 0.1219 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1219 (0.1276)  time: 0.9337 (0.9816)  data: 0.0184 (0.0620)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:07:58,012 maskrcnn_benchmark INFO: eta: 2:23:53  iter: 21200  loss: 0.1261 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1261 (0.1276)  time: 0.9445 (0.9810)  data: 0.0221 (0.0613)  lr: 0.480000  max mem: 6348\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "2020-06-07 13:11:06,523 maskrcnn_benchmark INFO: eta: 2:20:31  iter: 21400  loss: 0.1163 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1163 (0.1276)  time: 0.9423 (0.9804)  data: 0.0189 (0.0607)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:14:14,716 maskrcnn_benchmark INFO: eta: 2:17:10  iter: 21600  loss: 0.1261 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1261 (0.1276)  time: 0.9398 (0.9799)  data: 0.0212 (0.0602)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:17:23,132 maskrcnn_benchmark INFO: eta: 2:13:50  iter: 21800  loss: 0.1207 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1207 (0.1276)  time: 0.9328 (0.9793)  data: 0.0203 (0.0596)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:20:31,095 maskrcnn_benchmark INFO: eta: 2:10:30  iter: 22000  loss: 0.1253 (0.1276)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1253 (0.1276)  time: 0.9365 (0.9788)  data: 0.0222 (0.0590)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:23:39,444 maskrcnn_benchmark INFO: eta: 2:07:10  iter: 22200  loss: 0.1250 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1250 (0.1275)  time: 0.9355 (0.9782)  data: 0.0226 (0.0585)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:26:47,379 maskrcnn_benchmark INFO: eta: 2:03:50  iter: 22400  loss: 0.1221 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1221 (0.1275)  time: 0.9322 (0.9777)  data: 0.0211 (0.0579)  lr: 0.480000  max mem: 6348\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 13:29:55,207 maskrcnn_benchmark INFO: eta: 2:00:31  iter: 22600  loss: 0.1250 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1250 (0.1275)  time: 0.9407 (0.9772)  data: 0.0183 (0.0574)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:33:03,114 maskrcnn_benchmark INFO: eta: 1:57:11  iter: 22800  loss: 0.1281 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1281 (0.1275)  time: 0.9329 (0.9767)  data: 0.0212 (0.0569)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:36:11,307 maskrcnn_benchmark INFO: eta: 1:53:53  iter: 23000  loss: 0.1251 (0.1275)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1251 (0.1275)  time: 0.9391 (0.9762)  data: 0.0199 (0.0564)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:39:18,980 maskrcnn_benchmark INFO: eta: 1:50:34  iter: 23200  loss: 0.1257 (0.1274)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1257 (0.1274)  time: 0.9276 (0.9757)  data: 0.0170 (0.0559)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:42:26,772 maskrcnn_benchmark INFO: eta: 1:47:16  iter: 23400  loss: 0.1234 (0.1274)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1234 (0.1274)  time: 0.9328 (0.9752)  data: 0.0218 (0.0555)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:45:34,362 maskrcnn_benchmark INFO: eta: 1:43:58  iter: 23600  loss: 0.1211 (0.1274)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1211 (0.1274)  time: 0.9253 (0.9747)  data: 0.0180 (0.0550)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:48:42,499 maskrcnn_benchmark INFO: eta: 1:40:40  iter: 23800  loss: 0.1126 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1126 (0.1273)  time: 0.9381 (0.9743)  data: 0.0217 (0.0546)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:51:50,859 maskrcnn_benchmark INFO: ---Total norm 0.06503 clip coef 76.88617-----------------\n",
      "2020-06-07 13:51:50,868 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.03521, (torch.Size([4096, 12544]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.02866, (torch.Size([4096, 12544]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.02707, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02008, (torch.Size([51, 4096]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01455, (torch.Size([4096, 4096]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01396, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01115, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.01095, (torch.Size([4096, 4096]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01008, (torch.Size([4096, 1024]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.00717, (torch.Size([2048, 4808]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00700, (torch.Size([1024, 512]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.00698, (torch.Size([512, 1024]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.00650, (torch.Size([2048, 4808]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00506, (torch.Size([128]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00320, (torch.Size([4096]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00319, (torch.Size([51]))\n",
      "2020-06-07 13:51:50,869 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00315, (torch.Size([22801, 51]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00230, (torch.Size([128]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00219, (torch.Size([1024]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00201, (torch.Size([256]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00182, (torch.Size([256]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00178, (torch.Size([256]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00163, (torch.Size([2048, 512]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00148, (torch.Size([128]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00133, (torch.Size([512]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00125, (torch.Size([4096]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00118, (torch.Size([2048, 512]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00059, (torch.Size([4096]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00053, (torch.Size([2048]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00053, (torch.Size([2048]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00045, (torch.Size([2048]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00045, (torch.Size([2048]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00025, (torch.Size([256]))\n",
      "2020-06-07 13:51:50,870 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00025, (torch.Size([4096]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00017, (torch.Size([4096]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00001, (torch.Size([512]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00001, (torch.Size([512, 1024]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 13:51:50,871 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 13:51:50,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-07 13:51:50,872 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-07 13:51:50,872 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-07 13:51:50,874 maskrcnn_benchmark INFO: eta: 1:37:23  iter: 24000  loss: 0.1266 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1266 (0.1273)  time: 0.9427 (0.9739)  data: 0.0205 (0.0541)  lr: 0.480000  max mem: 6348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 13:54:58,804 maskrcnn_benchmark INFO: eta: 1:34:06  iter: 24200  loss: 0.1227 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1227 (0.1273)  time: 0.9322 (0.9735)  data: 0.0190 (0.0537)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 13:58:06,439 maskrcnn_benchmark INFO: eta: 1:30:49  iter: 24400  loss: 0.1317 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1317 (0.1273)  time: 0.9342 (0.9730)  data: 0.0213 (0.0533)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 14:01:14,423 maskrcnn_benchmark INFO: eta: 1:27:32  iter: 24600  loss: 0.1231 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1231 (0.1273)  time: 0.9319 (0.9726)  data: 0.0187 (0.0529)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 14:04:22,394 maskrcnn_benchmark INFO: eta: 1:24:15  iter: 24800  loss: 0.1246 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1246 (0.1273)  time: 0.9393 (0.9723)  data: 0.0209 (0.0525)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 14:07:29,998 maskrcnn_benchmark INFO: eta: 1:20:59  iter: 25000  loss: 0.1242 (0.1273)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1242 (0.1273)  time: 0.9337 (0.9719)  data: 0.0192 (0.0521)  lr: 0.480000  max mem: 6348\n",
      "2020-06-07 14:07:30,001 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0025000.pth\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]2020-06-07 14:07:32,358 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-07 14:07:32,385 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.33it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.33it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.33it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.33it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.33it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.33it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.47it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:12<00:00,  4.32it/s]\n",
      "2020-06-07 14:08:42,495 maskrcnn_benchmark INFO: Total run time: 0:01:10.110314 (0.1121765022277832 s / img per device, on 8 devices)\n",
      "2020-06-07 14:08:42,496 maskrcnn_benchmark INFO: Model inference time: 0:00:56.887012 (0.0910192195892334 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.30s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-07 14:10:26,754 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6069;   R @ 50: 0.6599;   R @ 100: 0.6751;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6963; ngR @ 50: 0.8241; ngR @ 100: 0.8911;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0089;  zR @ 50: 0.0311;  zR @ 100: 0.0400;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1181;  mR @ 50: 0.1402;  mR @ 100: 0.1530;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1344) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1642) (attached to:0.0000) (behind:0.4409) (belonging to:0.0000) (between:0.0000) (carrying:0.2061) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0221) (has:0.8271) (holding:0.6293) (in:0.3907) (in front of:0.1398) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5256) (of:0.5075) (on:0.8912) (on back of:0.0455) (over:0.1057) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4390) (says:0.0000) (sitting on:0.3194) (standing on:0.0109) (to:0.0000) (under:0.2054) (using:0.0385) (walking in:0.0000) (walking on:0.0128) (watching:0.3137) (wearing:0.9766) (wears:0.0000) (with:0.0785) \n",
      "SGG eval:   A @ 20: 0.6995;   A @ 50: 0.7042;   A @ 100: 0.7042;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-07 14:10:27,520 maskrcnn_benchmark INFO: Validation Result: 0.6751\n",
      "2020-06-07 14:10:27,520 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "2020-06-07 14:13:34,821 maskrcnn_benchmark INFO: eta: 1:18:32  iter: 25200  loss: 0.1185 (0.1272)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1185 (0.1272)  time: 0.9319 (0.9818)  data: 0.0208 (0.0621)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:16:42,682 maskrcnn_benchmark INFO: eta: 1:15:13  iter: 25400  loss: 0.1220 (0.1272)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1220 (0.1272)  time: 0.9327 (0.9813)  data: 0.0214 (0.0616)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:19:51,192 maskrcnn_benchmark INFO: eta: 1:11:55  iter: 25600  loss: 0.1179 (0.1271)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1179 (0.1271)  time: 0.9351 (0.9808)  data: 0.0198 (0.0611)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:22:58,836 maskrcnn_benchmark INFO: eta: 1:08:37  iter: 25800  loss: 0.1186 (0.1271)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1186 (0.1271)  time: 0.9374 (0.9804)  data: 0.0191 (0.0607)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:26:06,225 maskrcnn_benchmark INFO: eta: 1:05:19  iter: 26000  loss: 0.1133 (0.1270)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1133 (0.1270)  time: 0.9341 (0.9799)  data: 0.0221 (0.0602)  lr: 0.048000  max mem: 6348\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "2020-06-07 14:29:14,046 maskrcnn_benchmark INFO: eta: 1:02:01  iter: 26200  loss: 0.1178 (0.1270)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1178 (0.1270)  time: 0.9383 (0.9794)  data: 0.0183 (0.0598)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:32:21,786 maskrcnn_benchmark INFO: eta: 0:58:44  iter: 26400  loss: 0.1170 (0.1269)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1170 (0.1269)  time: 0.9280 (0.9790)  data: 0.0227 (0.0594)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:35:29,597 maskrcnn_benchmark INFO: eta: 0:55:27  iter: 26600  loss: 0.1191 (0.1268)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1191 (0.1268)  time: 0.9326 (0.9786)  data: 0.0202 (0.0589)  lr: 0.048000  max mem: 6348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 14:38:37,211 maskrcnn_benchmark INFO: eta: 0:52:09  iter: 26800  loss: 0.1179 (0.1268)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1179 (0.1268)  time: 0.9365 (0.9781)  data: 0.0169 (0.0585)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:41:45,145 maskrcnn_benchmark INFO: eta: 0:48:53  iter: 27000  loss: 0.1128 (0.1267)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1128 (0.1267)  time: 0.9391 (0.9777)  data: 0.0200 (0.0581)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:44:52,670 maskrcnn_benchmark INFO: eta: 0:45:36  iter: 27200  loss: 0.1182 (0.1266)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1182 (0.1266)  time: 0.9331 (0.9773)  data: 0.0172 (0.0577)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:48:00,420 maskrcnn_benchmark INFO: eta: 0:42:19  iter: 27400  loss: 0.1144 (0.1266)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1144 (0.1266)  time: 0.9361 (0.9769)  data: 0.0198 (0.0573)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:51:08,454 maskrcnn_benchmark INFO: eta: 0:39:03  iter: 27600  loss: 0.1234 (0.1265)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1234 (0.1265)  time: 0.9360 (0.9765)  data: 0.0211 (0.0569)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:54:15,996 maskrcnn_benchmark INFO: eta: 0:35:47  iter: 27800  loss: 0.1133 (0.1264)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1133 (0.1264)  time: 0.9356 (0.9761)  data: 0.0158 (0.0565)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 14:57:23,634 maskrcnn_benchmark INFO: ---Total norm 0.10416 clip coef 48.00386-----------------\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.07262, (torch.Size([4096, 12544]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.04291, (torch.Size([4096, 12544]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.03709, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.weight: 0.02448, (torch.Size([51, 4096]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.02064, (torch.Size([4096, 4096]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.02000, (torch.Size([4096, 4096]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.01288, (torch.Size([2048, 4808]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.weight: 0.01267, (torch.Size([4096, 1024]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01185, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.01138, (torch.Size([2048, 4808]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01053, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-07 14:57:23,643 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.00809, (torch.Size([512, 1024]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.00776, (torch.Size([1024, 512]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.bias : 0.00411, (torch.Size([4096]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00396, (torch.Size([128]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00389, (torch.Size([256]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00321, (torch.Size([1024]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00282, (torch.Size([22801, 51]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00220, (torch.Size([2048, 512]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00215, (torch.Size([512]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00191, (torch.Size([256]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00190, (torch.Size([2048, 512]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00186, (torch.Size([128]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.rel_compress.bias: 0.00185, (torch.Size([51]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00164, (torch.Size([256]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00144, (torch.Size([4096]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00121, (torch.Size([128]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00082, (torch.Size([2048]))\n",
      "2020-06-07 14:57:23,644 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00082, (torch.Size([2048]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00079, (torch.Size([4096]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00072, (torch.Size([2048]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00072, (torch.Size([2048]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00068, (torch.Size([4096]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00040, (torch.Size([4096]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00037, (torch.Size([256]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00000, (torch.Size([512]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00000, (torch.Size([512, 1024]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00000, (torch.Size([2048, 4424]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 14:57:23,645 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-07 14:57:23,646 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-07 14:57:23,649 maskrcnn_benchmark INFO: eta: 0:32:31  iter: 28000  loss: 0.1215 (0.1264)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1215 (0.1264)  time: 0.9423 (0.9758)  data: 0.0169 (0.0562)  lr: 0.048000  max mem: 6348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 15:00:31,388 maskrcnn_benchmark INFO: eta: 0:29:15  iter: 28200  loss: 0.1089 (0.1263)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1089 (0.1263)  time: 0.9403 (0.9754)  data: 0.0207 (0.0558)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:03:39,611 maskrcnn_benchmark INFO: eta: 0:26:00  iter: 28400  loss: 0.1158 (0.1262)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1158 (0.1262)  time: 0.9452 (0.9751)  data: 0.0209 (0.0555)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:06:47,348 maskrcnn_benchmark INFO: eta: 0:22:44  iter: 28600  loss: 0.1196 (0.1261)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1196 (0.1261)  time: 0.9319 (0.9747)  data: 0.0187 (0.0551)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:09:55,423 maskrcnn_benchmark INFO: eta: 0:19:29  iter: 28800  loss: 0.1151 (0.1261)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1151 (0.1261)  time: 0.9405 (0.9744)  data: 0.0191 (0.0548)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:13:02,981 maskrcnn_benchmark INFO: eta: 0:16:14  iter: 29000  loss: 0.1162 (0.1260)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1162 (0.1260)  time: 0.9362 (0.9740)  data: 0.0205 (0.0544)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:16:10,844 maskrcnn_benchmark INFO: eta: 0:12:58  iter: 29200  loss: 0.1175 (0.1259)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1175 (0.1259)  time: 0.9359 (0.9737)  data: 0.0222 (0.0541)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:19:18,547 maskrcnn_benchmark INFO: eta: 0:09:44  iter: 29400  loss: 0.1148 (0.1259)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1148 (0.1259)  time: 0.9323 (0.9734)  data: 0.0198 (0.0538)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:22:26,312 maskrcnn_benchmark INFO: eta: 0:06:29  iter: 29600  loss: 0.1138 (0.1258)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1138 (0.1258)  time: 0.9409 (0.9730)  data: 0.0166 (0.0535)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:25:34,290 maskrcnn_benchmark INFO: eta: 0:03:14  iter: 29800  loss: 0.1080 (0.1257)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1080 (0.1257)  time: 0.9358 (0.9727)  data: 0.0209 (0.0531)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:28:42,750 maskrcnn_benchmark INFO: eta: 0:00:00  iter: 30000  loss: 0.1104 (0.1256)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1104 (0.1256)  time: 0.9429 (0.9725)  data: 0.0213 (0.0528)  lr: 0.048000  max mem: 6348\n",
      "2020-06-07 15:28:42,753 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_0030000.pth\n",
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]2020-06-07 15:28:45,007 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/motif-precls-exmp/model_final.pth\n",
      "2020-06-07 15:28:47,139 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-07 15:28:47,170 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 313/313 [01:14<00:00,  4.19it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:14<00:00,  4.19it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:14<00:00,  4.19it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:14<00:00,  4.19it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:14<00:00,  4.19it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:14<00:00,  4.19it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:14<00:00,  4.19it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [01:10<00:00,  4.44it/s]\n",
      "2020-06-07 15:29:57,678 maskrcnn_benchmark INFO: Total run time: 0:01:10.508072 (0.1128129150390625 s / img per device, on 8 devices)\n",
      "2020-06-07 15:29:57,679 maskrcnn_benchmark INFO: Model inference time: 0:00:56.813555 (0.09090168724060059 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.61s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.43s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-07 15:31:43,694 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.6110;   R @ 50: 0.6661;   R @ 100: 0.6806;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.7037; ngR @ 50: 0.8278; ngR @ 100: 0.8937;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0400;  zR @ 100: 0.0578;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1413;  mR @ 50: 0.1705;  mR @ 100: 0.1837;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1562) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2191) (attached to:0.0000) (behind:0.4659) (belonging to:0.0000) (between:0.0000) (carrying:0.5482) (covered in:0.2024) (covering:0.0000) (eating:0.3810) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.8105) (holding:0.5118) (in:0.3643) (in front of:0.2213) (laying on:0.0000) (looking at:0.1087) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4919) (of:0.4934) (on:0.9014) (on back of:0.0455) (over:0.0854) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4241) (says:0.0000) (sitting on:0.3120) (standing on:0.0283) (to:0.0000) (under:0.2844) (using:0.1923) (walking in:0.0000) (walking on:0.2420) (watching:0.5098) (wearing:0.9766) (wears:0.0000) (with:0.1282) \n",
      "SGG eval:   A @ 20: 0.7038;   A @ 50: 0.7089;   A @ 100: 0.7089;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-07 15:31:44,474 maskrcnn_benchmark INFO: Validation Result: 0.6806\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-07 15:31:44,754 maskrcnn_benchmark INFO: Total training time: 5:59:36.260852 (0.7192 s / it)\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-07 15:31:44,894 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] \n",
      "img_dir datasets/vg/VG_100K \n",
      "image_file datasets/vg/image_data.json\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG][DEBUG] load_image_filenames(...)  load_image_filenames(...)OK \n",
      "OK\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "  0%|                                                  | 0/1654 [00:00<?, ?it/s][DEBUG] load_image_filenames(...) OK\n",
      "[DEBUG] load_image_filenames(...) OK\n",
      "  0%|                                                  | 0/1654 [00:00<?, ?it/s][DEBUG] load_image_filenames(...) OK\n",
      "  0%|                                                  | 0/1653 [00:00<?, ?it/s]2020-06-07 15:31:46,676 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).\n",
      "100%|███████████████████████████████████████| 1653/1653 [06:11<00:00,  4.45it/s]\n",
      "100%|███████████████████████████████████████| 1653/1653 [06:11<00:00,  4.45it/s]\n",
      "100%|███████████████████████████████████████| 1653/1653 [06:11<00:00,  4.45it/s]\n",
      "100%|███████████████████████████████████████| 1653/1653 [06:11<00:00,  4.45it/s]\n",
      "2020-06-07 15:37:58,458 maskrcnn_benchmark INFO: Total run time: 0:06:11.781584 (0.11246512410933353 s / img per device, on 8 devices)\n",
      "2020-06-07 15:37:58,458 maskrcnn_benchmark INFO: Model inference time: 0:05:07.227393 (0.09293727374226497 s / img per device, on 8 devices)\n",
      "2020-06-07 15:37:58,466 maskrcnn_benchmark.inference WARNING: WARNING! WARNING! WARNING! WARNING! WARNING! WARNING!Number of images that were gathered from multiple processes is not a contiguous set. Some images might be missing from the evaluation\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(325526, 7)\n",
      "0/325526\n",
      "DONE (t=2.88s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=128.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=22.69s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.469\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.457\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.466\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 375, in main\n",
      "    run_test(cfg, model, args.distributed, logger)\n",
      "  File \"tools/relation_train_net.py\", line 306, in run_test\n",
      "    logger=logger,\n",
      "  File \"/root/Scene/maskrcnn_benchmark/engine/inference.py\", line 149, in inference\n",
      "    **extra_args)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/__init__.py\", line 27, in evaluate\n",
      "    return vg_evaluation(**args)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/__init__.py\", line 19, in vg_evaluation\n",
      "    iou_types=iou_types,\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/vg_eval.py\", line 155, in do_vg_evaluation\n",
      "    evaluate_relation_of_one_image(groundtruth, prediction, global_container, evaluator)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/vg_eval.py\", line 291, in evaluate_relation_of_one_image\n",
      "    local_container = evaluator['eval_recall'].calculate_recall(global_container, local_container, mode)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/sgg_eval.py\", line 74, in calculate_recall\n",
      "    pred_rels, pred_classes, pred_boxes, pred_scores, obj_scores)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/sgg_eval.py\", line 357, in _triplet\n",
      "    triplets = np.column_stack((classes[sub_id], pred_label, classes[ob_id]))\n",
      "IndexError: index 14 is out of bounds for axis 0 with size 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py\", line 263, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py\", line 259, in main\n",
      "    cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'tools/relation_train_net.py', '--local_rank=7', '--config-file', 'configs/e2e_relation_X_101_32_8_FPN_1x.yaml', 'MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'SOLVER.IMS_PER_BATCH', '48', 'TEST.IMS_PER_BATCH', '16', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '30000', 'SOLVER.VAL_PERIOD', '5000', 'SOLVER.CHECKPOINT_PERIOD', '5000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10025 --nproc_per_node=8 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \\\n",
    "SOLVER.IMS_PER_BATCH 48 TEST.IMS_PER_BATCH 16 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 30000 SOLVER.VAL_PERIOD 5000 SOLVER.CHECKPOINT_PERIOD 5000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/motif-precls-exmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_743-_bXXil"
   },
   "source": [
    "Test Example 1 : (PreCls, Motif Model)\n",
    "~~~\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "python -m torch.distributed.launch \n",
    "--master_port 10027 \n",
    "--nproc_per_node=1\n",
    "\n",
    "tools/relation_test_net.py \n",
    "--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\"\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \n",
    "TEST.IMS_PER_BATCH 1 <----------------------------- must be equal to nproc_per_node\n",
    "DTYPE \"float16\" \n",
    "GLOVE_DIR /home/kaihua/glove \n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoints/motif-precls-exmp \n",
    "OUTPUT_DIR checkpoints/motif-precls-exmp\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T21:42:59.090762Z",
     "start_time": "2020-06-07T21:29:57.142897Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "izO66-4lXYgF",
    "outputId": "fbb63056-c6b4-4d7b-d18a-959db9e3fa44",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-07 21:30:10,825 maskrcnn_benchmark INFO: Using 8 GPUs\n",
      "2020-06-07 21:30:10,825 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: none\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: MotifPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/motif-precls-exmp\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 16\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 32\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-07 21:30:10,826 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-07 21:30:15,987 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "2020-06-07 21:30:19,274 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-07 21:30:19,274 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2020-06-07 21:30:19,275 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-07 21:30:19,275 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ __background__ -> __background__ \n",
      "\n",
      "fail on __background__\n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "2020-06-07 21:30:20,914 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/motif-precls-exmp/model_final.pth\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-07 21:30:23,042 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "  0%|                                                   | 0/828 [00:00<?, ?it/s]2020-06-07 21:30:24,828 maskrcnn_benchmark.inference INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).\n",
      "  0%|                                                   | 0/827 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "100%|█████████████████████████████████████████| 827/827 [05:38<00:00,  2.45it/s]\n",
      "100%|█████████████████████████████████████████| 827/827 [05:38<00:00,  2.44it/s]\n",
      "100%|█████████████████████████████████████████| 827/827 [05:37<00:00,  2.45it/s]\n",
      "100%|█████████████████████████████████████████| 827/827 [05:37<00:00,  2.45it/s]\n",
      "100%|█████████████████████████████████████████| 827/827 [05:37<00:00,  2.45it/s]\n",
      "2020-06-07 21:36:02,828 maskrcnn_benchmark.inference INFO: Total run time: 0:05:37.999834 (0.10224603609536424 s / img per device, on 8 devices)\n",
      "2020-06-07 21:36:02,828 maskrcnn_benchmark.inference INFO: Model inference time: 0:04:40.751338 (0.08492818210846734 s / img per device, on 8 devices)\n",
      "2020-06-07 21:36:02,838 maskrcnn_benchmark.inference WARNING: WARNING! WARNING! WARNING! WARNING! WARNING! WARNING!Number of images that were gathered from multiple processes is not a contiguous set. Some images might be missing from the evaluation\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(325541, 7)\n",
      "0/325541\n",
      "DONE (t=3.31s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=144.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=25.81s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.457\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.466\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
      "index 14 is out of bounds for axis 0 with size 8\n",
      "len(classes) 8\n",
      "sub_id [14  8  6 14  4  6 14  7  8  4  6  7  8 14  4  6 13  7  7  3  4 10  9  8\n",
      " 14  0  0  4  7  4  0  9 14  6  6  5  9  0 13 12  2  9 11 12 14 10  9  6\n",
      "  0  0  3 16 16 14  7 10  5 12  5 16 14 15  6  0 14 16  7 12  1  2  2  5\n",
      "  3 14  4  9 12  7  2 13 13 12  3  8  9 10 15 12 15  2  7  5  6 16  1  7\n",
      "  6 16 12  3 13 15  4  2  2 15 13 16  7 15  6 14  8  8  4  0  8  9  4 11\n",
      " 10  4 13  5 12  2  5  2  0 13  7 11  6 15  6  3  8  5  4  5 12  9  1  5\n",
      "  2  6 13  2 10 13 12 16  3 14 11  7  8  8 11 10  2 13  1  3  4 11 14 10\n",
      "  5  5  5 11 13 12 10  9  1  0 11  5  5  8 12 15  2 11  3 14 12  7  0  9\n",
      "  9 10 15  4 16  1 13 11 10 10  3 16  0  9  2 11 11  5 15  1  1  1  1  6\n",
      "  9 11  3 11  1  3 13  9 10  3  2  6 16  0 12  1  7 13 16  0  3  1 10  2\n",
      "  4 16  1 16  3 11  0 13  1  3 15 15 10 12 15  4 11  9 15 16  1 10  0 15\n",
      " 14 16  8 15  7  8  8  8]\n",
      "len(pred_label) 272\n",
      "ob_id [ 9 13  0  0  0  9  5  0  3  9  5  9 10 16  5 16  8  5 16  8 16  8 14  5\n",
      " 15  7 14  7 15 15  4  7 12 15 12 14  4  6  5  5 12  6  5 14 13 13  5  7\n",
      "  9  5 13 14  9  4 12  5  7  0  4  5 10  7  2 16  3  7  2  9 11 14  5  6\n",
      " 10  2 12 16  7 13  7 14 10  6  5  9  0  3  4  4 14  0  3  8 13  0  5 10\n",
      "  4  4  2 14  3  5 13  9 15  0  7  6  4  9 10 11 12 16  2 12  0 12  3 14\n",
      " 14 10  4  9 16  4  0  3 15  9 11  1  3 16 14  7  2 13 14 12  8 15  3 16\n",
      " 16 11  6  6  7 12 13 15  2  7  7  1 11 15  9  9  8 16 14  4 11  4  1  4\n",
      " 11 15 10 13  0 15 12 13 13  2  6  2  3  1 10  6 13  8  9  6  3  6  8  2\n",
      "  8 16  2  1 12  7 11  0  6  0 12 13 13 10 10 12 10  1 12  9  4 10  2  8\n",
      "  3  3 16 16  8  0  2 11 11 15  1  1 10 10 11  0 14 15  8  3  6 12  2 11\n",
      "  8  3 15  2  1  2 11  1 16 11  8 13 15  1  3  6 15  1 10 11  6  1  1 11\n",
      "  8  1  7  1  8  6 14  4]\n",
      "[ 13  58  76  91 131  13  13  13]\n",
      "[31 31 31 31 31 31 31 31 30 31 31 31 30 31 31 31 20 31 30 20 31 20 20 30\n",
      " 31 20 20 31 30 31 20 20 31 31 31 20 20 20 22 22 30 20 22 20 31 29 22 31\n",
      " 31 22 30 20 31 31 30 22 20 29 20 22 31 20 31 31 31 20 30 29 30 20 30 20\n",
      " 30 31 31 22 20 30 20 20 29 20 22 30 31 30 20 20 20 29 30 20 31 31 22 30\n",
      " 31 20 30 20 30 30 31 30 29 30 20 20 50 30 31 30 30 30 30 29 30 29 30 20\n",
      " 20 31 20 31 29 20 31 29 31 22 30 50 31 30 30 20 30 29 31 31 20 31 43 50\n",
      " 30 31 20 20 20 22 22 31 29 31 20 30 30 30 29 22 20 22 20 20 31 20 30 20\n",
      " 50 50 50 43 22 31 22 22 43 31 20 50 50 30 22 20 30 20 30 50 30 50 20 31\n",
      " 20 22 29 30 22 20  1 30 20 22 30 22 22 22 30 22 43 50 30 30 20 43 29 31\n",
      " 30 43 30 30 20 30 30 22 22 29 29 31 22 22 30 30 31 31 20 30 20 30  8 30\n",
      " 31 30 43 31 29 30 22 33 30 30 20 30 31 30 30 50 30 30 30 22 20 30 30 30\n",
      " 31 30 30 30 30 50 30 20]\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_test_net.py\", line 112, in <module>\n",
      "    main()\n",
      "  File \"tools/relation_test_net.py\", line 106, in main\n",
      "    output_folder=output_folder,\n",
      "  File \"/root/Scene/maskrcnn_benchmark/engine/inference.py\", line 149, in inference\n",
      "    **extra_args)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/__init__.py\", line 27, in evaluate\n",
      "    return vg_evaluation(**args)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/__init__.py\", line 19, in vg_evaluation\n",
      "    iou_types=iou_types,\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/vg_eval.py\", line 155, in do_vg_evaluation\n",
      "    evaluate_relation_of_one_image(groundtruth, prediction, global_container, evaluator)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/vg_eval.py\", line 291, in evaluate_relation_of_one_image\n",
      "    local_container = evaluator['eval_recall'].calculate_recall(global_container, local_container, mode)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/sgg_eval.py\", line 74, in calculate_recall\n",
      "    pred_rels, pred_classes, pred_boxes, pred_scores, obj_scores)\n",
      "  File \"/root/Scene/maskrcnn_benchmark/data/datasets/evaluation/vg/sgg_eval.py\", line 373, in _triplet\n",
      "    triplet_boxes = np.column_stack((boxes[sub_id], boxes[ob_id]))\n",
      "IndexError: index 14 is out of bounds for axis 0 with size 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n",
      "    \"__main__\", mod_spec)\r\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py\", line 263, in <module>\r\n",
      "    main()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py\", line 259, in main\r\n",
      "    cmd=cmd)\r\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'tools/relation_test_net.py', '--local_rank=7', '--config-file', 'configs/e2e_relation_X_101_32_8_FPN_1x.yaml', 'MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'MotifPredictor', 'TEST.IMS_PER_BATCH', '32', 'DTYPE', 'float16', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/motif-precls-exmp']' returned non-zero exit status 1.\r\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10027 --nproc_per_node=8 tools/relation_test_net.py \\\n",
    "--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \\\n",
    "TEST.IMS_PER_BATCH 32 DTYPE \"float16\" \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/motif-precls-exmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T07:56:01.930840Z",
     "start_time": "2020-06-08T07:37:32.714571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-08 07:37:47,271 maskrcnn_benchmark INFO: Using 8 GPUs\n",
      "2020-06-08 07:37:47,271 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: none\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: MotifPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/motif-precls-exmp\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 16\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 8\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-08 07:37:47,272 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-08 07:37:51,920 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "2020-06-08 07:37:55,121 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 07:37:55,121 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2020-06-08 07:37:55,122 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/motif-precls-exmp/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-08 07:37:55,122 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "2020-06-08 07:37:57,506 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/motif-precls-exmp/model_final.pth\n",
      "  0%|                                                  | 0/3306 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                  | 0/3306 [00:00<?, ?it/s]2020-06-08 07:38:01,368 maskrcnn_benchmark.inference INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).\n",
      "  0%|                                                  | 0/3306 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                  | 0/3306 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                  | 0/3306 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:39<00:00,  7.20it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:37<00:00,  7.22it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:39<00:00,  7.19it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:38<00:00,  7.21it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:37<00:00,  7.22it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:38<00:00,  7.21it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:38<00:00,  7.21it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:38<00:00,  7.21it/s]\n",
      "2020-06-08 07:45:40,221 maskrcnn_benchmark.inference INFO: Total run time: 0:07:38.852865 (0.13880446638199473 s / img per device, on 8 devices)\n",
      "2020-06-08 07:45:40,222 maskrcnn_benchmark.inference INFO: Model inference time: 0:05:55.162023 (0.10743765357510185 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(325563, 7)\n",
      "0/325563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=3.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=143.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=19.78s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.659\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.995\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "img id in: 0\n",
      "img id out: 0\n",
      "img id in: 1\n",
      "img id out: 1\n",
      "img id in: 2\n",
      "img id out: 2\n",
      "img id in: 3\n",
      "img id out: 3\n",
      "img id in: 4\n",
      "img id out: 4\n",
      "img id in: 5\n",
      "img id out: 5\n",
      "img id in: 6\n",
      "img id out: 6\n",
      "img id in: 7\n",
      "img id out: 7\n",
      "img id in: 8\n",
      "img id out: 8\n",
      "img id in: 9\n",
      "img id out: 9\n",
      "img id in: 10\n",
      "img id out: 10\n",
      "img id in: 11\n",
      "img id out: 11\n",
      "img id in: 12\n",
      "img id out: 12\n",
      "img id in: 13\n",
      "img id out: 13\n",
      "img id in: 14\n",
      "img id out: 14\n",
      "img id in: 15\n",
      "img id out: 15\n",
      "img id in: 16\n",
      "img id out: 16\n",
      "img id in: 17\n",
      "img id out: 17\n",
      "img id in: 18\n",
      "img id out: 18\n",
      "img id in: 19\n",
      "img id out: 19\n",
      "img id in: 20\n",
      "img id out: 20\n",
      "img id in: 21\n",
      "img id out: 21\n",
      "img id in: 22\n",
      "img id out: 22\n",
      "img id in: 23\n",
      "img id out: 23\n",
      "img id in: 24\n",
      "img id out: 24\n",
      "img id in: 25\n",
      "img id out: 25\n",
      "img id in: 26\n",
      "img id out: 26\n",
      "img id in: 27\n",
      "img id out: 27\n",
      "img id in: 28\n",
      "img id out: 28\n",
      "img id in: 29\n",
      "img id out: 29\n",
      "img id in: 30\n",
      "img id out: 30\n",
      "img id in: 31\n",
      "img id out: 31\n",
      "img id in: 32\n",
      "img id out: 32\n",
      "img id in: 33\n",
      "img id out: 33\n",
      "img id in: 34\n",
      "img id out: 34\n",
      "img id in: 35\n",
      "img id out: 35\n",
      "img id in: 36\n",
      "img id out: 36\n",
      "img id in: 37\n",
      "img id out: 37\n",
      "img id in: 38\n",
      "img id out: 38\n",
      "img id in: 39\n",
      "img id out: 39\n",
      "img id in: 40\n",
      "img id out: 40\n",
      "img id in: 41\n",
      "img id out: 41\n",
      "img id in: 42\n",
      "img id out: 42\n",
      "img id in: 43\n",
      "img id out: 43\n",
      "img id in: 44\n",
      "img id out: 44\n",
      "img id in: 45\n",
      "img id out: 45\n",
      "img id in: 46\n",
      "img id out: 46\n",
      "img id in: 47\n",
      "img id out: 47\n",
      "img id in: 48\n",
      "img id out: 48\n",
      "img id in: 49\n",
      "img id out: 49\n",
      "img id in: 50\n",
      "img id out: 50\n",
      "img id in: 51\n",
      "img id out: 51\n",
      "img id in: 52\n",
      "img id out: 52\n",
      "img id in: 53\n",
      "img id out: 53\n",
      "img id in: 54\n",
      "img id out: 54\n",
      "img id in: 55\n",
      "img id out: 55\n",
      "img id in: 56\n",
      "img id out: 56\n",
      "img id in: 57\n",
      "img id out: 57\n",
      "img id in: 58\n",
      "img id out: 58\n",
      "img id in: 59\n",
      "img id out: 59\n",
      "img id in: 60\n",
      "img id out: 60\n",
      "img id in: 61\n",
      "img id out: 61\n",
      "img id in: 62\n",
      "img id out: 62\n",
      "img id in: 63\n",
      "img id out: 63\n",
      "img id in: 64\n",
      "img id out: 64\n",
      "img id in: 65\n",
      "img id out: 65\n",
      "img id in: 66\n",
      "img id out: 66\n",
      "img id in: 67\n",
      "img id out: 67\n",
      "img id in: 68\n",
      "img id out: 68\n",
      "img id in: 69\n",
      "img id out: 69\n",
      "img id in: 70\n",
      "img id out: 70\n",
      "img id in: 71\n",
      "img id out: 71\n",
      "img id in: 72\n",
      "img id out: 72\n",
      "img id in: 73\n",
      "img id out: 73\n",
      "img id in: 74\n",
      "img id out: 74\n",
      "img id in: 75\n",
      "img id out: 75\n",
      "img id in: 76\n",
      "img id out: 76\n",
      "img id in: 77\n",
      "img id out: 77\n",
      "img id in: 78\n",
      "img id out: 78\n",
      "img id in: 79\n",
      "img id out: 79\n",
      "img id in: 80\n",
      "img id out: 80\n",
      "img id in: 81\n",
      "img id out: 81\n",
      "img id in: 82\n",
      "img id out: 82\n",
      "img id in: 83\n",
      "img id out: 83\n",
      "img id in: 84\n",
      "img id out: 84\n",
      "img id in: 85\n",
      "img id out: 85\n",
      "img id in: 86\n",
      "img id out: 86\n",
      "img id in: 87\n",
      "img id out: 87\n",
      "img id in: 88\n",
      "img id out: 88\n",
      "img id in: 89\n",
      "img id out: 89\n",
      "img id in: 90\n",
      "img id out: 90\n",
      "img id in: 91\n",
      "img id out: 91\n",
      "img id in: 92\n",
      "img id out: 92\n",
      "img id in: 93\n",
      "img id out: 93\n",
      "img id in: 94\n",
      "img id out: 94\n",
      "img id in: 95\n",
      "img id out: 95\n",
      "img id in: 96\n",
      "img id out: 96\n",
      "img id in: 97\n",
      "img id out: 97\n",
      "img id in: 98\n",
      "img id out: 98\n",
      "img id in: 99\n",
      "img id out: 99\n",
      "img id in: 100\n",
      "img id out: 100\n",
      "img id in: 101\n",
      "img id out: 101\n",
      "img id in: 102\n",
      "img id out: 102\n",
      "img id in: 103\n",
      "img id out: 103\n",
      "img id in: 104\n",
      "img id out: 104\n",
      "img id in: 105\n",
      "img id out: 105\n",
      "img id in: 106\n",
      "img id out: 106\n",
      "img id in: 107\n",
      "img id out: 107\n",
      "img id in: 108\n",
      "img id out: 108\n",
      "img id in: 109\n",
      "img id out: 109\n",
      "img id in: 110\n",
      "img id out: 110\n",
      "img id in: 111\n",
      "img id out: 111\n",
      "img id in: 112\n",
      "img id out: 112\n",
      "img id in: 113\n",
      "img id out: 113\n",
      "img id in: 114\n",
      "img id out: 114\n",
      "img id in: 115\n",
      "img id out: 115\n",
      "img id in: 116\n",
      "img id out: 116\n",
      "img id in: 117\n",
      "img id out: 117\n",
      "img id in: 118\n",
      "img id out: 118\n",
      "img id in: 119\n",
      "img id out: 119\n",
      "img id in: 120\n",
      "img id out: 120\n",
      "img id in: 121\n",
      "img id out: 121\n",
      "img id in: 122\n",
      "img id out: 122\n",
      "img id in: 123\n",
      "img id out: 123\n",
      "img id in: 124\n",
      "img id out: 124\n",
      "img id in: 125\n",
      "img id out: 125\n",
      "img id in: 126\n",
      "img id out: 126\n",
      "img id in: 127\n",
      "img id out: 127\n",
      "img id in: 128\n",
      "img id out: 128\n",
      "img id in: 129\n",
      "img id out: 129\n",
      "img id in: 130\n",
      "img id out: 130\n",
      "img id in: 131\n",
      "img id out: 131\n",
      "img id in: 132\n",
      "img id out: 132\n",
      "img id in: 133\n",
      "img id out: 133\n",
      "img id in: 134\n",
      "img id out: 134\n",
      "img id in: 135\n",
      "img id out: 135\n",
      "img id in: 136\n",
      "img id out: 136\n",
      "img id in: 137\n",
      "img id out: 137\n",
      "img id in: 138\n",
      "img id out: 138\n",
      "img id in: 139\n",
      "img id out: 139\n",
      "img id in: 140\n",
      "img id out: 140\n",
      "img id in: 141\n",
      "img id out: 141\n",
      "img id in: 142\n",
      "img id out: 142\n",
      "img id in: 143\n",
      "img id out: 143\n",
      "img id in: 144\n",
      "img id out: 144\n",
      "img id in: 145\n",
      "img id out: 145\n",
      "img id in: 146\n",
      "img id out: 146\n",
      "img id in: 147\n",
      "img id out: 147\n",
      "img id in: 148\n",
      "img id out: 148\n",
      "img id in: 149\n",
      "img id out: 149\n",
      "img id in: 150\n",
      "img id out: 150\n",
      "img id in: 151\n",
      "img id out: 151\n",
      "img id in: 152\n",
      "img id out: 152\n",
      "img id in: 153\n",
      "img id out: 153\n",
      "img id in: 154\n",
      "img id out: 154\n",
      "img id in: 155\n",
      "img id out: 155\n",
      "img id in: 156\n",
      "img id out: 156\n",
      "img id in: 157\n",
      "img id out: 157\n",
      "img id in: 158\n",
      "img id out: 158\n",
      "img id in: 159\n",
      "img id out: 159\n",
      "img id in: 160\n",
      "img id out: 160\n",
      "img id in: 161\n",
      "img id out: 161\n",
      "img id in: 162\n",
      "img id out: 162\n",
      "img id in: 163\n",
      "img id out: 163\n",
      "img id in: 164\n",
      "img id out: 164\n",
      "img id in: 165\n",
      "img id out: 165\n",
      "img id in: 166\n",
      "img id out: 166\n",
      "img id in: 167\n",
      "img id out: 167\n",
      "img id in: 168\n",
      "img id out: 168\n",
      "img id in: 169\n",
      "img id out: 169\n",
      "img id in: 170\n",
      "img id out: 170\n",
      "img id in: 171\n",
      "img id out: 171\n",
      "img id in: 172\n",
      "img id out: 172\n",
      "img id in: 173\n",
      "img id out: 173\n",
      "img id in: 174\n",
      "img id out: 174\n",
      "img id in: 175\n",
      "img id out: 175\n",
      "img id in: 176\n",
      "img id out: 176\n",
      "img id in: 177\n",
      "img id out: 177\n",
      "img id in: 178\n",
      "img id out: 178\n",
      "img id in: 179\n",
      "img id out: 179\n",
      "img id in: 180\n",
      "img id out: 180\n",
      "img id in: 181\n",
      "img id out: 181\n",
      "img id in: 182\n",
      "img id out: 182\n",
      "img id in: 183\n",
      "img id out: 183\n",
      "img id in: 184\n",
      "img id out: 184\n",
      "img id in: 185\n",
      "img id out: 185\n",
      "img id in: 186\n",
      "img id out: 186\n",
      "img id in: 187\n",
      "img id out: 187\n",
      "img id in: 188\n",
      "img id out: 188\n",
      "img id in: 189\n",
      "img id out: 189\n",
      "img id in: 190\n",
      "img id out: 190\n",
      "img id in: 191\n",
      "img id out: 191\n",
      "img id in: 192\n",
      "img id out: 192\n",
      "img id in: 193\n",
      "img id out: 193\n",
      "img id in: 194\n",
      "img id out: 194\n",
      "img id in: 195\n",
      "img id out: 195\n",
      "img id in: 196\n",
      "img id out: 196\n",
      "img id in: 197\n",
      "img id out: 197\n",
      "img id in: 198\n",
      "img id out: 198\n",
      "img id in: 199\n",
      "img id out: 199\n",
      "img id in: 200\n",
      "img id out: 200\n",
      "img id in: 201\n",
      "img id out: 201\n",
      "img id in: 202\n",
      "img id out: 202\n",
      "img id in: 203\n",
      "img id out: 203\n",
      "img id in: 204\n",
      "img id out: 204\n",
      "img id in: 205\n",
      "img id out: 205\n",
      "img id in: 206\n",
      "img id out: 206\n",
      "img id in: 207\n",
      "img id out: 207\n",
      "img id in: 208\n",
      "img id out: 208\n",
      "img id in: 209\n",
      "img id out: 209\n",
      "img id in: 210\n",
      "img id out: 210\n",
      "img id in: 211\n",
      "img id out: 211\n",
      "img id in: 212\n",
      "img id out: 212\n",
      "img id in: 213\n",
      "img id out: 213\n",
      "img id in: 214\n",
      "img id out: 214\n",
      "img id in: 215\n",
      "img id out: 215\n",
      "img id in: 216\n",
      "img id out: 216\n",
      "img id in: 217\n",
      "img id out: 217\n",
      "img id in: 218\n",
      "img id out: 218\n",
      "img id in: 219\n",
      "img id out: 219\n",
      "img id in: 220\n",
      "img id out: 220\n",
      "img id in: 221\n",
      "img id out: 221\n",
      "img id in: 222\n",
      "img id out: 222\n",
      "img id in: 223\n",
      "img id out: 223\n",
      "img id in: 224\n",
      "img id out: 224\n",
      "img id in: 225\n",
      "img id out: 225\n",
      "img id in: 226\n",
      "img id out: 226\n",
      "img id in: 227\n",
      "img id out: 227\n",
      "img id in: 228\n",
      "img id out: 228\n",
      "img id in: 229\n",
      "img id out: 229\n",
      "img id in: 230\n",
      "img id out: 230\n",
      "img id in: 231\n",
      "img id out: 231\n",
      "img id in: 232\n",
      "img id out: 232\n",
      "img id in: 233\n",
      "img id out: 233\n",
      "img id in: 234\n",
      "img id out: 234\n",
      "img id in: 235\n",
      "img id out: 235\n",
      "img id in: 236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 236\n",
      "img id in: 237\n",
      "img id out: 237\n",
      "img id in: 238\n",
      "img id out: 238\n",
      "img id in: 239\n",
      "img id out: 239\n",
      "img id in: 240\n",
      "img id out: 240\n",
      "img id in: 241\n",
      "img id out: 241\n",
      "img id in: 242\n",
      "img id out: 242\n",
      "img id in: 243\n",
      "img id out: 243\n",
      "img id in: 244\n",
      "img id out: 244\n",
      "img id in: 245\n",
      "img id out: 245\n",
      "img id in: 246\n",
      "img id out: 246\n",
      "img id in: 247\n",
      "img id out: 247\n",
      "img id in: 248\n",
      "img id out: 248\n",
      "img id in: 249\n",
      "img id out: 249\n",
      "img id in: 250\n",
      "img id out: 250\n",
      "img id in: 251\n",
      "img id out: 251\n",
      "img id in: 252\n",
      "img id out: 252\n",
      "img id in: 253\n",
      "img id out: 253\n",
      "img id in: 254\n",
      "img id out: 254\n",
      "img id in: 255\n",
      "img id out: 255\n",
      "img id in: 256\n",
      "img id out: 256\n",
      "img id in: 257\n",
      "img id out: 257\n",
      "img id in: 258\n",
      "img id out: 258\n",
      "img id in: 259\n",
      "img id out: 259\n",
      "img id in: 260\n",
      "img id out: 260\n",
      "img id in: 261\n",
      "img id out: 261\n",
      "img id in: 262\n",
      "img id out: 262\n",
      "img id in: 263\n",
      "img id out: 263\n",
      "img id in: 264\n",
      "img id out: 264\n",
      "img id in: 265\n",
      "img id out: 265\n",
      "img id in: 266\n",
      "img id out: 266\n",
      "img id in: 267\n",
      "img id out: 267\n",
      "img id in: 268\n",
      "img id out: 268\n",
      "img id in: 269\n",
      "img id out: 269\n",
      "img id in: 270\n",
      "img id out: 270\n",
      "img id in: 271\n",
      "img id out: 271\n",
      "img id in: 272\n",
      "img id out: 272\n",
      "img id in: 273\n",
      "img id out: 273\n",
      "img id in: 274\n",
      "img id out: 274\n",
      "img id in: 275\n",
      "img id out: 275\n",
      "img id in: 276\n",
      "img id out: 276\n",
      "img id in: 277\n",
      "img id out: 277\n",
      "img id in: 278\n",
      "img id out: 278\n",
      "img id in: 279\n",
      "img id out: 279\n",
      "img id in: 280\n",
      "img id out: 280\n",
      "img id in: 281\n",
      "img id out: 281\n",
      "img id in: 282\n",
      "img id out: 282\n",
      "img id in: 283\n",
      "img id out: 283\n",
      "img id in: 284\n",
      "img id out: 284\n",
      "img id in: 285\n",
      "img id out: 285\n",
      "img id in: 286\n",
      "img id out: 286\n",
      "img id in: 287\n",
      "img id out: 287\n",
      "img id in: 288\n",
      "img id out: 288\n",
      "img id in: 289\n",
      "img id out: 289\n",
      "img id in: 290\n",
      "img id out: 290\n",
      "img id in: 291\n",
      "img id out: 291\n",
      "img id in: 292\n",
      "img id out: 292\n",
      "img id in: 293\n",
      "img id out: 293\n",
      "img id in: 294\n",
      "img id out: 294\n",
      "img id in: 295\n",
      "img id out: 295\n",
      "img id in: 296\n",
      "img id out: 296\n",
      "img id in: 297\n",
      "img id out: 297\n",
      "img id in: 298\n",
      "img id out: 298\n",
      "img id in: 299\n",
      "img id out: 299\n",
      "img id in: 300\n",
      "img id out: 300\n",
      "img id in: 301\n",
      "img id out: 301\n",
      "img id in: 302\n",
      "img id out: 302\n",
      "img id in: 303\n",
      "img id out: 303\n",
      "img id in: 304\n",
      "img id out: 304\n",
      "img id in: 305\n",
      "img id out: 305\n",
      "img id in: 306\n",
      "img id out: 306\n",
      "img id in: 307\n",
      "img id out: 307\n",
      "img id in: 308\n",
      "img id out: 308\n",
      "img id in: 309\n",
      "img id out: 309\n",
      "img id in: 310\n",
      "img id out: 310\n",
      "img id in: 311\n",
      "img id out: 311\n",
      "img id in: 312\n",
      "img id out: 312\n",
      "img id in: 313\n",
      "img id out: 313\n",
      "img id in: 314\n",
      "img id out: 314\n",
      "img id in: 315\n",
      "img id out: 315\n",
      "img id in: 316\n",
      "img id out: 316\n",
      "img id in: 317\n",
      "img id out: 317\n",
      "img id in: 318\n",
      "img id out: 318\n",
      "img id in: 319\n",
      "img id out: 319\n",
      "img id in: 320\n",
      "img id out: 320\n",
      "img id in: 321\n",
      "img id out: 321\n",
      "img id in: 322\n",
      "img id out: 322\n",
      "img id in: 323\n",
      "img id out: 323\n",
      "img id in: 324\n",
      "img id out: 324\n",
      "img id in: 325\n",
      "img id out: 325\n",
      "img id in: 326\n",
      "img id out: 326\n",
      "img id in: 327\n",
      "img id out: 327\n",
      "img id in: 328\n",
      "img id out: 328\n",
      "img id in: 329\n",
      "img id out: 329\n",
      "img id in: 330\n",
      "img id out: 330\n",
      "img id in: 331\n",
      "img id out: 331\n",
      "img id in: 332\n",
      "img id out: 332\n",
      "img id in: 333\n",
      "img id out: 333\n",
      "img id in: 334\n",
      "img id out: 334\n",
      "img id in: 335\n",
      "img id out: 335\n",
      "img id in: 336\n",
      "img id out: 336\n",
      "img id in: 337\n",
      "img id out: 337\n",
      "img id in: 338\n",
      "img id out: 338\n",
      "img id in: 339\n",
      "img id out: 339\n",
      "img id in: 340\n",
      "img id out: 340\n",
      "img id in: 341\n",
      "img id out: 341\n",
      "img id in: 342\n",
      "img id out: 342\n",
      "img id in: 343\n",
      "img id out: 343\n",
      "img id in: 344\n",
      "img id out: 344\n",
      "img id in: 345\n",
      "img id out: 345\n",
      "img id in: 346\n",
      "img id out: 346\n",
      "img id in: 347\n",
      "img id out: 347\n",
      "img id in: 348\n",
      "img id out: 348\n",
      "img id in: 349\n",
      "img id out: 349\n",
      "img id in: 350\n",
      "img id out: 350\n",
      "img id in: 351\n",
      "img id out: 351\n",
      "img id in: 352\n",
      "img id out: 352\n",
      "img id in: 353\n",
      "img id out: 353\n",
      "img id in: 354\n",
      "img id out: 354\n",
      "img id in: 355\n",
      "img id out: 355\n",
      "img id in: 356\n",
      "img id out: 356\n",
      "img id in: 357\n",
      "img id out: 357\n",
      "img id in: 358\n",
      "img id out: 358\n",
      "img id in: 359\n",
      "img id out: 359\n",
      "img id in: 360\n",
      "img id out: 360\n",
      "img id in: 361\n",
      "img id out: 361\n",
      "img id in: 362\n",
      "img id out: 362\n",
      "img id in: 363\n",
      "img id out: 363\n",
      "img id in: 364\n",
      "img id out: 364\n",
      "img id in: 365\n",
      "img id out: 365\n",
      "img id in: 366\n",
      "img id out: 366\n",
      "img id in: 367\n",
      "img id out: 367\n",
      "img id in: 368\n",
      "img id out: 368\n",
      "img id in: 369\n",
      "img id out: 369\n",
      "img id in: 370\n",
      "img id out: 370\n",
      "img id in: 371\n",
      "img id out: 371\n",
      "img id in: 372\n",
      "img id out: 372\n",
      "img id in: 373\n",
      "img id out: 373\n",
      "img id in: 374\n",
      "img id out: 374\n",
      "img id in: 375\n",
      "img id out: 375\n",
      "img id in: 376\n",
      "img id out: 376\n",
      "img id in: 377\n",
      "img id out: 377\n",
      "img id in: 378\n",
      "img id out: 378\n",
      "img id in: 379\n",
      "img id out: 379\n",
      "img id in: 380\n",
      "img id out: 380\n",
      "img id in: 381\n",
      "img id out: 381\n",
      "img id in: 382\n",
      "img id out: 382\n",
      "img id in: 383\n",
      "img id out: 383\n",
      "img id in: 384\n",
      "img id out: 384\n",
      "img id in: 385\n",
      "img id out: 385\n",
      "img id in: 386\n",
      "img id out: 386\n",
      "img id in: 387\n",
      "img id out: 387\n",
      "img id in: 388\n",
      "img id out: 388\n",
      "img id in: 389\n",
      "img id out: 389\n",
      "img id in: 390\n",
      "img id out: 390\n",
      "img id in: 391\n",
      "img id out: 391\n",
      "img id in: 392\n",
      "img id out: 392\n",
      "img id in: 393\n",
      "img id out: 393\n",
      "img id in: 394\n",
      "img id out: 394\n",
      "img id in: 395\n",
      "img id out: 395\n",
      "img id in: 396\n",
      "img id out: 396\n",
      "img id in: 397\n",
      "img id out: 397\n",
      "img id in: 398\n",
      "img id out: 398\n",
      "img id in: 399\n",
      "img id out: 399\n",
      "img id in: 400\n",
      "img id out: 400\n",
      "img id in: 401\n",
      "img id out: 401\n",
      "img id in: 402\n",
      "img id out: 402\n",
      "img id in: 403\n",
      "img id out: 403\n",
      "img id in: 404\n",
      "img id out: 404\n",
      "img id in: 405\n",
      "img id out: 405\n",
      "img id in: 406\n",
      "img id out: 406\n",
      "img id in: 407\n",
      "img id out: 407\n",
      "img id in: 408\n",
      "img id out: 408\n",
      "img id in: 409\n",
      "img id out: 409\n",
      "img id in: 410\n",
      "img id out: 410\n",
      "img id in: 411\n",
      "img id out: 411\n",
      "img id in: 412\n",
      "img id out: 412\n",
      "img id in: 413\n",
      "img id out: 413\n",
      "img id in: 414\n",
      "img id out: 414\n",
      "img id in: 415\n",
      "img id out: 415\n",
      "img id in: 416\n",
      "img id out: 416\n",
      "img id in: 417\n",
      "img id out: 417\n",
      "img id in: 418\n",
      "img id out: 418\n",
      "img id in: 419\n",
      "img id out: 419\n",
      "img id in: 420\n",
      "img id out: 420\n",
      "img id in: 421\n",
      "img id out: 421\n",
      "img id in: 422\n",
      "img id out: 422\n",
      "img id in: 423\n",
      "img id out: 423\n",
      "img id in: 424\n",
      "img id out: 424\n",
      "img id in: 425\n",
      "img id out: 425\n",
      "img id in: 426\n",
      "img id out: 426\n",
      "img id in: 427\n",
      "img id out: 427\n",
      "img id in: 428\n",
      "img id out: 428\n",
      "img id in: 429\n",
      "img id out: 429\n",
      "img id in: 430\n",
      "img id out: 430\n",
      "img id in: 431\n",
      "img id out: 431\n",
      "img id in: 432\n",
      "img id out: 432\n",
      "img id in: 433\n",
      "img id out: 433\n",
      "img id in: 434\n",
      "img id out: 434\n",
      "img id in: 435\n",
      "img id out: 435\n",
      "img id in: 436\n",
      "img id out: 436\n",
      "img id in: 437\n",
      "img id out: 437\n",
      "img id in: 438\n",
      "img id out: 438\n",
      "img id in: 439\n",
      "img id out: 439\n",
      "img id in: 440\n",
      "img id out: 440\n",
      "img id in: 441\n",
      "img id out: 441\n",
      "img id in: 442\n",
      "img id out: 442\n",
      "img id in: 443\n",
      "img id out: 443\n",
      "img id in: 444\n",
      "img id out: 444\n",
      "img id in: 445\n",
      "img id out: 445\n",
      "img id in: 446\n",
      "img id out: 446\n",
      "img id in: 447\n",
      "img id out: 447\n",
      "img id in: 448\n",
      "img id out: 448\n",
      "img id in: 449\n",
      "img id out: 449\n",
      "img id in: 450\n",
      "img id out: 450\n",
      "img id in: 451\n",
      "img id out: 451\n",
      "img id in: 452\n",
      "img id out: 452\n",
      "img id in: 453\n",
      "img id out: 453\n",
      "img id in: 454\n",
      "img id out: 454\n",
      "img id in: 455\n",
      "img id out: 455\n",
      "img id in: 456\n",
      "img id out: 456\n",
      "img id in: 457\n",
      "img id out: 457\n",
      "img id in: 458\n",
      "img id out: 458\n",
      "img id in: 459\n",
      "img id out: 459\n",
      "img id in: 460\n",
      "img id out: 460\n",
      "img id in: 461\n",
      "img id out: 461\n",
      "img id in: 462\n",
      "img id out: 462\n",
      "img id in: 463\n",
      "img id out: 463\n",
      "img id in: 464\n",
      "img id out: 464\n",
      "img id in: 465\n",
      "img id out: 465\n",
      "img id in: 466\n",
      "img id out: 466\n",
      "img id in: 467\n",
      "img id out: 467\n",
      "img id in: 468\n",
      "img id out: 468\n",
      "img id in: 469\n",
      "img id out: 469\n",
      "img id in: 470\n",
      "img id out: 470\n",
      "img id in: 471\n",
      "img id out: 471\n",
      "img id in: 472\n",
      "img id out: 472\n",
      "img id in: 473\n",
      "img id out: 473\n",
      "img id in: 474\n",
      "img id out: 474\n",
      "img id in: 475\n",
      "img id out: 475\n",
      "img id in: 476\n",
      "img id out: 476\n",
      "img id in: 477\n",
      "img id out: 477\n",
      "img id in: 478\n",
      "img id out: 478\n",
      "img id in: 479\n",
      "img id out: 479\n",
      "img id in: 480\n",
      "img id out: 480\n",
      "img id in: 481\n",
      "img id out: 481\n",
      "img id in: 482\n",
      "img id out: 482\n",
      "img id in: 483\n",
      "img id out: 483\n",
      "img id in: 484\n",
      "img id out: 484\n",
      "img id in: 485\n",
      "img id out: 485\n",
      "img id in: 486\n",
      "img id out: 486\n",
      "img id in: 487\n",
      "img id out: 487\n",
      "img id in: 488\n",
      "img id out: 488\n",
      "img id in: 489\n",
      "img id out: 489\n",
      "img id in: 490\n",
      "img id out: 490\n",
      "img id in: 491\n",
      "img id out: 491\n",
      "img id in: 492\n",
      "img id out: 492\n",
      "img id in: 493\n",
      "img id out: 493\n",
      "img id in: 494\n",
      "img id out: 494\n",
      "img id in: 495\n",
      "img id out: 495\n",
      "img id in: 496\n",
      "img id out: 496\n",
      "img id in: 497\n",
      "img id out: 497\n",
      "img id in: 498\n",
      "img id out: 498\n",
      "img id in: 499\n",
      "img id out: 499\n",
      "img id in: 500\n",
      "img id out: 500\n",
      "img id in: 501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 501\n",
      "img id in: 502\n",
      "img id out: 502\n",
      "img id in: 503\n",
      "img id out: 503\n",
      "img id in: 504\n",
      "img id out: 504\n",
      "img id in: 505\n",
      "img id out: 505\n",
      "img id in: 506\n",
      "img id out: 506\n",
      "img id in: 507\n",
      "img id out: 507\n",
      "img id in: 508\n",
      "img id out: 508\n",
      "img id in: 509\n",
      "img id out: 509\n",
      "img id in: 510\n",
      "img id out: 510\n",
      "img id in: 511\n",
      "img id out: 511\n",
      "img id in: 512\n",
      "img id out: 512\n",
      "img id in: 513\n",
      "img id out: 513\n",
      "img id in: 514\n",
      "img id out: 514\n",
      "img id in: 515\n",
      "img id out: 515\n",
      "img id in: 516\n",
      "img id out: 516\n",
      "img id in: 517\n",
      "img id out: 517\n",
      "img id in: 518\n",
      "img id out: 518\n",
      "img id in: 519\n",
      "img id out: 519\n",
      "img id in: 520\n",
      "img id out: 520\n",
      "img id in: 521\n",
      "img id out: 521\n",
      "img id in: 522\n",
      "img id out: 522\n",
      "img id in: 523\n",
      "img id out: 523\n",
      "img id in: 524\n",
      "img id out: 524\n",
      "img id in: 525\n",
      "img id out: 525\n",
      "img id in: 526\n",
      "img id out: 526\n",
      "img id in: 527\n",
      "img id out: 527\n",
      "img id in: 528\n",
      "img id out: 528\n",
      "img id in: 529\n",
      "img id out: 529\n",
      "img id in: 530\n",
      "img id out: 530\n",
      "img id in: 531\n",
      "img id out: 531\n",
      "img id in: 532\n",
      "img id out: 532\n",
      "img id in: 533\n",
      "img id out: 533\n",
      "img id in: 534\n",
      "img id out: 534\n",
      "img id in: 535\n",
      "img id out: 535\n",
      "img id in: 536\n",
      "img id out: 536\n",
      "img id in: 537\n",
      "img id out: 537\n",
      "img id in: 538\n",
      "img id out: 538\n",
      "img id in: 539\n",
      "img id out: 539\n",
      "img id in: 540\n",
      "img id out: 540\n",
      "img id in: 541\n",
      "img id out: 541\n",
      "img id in: 542\n",
      "img id out: 542\n",
      "img id in: 543\n",
      "img id out: 543\n",
      "img id in: 544\n",
      "img id out: 544\n",
      "img id in: 545\n",
      "img id out: 545\n",
      "img id in: 546\n",
      "img id out: 546\n",
      "img id in: 547\n",
      "img id out: 547\n",
      "img id in: 548\n",
      "img id out: 548\n",
      "img id in: 549\n",
      "img id out: 549\n",
      "img id in: 550\n",
      "img id out: 550\n",
      "img id in: 551\n",
      "img id out: 551\n",
      "img id in: 552\n",
      "img id out: 552\n",
      "img id in: 553\n",
      "img id out: 553\n",
      "img id in: 554\n",
      "img id out: 554\n",
      "img id in: 555\n",
      "img id out: 555\n",
      "img id in: 556\n",
      "img id out: 556\n",
      "img id in: 557\n",
      "img id out: 557\n",
      "img id in: 558\n",
      "img id out: 558\n",
      "img id in: 559\n",
      "img id out: 559\n",
      "img id in: 560\n",
      "img id out: 560\n",
      "img id in: 561\n",
      "img id out: 561\n",
      "img id in: 562\n",
      "img id out: 562\n",
      "img id in: 563\n",
      "img id out: 563\n",
      "img id in: 564\n",
      "img id out: 564\n",
      "img id in: 565\n",
      "img id out: 565\n",
      "img id in: 566\n",
      "img id out: 566\n",
      "img id in: 567\n",
      "img id out: 567\n",
      "img id in: 568\n",
      "img id out: 568\n",
      "img id in: 569\n",
      "img id out: 569\n",
      "img id in: 570\n",
      "img id out: 570\n",
      "img id in: 571\n",
      "img id out: 571\n",
      "img id in: 572\n",
      "img id out: 572\n",
      "img id in: 573\n",
      "img id out: 573\n",
      "img id in: 574\n",
      "img id out: 574\n",
      "img id in: 575\n",
      "img id out: 575\n",
      "img id in: 576\n",
      "img id out: 576\n",
      "img id in: 577\n",
      "img id out: 577\n",
      "img id in: 578\n",
      "img id out: 578\n",
      "img id in: 579\n",
      "img id out: 579\n",
      "img id in: 580\n",
      "img id out: 580\n",
      "img id in: 581\n",
      "img id out: 581\n",
      "img id in: 582\n",
      "img id out: 582\n",
      "img id in: 583\n",
      "img id out: 583\n",
      "img id in: 584\n",
      "img id out: 584\n",
      "img id in: 585\n",
      "img id out: 585\n",
      "img id in: 586\n",
      "img id out: 586\n",
      "img id in: 587\n",
      "img id out: 587\n",
      "img id in: 588\n",
      "img id out: 588\n",
      "img id in: 589\n",
      "img id out: 589\n",
      "img id in: 590\n",
      "img id out: 590\n",
      "img id in: 591\n",
      "img id out: 591\n",
      "img id in: 592\n",
      "img id out: 592\n",
      "img id in: 593\n",
      "img id out: 593\n",
      "img id in: 594\n",
      "img id out: 594\n",
      "img id in: 595\n",
      "img id out: 595\n",
      "img id in: 596\n",
      "img id out: 596\n",
      "img id in: 597\n",
      "img id out: 597\n",
      "img id in: 598\n",
      "img id out: 598\n",
      "img id in: 599\n",
      "img id out: 599\n",
      "img id in: 600\n",
      "img id out: 600\n",
      "img id in: 601\n",
      "img id out: 601\n",
      "img id in: 602\n",
      "img id out: 602\n",
      "img id in: 603\n",
      "img id out: 603\n",
      "img id in: 604\n",
      "img id out: 604\n",
      "img id in: 605\n",
      "img id out: 605\n",
      "img id in: 606\n",
      "img id out: 606\n",
      "img id in: 607\n",
      "img id out: 607\n",
      "img id in: 608\n",
      "img id out: 608\n",
      "img id in: 609\n",
      "img id out: 609\n",
      "img id in: 610\n",
      "img id out: 610\n",
      "img id in: 611\n",
      "img id out: 611\n",
      "img id in: 612\n",
      "img id out: 612\n",
      "img id in: 613\n",
      "img id out: 613\n",
      "img id in: 614\n",
      "img id out: 614\n",
      "img id in: 615\n",
      "img id out: 615\n",
      "img id in: 616\n",
      "img id out: 616\n",
      "img id in: 617\n",
      "img id out: 617\n",
      "img id in: 618\n",
      "img id out: 618\n",
      "img id in: 619\n",
      "img id out: 619\n",
      "img id in: 620\n",
      "img id out: 620\n",
      "img id in: 621\n",
      "img id out: 621\n",
      "img id in: 622\n",
      "img id out: 622\n",
      "img id in: 623\n",
      "img id out: 623\n",
      "img id in: 624\n",
      "img id out: 624\n",
      "img id in: 625\n",
      "img id out: 625\n",
      "img id in: 626\n",
      "img id out: 626\n",
      "img id in: 627\n",
      "img id out: 627\n",
      "img id in: 628\n",
      "img id out: 628\n",
      "img id in: 629\n",
      "img id out: 629\n",
      "img id in: 630\n",
      "img id out: 630\n",
      "img id in: 631\n",
      "img id out: 631\n",
      "img id in: 632\n",
      "img id out: 632\n",
      "img id in: 633\n",
      "img id out: 633\n",
      "img id in: 634\n",
      "img id out: 634\n",
      "img id in: 635\n",
      "img id out: 635\n",
      "img id in: 636\n",
      "img id out: 636\n",
      "img id in: 637\n",
      "img id out: 637\n",
      "img id in: 638\n",
      "img id out: 638\n",
      "img id in: 639\n",
      "img id out: 639\n",
      "img id in: 640\n",
      "img id out: 640\n",
      "img id in: 641\n",
      "img id out: 641\n",
      "img id in: 642\n",
      "img id out: 642\n",
      "img id in: 643\n",
      "img id out: 643\n",
      "img id in: 644\n",
      "img id out: 644\n",
      "img id in: 645\n",
      "img id out: 645\n",
      "img id in: 646\n",
      "img id out: 646\n",
      "img id in: 647\n",
      "img id out: 647\n",
      "img id in: 648\n",
      "img id out: 648\n",
      "img id in: 649\n",
      "img id out: 649\n",
      "img id in: 650\n",
      "img id out: 650\n",
      "img id in: 651\n",
      "img id out: 651\n",
      "img id in: 652\n",
      "img id out: 652\n",
      "img id in: 653\n",
      "img id out: 653\n",
      "img id in: 654\n",
      "img id out: 654\n",
      "img id in: 655\n",
      "img id out: 655\n",
      "img id in: 656\n",
      "img id out: 656\n",
      "img id in: 657\n",
      "img id out: 657\n",
      "img id in: 658\n",
      "img id out: 658\n",
      "img id in: 659\n",
      "img id out: 659\n",
      "img id in: 660\n",
      "img id out: 660\n",
      "img id in: 661\n",
      "img id out: 661\n",
      "img id in: 662\n",
      "img id out: 662\n",
      "img id in: 663\n",
      "img id out: 663\n",
      "img id in: 664\n",
      "img id out: 664\n",
      "img id in: 665\n",
      "img id out: 665\n",
      "img id in: 666\n",
      "img id out: 666\n",
      "img id in: 667\n",
      "img id out: 667\n",
      "img id in: 668\n",
      "img id out: 668\n",
      "img id in: 669\n",
      "img id out: 669\n",
      "img id in: 670\n",
      "img id out: 670\n",
      "img id in: 671\n",
      "img id out: 671\n",
      "img id in: 672\n",
      "img id out: 672\n",
      "img id in: 673\n",
      "img id out: 673\n",
      "img id in: 674\n",
      "img id out: 674\n",
      "img id in: 675\n",
      "img id out: 675\n",
      "img id in: 676\n",
      "img id out: 676\n",
      "img id in: 677\n",
      "img id out: 677\n",
      "img id in: 678\n",
      "img id out: 678\n",
      "img id in: 679\n",
      "img id out: 679\n",
      "img id in: 680\n",
      "img id out: 680\n",
      "img id in: 681\n",
      "img id out: 681\n",
      "img id in: 682\n",
      "img id out: 682\n",
      "img id in: 683\n",
      "img id out: 683\n",
      "img id in: 684\n",
      "img id out: 684\n",
      "img id in: 685\n",
      "img id out: 685\n",
      "img id in: 686\n",
      "img id out: 686\n",
      "img id in: 687\n",
      "img id out: 687\n",
      "img id in: 688\n",
      "img id out: 688\n",
      "img id in: 689\n",
      "img id out: 689\n",
      "img id in: 690\n",
      "img id out: 690\n",
      "img id in: 691\n",
      "img id out: 691\n",
      "img id in: 692\n",
      "img id out: 692\n",
      "img id in: 693\n",
      "img id out: 693\n",
      "img id in: 694\n",
      "img id out: 694\n",
      "img id in: 695\n",
      "img id out: 695\n",
      "img id in: 696\n",
      "img id out: 696\n",
      "img id in: 697\n",
      "img id out: 697\n",
      "img id in: 698\n",
      "img id out: 698\n",
      "img id in: 699\n",
      "img id out: 699\n",
      "img id in: 700\n",
      "img id out: 700\n",
      "img id in: 701\n",
      "img id out: 701\n",
      "img id in: 702\n",
      "img id out: 702\n",
      "img id in: 703\n",
      "img id out: 703\n",
      "img id in: 704\n",
      "img id out: 704\n",
      "img id in: 705\n",
      "img id out: 705\n",
      "img id in: 706\n",
      "img id out: 706\n",
      "img id in: 707\n",
      "img id out: 707\n",
      "img id in: 708\n",
      "img id out: 708\n",
      "img id in: 709\n",
      "img id out: 709\n",
      "img id in: 710\n",
      "img id out: 710\n",
      "img id in: 711\n",
      "img id out: 711\n",
      "img id in: 712\n",
      "img id out: 712\n",
      "img id in: 713\n",
      "img id out: 713\n",
      "img id in: 714\n",
      "img id out: 714\n",
      "img id in: 715\n",
      "img id out: 715\n",
      "img id in: 716\n",
      "img id out: 716\n",
      "img id in: 717\n",
      "img id out: 717\n",
      "img id in: 718\n",
      "img id out: 718\n",
      "img id in: 719\n",
      "img id out: 719\n",
      "img id in: 720\n",
      "img id out: 720\n",
      "img id in: 721\n",
      "img id out: 721\n",
      "img id in: 722\n",
      "img id out: 722\n",
      "img id in: 723\n",
      "img id out: 723\n",
      "img id in: 724\n",
      "img id out: 724\n",
      "img id in: 725\n",
      "img id out: 725\n",
      "img id in: 726\n",
      "img id out: 726\n",
      "img id in: 727\n",
      "img id out: 727\n",
      "img id in: 728\n",
      "img id out: 728\n",
      "img id in: 729\n",
      "img id out: 729\n",
      "img id in: 730\n",
      "img id out: 730\n",
      "img id in: 731\n",
      "img id out: 731\n",
      "img id in: 732\n",
      "img id out: 732\n",
      "img id in: 733\n",
      "img id out: 733\n",
      "img id in: 734\n",
      "img id out: 734\n",
      "img id in: 735\n",
      "img id out: 735\n",
      "img id in: 736\n",
      "img id out: 736\n",
      "img id in: 737\n",
      "img id out: 737\n",
      "img id in: 738\n",
      "img id out: 738\n",
      "img id in: 739\n",
      "img id out: 739\n",
      "img id in: 740\n",
      "img id out: 740\n",
      "img id in: 741\n",
      "img id out: 741\n",
      "img id in: 742\n",
      "img id out: 742\n",
      "img id in: 743\n",
      "img id out: 743\n",
      "img id in: 744\n",
      "img id out: 744\n",
      "img id in: 745\n",
      "img id out: 745\n",
      "img id in: 746\n",
      "img id out: 746\n",
      "img id in: 747\n",
      "img id out: 747\n",
      "img id in: 748\n",
      "img id out: 748\n",
      "img id in: 749\n",
      "img id out: 749\n",
      "img id in: 750\n",
      "img id out: 750\n",
      "img id in: 751\n",
      "img id out: 751\n",
      "img id in: 752\n",
      "img id out: 752\n",
      "img id in: 753\n",
      "img id out: 753\n",
      "img id in: 754\n",
      "img id out: 754\n",
      "img id in: 755\n",
      "img id out: 755\n",
      "img id in: 756\n",
      "img id out: 756\n",
      "img id in: 757\n",
      "img id out: 757\n",
      "img id in: 758\n",
      "img id out: 758\n",
      "img id in: 759\n",
      "img id out: 759\n",
      "img id in: 760\n",
      "img id out: 760\n",
      "img id in: 761\n",
      "img id out: 761\n",
      "img id in: 762\n",
      "img id out: 762\n",
      "img id in: 763\n",
      "img id out: 763\n",
      "img id in: 764\n",
      "img id out: 764\n",
      "img id in: 765\n",
      "img id out: 765\n",
      "img id in: 766\n",
      "img id out: 766\n",
      "img id in: 767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 767\n",
      "img id in: 768\n",
      "img id out: 768\n",
      "img id in: 769\n",
      "img id out: 769\n",
      "img id in: 770\n",
      "img id out: 770\n",
      "img id in: 771\n",
      "img id out: 771\n",
      "img id in: 772\n",
      "img id out: 772\n",
      "img id in: 773\n",
      "img id out: 773\n",
      "img id in: 774\n",
      "img id out: 774\n",
      "img id in: 775\n",
      "img id out: 775\n",
      "img id in: 776\n",
      "img id out: 776\n",
      "img id in: 777\n",
      "img id out: 777\n",
      "img id in: 778\n",
      "img id out: 778\n",
      "img id in: 779\n",
      "img id out: 779\n",
      "img id in: 780\n",
      "img id out: 780\n",
      "img id in: 781\n",
      "img id out: 781\n",
      "img id in: 782\n",
      "img id out: 782\n",
      "img id in: 783\n",
      "img id out: 783\n",
      "img id in: 784\n",
      "img id out: 784\n",
      "img id in: 785\n",
      "img id out: 785\n",
      "img id in: 786\n",
      "img id out: 786\n",
      "img id in: 787\n",
      "img id out: 787\n",
      "img id in: 788\n",
      "img id out: 788\n",
      "img id in: 789\n",
      "img id out: 789\n",
      "img id in: 790\n",
      "img id out: 790\n",
      "img id in: 791\n",
      "img id out: 791\n",
      "img id in: 792\n",
      "img id out: 792\n",
      "img id in: 793\n",
      "img id out: 793\n",
      "img id in: 794\n",
      "img id out: 794\n",
      "img id in: 795\n",
      "img id out: 795\n",
      "img id in: 796\n",
      "img id out: 796\n",
      "img id in: 797\n",
      "img id out: 797\n",
      "img id in: 798\n",
      "img id out: 798\n",
      "img id in: 799\n",
      "img id out: 799\n",
      "img id in: 800\n",
      "img id out: 800\n",
      "img id in: 801\n",
      "img id out: 801\n",
      "img id in: 802\n",
      "img id out: 802\n",
      "img id in: 803\n",
      "img id out: 803\n",
      "img id in: 804\n",
      "img id out: 804\n",
      "img id in: 805\n",
      "img id out: 805\n",
      "img id in: 806\n",
      "img id out: 806\n",
      "img id in: 807\n",
      "img id out: 807\n",
      "img id in: 808\n",
      "img id out: 808\n",
      "img id in: 809\n",
      "img id out: 809\n",
      "img id in: 810\n",
      "img id out: 810\n",
      "img id in: 811\n",
      "img id out: 811\n",
      "img id in: 812\n",
      "img id out: 812\n",
      "img id in: 813\n",
      "img id out: 813\n",
      "img id in: 814\n",
      "img id out: 814\n",
      "img id in: 815\n",
      "img id out: 815\n",
      "img id in: 816\n",
      "img id out: 816\n",
      "img id in: 817\n",
      "img id out: 817\n",
      "img id in: 818\n",
      "img id out: 818\n",
      "img id in: 819\n",
      "img id out: 819\n",
      "img id in: 820\n",
      "img id out: 820\n",
      "img id in: 821\n",
      "img id out: 821\n",
      "img id in: 822\n",
      "img id out: 822\n",
      "img id in: 823\n",
      "img id out: 823\n",
      "img id in: 824\n",
      "img id out: 824\n",
      "img id in: 825\n",
      "img id out: 825\n",
      "img id in: 826\n",
      "img id out: 826\n",
      "img id in: 827\n",
      "img id out: 827\n",
      "img id in: 828\n",
      "img id out: 828\n",
      "img id in: 829\n",
      "img id out: 829\n",
      "img id in: 830\n",
      "img id out: 830\n",
      "img id in: 831\n",
      "img id out: 831\n",
      "img id in: 832\n",
      "img id out: 832\n",
      "img id in: 833\n",
      "img id out: 833\n",
      "img id in: 834\n",
      "img id out: 834\n",
      "img id in: 835\n",
      "img id out: 835\n",
      "img id in: 836\n",
      "img id out: 836\n",
      "img id in: 837\n",
      "img id out: 837\n",
      "img id in: 838\n",
      "img id out: 838\n",
      "img id in: 839\n",
      "img id out: 839\n",
      "img id in: 840\n",
      "img id out: 840\n",
      "img id in: 841\n",
      "img id out: 841\n",
      "img id in: 842\n",
      "img id out: 842\n",
      "img id in: 843\n",
      "img id out: 843\n",
      "img id in: 844\n",
      "img id out: 844\n",
      "img id in: 845\n",
      "img id out: 845\n",
      "img id in: 846\n",
      "img id out: 846\n",
      "img id in: 847\n",
      "img id out: 847\n",
      "img id in: 848\n",
      "img id out: 848\n",
      "img id in: 849\n",
      "img id out: 849\n",
      "img id in: 850\n",
      "img id out: 850\n",
      "img id in: 851\n",
      "img id out: 851\n",
      "img id in: 852\n",
      "img id out: 852\n",
      "img id in: 853\n",
      "img id out: 853\n",
      "img id in: 854\n",
      "img id out: 854\n",
      "img id in: 855\n",
      "img id out: 855\n",
      "img id in: 856\n",
      "img id out: 856\n",
      "img id in: 857\n",
      "img id out: 857\n",
      "img id in: 858\n",
      "img id out: 858\n",
      "img id in: 859\n",
      "img id out: 859\n",
      "img id in: 860\n",
      "img id out: 860\n",
      "img id in: 861\n",
      "img id out: 861\n",
      "img id in: 862\n",
      "img id out: 862\n",
      "img id in: 863\n",
      "img id out: 863\n",
      "img id in: 864\n",
      "img id out: 864\n",
      "img id in: 865\n",
      "img id out: 865\n",
      "img id in: 866\n",
      "img id out: 866\n",
      "img id in: 867\n",
      "img id out: 867\n",
      "img id in: 868\n",
      "img id out: 868\n",
      "img id in: 869\n",
      "img id out: 869\n",
      "img id in: 870\n",
      "img id out: 870\n",
      "img id in: 871\n",
      "img id out: 871\n",
      "img id in: 872\n",
      "img id out: 872\n",
      "img id in: 873\n",
      "img id out: 873\n",
      "img id in: 874\n",
      "img id out: 874\n",
      "img id in: 875\n",
      "img id out: 875\n",
      "img id in: 876\n",
      "img id out: 876\n",
      "img id in: 877\n",
      "img id out: 877\n",
      "img id in: 878\n",
      "img id out: 878\n",
      "img id in: 879\n",
      "img id out: 879\n",
      "img id in: 880\n",
      "img id out: 880\n",
      "img id in: 881\n",
      "img id out: 881\n",
      "img id in: 882\n",
      "img id out: 882\n",
      "img id in: 883\n",
      "img id out: 883\n",
      "img id in: 884\n",
      "img id out: 884\n",
      "img id in: 885\n",
      "img id out: 885\n",
      "img id in: 886\n",
      "img id out: 886\n",
      "img id in: 887\n",
      "img id out: 887\n",
      "img id in: 888\n",
      "img id out: 888\n",
      "img id in: 889\n",
      "img id out: 889\n",
      "img id in: 890\n",
      "img id out: 890\n",
      "img id in: 891\n",
      "img id out: 891\n",
      "img id in: 892\n",
      "img id out: 892\n",
      "img id in: 893\n",
      "img id out: 893\n",
      "img id in: 894\n",
      "img id out: 894\n",
      "img id in: 895\n",
      "img id out: 895\n",
      "img id in: 896\n",
      "img id out: 896\n",
      "img id in: 897\n",
      "img id out: 897\n",
      "img id in: 898\n",
      "img id out: 898\n",
      "img id in: 899\n",
      "img id out: 899\n",
      "img id in: 900\n",
      "img id out: 900\n",
      "img id in: 901\n",
      "img id out: 901\n",
      "img id in: 902\n",
      "img id out: 902\n",
      "img id in: 903\n",
      "img id out: 903\n",
      "img id in: 904\n",
      "img id out: 904\n",
      "img id in: 905\n",
      "img id out: 905\n",
      "img id in: 906\n",
      "img id out: 906\n",
      "img id in: 907\n",
      "img id out: 907\n",
      "img id in: 908\n",
      "img id out: 908\n",
      "img id in: 909\n",
      "img id out: 909\n",
      "img id in: 910\n",
      "img id out: 910\n",
      "img id in: 911\n",
      "img id out: 911\n",
      "img id in: 912\n",
      "img id out: 912\n",
      "img id in: 913\n",
      "img id out: 913\n",
      "img id in: 914\n",
      "img id out: 914\n",
      "img id in: 915\n",
      "img id out: 915\n",
      "img id in: 916\n",
      "img id out: 916\n",
      "img id in: 917\n",
      "img id out: 917\n",
      "img id in: 918\n",
      "img id out: 918\n",
      "img id in: 919\n",
      "img id out: 919\n",
      "img id in: 920\n",
      "img id out: 920\n",
      "img id in: 921\n",
      "img id out: 921\n",
      "img id in: 922\n",
      "img id out: 922\n",
      "img id in: 923\n",
      "img id out: 923\n",
      "img id in: 924\n",
      "img id out: 924\n",
      "img id in: 925\n",
      "img id out: 925\n",
      "img id in: 926\n",
      "img id out: 926\n",
      "img id in: 927\n",
      "img id out: 927\n",
      "img id in: 928\n",
      "img id out: 928\n",
      "img id in: 929\n",
      "img id out: 929\n",
      "img id in: 930\n",
      "img id out: 930\n",
      "img id in: 931\n",
      "img id out: 931\n",
      "img id in: 932\n",
      "img id out: 932\n",
      "img id in: 933\n",
      "img id out: 933\n",
      "img id in: 934\n",
      "img id out: 934\n",
      "img id in: 935\n",
      "img id out: 935\n",
      "img id in: 936\n",
      "img id out: 936\n",
      "img id in: 937\n",
      "img id out: 937\n",
      "img id in: 938\n",
      "img id out: 938\n",
      "img id in: 939\n",
      "img id out: 939\n",
      "img id in: 940\n",
      "img id out: 940\n",
      "img id in: 941\n",
      "img id out: 941\n",
      "img id in: 942\n",
      "img id out: 942\n",
      "img id in: 943\n",
      "img id out: 943\n",
      "img id in: 944\n",
      "img id out: 944\n",
      "img id in: 945\n",
      "img id out: 945\n",
      "img id in: 946\n",
      "img id out: 946\n",
      "img id in: 947\n",
      "img id out: 947\n",
      "img id in: 948\n",
      "img id out: 948\n",
      "img id in: 949\n",
      "img id out: 949\n",
      "img id in: 950\n",
      "img id out: 950\n",
      "img id in: 951\n",
      "img id out: 951\n",
      "img id in: 952\n",
      "img id out: 952\n",
      "img id in: 953\n",
      "img id out: 953\n",
      "img id in: 954\n",
      "img id out: 954\n",
      "img id in: 955\n",
      "img id out: 955\n",
      "img id in: 956\n",
      "img id out: 956\n",
      "img id in: 957\n",
      "img id out: 957\n",
      "img id in: 958\n",
      "img id out: 958\n",
      "img id in: 959\n",
      "img id out: 959\n",
      "img id in: 960\n",
      "img id out: 960\n",
      "img id in: 961\n",
      "img id out: 961\n",
      "img id in: 962\n",
      "img id out: 962\n",
      "img id in: 963\n",
      "img id out: 963\n",
      "img id in: 964\n",
      "img id out: 964\n",
      "img id in: 965\n",
      "img id out: 965\n",
      "img id in: 966\n",
      "img id out: 966\n",
      "img id in: 967\n",
      "img id out: 967\n",
      "img id in: 968\n",
      "img id out: 968\n",
      "img id in: 969\n",
      "img id out: 969\n",
      "img id in: 970\n",
      "img id out: 970\n",
      "img id in: 971\n",
      "img id out: 971\n",
      "img id in: 972\n",
      "img id out: 972\n",
      "img id in: 973\n",
      "img id out: 973\n",
      "img id in: 974\n",
      "img id out: 974\n",
      "img id in: 975\n",
      "img id out: 975\n",
      "img id in: 976\n",
      "img id out: 976\n",
      "img id in: 977\n",
      "img id out: 977\n",
      "img id in: 978\n",
      "img id out: 978\n",
      "img id in: 979\n",
      "img id out: 979\n",
      "img id in: 980\n",
      "img id out: 980\n",
      "img id in: 981\n",
      "img id out: 981\n",
      "img id in: 982\n",
      "img id out: 982\n",
      "img id in: 983\n",
      "img id out: 983\n",
      "img id in: 984\n",
      "img id out: 984\n",
      "img id in: 985\n",
      "img id out: 985\n",
      "img id in: 986\n",
      "img id out: 986\n",
      "img id in: 987\n",
      "img id out: 987\n",
      "img id in: 988\n",
      "img id out: 988\n",
      "img id in: 989\n",
      "img id out: 989\n",
      "img id in: 990\n",
      "img id out: 990\n",
      "img id in: 991\n",
      "img id out: 991\n",
      "img id in: 992\n",
      "img id out: 992\n",
      "img id in: 993\n",
      "img id out: 993\n",
      "img id in: 994\n",
      "img id out: 994\n",
      "img id in: 995\n",
      "img id out: 995\n",
      "img id in: 996\n",
      "img id out: 996\n",
      "img id in: 997\n",
      "img id out: 997\n",
      "img id in: 998\n",
      "img id out: 998\n",
      "img id in: 999\n",
      "img id out: 999\n",
      "img id in: 1000\n",
      "img id out: 1000\n",
      "img id in: 1001\n",
      "img id out: 1001\n",
      "img id in: 1002\n",
      "img id out: 1002\n",
      "img id in: 1003\n",
      "img id out: 1003\n",
      "img id in: 1004\n",
      "img id out: 1004\n",
      "img id in: 1005\n",
      "img id out: 1005\n",
      "img id in: 1006\n",
      "img id out: 1006\n",
      "img id in: 1007\n",
      "img id out: 1007\n",
      "img id in: 1008\n",
      "img id out: 1008\n",
      "img id in: 1009\n",
      "img id out: 1009\n",
      "img id in: 1010\n",
      "img id out: 1010\n",
      "img id in: 1011\n",
      "img id out: 1011\n",
      "img id in: 1012\n",
      "img id out: 1012\n",
      "img id in: 1013\n",
      "img id out: 1013\n",
      "img id in: 1014\n",
      "img id out: 1014\n",
      "img id in: 1015\n",
      "img id out: 1015\n",
      "img id in: 1016\n",
      "img id out: 1016\n",
      "img id in: 1017\n",
      "img id out: 1017\n",
      "img id in: 1018\n",
      "img id out: 1018\n",
      "img id in: 1019\n",
      "img id out: 1019\n",
      "img id in: 1020\n",
      "img id out: 1020\n",
      "img id in: 1021\n",
      "img id out: 1021\n",
      "img id in: 1022\n",
      "img id out: 1022\n",
      "img id in: 1023\n",
      "img id out: 1023\n",
      "img id in: 1024\n",
      "img id out: 1024\n",
      "img id in: 1025\n",
      "img id out: 1025\n",
      "img id in: 1026\n",
      "img id out: 1026\n",
      "img id in: 1027\n",
      "img id out: 1027\n",
      "img id in: 1028\n",
      "img id out: 1028\n",
      "img id in: 1029\n",
      "img id out: 1029\n",
      "img id in: 1030\n",
      "img id out: 1030\n",
      "img id in: 1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 1031\n",
      "img id in: 1032\n",
      "img id out: 1032\n",
      "img id in: 1033\n",
      "img id out: 1033\n",
      "img id in: 1034\n",
      "img id out: 1034\n",
      "img id in: 1035\n",
      "img id out: 1035\n",
      "img id in: 1036\n",
      "img id out: 1036\n",
      "img id in: 1037\n",
      "img id out: 1037\n",
      "img id in: 1038\n",
      "img id out: 1038\n",
      "img id in: 1039\n",
      "img id out: 1039\n",
      "img id in: 1040\n",
      "img id out: 1040\n",
      "img id in: 1041\n",
      "img id out: 1041\n",
      "img id in: 1042\n",
      "img id out: 1042\n",
      "img id in: 1043\n",
      "img id out: 1043\n",
      "img id in: 1044\n",
      "img id out: 1044\n",
      "img id in: 1045\n",
      "img id out: 1045\n",
      "img id in: 1046\n",
      "img id out: 1046\n",
      "img id in: 1047\n",
      "img id out: 1047\n",
      "img id in: 1048\n",
      "img id out: 1048\n",
      "img id in: 1049\n",
      "img id out: 1049\n",
      "img id in: 1050\n",
      "img id out: 1050\n",
      "img id in: 1051\n",
      "img id out: 1051\n",
      "img id in: 1052\n",
      "img id out: 1052\n",
      "img id in: 1053\n",
      "img id out: 1053\n",
      "img id in: 1054\n",
      "img id out: 1054\n",
      "img id in: 1055\n",
      "img id out: 1055\n",
      "img id in: 1056\n",
      "img id out: 1056\n",
      "img id in: 1057\n",
      "img id out: 1057\n",
      "img id in: 1058\n",
      "img id out: 1058\n",
      "img id in: 1059\n",
      "img id out: 1059\n",
      "img id in: 1060\n",
      "img id out: 1060\n",
      "img id in: 1061\n",
      "img id out: 1061\n",
      "img id in: 1062\n",
      "img id out: 1062\n",
      "img id in: 1063\n",
      "img id out: 1063\n",
      "img id in: 1064\n",
      "img id out: 1064\n",
      "img id in: 1065\n",
      "img id out: 1065\n",
      "img id in: 1066\n",
      "img id out: 1066\n",
      "img id in: 1067\n",
      "img id out: 1067\n",
      "img id in: 1068\n",
      "img id out: 1068\n",
      "img id in: 1069\n",
      "img id out: 1069\n",
      "img id in: 1070\n",
      "img id out: 1070\n",
      "img id in: 1071\n",
      "img id out: 1071\n",
      "img id in: 1072\n",
      "img id out: 1072\n",
      "img id in: 1073\n",
      "img id out: 1073\n",
      "img id in: 1074\n",
      "img id out: 1074\n",
      "img id in: 1075\n",
      "img id out: 1075\n",
      "img id in: 1076\n",
      "img id out: 1076\n",
      "img id in: 1077\n",
      "img id out: 1077\n",
      "img id in: 1078\n",
      "img id out: 1078\n",
      "img id in: 1079\n",
      "img id out: 1079\n",
      "img id in: 1080\n",
      "img id out: 1080\n",
      "img id in: 1081\n",
      "img id out: 1081\n",
      "img id in: 1082\n",
      "img id out: 1082\n",
      "img id in: 1083\n",
      "img id out: 1083\n",
      "img id in: 1084\n",
      "img id out: 1084\n",
      "img id in: 1085\n",
      "img id out: 1085\n",
      "img id in: 1086\n",
      "img id out: 1086\n",
      "img id in: 1087\n",
      "img id out: 1087\n",
      "img id in: 1088\n",
      "img id out: 1088\n",
      "img id in: 1089\n",
      "img id out: 1089\n",
      "img id in: 1090\n",
      "img id out: 1090\n",
      "img id in: 1091\n",
      "img id out: 1091\n",
      "img id in: 1092\n",
      "img id out: 1092\n",
      "img id in: 1093\n",
      "img id out: 1093\n",
      "img id in: 1094\n",
      "img id out: 1094\n",
      "img id in: 1095\n",
      "img id out: 1095\n",
      "img id in: 1096\n",
      "img id out: 1096\n",
      "img id in: 1097\n",
      "img id out: 1097\n",
      "img id in: 1098\n",
      "img id out: 1098\n",
      "img id in: 1099\n",
      "img id out: 1099\n",
      "img id in: 1100\n",
      "img id out: 1100\n",
      "img id in: 1101\n",
      "img id out: 1101\n",
      "img id in: 1102\n",
      "img id out: 1102\n",
      "img id in: 1103\n",
      "img id out: 1103\n",
      "img id in: 1104\n",
      "img id out: 1104\n",
      "img id in: 1105\n",
      "img id out: 1105\n",
      "img id in: 1106\n",
      "img id out: 1106\n",
      "img id in: 1107\n",
      "img id out: 1107\n",
      "img id in: 1108\n",
      "img id out: 1108\n",
      "img id in: 1109\n",
      "img id out: 1109\n",
      "img id in: 1110\n",
      "img id out: 1110\n",
      "img id in: 1111\n",
      "img id out: 1111\n",
      "img id in: 1112\n",
      "img id out: 1112\n",
      "img id in: 1113\n",
      "img id out: 1113\n",
      "img id in: 1114\n",
      "img id out: 1114\n",
      "img id in: 1115\n",
      "img id out: 1115\n",
      "img id in: 1116\n",
      "img id out: 1116\n",
      "img id in: 1117\n",
      "img id out: 1117\n",
      "img id in: 1118\n",
      "img id out: 1118\n",
      "img id in: 1119\n",
      "img id out: 1119\n",
      "img id in: 1120\n",
      "img id out: 1120\n",
      "img id in: 1121\n",
      "img id out: 1121\n",
      "img id in: 1122\n",
      "img id out: 1122\n",
      "img id in: 1123\n",
      "img id out: 1123\n",
      "img id in: 1124\n",
      "img id out: 1124\n",
      "img id in: 1125\n",
      "img id out: 1125\n",
      "img id in: 1126\n",
      "img id out: 1126\n",
      "img id in: 1127\n",
      "img id out: 1127\n",
      "img id in: 1128\n",
      "img id out: 1128\n",
      "img id in: 1129\n",
      "img id out: 1129\n",
      "img id in: 1130\n",
      "img id out: 1130\n",
      "img id in: 1131\n",
      "img id out: 1131\n",
      "img id in: 1132\n",
      "img id out: 1132\n",
      "img id in: 1133\n",
      "img id out: 1133\n",
      "img id in: 1134\n",
      "img id out: 1134\n",
      "img id in: 1135\n",
      "img id out: 1135\n",
      "img id in: 1136\n",
      "img id out: 1136\n",
      "img id in: 1137\n",
      "img id out: 1137\n",
      "img id in: 1138\n",
      "img id out: 1138\n",
      "img id in: 1139\n",
      "img id out: 1139\n",
      "img id in: 1140\n",
      "img id out: 1140\n",
      "img id in: 1141\n",
      "img id out: 1141\n",
      "img id in: 1142\n",
      "img id out: 1142\n",
      "img id in: 1143\n",
      "img id out: 1143\n",
      "img id in: 1144\n",
      "img id out: 1144\n",
      "img id in: 1145\n",
      "img id out: 1145\n",
      "img id in: 1146\n",
      "img id out: 1146\n",
      "img id in: 1147\n",
      "img id out: 1147\n",
      "img id in: 1148\n",
      "img id out: 1148\n",
      "img id in: 1149\n",
      "img id out: 1149\n",
      "img id in: 1150\n",
      "img id out: 1150\n",
      "img id in: 1151\n",
      "img id out: 1151\n",
      "img id in: 1152\n",
      "img id out: 1152\n",
      "img id in: 1153\n",
      "img id out: 1153\n",
      "img id in: 1154\n",
      "img id out: 1154\n",
      "img id in: 1155\n",
      "img id out: 1155\n",
      "img id in: 1156\n",
      "img id out: 1156\n",
      "img id in: 1157\n",
      "img id out: 1157\n",
      "img id in: 1158\n",
      "img id out: 1158\n",
      "img id in: 1159\n",
      "img id out: 1159\n",
      "img id in: 1160\n",
      "img id out: 1160\n",
      "img id in: 1161\n",
      "img id out: 1161\n",
      "img id in: 1162\n",
      "img id out: 1162\n",
      "img id in: 1163\n",
      "img id out: 1163\n",
      "img id in: 1164\n",
      "img id out: 1164\n",
      "img id in: 1165\n",
      "img id out: 1165\n",
      "img id in: 1166\n",
      "img id out: 1166\n",
      "img id in: 1167\n",
      "img id out: 1167\n",
      "img id in: 1168\n",
      "img id out: 1168\n",
      "img id in: 1169\n",
      "img id out: 1169\n",
      "img id in: 1170\n",
      "img id out: 1170\n",
      "img id in: 1171\n",
      "img id out: 1171\n",
      "img id in: 1172\n",
      "img id out: 1172\n",
      "img id in: 1173\n",
      "img id out: 1173\n",
      "img id in: 1174\n",
      "img id out: 1174\n",
      "img id in: 1175\n",
      "img id out: 1175\n",
      "img id in: 1176\n",
      "img id out: 1176\n",
      "img id in: 1177\n",
      "img id out: 1177\n",
      "img id in: 1178\n",
      "img id out: 1178\n",
      "img id in: 1179\n",
      "img id out: 1179\n",
      "img id in: 1180\n",
      "img id out: 1180\n",
      "img id in: 1181\n",
      "img id out: 1181\n",
      "img id in: 1182\n",
      "img id out: 1182\n",
      "img id in: 1183\n",
      "img id out: 1183\n",
      "img id in: 1184\n",
      "img id out: 1184\n",
      "img id in: 1185\n",
      "img id out: 1185\n",
      "img id in: 1186\n",
      "img id out: 1186\n",
      "img id in: 1187\n",
      "img id out: 1187\n",
      "img id in: 1188\n",
      "img id out: 1188\n",
      "img id in: 1189\n",
      "img id out: 1189\n",
      "img id in: 1190\n",
      "img id out: 1190\n",
      "img id in: 1191\n",
      "img id out: 1191\n",
      "img id in: 1192\n",
      "img id out: 1192\n",
      "img id in: 1193\n",
      "img id out: 1193\n",
      "img id in: 1194\n",
      "img id out: 1194\n",
      "img id in: 1195\n",
      "img id out: 1195\n",
      "img id in: 1196\n",
      "img id out: 1196\n",
      "img id in: 1197\n",
      "img id out: 1197\n",
      "img id in: 1198\n",
      "img id out: 1198\n",
      "img id in: 1199\n",
      "img id out: 1199\n",
      "img id in: 1200\n",
      "img id out: 1200\n",
      "img id in: 1201\n",
      "img id out: 1201\n",
      "img id in: 1202\n",
      "img id out: 1202\n",
      "img id in: 1203\n",
      "img id out: 1203\n",
      "img id in: 1204\n",
      "img id out: 1204\n",
      "img id in: 1205\n",
      "img id out: 1205\n",
      "img id in: 1206\n",
      "img id out: 1206\n",
      "img id in: 1207\n",
      "img id out: 1207\n",
      "img id in: 1208\n",
      "img id out: 1208\n",
      "img id in: 1209\n",
      "img id out: 1209\n",
      "img id in: 1210\n",
      "img id out: 1210\n",
      "img id in: 1211\n",
      "img id out: 1211\n",
      "img id in: 1212\n",
      "img id out: 1212\n",
      "img id in: 1213\n",
      "img id out: 1213\n",
      "img id in: 1214\n",
      "img id out: 1214\n",
      "img id in: 1215\n",
      "img id out: 1215\n",
      "img id in: 1216\n",
      "img id out: 1216\n",
      "img id in: 1217\n",
      "img id out: 1217\n",
      "img id in: 1218\n",
      "img id out: 1218\n",
      "img id in: 1219\n",
      "img id out: 1219\n",
      "img id in: 1220\n",
      "img id out: 1220\n",
      "img id in: 1221\n",
      "img id out: 1221\n",
      "img id in: 1222\n",
      "img id out: 1222\n",
      "img id in: 1223\n",
      "img id out: 1223\n",
      "img id in: 1224\n",
      "img id out: 1224\n",
      "img id in: 1225\n",
      "img id out: 1225\n",
      "img id in: 1226\n",
      "img id out: 1226\n",
      "img id in: 1227\n",
      "img id out: 1227\n",
      "img id in: 1228\n",
      "img id out: 1228\n",
      "img id in: 1229\n",
      "img id out: 1229\n",
      "img id in: 1230\n",
      "img id out: 1230\n",
      "img id in: 1231\n",
      "img id out: 1231\n",
      "img id in: 1232\n",
      "img id out: 1232\n",
      "img id in: 1233\n",
      "img id out: 1233\n",
      "img id in: 1234\n",
      "img id out: 1234\n",
      "img id in: 1235\n",
      "img id out: 1235\n",
      "img id in: 1236\n",
      "img id out: 1236\n",
      "img id in: 1237\n",
      "img id out: 1237\n",
      "img id in: 1238\n",
      "img id out: 1238\n",
      "img id in: 1239\n",
      "img id out: 1239\n",
      "img id in: 1240\n",
      "img id out: 1240\n",
      "img id in: 1241\n",
      "img id out: 1241\n",
      "img id in: 1242\n",
      "img id out: 1242\n",
      "img id in: 1243\n",
      "img id out: 1243\n",
      "img id in: 1244\n",
      "img id out: 1244\n",
      "img id in: 1245\n",
      "img id out: 1245\n",
      "img id in: 1246\n",
      "img id out: 1246\n",
      "img id in: 1247\n",
      "img id out: 1247\n",
      "img id in: 1248\n",
      "img id out: 1248\n",
      "img id in: 1249\n",
      "img id out: 1249\n",
      "img id in: 1250\n",
      "img id out: 1250\n",
      "img id in: 1251\n",
      "img id out: 1251\n",
      "img id in: 1252\n",
      "img id out: 1252\n",
      "img id in: 1253\n",
      "img id out: 1253\n",
      "img id in: 1254\n",
      "img id out: 1254\n",
      "img id in: 1255\n",
      "img id out: 1255\n",
      "img id in: 1256\n",
      "img id out: 1256\n",
      "img id in: 1257\n",
      "img id out: 1257\n",
      "img id in: 1258\n",
      "img id out: 1258\n",
      "img id in: 1259\n",
      "img id out: 1259\n",
      "img id in: 1260\n",
      "img id out: 1260\n",
      "img id in: 1261\n",
      "img id out: 1261\n",
      "img id in: 1262\n",
      "img id out: 1262\n",
      "img id in: 1263\n",
      "img id out: 1263\n",
      "img id in: 1264\n",
      "img id out: 1264\n",
      "img id in: 1265\n",
      "img id out: 1265\n",
      "img id in: 1266\n",
      "img id out: 1266\n",
      "img id in: 1267\n",
      "img id out: 1267\n",
      "img id in: 1268\n",
      "img id out: 1268\n",
      "img id in: 1269\n",
      "img id out: 1269\n",
      "img id in: 1270\n",
      "img id out: 1270\n",
      "img id in: 1271\n",
      "img id out: 1271\n",
      "img id in: 1272\n",
      "img id out: 1272\n",
      "img id in: 1273\n",
      "img id out: 1273\n",
      "img id in: 1274\n",
      "img id out: 1274\n",
      "img id in: 1275\n",
      "img id out: 1275\n",
      "img id in: 1276\n",
      "img id out: 1276\n",
      "img id in: 1277\n",
      "img id out: 1277\n",
      "img id in: 1278\n",
      "img id out: 1278\n",
      "img id in: 1279\n",
      "img id out: 1279\n",
      "img id in: 1280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 1280\n",
      "img id in: 1281\n",
      "img id out: 1281\n",
      "img id in: 1282\n",
      "img id out: 1282\n",
      "img id in: 1283\n",
      "img id out: 1283\n",
      "img id in: 1284\n",
      "img id out: 1284\n",
      "img id in: 1285\n",
      "img id out: 1285\n",
      "img id in: 1286\n",
      "img id out: 1286\n",
      "img id in: 1287\n",
      "img id out: 1287\n",
      "img id in: 1288\n",
      "img id out: 1288\n",
      "img id in: 1289\n",
      "img id out: 1289\n",
      "img id in: 1290\n",
      "img id out: 1290\n",
      "img id in: 1291\n",
      "img id out: 1291\n",
      "img id in: 1292\n",
      "img id out: 1292\n",
      "img id in: 1293\n",
      "img id out: 1293\n",
      "img id in: 1294\n",
      "img id out: 1294\n",
      "img id in: 1295\n",
      "img id out: 1295\n",
      "img id in: 1296\n",
      "img id out: 1296\n",
      "img id in: 1297\n",
      "img id out: 1297\n",
      "img id in: 1298\n",
      "img id out: 1298\n",
      "img id in: 1299\n",
      "img id out: 1299\n",
      "img id in: 1300\n",
      "img id out: 1300\n",
      "img id in: 1301\n",
      "img id out: 1301\n",
      "img id in: 1302\n",
      "img id out: 1302\n",
      "img id in: 1303\n",
      "img id out: 1303\n",
      "img id in: 1304\n",
      "img id out: 1304\n",
      "img id in: 1305\n",
      "img id out: 1305\n",
      "img id in: 1306\n",
      "img id out: 1306\n",
      "img id in: 1307\n",
      "img id out: 1307\n",
      "img id in: 1308\n",
      "img id out: 1308\n",
      "img id in: 1309\n",
      "img id out: 1309\n",
      "img id in: 1310\n",
      "img id out: 1310\n",
      "img id in: 1311\n",
      "img id out: 1311\n",
      "img id in: 1312\n",
      "img id out: 1312\n",
      "img id in: 1313\n",
      "img id out: 1313\n",
      "img id in: 1314\n",
      "img id out: 1314\n",
      "img id in: 1315\n",
      "img id out: 1315\n",
      "img id in: 1316\n",
      "img id out: 1316\n",
      "img id in: 1317\n",
      "img id out: 1317\n",
      "img id in: 1318\n",
      "img id out: 1318\n",
      "img id in: 1319\n",
      "img id out: 1319\n",
      "img id in: 1320\n",
      "img id out: 1320\n",
      "img id in: 1321\n",
      "img id out: 1321\n",
      "img id in: 1322\n",
      "img id out: 1322\n",
      "img id in: 1323\n",
      "img id out: 1323\n",
      "img id in: 1324\n",
      "img id out: 1324\n",
      "img id in: 1325\n",
      "img id out: 1325\n",
      "img id in: 1326\n",
      "img id out: 1326\n",
      "img id in: 1327\n",
      "img id out: 1327\n",
      "img id in: 1328\n",
      "img id out: 1328\n",
      "img id in: 1329\n",
      "img id out: 1329\n",
      "img id in: 1330\n",
      "img id out: 1330\n",
      "img id in: 1331\n",
      "img id out: 1331\n",
      "img id in: 1332\n",
      "img id out: 1332\n",
      "img id in: 1333\n",
      "img id out: 1333\n",
      "img id in: 1334\n",
      "img id out: 1334\n",
      "img id in: 1335\n",
      "img id out: 1335\n",
      "img id in: 1336\n",
      "img id out: 1336\n",
      "img id in: 1337\n",
      "img id out: 1337\n",
      "img id in: 1338\n",
      "img id out: 1338\n",
      "img id in: 1339\n",
      "img id out: 1339\n",
      "img id in: 1340\n",
      "img id out: 1340\n",
      "img id in: 1341\n",
      "img id out: 1341\n",
      "img id in: 1342\n",
      "img id out: 1342\n",
      "img id in: 1343\n",
      "img id out: 1343\n",
      "img id in: 1344\n",
      "img id out: 1344\n",
      "img id in: 1345\n",
      "img id out: 1345\n",
      "img id in: 1346\n",
      "img id out: 1346\n",
      "img id in: 1347\n",
      "img id out: 1347\n",
      "img id in: 1348\n",
      "img id out: 1348\n",
      "img id in: 1349\n",
      "img id out: 1349\n",
      "img id in: 1350\n",
      "img id out: 1350\n",
      "img id in: 1351\n",
      "img id out: 1351\n",
      "img id in: 1352\n",
      "img id out: 1352\n",
      "img id in: 1353\n",
      "img id out: 1353\n",
      "img id in: 1354\n",
      "img id out: 1354\n",
      "img id in: 1355\n",
      "img id out: 1355\n",
      "img id in: 1356\n",
      "img id out: 1356\n",
      "img id in: 1357\n",
      "img id out: 1357\n",
      "img id in: 1358\n",
      "img id out: 1358\n",
      "img id in: 1359\n",
      "img id out: 1359\n",
      "img id in: 1360\n",
      "img id out: 1360\n",
      "img id in: 1361\n",
      "img id out: 1361\n",
      "img id in: 1362\n",
      "img id out: 1362\n",
      "img id in: 1363\n",
      "img id out: 1363\n",
      "img id in: 1364\n",
      "img id out: 1364\n",
      "img id in: 1365\n",
      "img id out: 1365\n",
      "img id in: 1366\n",
      "img id out: 1366\n",
      "img id in: 1367\n",
      "img id out: 1367\n",
      "img id in: 1368\n",
      "img id out: 1368\n",
      "img id in: 1369\n",
      "img id out: 1369\n",
      "img id in: 1370\n",
      "img id out: 1370\n",
      "img id in: 1371\n",
      "img id out: 1371\n",
      "img id in: 1372\n",
      "img id out: 1372\n",
      "img id in: 1373\n",
      "img id out: 1373\n",
      "img id in: 1374\n",
      "img id out: 1374\n",
      "img id in: 1375\n",
      "img id out: 1375\n",
      "img id in: 1376\n",
      "img id out: 1376\n",
      "img id in: 1377\n",
      "img id out: 1377\n",
      "img id in: 1378\n",
      "img id out: 1378\n",
      "img id in: 1379\n",
      "img id out: 1379\n",
      "img id in: 1380\n",
      "img id out: 1380\n",
      "img id in: 1381\n",
      "img id out: 1381\n",
      "img id in: 1382\n",
      "img id out: 1382\n",
      "img id in: 1383\n",
      "img id out: 1383\n",
      "img id in: 1384\n",
      "img id out: 1384\n",
      "img id in: 1385\n",
      "img id out: 1385\n",
      "img id in: 1386\n",
      "img id out: 1386\n",
      "img id in: 1387\n",
      "img id out: 1387\n",
      "img id in: 1388\n",
      "img id out: 1388\n",
      "img id in: 1389\n",
      "img id out: 1389\n",
      "img id in: 1390\n",
      "img id out: 1390\n",
      "img id in: 1391\n",
      "img id out: 1391\n",
      "img id in: 1392\n",
      "img id out: 1392\n",
      "img id in: 1393\n",
      "img id out: 1393\n",
      "img id in: 1394\n",
      "img id out: 1394\n",
      "img id in: 1395\n",
      "img id out: 1395\n",
      "img id in: 1396\n",
      "img id out: 1396\n",
      "img id in: 1397\n",
      "img id out: 1397\n",
      "img id in: 1398\n",
      "img id out: 1398\n",
      "img id in: 1399\n",
      "img id out: 1399\n",
      "img id in: 1400\n",
      "img id out: 1400\n",
      "img id in: 1401\n",
      "img id out: 1401\n",
      "img id in: 1402\n",
      "img id out: 1402\n",
      "img id in: 1403\n",
      "img id out: 1403\n",
      "img id in: 1404\n",
      "img id out: 1404\n",
      "img id in: 1405\n",
      "img id out: 1405\n",
      "img id in: 1406\n",
      "img id out: 1406\n",
      "img id in: 1407\n",
      "img id out: 1407\n",
      "img id in: 1408\n",
      "img id out: 1408\n",
      "img id in: 1409\n",
      "img id out: 1409\n",
      "img id in: 1410\n",
      "img id out: 1410\n",
      "img id in: 1411\n",
      "img id out: 1411\n",
      "img id in: 1412\n",
      "img id out: 1412\n",
      "img id in: 1413\n",
      "img id out: 1413\n",
      "img id in: 1414\n",
      "img id out: 1414\n",
      "img id in: 1415\n",
      "img id out: 1415\n",
      "img id in: 1416\n",
      "img id out: 1416\n",
      "img id in: 1417\n",
      "img id out: 1417\n",
      "img id in: 1418\n",
      "img id out: 1418\n",
      "img id in: 1419\n",
      "img id out: 1419\n",
      "img id in: 1420\n",
      "img id out: 1420\n",
      "img id in: 1421\n",
      "img id out: 1421\n",
      "img id in: 1422\n",
      "img id out: 1422\n",
      "img id in: 1423\n",
      "img id out: 1423\n",
      "img id in: 1424\n",
      "img id out: 1424\n",
      "img id in: 1425\n",
      "img id out: 1425\n",
      "img id in: 1426\n",
      "img id out: 1426\n",
      "img id in: 1427\n",
      "img id out: 1427\n",
      "img id in: 1428\n",
      "img id out: 1428\n",
      "img id in: 1429\n",
      "img id out: 1429\n",
      "img id in: 1430\n",
      "img id out: 1430\n",
      "img id in: 1431\n",
      "img id out: 1431\n",
      "img id in: 1432\n",
      "img id out: 1432\n",
      "img id in: 1433\n",
      "img id out: 1433\n",
      "img id in: 1434\n",
      "img id out: 1434\n",
      "img id in: 1435\n",
      "img id out: 1435\n",
      "img id in: 1436\n",
      "img id out: 1436\n",
      "img id in: 1437\n",
      "img id out: 1437\n",
      "img id in: 1438\n",
      "img id out: 1438\n",
      "img id in: 1439\n",
      "img id out: 1439\n",
      "img id in: 1440\n",
      "img id out: 1440\n",
      "img id in: 1441\n",
      "img id out: 1441\n",
      "img id in: 1442\n",
      "img id out: 1442\n",
      "img id in: 1443\n",
      "img id out: 1443\n",
      "img id in: 1444\n",
      "img id out: 1444\n",
      "img id in: 1445\n",
      "img id out: 1445\n",
      "img id in: 1446\n",
      "img id out: 1446\n",
      "img id in: 1447\n",
      "img id out: 1447\n",
      "img id in: 1448\n",
      "img id out: 1448\n",
      "img id in: 1449\n",
      "img id out: 1449\n",
      "img id in: 1450\n",
      "img id out: 1450\n",
      "img id in: 1451\n",
      "img id out: 1451\n",
      "img id in: 1452\n",
      "img id out: 1452\n",
      "img id in: 1453\n",
      "img id out: 1453\n",
      "img id in: 1454\n",
      "img id out: 1454\n",
      "img id in: 1455\n",
      "img id out: 1455\n",
      "img id in: 1456\n",
      "img id out: 1456\n",
      "img id in: 1457\n",
      "img id out: 1457\n",
      "img id in: 1458\n",
      "img id out: 1458\n",
      "img id in: 1459\n",
      "img id out: 1459\n",
      "img id in: 1460\n",
      "img id out: 1460\n",
      "img id in: 1461\n",
      "img id out: 1461\n",
      "img id in: 1462\n",
      "img id out: 1462\n",
      "img id in: 1463\n",
      "img id out: 1463\n",
      "img id in: 1464\n",
      "img id out: 1464\n",
      "img id in: 1465\n",
      "img id out: 1465\n",
      "img id in: 1466\n",
      "img id out: 1466\n",
      "img id in: 1467\n",
      "img id out: 1467\n",
      "img id in: 1468\n",
      "img id out: 1468\n",
      "img id in: 1469\n",
      "img id out: 1469\n",
      "img id in: 1470\n",
      "img id out: 1470\n",
      "img id in: 1471\n",
      "img id out: 1471\n",
      "img id in: 1472\n",
      "img id out: 1472\n",
      "img id in: 1473\n",
      "img id out: 1473\n",
      "img id in: 1474\n",
      "img id out: 1474\n",
      "img id in: 1475\n",
      "img id out: 1475\n",
      "img id in: 1476\n",
      "img id out: 1476\n",
      "img id in: 1477\n",
      "img id out: 1477\n",
      "img id in: 1478\n",
      "img id out: 1478\n",
      "img id in: 1479\n",
      "img id out: 1479\n",
      "img id in: 1480\n",
      "img id out: 1480\n",
      "img id in: 1481\n",
      "img id out: 1481\n",
      "img id in: 1482\n",
      "img id out: 1482\n",
      "img id in: 1483\n",
      "img id out: 1483\n",
      "img id in: 1484\n",
      "img id out: 1484\n",
      "img id in: 1485\n",
      "img id out: 1485\n",
      "img id in: 1486\n",
      "img id out: 1486\n",
      "img id in: 1487\n",
      "img id out: 1487\n",
      "img id in: 1488\n",
      "img id out: 1488\n",
      "img id in: 1489\n",
      "img id out: 1489\n",
      "img id in: 1490\n",
      "img id out: 1490\n",
      "img id in: 1491\n",
      "img id out: 1491\n",
      "img id in: 1492\n",
      "img id out: 1492\n",
      "img id in: 1493\n",
      "img id out: 1493\n",
      "img id in: 1494\n",
      "img id out: 1494\n",
      "img id in: 1495\n",
      "img id out: 1495\n",
      "img id in: 1496\n",
      "img id out: 1496\n",
      "img id in: 1497\n",
      "img id out: 1497\n",
      "img id in: 1498\n",
      "img id out: 1498\n",
      "img id in: 1499\n",
      "img id out: 1499\n",
      "img id in: 1500\n",
      "img id out: 1500\n",
      "img id in: 1501\n",
      "img id out: 1501\n",
      "img id in: 1502\n",
      "img id out: 1502\n",
      "img id in: 1503\n",
      "img id out: 1503\n",
      "img id in: 1504\n",
      "img id out: 1504\n",
      "img id in: 1505\n",
      "img id out: 1505\n",
      "img id in: 1506\n",
      "img id out: 1506\n",
      "img id in: 1507\n",
      "img id out: 1507\n",
      "img id in: 1508\n",
      "img id out: 1508\n",
      "img id in: 1509\n",
      "img id out: 1509\n",
      "img id in: 1510\n",
      "img id out: 1510\n",
      "img id in: 1511\n",
      "img id out: 1511\n",
      "img id in: 1512\n",
      "img id out: 1512\n",
      "img id in: 1513\n",
      "img id out: 1513\n",
      "img id in: 1514\n",
      "img id out: 1514\n",
      "img id in: 1515\n",
      "img id out: 1515\n",
      "img id in: 1516\n",
      "img id out: 1516\n",
      "img id in: 1517\n",
      "img id out: 1517\n",
      "img id in: 1518\n",
      "img id out: 1518\n",
      "img id in: 1519\n",
      "img id out: 1519\n",
      "img id in: 1520\n",
      "img id out: 1520\n",
      "img id in: 1521\n",
      "img id out: 1521\n",
      "img id in: 1522\n",
      "img id out: 1522\n",
      "img id in: 1523\n",
      "img id out: 1523\n",
      "img id in: 1524\n",
      "img id out: 1524\n",
      "img id in: 1525\n",
      "img id out: 1525\n",
      "img id in: 1526\n",
      "img id out: 1526\n",
      "img id in: 1527\n",
      "img id out: 1527\n",
      "img id in: 1528\n",
      "img id out: 1528\n",
      "img id in: 1529\n",
      "img id out: 1529\n",
      "img id in: 1530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 1530\n",
      "img id in: 1531\n",
      "img id out: 1531\n",
      "img id in: 1532\n",
      "img id out: 1532\n",
      "img id in: 1533\n",
      "img id out: 1533\n",
      "img id in: 1534\n",
      "img id out: 1534\n",
      "img id in: 1535\n",
      "img id out: 1535\n",
      "img id in: 1536\n",
      "img id out: 1536\n",
      "img id in: 1537\n",
      "img id out: 1537\n",
      "img id in: 1538\n",
      "img id out: 1538\n",
      "img id in: 1539\n",
      "img id out: 1539\n",
      "img id in: 1540\n",
      "img id out: 1540\n",
      "img id in: 1541\n",
      "img id out: 1541\n",
      "img id in: 1542\n",
      "img id out: 1542\n",
      "img id in: 1543\n",
      "img id out: 1543\n",
      "img id in: 1544\n",
      "img id out: 1544\n",
      "img id in: 1545\n",
      "img id out: 1545\n",
      "img id in: 1546\n",
      "img id out: 1546\n",
      "img id in: 1547\n",
      "img id out: 1547\n",
      "img id in: 1548\n",
      "img id out: 1548\n",
      "img id in: 1549\n",
      "img id out: 1549\n",
      "img id in: 1550\n",
      "img id out: 1550\n",
      "img id in: 1551\n",
      "img id out: 1551\n",
      "img id in: 1552\n",
      "img id out: 1552\n",
      "img id in: 1553\n",
      "img id out: 1553\n",
      "img id in: 1554\n",
      "img id out: 1554\n",
      "img id in: 1555\n",
      "img id out: 1555\n",
      "img id in: 1556\n",
      "img id out: 1556\n",
      "img id in: 1557\n",
      "img id out: 1557\n",
      "img id in: 1558\n",
      "img id out: 1558\n",
      "img id in: 1559\n",
      "img id out: 1559\n",
      "img id in: 1560\n",
      "img id out: 1560\n",
      "img id in: 1561\n",
      "img id out: 1561\n",
      "img id in: 1562\n",
      "img id out: 1562\n",
      "img id in: 1563\n",
      "img id out: 1563\n",
      "img id in: 1564\n",
      "img id out: 1564\n",
      "img id in: 1565\n",
      "img id out: 1565\n",
      "img id in: 1566\n",
      "img id out: 1566\n",
      "img id in: 1567\n",
      "img id out: 1567\n",
      "img id in: 1568\n",
      "img id out: 1568\n",
      "img id in: 1569\n",
      "img id out: 1569\n",
      "img id in: 1570\n",
      "img id out: 1570\n",
      "img id in: 1571\n",
      "img id out: 1571\n",
      "img id in: 1572\n",
      "img id out: 1572\n",
      "img id in: 1573\n",
      "img id out: 1573\n",
      "img id in: 1574\n",
      "img id out: 1574\n",
      "img id in: 1575\n",
      "img id out: 1575\n",
      "img id in: 1576\n",
      "img id out: 1576\n",
      "img id in: 1577\n",
      "img id out: 1577\n",
      "img id in: 1578\n",
      "img id out: 1578\n",
      "img id in: 1579\n",
      "img id out: 1579\n",
      "img id in: 1580\n",
      "img id out: 1580\n",
      "img id in: 1581\n",
      "img id out: 1581\n",
      "img id in: 1582\n",
      "img id out: 1582\n",
      "img id in: 1583\n",
      "img id out: 1583\n",
      "img id in: 1584\n",
      "img id out: 1584\n",
      "img id in: 1585\n",
      "img id out: 1585\n",
      "img id in: 1586\n",
      "img id out: 1586\n",
      "img id in: 1587\n",
      "img id out: 1587\n",
      "img id in: 1588\n",
      "img id out: 1588\n",
      "img id in: 1589\n",
      "img id out: 1589\n",
      "img id in: 1590\n",
      "img id out: 1590\n",
      "img id in: 1591\n",
      "img id out: 1591\n",
      "img id in: 1592\n",
      "img id out: 1592\n",
      "img id in: 1593\n",
      "img id out: 1593\n",
      "img id in: 1594\n",
      "img id out: 1594\n",
      "img id in: 1595\n",
      "img id out: 1595\n",
      "img id in: 1596\n",
      "img id out: 1596\n",
      "img id in: 1597\n",
      "img id out: 1597\n",
      "img id in: 1598\n",
      "img id out: 1598\n",
      "img id in: 1599\n",
      "img id out: 1599\n",
      "img id in: 1600\n",
      "img id out: 1600\n",
      "img id in: 1601\n",
      "img id out: 1601\n",
      "img id in: 1602\n",
      "img id out: 1602\n",
      "img id in: 1603\n",
      "img id out: 1603\n",
      "img id in: 1604\n",
      "img id out: 1604\n",
      "img id in: 1605\n",
      "img id out: 1605\n",
      "img id in: 1606\n",
      "img id out: 1606\n",
      "img id in: 1607\n",
      "img id out: 1607\n",
      "img id in: 1608\n",
      "img id out: 1608\n",
      "img id in: 1609\n",
      "img id out: 1609\n",
      "img id in: 1610\n",
      "img id out: 1610\n",
      "img id in: 1611\n",
      "img id out: 1611\n",
      "img id in: 1612\n",
      "img id out: 1612\n",
      "img id in: 1613\n",
      "img id out: 1613\n",
      "img id in: 1614\n",
      "img id out: 1614\n",
      "img id in: 1615\n",
      "img id out: 1615\n",
      "img id in: 1616\n",
      "img id out: 1616\n",
      "img id in: 1617\n",
      "img id out: 1617\n",
      "img id in: 1618\n",
      "img id out: 1618\n",
      "img id in: 1619\n",
      "img id out: 1619\n",
      "img id in: 1620\n",
      "img id out: 1620\n",
      "img id in: 1621\n",
      "img id out: 1621\n",
      "img id in: 1622\n",
      "img id out: 1622\n",
      "img id in: 1623\n",
      "img id out: 1623\n",
      "img id in: 1624\n",
      "img id out: 1624\n",
      "img id in: 1625\n",
      "img id out: 1625\n",
      "img id in: 1626\n",
      "img id out: 1626\n",
      "img id in: 1627\n",
      "img id out: 1627\n",
      "img id in: 1628\n",
      "img id out: 1628\n",
      "img id in: 1629\n",
      "img id out: 1629\n",
      "img id in: 1630\n",
      "img id out: 1630\n",
      "img id in: 1631\n",
      "img id out: 1631\n",
      "img id in: 1632\n",
      "img id out: 1632\n",
      "img id in: 1633\n",
      "img id out: 1633\n",
      "img id in: 1634\n",
      "img id out: 1634\n",
      "img id in: 1635\n",
      "img id out: 1635\n",
      "img id in: 1636\n",
      "img id out: 1636\n",
      "img id in: 1637\n",
      "img id out: 1637\n",
      "img id in: 1638\n",
      "img id out: 1638\n",
      "img id in: 1639\n",
      "img id out: 1639\n",
      "img id in: 1640\n",
      "img id out: 1640\n",
      "img id in: 1641\n",
      "img id out: 1641\n",
      "img id in: 1642\n",
      "img id out: 1642\n",
      "img id in: 1643\n",
      "img id out: 1643\n",
      "img id in: 1644\n",
      "img id out: 1644\n",
      "img id in: 1645\n",
      "img id out: 1645\n",
      "img id in: 1646\n",
      "img id out: 1646\n",
      "img id in: 1647\n",
      "img id out: 1647\n",
      "img id in: 1648\n",
      "img id out: 1648\n",
      "img id in: 1649\n",
      "img id out: 1649\n",
      "img id in: 1650\n",
      "img id out: 1650\n",
      "img id in: 1651\n",
      "img id out: 1651\n",
      "img id in: 1652\n",
      "img id out: 1652\n",
      "img id in: 1653\n",
      "img id out: 1653\n",
      "img id in: 1654\n",
      "img id out: 1654\n",
      "img id in: 1655\n",
      "img id out: 1655\n",
      "img id in: 1656\n",
      "img id out: 1656\n",
      "img id in: 1657\n",
      "img id out: 1657\n",
      "img id in: 1658\n",
      "img id out: 1658\n",
      "img id in: 1659\n",
      "img id out: 1659\n",
      "img id in: 1660\n",
      "img id out: 1660\n",
      "img id in: 1661\n",
      "img id out: 1661\n",
      "img id in: 1662\n",
      "img id out: 1662\n",
      "img id in: 1663\n",
      "img id out: 1663\n",
      "img id in: 1664\n",
      "img id out: 1664\n",
      "img id in: 1665\n",
      "img id out: 1665\n",
      "img id in: 1666\n",
      "img id out: 1666\n",
      "img id in: 1667\n",
      "img id out: 1667\n",
      "img id in: 1668\n",
      "img id out: 1668\n",
      "img id in: 1669\n",
      "img id out: 1669\n",
      "img id in: 1670\n",
      "img id out: 1670\n",
      "img id in: 1671\n",
      "img id out: 1671\n",
      "img id in: 1672\n",
      "img id out: 1672\n",
      "img id in: 1673\n",
      "img id out: 1673\n",
      "img id in: 1674\n",
      "img id out: 1674\n",
      "img id in: 1675\n",
      "img id out: 1675\n",
      "img id in: 1676\n",
      "img id out: 1676\n",
      "img id in: 1677\n",
      "img id out: 1677\n",
      "img id in: 1678\n",
      "img id out: 1678\n",
      "img id in: 1679\n",
      "img id out: 1679\n",
      "img id in: 1680\n",
      "img id out: 1680\n",
      "img id in: 1681\n",
      "img id out: 1681\n",
      "img id in: 1682\n",
      "img id out: 1682\n",
      "img id in: 1683\n",
      "img id out: 1683\n",
      "img id in: 1684\n",
      "img id out: 1684\n",
      "img id in: 1685\n",
      "img id out: 1685\n",
      "img id in: 1686\n",
      "img id out: 1686\n",
      "img id in: 1687\n",
      "img id out: 1687\n",
      "img id in: 1688\n",
      "img id out: 1688\n",
      "img id in: 1689\n",
      "img id out: 1689\n",
      "img id in: 1690\n",
      "img id out: 1690\n",
      "img id in: 1691\n",
      "img id out: 1691\n",
      "img id in: 1692\n",
      "img id out: 1692\n",
      "img id in: 1693\n",
      "img id out: 1693\n",
      "img id in: 1694\n",
      "img id out: 1694\n",
      "img id in: 1695\n",
      "img id out: 1695\n",
      "img id in: 1696\n",
      "img id out: 1696\n",
      "img id in: 1697\n",
      "img id out: 1697\n",
      "img id in: 1698\n",
      "img id out: 1698\n",
      "img id in: 1699\n",
      "img id out: 1699\n",
      "img id in: 1700\n",
      "img id out: 1700\n",
      "img id in: 1701\n",
      "img id out: 1701\n",
      "img id in: 1702\n",
      "img id out: 1702\n",
      "img id in: 1703\n",
      "img id out: 1703\n",
      "img id in: 1704\n",
      "img id out: 1704\n",
      "img id in: 1705\n",
      "img id out: 1705\n",
      "img id in: 1706\n",
      "img id out: 1706\n",
      "img id in: 1707\n",
      "img id out: 1707\n",
      "img id in: 1708\n",
      "img id out: 1708\n",
      "img id in: 1709\n",
      "img id out: 1709\n",
      "img id in: 1710\n",
      "img id out: 1710\n",
      "img id in: 1711\n",
      "img id out: 1711\n",
      "img id in: 1712\n",
      "img id out: 1712\n",
      "img id in: 1713\n",
      "img id out: 1713\n",
      "img id in: 1714\n",
      "img id out: 1714\n",
      "img id in: 1715\n",
      "img id out: 1715\n",
      "img id in: 1716\n",
      "img id out: 1716\n",
      "img id in: 1717\n",
      "img id out: 1717\n",
      "img id in: 1718\n",
      "img id out: 1718\n",
      "img id in: 1719\n",
      "img id out: 1719\n",
      "img id in: 1720\n",
      "img id out: 1720\n",
      "img id in: 1721\n",
      "img id out: 1721\n",
      "img id in: 1722\n",
      "img id out: 1722\n",
      "img id in: 1723\n",
      "img id out: 1723\n",
      "img id in: 1724\n",
      "img id out: 1724\n",
      "img id in: 1725\n",
      "img id out: 1725\n",
      "img id in: 1726\n",
      "img id out: 1726\n",
      "img id in: 1727\n",
      "img id out: 1727\n",
      "img id in: 1728\n",
      "img id out: 1728\n",
      "img id in: 1729\n",
      "img id out: 1729\n",
      "img id in: 1730\n",
      "img id out: 1730\n",
      "img id in: 1731\n",
      "img id out: 1731\n",
      "img id in: 1732\n",
      "img id out: 1732\n",
      "img id in: 1733\n",
      "img id out: 1733\n",
      "img id in: 1734\n",
      "img id out: 1734\n",
      "img id in: 1735\n",
      "img id out: 1735\n",
      "img id in: 1736\n",
      "img id out: 1736\n",
      "img id in: 1737\n",
      "img id out: 1737\n",
      "img id in: 1738\n",
      "img id out: 1738\n",
      "img id in: 1739\n",
      "img id out: 1739\n",
      "img id in: 1740\n",
      "img id out: 1740\n",
      "img id in: 1741\n",
      "img id out: 1741\n",
      "img id in: 1742\n",
      "img id out: 1742\n",
      "img id in: 1743\n",
      "img id out: 1743\n",
      "img id in: 1744\n",
      "img id out: 1744\n",
      "img id in: 1745\n",
      "img id out: 1745\n",
      "img id in: 1746\n",
      "img id out: 1746\n",
      "img id in: 1747\n",
      "img id out: 1747\n",
      "img id in: 1748\n",
      "img id out: 1748\n",
      "img id in: 1749\n",
      "img id out: 1749\n",
      "img id in: 1750\n",
      "img id out: 1750\n",
      "img id in: 1751\n",
      "img id out: 1751\n",
      "img id in: 1752\n",
      "img id out: 1752\n",
      "img id in: 1753\n",
      "img id out: 1753\n",
      "img id in: 1754\n",
      "img id out: 1754\n",
      "img id in: 1755\n",
      "img id out: 1755\n",
      "img id in: 1756\n",
      "img id out: 1756\n",
      "img id in: 1757\n",
      "img id out: 1757\n",
      "img id in: 1758\n",
      "img id out: 1758\n",
      "img id in: 1759\n",
      "img id out: 1759\n",
      "img id in: 1760\n",
      "img id out: 1760\n",
      "img id in: 1761\n",
      "img id out: 1761\n",
      "img id in: 1762\n",
      "img id out: 1762\n",
      "img id in: 1763\n",
      "img id out: 1763\n",
      "img id in: 1764\n",
      "img id out: 1764\n",
      "img id in: 1765\n",
      "img id out: 1765\n",
      "img id in: 1766\n",
      "img id out: 1766\n",
      "img id in: 1767\n",
      "img id out: 1767\n",
      "img id in: 1768\n",
      "img id out: 1768\n",
      "img id in: 1769\n",
      "img id out: 1769\n",
      "img id in: 1770\n",
      "img id out: 1770\n",
      "img id in: 1771\n",
      "img id out: 1771\n",
      "img id in: 1772\n",
      "img id out: 1772\n",
      "img id in: 1773\n",
      "img id out: 1773\n",
      "img id in: 1774\n",
      "img id out: 1774\n",
      "img id in: 1775\n",
      "img id out: 1775\n",
      "img id in: 1776\n",
      "img id out: 1776\n",
      "img id in: 1777\n",
      "img id out: 1777\n",
      "img id in: 1778\n",
      "img id out: 1778\n",
      "img id in: 1779\n",
      "img id out: 1779\n",
      "img id in: 1780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 1780\n",
      "img id in: 1781\n",
      "img id out: 1781\n",
      "img id in: 1782\n",
      "img id out: 1782\n",
      "img id in: 1783\n",
      "img id out: 1783\n",
      "img id in: 1784\n",
      "img id out: 1784\n",
      "img id in: 1785\n",
      "img id out: 1785\n",
      "img id in: 1786\n",
      "img id out: 1786\n",
      "img id in: 1787\n",
      "img id out: 1787\n",
      "img id in: 1788\n",
      "img id out: 1788\n",
      "img id in: 1789\n",
      "img id out: 1789\n",
      "img id in: 1790\n",
      "img id out: 1790\n",
      "img id in: 1791\n",
      "img id out: 1791\n",
      "img id in: 1792\n",
      "img id out: 1792\n",
      "img id in: 1793\n",
      "img id out: 1793\n",
      "img id in: 1794\n",
      "img id out: 1794\n",
      "img id in: 1795\n",
      "img id out: 1795\n",
      "img id in: 1796\n",
      "img id out: 1796\n",
      "img id in: 1797\n",
      "img id out: 1797\n",
      "img id in: 1798\n",
      "img id out: 1798\n",
      "img id in: 1799\n",
      "img id out: 1799\n",
      "img id in: 1800\n",
      "img id out: 1800\n",
      "img id in: 1801\n",
      "img id out: 1801\n",
      "img id in: 1802\n",
      "img id out: 1802\n",
      "img id in: 1803\n",
      "img id out: 1803\n",
      "img id in: 1804\n",
      "img id out: 1804\n",
      "img id in: 1805\n",
      "img id out: 1805\n",
      "img id in: 1806\n",
      "img id out: 1806\n",
      "img id in: 1807\n",
      "img id out: 1807\n",
      "img id in: 1808\n",
      "img id out: 1808\n",
      "img id in: 1809\n",
      "img id out: 1809\n",
      "img id in: 1810\n",
      "img id out: 1810\n",
      "img id in: 1811\n",
      "img id out: 1811\n",
      "img id in: 1812\n",
      "img id out: 1812\n",
      "img id in: 1813\n",
      "img id out: 1813\n",
      "img id in: 1814\n",
      "img id out: 1814\n",
      "img id in: 1815\n",
      "img id out: 1815\n",
      "img id in: 1816\n",
      "img id out: 1816\n",
      "img id in: 1817\n",
      "img id out: 1817\n",
      "img id in: 1818\n",
      "img id out: 1818\n",
      "img id in: 1819\n",
      "img id out: 1819\n",
      "img id in: 1820\n",
      "img id out: 1820\n",
      "img id in: 1821\n",
      "img id out: 1821\n",
      "img id in: 1822\n",
      "img id out: 1822\n",
      "img id in: 1823\n",
      "img id out: 1823\n",
      "img id in: 1824\n",
      "img id out: 1824\n",
      "img id in: 1825\n",
      "img id out: 1825\n",
      "img id in: 1826\n",
      "img id out: 1826\n",
      "img id in: 1827\n",
      "img id out: 1827\n",
      "img id in: 1828\n",
      "img id out: 1828\n",
      "img id in: 1829\n",
      "img id out: 1829\n",
      "img id in: 1830\n",
      "img id out: 1830\n",
      "img id in: 1831\n",
      "img id out: 1831\n",
      "img id in: 1832\n",
      "img id out: 1832\n",
      "img id in: 1833\n",
      "img id out: 1833\n",
      "img id in: 1834\n",
      "img id out: 1834\n",
      "img id in: 1835\n",
      "img id out: 1835\n",
      "img id in: 1836\n",
      "img id out: 1836\n",
      "img id in: 1837\n",
      "img id out: 1837\n",
      "img id in: 1838\n",
      "img id out: 1838\n",
      "img id in: 1839\n",
      "img id out: 1839\n",
      "img id in: 1840\n",
      "img id out: 1840\n",
      "img id in: 1841\n",
      "img id out: 1841\n",
      "img id in: 1842\n",
      "img id out: 1842\n",
      "img id in: 1843\n",
      "img id out: 1843\n",
      "img id in: 1844\n",
      "img id out: 1844\n",
      "img id in: 1845\n",
      "img id out: 1845\n",
      "img id in: 1846\n",
      "img id out: 1846\n",
      "img id in: 1847\n",
      "img id out: 1847\n",
      "img id in: 1848\n",
      "img id out: 1848\n",
      "img id in: 1849\n",
      "img id out: 1849\n",
      "img id in: 1850\n",
      "img id out: 1850\n",
      "img id in: 1851\n",
      "img id out: 1851\n",
      "img id in: 1852\n",
      "img id out: 1852\n",
      "img id in: 1853\n",
      "img id out: 1853\n",
      "img id in: 1854\n",
      "img id out: 1854\n",
      "img id in: 1855\n",
      "img id out: 1855\n",
      "img id in: 1856\n",
      "img id out: 1856\n",
      "img id in: 1857\n",
      "img id out: 1857\n",
      "img id in: 1858\n",
      "img id out: 1858\n",
      "img id in: 1859\n",
      "img id out: 1859\n",
      "img id in: 1860\n",
      "img id out: 1860\n",
      "img id in: 1861\n",
      "img id out: 1861\n",
      "img id in: 1862\n",
      "img id out: 1862\n",
      "img id in: 1863\n",
      "img id out: 1863\n",
      "img id in: 1864\n",
      "img id out: 1864\n",
      "img id in: 1865\n",
      "img id out: 1865\n",
      "img id in: 1866\n",
      "img id out: 1866\n",
      "img id in: 1867\n",
      "img id out: 1867\n",
      "img id in: 1868\n",
      "img id out: 1868\n",
      "img id in: 1869\n",
      "img id out: 1869\n",
      "img id in: 1870\n",
      "img id out: 1870\n",
      "img id in: 1871\n",
      "img id out: 1871\n",
      "img id in: 1872\n",
      "img id out: 1872\n",
      "img id in: 1873\n",
      "img id out: 1873\n",
      "img id in: 1874\n",
      "img id out: 1874\n",
      "img id in: 1875\n",
      "img id out: 1875\n",
      "img id in: 1876\n",
      "img id out: 1876\n",
      "img id in: 1877\n",
      "img id out: 1877\n",
      "img id in: 1878\n",
      "img id out: 1878\n",
      "img id in: 1879\n",
      "img id out: 1879\n",
      "img id in: 1880\n",
      "img id out: 1880\n",
      "img id in: 1881\n",
      "img id out: 1881\n",
      "img id in: 1882\n",
      "img id out: 1882\n",
      "img id in: 1883\n",
      "img id out: 1883\n",
      "img id in: 1884\n",
      "img id out: 1884\n",
      "img id in: 1885\n",
      "img id out: 1885\n",
      "img id in: 1886\n",
      "img id out: 1886\n",
      "img id in: 1887\n",
      "img id out: 1887\n",
      "img id in: 1888\n",
      "img id out: 1888\n",
      "img id in: 1889\n",
      "img id out: 1889\n",
      "img id in: 1890\n",
      "img id out: 1890\n",
      "img id in: 1891\n",
      "img id out: 1891\n",
      "img id in: 1892\n",
      "img id out: 1892\n",
      "img id in: 1893\n",
      "img id out: 1893\n",
      "img id in: 1894\n",
      "img id out: 1894\n",
      "img id in: 1895\n",
      "img id out: 1895\n",
      "img id in: 1896\n",
      "img id out: 1896\n",
      "img id in: 1897\n",
      "img id out: 1897\n",
      "img id in: 1898\n",
      "img id out: 1898\n",
      "img id in: 1899\n",
      "img id out: 1899\n",
      "img id in: 1900\n",
      "img id out: 1900\n",
      "img id in: 1901\n",
      "img id out: 1901\n",
      "img id in: 1902\n",
      "img id out: 1902\n",
      "img id in: 1903\n",
      "img id out: 1903\n",
      "img id in: 1904\n",
      "img id out: 1904\n",
      "img id in: 1905\n",
      "img id out: 1905\n",
      "img id in: 1906\n",
      "img id out: 1906\n",
      "img id in: 1907\n",
      "img id out: 1907\n",
      "img id in: 1908\n",
      "img id out: 1908\n",
      "img id in: 1909\n",
      "img id out: 1909\n",
      "img id in: 1910\n",
      "img id out: 1910\n",
      "img id in: 1911\n",
      "img id out: 1911\n",
      "img id in: 1912\n",
      "img id out: 1912\n",
      "img id in: 1913\n",
      "img id out: 1913\n",
      "img id in: 1914\n",
      "img id out: 1914\n",
      "img id in: 1915\n",
      "img id out: 1915\n",
      "img id in: 1916\n",
      "img id out: 1916\n",
      "img id in: 1917\n",
      "img id out: 1917\n",
      "img id in: 1918\n",
      "img id out: 1918\n",
      "img id in: 1919\n",
      "img id out: 1919\n",
      "img id in: 1920\n",
      "img id out: 1920\n",
      "img id in: 1921\n",
      "img id out: 1921\n",
      "img id in: 1922\n",
      "img id out: 1922\n",
      "img id in: 1923\n",
      "img id out: 1923\n",
      "img id in: 1924\n",
      "img id out: 1924\n",
      "img id in: 1925\n",
      "img id out: 1925\n",
      "img id in: 1926\n",
      "img id out: 1926\n",
      "img id in: 1927\n",
      "img id out: 1927\n",
      "img id in: 1928\n",
      "img id out: 1928\n",
      "img id in: 1929\n",
      "img id out: 1929\n",
      "img id in: 1930\n",
      "img id out: 1930\n",
      "img id in: 1931\n",
      "img id out: 1931\n",
      "img id in: 1932\n",
      "img id out: 1932\n",
      "img id in: 1933\n",
      "img id out: 1933\n",
      "img id in: 1934\n",
      "img id out: 1934\n",
      "img id in: 1935\n",
      "img id out: 1935\n",
      "img id in: 1936\n",
      "img id out: 1936\n",
      "img id in: 1937\n",
      "img id out: 1937\n",
      "img id in: 1938\n",
      "img id out: 1938\n",
      "img id in: 1939\n",
      "img id out: 1939\n",
      "img id in: 1940\n",
      "img id out: 1940\n",
      "img id in: 1941\n",
      "img id out: 1941\n",
      "img id in: 1942\n",
      "img id out: 1942\n",
      "img id in: 1943\n",
      "img id out: 1943\n",
      "img id in: 1944\n",
      "img id out: 1944\n",
      "img id in: 1945\n",
      "img id out: 1945\n",
      "img id in: 1946\n",
      "img id out: 1946\n",
      "img id in: 1947\n",
      "img id out: 1947\n",
      "img id in: 1948\n",
      "img id out: 1948\n",
      "img id in: 1949\n",
      "img id out: 1949\n",
      "img id in: 1950\n",
      "img id out: 1950\n",
      "img id in: 1951\n",
      "img id out: 1951\n",
      "img id in: 1952\n",
      "img id out: 1952\n",
      "img id in: 1953\n",
      "img id out: 1953\n",
      "img id in: 1954\n",
      "img id out: 1954\n",
      "img id in: 1955\n",
      "img id out: 1955\n",
      "img id in: 1956\n",
      "img id out: 1956\n",
      "img id in: 1957\n",
      "img id out: 1957\n",
      "img id in: 1958\n",
      "img id out: 1958\n",
      "img id in: 1959\n",
      "img id out: 1959\n",
      "img id in: 1960\n",
      "img id out: 1960\n",
      "img id in: 1961\n",
      "img id out: 1961\n",
      "img id in: 1962\n",
      "img id out: 1962\n",
      "img id in: 1963\n",
      "img id out: 1963\n",
      "img id in: 1964\n",
      "img id out: 1964\n",
      "img id in: 1965\n",
      "img id out: 1965\n",
      "img id in: 1966\n",
      "img id out: 1966\n",
      "img id in: 1967\n",
      "img id out: 1967\n",
      "img id in: 1968\n",
      "img id out: 1968\n",
      "img id in: 1969\n",
      "img id out: 1969\n",
      "img id in: 1970\n",
      "img id out: 1970\n",
      "img id in: 1971\n",
      "img id out: 1971\n",
      "img id in: 1972\n",
      "img id out: 1972\n",
      "img id in: 1973\n",
      "img id out: 1973\n",
      "img id in: 1974\n",
      "img id out: 1974\n",
      "img id in: 1975\n",
      "img id out: 1975\n",
      "img id in: 1976\n",
      "img id out: 1976\n",
      "img id in: 1977\n",
      "img id out: 1977\n",
      "img id in: 1978\n",
      "img id out: 1978\n",
      "img id in: 1979\n",
      "img id out: 1979\n",
      "img id in: 1980\n",
      "img id out: 1980\n",
      "img id in: 1981\n",
      "img id out: 1981\n",
      "img id in: 1982\n",
      "img id out: 1982\n",
      "img id in: 1983\n",
      "img id out: 1983\n",
      "img id in: 1984\n",
      "img id out: 1984\n",
      "img id in: 1985\n",
      "img id out: 1985\n",
      "img id in: 1986\n",
      "img id out: 1986\n",
      "img id in: 1987\n",
      "img id out: 1987\n",
      "img id in: 1988\n",
      "img id out: 1988\n",
      "img id in: 1989\n",
      "img id out: 1989\n",
      "img id in: 1990\n",
      "img id out: 1990\n",
      "img id in: 1991\n",
      "img id out: 1991\n",
      "img id in: 1992\n",
      "img id out: 1992\n",
      "img id in: 1993\n",
      "img id out: 1993\n",
      "img id in: 1994\n",
      "img id out: 1994\n",
      "img id in: 1995\n",
      "img id out: 1995\n",
      "img id in: 1996\n",
      "img id out: 1996\n",
      "img id in: 1997\n",
      "img id out: 1997\n",
      "img id in: 1998\n",
      "img id out: 1998\n",
      "img id in: 1999\n",
      "img id out: 1999\n",
      "img id in: 2000\n",
      "img id out: 2000\n",
      "img id in: 2001\n",
      "img id out: 2001\n",
      "img id in: 2002\n",
      "img id out: 2002\n",
      "img id in: 2003\n",
      "img id out: 2003\n",
      "img id in: 2004\n",
      "img id out: 2004\n",
      "img id in: 2005\n",
      "img id out: 2005\n",
      "img id in: 2006\n",
      "img id out: 2006\n",
      "img id in: 2007\n",
      "img id out: 2007\n",
      "img id in: 2008\n",
      "img id out: 2008\n",
      "img id in: 2009\n",
      "img id out: 2009\n",
      "img id in: 2010\n",
      "img id out: 2010\n",
      "img id in: 2011\n",
      "img id out: 2011\n",
      "img id in: 2012\n",
      "img id out: 2012\n",
      "img id in: 2013\n",
      "img id out: 2013\n",
      "img id in: 2014\n",
      "img id out: 2014\n",
      "img id in: 2015\n",
      "img id out: 2015\n",
      "img id in: 2016\n",
      "img id out: 2016\n",
      "img id in: 2017\n",
      "img id out: 2017\n",
      "img id in: 2018\n",
      "img id out: 2018\n",
      "img id in: 2019\n",
      "img id out: 2019\n",
      "img id in: 2020\n",
      "img id out: 2020\n",
      "img id in: 2021\n",
      "img id out: 2021\n",
      "img id in: 2022\n",
      "img id out: 2022\n",
      "img id in: 2023\n",
      "img id out: 2023\n",
      "img id in: 2024\n",
      "img id out: 2024\n",
      "img id in: 2025\n",
      "img id out: 2025\n",
      "img id in: 2026\n",
      "img id out: 2026\n",
      "img id in: 2027\n",
      "img id out: 2027\n",
      "img id in: 2028\n",
      "img id out: 2028\n",
      "img id in: 2029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 2029\n",
      "img id in: 2030\n",
      "img id out: 2030\n",
      "img id in: 2031\n",
      "img id out: 2031\n",
      "img id in: 2032\n",
      "img id out: 2032\n",
      "img id in: 2033\n",
      "img id out: 2033\n",
      "img id in: 2034\n",
      "img id out: 2034\n",
      "img id in: 2035\n",
      "img id out: 2035\n",
      "img id in: 2036\n",
      "img id out: 2036\n",
      "img id in: 2037\n",
      "img id out: 2037\n",
      "img id in: 2038\n",
      "img id out: 2038\n",
      "img id in: 2039\n",
      "img id out: 2039\n",
      "img id in: 2040\n",
      "img id out: 2040\n",
      "img id in: 2041\n",
      "img id out: 2041\n",
      "img id in: 2042\n",
      "img id out: 2042\n",
      "img id in: 2043\n",
      "img id out: 2043\n",
      "img id in: 2044\n",
      "img id out: 2044\n",
      "img id in: 2045\n",
      "img id out: 2045\n",
      "img id in: 2046\n",
      "img id out: 2046\n",
      "img id in: 2047\n",
      "img id out: 2047\n",
      "img id in: 2048\n",
      "img id out: 2048\n",
      "img id in: 2049\n",
      "img id out: 2049\n",
      "img id in: 2050\n",
      "img id out: 2050\n",
      "img id in: 2051\n",
      "img id out: 2051\n",
      "img id in: 2052\n",
      "img id out: 2052\n",
      "img id in: 2053\n",
      "img id out: 2053\n",
      "img id in: 2054\n",
      "img id out: 2054\n",
      "img id in: 2055\n",
      "img id out: 2055\n",
      "img id in: 2056\n",
      "img id out: 2056\n",
      "img id in: 2057\n",
      "img id out: 2057\n",
      "img id in: 2058\n",
      "img id out: 2058\n",
      "img id in: 2059\n",
      "img id out: 2059\n",
      "img id in: 2060\n",
      "img id out: 2060\n",
      "img id in: 2061\n",
      "img id out: 2061\n",
      "img id in: 2062\n",
      "img id out: 2062\n",
      "img id in: 2063\n",
      "img id out: 2063\n",
      "img id in: 2064\n",
      "img id out: 2064\n",
      "img id in: 2065\n",
      "img id out: 2065\n",
      "img id in: 2066\n",
      "img id out: 2066\n",
      "img id in: 2067\n",
      "img id out: 2067\n",
      "img id in: 2068\n",
      "img id out: 2068\n",
      "img id in: 2069\n",
      "img id out: 2069\n",
      "img id in: 2070\n",
      "img id out: 2070\n",
      "img id in: 2071\n",
      "img id out: 2071\n",
      "img id in: 2072\n",
      "img id out: 2072\n",
      "img id in: 2073\n",
      "img id out: 2073\n",
      "img id in: 2074\n",
      "img id out: 2074\n",
      "img id in: 2075\n",
      "img id out: 2075\n",
      "img id in: 2076\n",
      "img id out: 2076\n",
      "img id in: 2077\n",
      "img id out: 2077\n",
      "img id in: 2078\n",
      "img id out: 2078\n",
      "img id in: 2079\n",
      "img id out: 2079\n",
      "img id in: 2080\n",
      "img id out: 2080\n",
      "img id in: 2081\n",
      "img id out: 2081\n",
      "img id in: 2082\n",
      "img id out: 2082\n",
      "img id in: 2083\n",
      "img id out: 2083\n",
      "img id in: 2084\n",
      "img id out: 2084\n",
      "img id in: 2085\n",
      "img id out: 2085\n",
      "img id in: 2086\n",
      "img id out: 2086\n",
      "img id in: 2087\n",
      "img id out: 2087\n",
      "img id in: 2088\n",
      "img id out: 2088\n",
      "img id in: 2089\n",
      "img id out: 2089\n",
      "img id in: 2090\n",
      "img id out: 2090\n",
      "img id in: 2091\n",
      "img id out: 2091\n",
      "img id in: 2092\n",
      "img id out: 2092\n",
      "img id in: 2093\n",
      "img id out: 2093\n",
      "img id in: 2094\n",
      "img id out: 2094\n",
      "img id in: 2095\n",
      "img id out: 2095\n",
      "img id in: 2096\n",
      "img id out: 2096\n",
      "img id in: 2097\n",
      "img id out: 2097\n",
      "img id in: 2098\n",
      "img id out: 2098\n",
      "img id in: 2099\n",
      "img id out: 2099\n",
      "img id in: 2100\n",
      "img id out: 2100\n",
      "img id in: 2101\n",
      "img id out: 2101\n",
      "img id in: 2102\n",
      "img id out: 2102\n",
      "img id in: 2103\n",
      "img id out: 2103\n",
      "img id in: 2104\n",
      "img id out: 2104\n",
      "img id in: 2105\n",
      "img id out: 2105\n",
      "img id in: 2106\n",
      "img id out: 2106\n",
      "img id in: 2107\n",
      "img id out: 2107\n",
      "img id in: 2108\n",
      "img id out: 2108\n",
      "img id in: 2109\n",
      "img id out: 2109\n",
      "img id in: 2110\n",
      "img id out: 2110\n",
      "img id in: 2111\n",
      "img id out: 2111\n",
      "img id in: 2112\n",
      "img id out: 2112\n",
      "img id in: 2113\n",
      "img id out: 2113\n",
      "img id in: 2114\n",
      "img id out: 2114\n",
      "img id in: 2115\n",
      "img id out: 2115\n",
      "img id in: 2116\n",
      "img id out: 2116\n",
      "img id in: 2117\n",
      "img id out: 2117\n",
      "img id in: 2118\n",
      "img id out: 2118\n",
      "img id in: 2119\n",
      "img id out: 2119\n",
      "img id in: 2120\n",
      "img id out: 2120\n",
      "img id in: 2121\n",
      "img id out: 2121\n",
      "img id in: 2122\n",
      "img id out: 2122\n",
      "img id in: 2123\n",
      "img id out: 2123\n",
      "img id in: 2124\n",
      "img id out: 2124\n",
      "img id in: 2125\n",
      "img id out: 2125\n",
      "img id in: 2126\n",
      "img id out: 2126\n",
      "img id in: 2127\n",
      "img id out: 2127\n",
      "img id in: 2128\n",
      "img id out: 2128\n",
      "img id in: 2129\n",
      "img id out: 2129\n",
      "img id in: 2130\n",
      "img id out: 2130\n",
      "img id in: 2131\n",
      "img id out: 2131\n",
      "img id in: 2132\n",
      "img id out: 2132\n",
      "img id in: 2133\n",
      "img id out: 2133\n",
      "img id in: 2134\n",
      "img id out: 2134\n",
      "img id in: 2135\n",
      "img id out: 2135\n",
      "img id in: 2136\n",
      "img id out: 2136\n",
      "img id in: 2137\n",
      "img id out: 2137\n",
      "img id in: 2138\n",
      "img id out: 2138\n",
      "img id in: 2139\n",
      "img id out: 2139\n",
      "img id in: 2140\n",
      "img id out: 2140\n",
      "img id in: 2141\n",
      "img id out: 2141\n",
      "img id in: 2142\n",
      "img id out: 2142\n",
      "img id in: 2143\n",
      "img id out: 2143\n",
      "img id in: 2144\n",
      "img id out: 2144\n",
      "img id in: 2145\n",
      "img id out: 2145\n",
      "img id in: 2146\n",
      "img id out: 2146\n",
      "img id in: 2147\n",
      "img id out: 2147\n",
      "img id in: 2148\n",
      "img id out: 2148\n",
      "img id in: 2149\n",
      "img id out: 2149\n",
      "img id in: 2150\n",
      "img id out: 2150\n",
      "img id in: 2151\n",
      "img id out: 2151\n",
      "img id in: 2152\n",
      "img id out: 2152\n",
      "img id in: 2153\n",
      "img id out: 2153\n",
      "img id in: 2154\n",
      "img id out: 2154\n",
      "img id in: 2155\n",
      "img id out: 2155\n",
      "img id in: 2156\n",
      "img id out: 2156\n",
      "img id in: 2157\n",
      "img id out: 2157\n",
      "img id in: 2158\n",
      "img id out: 2158\n",
      "img id in: 2159\n",
      "img id out: 2159\n",
      "img id in: 2160\n",
      "img id out: 2160\n",
      "img id in: 2161\n",
      "img id out: 2161\n",
      "img id in: 2162\n",
      "img id out: 2162\n",
      "img id in: 2163\n",
      "img id out: 2163\n",
      "img id in: 2164\n",
      "img id out: 2164\n",
      "img id in: 2165\n",
      "img id out: 2165\n",
      "img id in: 2166\n",
      "img id out: 2166\n",
      "img id in: 2167\n",
      "img id out: 2167\n",
      "img id in: 2168\n",
      "img id out: 2168\n",
      "img id in: 2169\n",
      "img id out: 2169\n",
      "img id in: 2170\n",
      "img id out: 2170\n",
      "img id in: 2171\n",
      "img id out: 2171\n",
      "img id in: 2172\n",
      "img id out: 2172\n",
      "img id in: 2173\n",
      "img id out: 2173\n",
      "img id in: 2174\n",
      "img id out: 2174\n",
      "img id in: 2175\n",
      "img id out: 2175\n",
      "img id in: 2176\n",
      "img id out: 2176\n",
      "img id in: 2177\n",
      "img id out: 2177\n",
      "img id in: 2178\n",
      "img id out: 2178\n",
      "img id in: 2179\n",
      "img id out: 2179\n",
      "img id in: 2180\n",
      "img id out: 2180\n",
      "img id in: 2181\n",
      "img id out: 2181\n",
      "img id in: 2182\n",
      "img id out: 2182\n",
      "img id in: 2183\n",
      "img id out: 2183\n",
      "img id in: 2184\n",
      "img id out: 2184\n",
      "img id in: 2185\n",
      "img id out: 2185\n",
      "img id in: 2186\n",
      "img id out: 2186\n",
      "img id in: 2187\n",
      "img id out: 2187\n",
      "img id in: 2188\n",
      "img id out: 2188\n",
      "img id in: 2189\n",
      "img id out: 2189\n",
      "img id in: 2190\n",
      "img id out: 2190\n",
      "img id in: 2191\n",
      "img id out: 2191\n",
      "img id in: 2192\n",
      "img id out: 2192\n",
      "img id in: 2193\n",
      "img id out: 2193\n",
      "img id in: 2194\n",
      "img id out: 2194\n",
      "img id in: 2195\n",
      "img id out: 2195\n",
      "img id in: 2196\n",
      "img id out: 2196\n",
      "img id in: 2197\n",
      "img id out: 2197\n",
      "img id in: 2198\n",
      "img id out: 2198\n",
      "img id in: 2199\n",
      "img id out: 2199\n",
      "img id in: 2200\n",
      "img id out: 2200\n",
      "img id in: 2201\n",
      "img id out: 2201\n",
      "img id in: 2202\n",
      "img id out: 2202\n",
      "img id in: 2203\n",
      "img id out: 2203\n",
      "img id in: 2204\n",
      "img id out: 2204\n",
      "img id in: 2205\n",
      "img id out: 2205\n",
      "img id in: 2206\n",
      "img id out: 2206\n",
      "img id in: 2207\n",
      "img id out: 2207\n",
      "img id in: 2208\n",
      "img id out: 2208\n",
      "img id in: 2209\n",
      "img id out: 2209\n",
      "img id in: 2210\n",
      "img id out: 2210\n",
      "img id in: 2211\n",
      "img id out: 2211\n",
      "img id in: 2212\n",
      "img id out: 2212\n",
      "img id in: 2213\n",
      "img id out: 2213\n",
      "img id in: 2214\n",
      "img id out: 2214\n",
      "img id in: 2215\n",
      "img id out: 2215\n",
      "img id in: 2216\n",
      "img id out: 2216\n",
      "img id in: 2217\n",
      "img id out: 2217\n",
      "img id in: 2218\n",
      "img id out: 2218\n",
      "img id in: 2219\n",
      "img id out: 2219\n",
      "img id in: 2220\n",
      "img id out: 2220\n",
      "img id in: 2221\n",
      "img id out: 2221\n",
      "img id in: 2222\n",
      "img id out: 2222\n",
      "img id in: 2223\n",
      "img id out: 2223\n",
      "img id in: 2224\n",
      "img id out: 2224\n",
      "img id in: 2225\n",
      "img id out: 2225\n",
      "img id in: 2226\n",
      "img id out: 2226\n",
      "img id in: 2227\n",
      "img id out: 2227\n",
      "img id in: 2228\n",
      "img id out: 2228\n",
      "img id in: 2229\n",
      "img id out: 2229\n",
      "img id in: 2230\n",
      "img id out: 2230\n",
      "img id in: 2231\n",
      "img id out: 2231\n",
      "img id in: 2232\n",
      "img id out: 2232\n",
      "img id in: 2233\n",
      "img id out: 2233\n",
      "img id in: 2234\n",
      "img id out: 2234\n",
      "img id in: 2235\n",
      "img id out: 2235\n",
      "img id in: 2236\n",
      "img id out: 2236\n",
      "img id in: 2237\n",
      "img id out: 2237\n",
      "img id in: 2238\n",
      "img id out: 2238\n",
      "img id in: 2239\n",
      "img id out: 2239\n",
      "img id in: 2240\n",
      "img id out: 2240\n",
      "img id in: 2241\n",
      "img id out: 2241\n",
      "img id in: 2242\n",
      "img id out: 2242\n",
      "img id in: 2243\n",
      "img id out: 2243\n",
      "img id in: 2244\n",
      "img id out: 2244\n",
      "img id in: 2245\n",
      "img id out: 2245\n",
      "img id in: 2246\n",
      "img id out: 2246\n",
      "img id in: 2247\n",
      "img id out: 2247\n",
      "img id in: 2248\n",
      "img id out: 2248\n",
      "img id in: 2249\n",
      "img id out: 2249\n",
      "img id in: 2250\n",
      "img id out: 2250\n",
      "img id in: 2251\n",
      "img id out: 2251\n",
      "img id in: 2252\n",
      "img id out: 2252\n",
      "img id in: 2253\n",
      "img id out: 2253\n",
      "img id in: 2254\n",
      "img id out: 2254\n",
      "img id in: 2255\n",
      "img id out: 2255\n",
      "img id in: 2256\n",
      "img id out: 2256\n",
      "img id in: 2257\n",
      "img id out: 2257\n",
      "img id in: 2258\n",
      "img id out: 2258\n",
      "img id in: 2259\n",
      "img id out: 2259\n",
      "img id in: 2260\n",
      "img id out: 2260\n",
      "img id in: 2261\n",
      "img id out: 2261\n",
      "img id in: 2262\n",
      "img id out: 2262\n",
      "img id in: 2263\n",
      "img id out: 2263\n",
      "img id in: 2264\n",
      "img id out: 2264\n",
      "img id in: 2265\n",
      "img id out: 2265\n",
      "img id in: 2266\n",
      "img id out: 2266\n",
      "img id in: 2267\n",
      "img id out: 2267\n",
      "img id in: 2268\n",
      "img id out: 2268\n",
      "img id in: 2269\n",
      "img id out: 2269\n",
      "img id in: 2270\n",
      "img id out: 2270\n",
      "img id in: 2271\n",
      "img id out: 2271\n",
      "img id in: 2272\n",
      "img id out: 2272\n",
      "img id in: 2273\n",
      "img id out: 2273\n",
      "img id in: 2274\n",
      "img id out: 2274\n",
      "img id in: 2275\n",
      "img id out: 2275\n",
      "img id in: 2276\n",
      "img id out: 2276\n",
      "img id in: 2277\n",
      "img id out: 2277\n",
      "img id in: 2278\n",
      "img id out: 2278\n",
      "img id in: 2279\n",
      "img id out: 2279\n",
      "img id in: 2280\n",
      "img id out: 2280\n",
      "img id in: 2281\n",
      "img id out: 2281\n",
      "img id in: 2282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 2282\n",
      "img id in: 2283\n",
      "img id out: 2283\n",
      "img id in: 2284\n",
      "img id out: 2284\n",
      "img id in: 2285\n",
      "img id out: 2285\n",
      "img id in: 2286\n",
      "img id out: 2286\n",
      "img id in: 2287\n",
      "img id out: 2287\n",
      "img id in: 2288\n",
      "img id out: 2288\n",
      "img id in: 2289\n",
      "img id out: 2289\n",
      "img id in: 2290\n",
      "img id out: 2290\n",
      "img id in: 2291\n",
      "img id out: 2291\n",
      "img id in: 2292\n",
      "img id out: 2292\n",
      "img id in: 2293\n",
      "img id out: 2293\n",
      "img id in: 2294\n",
      "img id out: 2294\n",
      "img id in: 2295\n",
      "img id out: 2295\n",
      "img id in: 2296\n",
      "img id out: 2296\n",
      "img id in: 2297\n",
      "img id out: 2297\n",
      "img id in: 2298\n",
      "img id out: 2298\n",
      "img id in: 2299\n",
      "img id out: 2299\n",
      "img id in: 2300\n",
      "img id out: 2300\n",
      "img id in: 2301\n",
      "img id out: 2301\n",
      "img id in: 2302\n",
      "img id out: 2302\n",
      "img id in: 2303\n",
      "img id out: 2303\n",
      "img id in: 2304\n",
      "img id out: 2304\n",
      "img id in: 2305\n",
      "img id out: 2305\n",
      "img id in: 2306\n",
      "img id out: 2306\n",
      "img id in: 2307\n",
      "img id out: 2307\n",
      "img id in: 2308\n",
      "img id out: 2308\n",
      "img id in: 2309\n",
      "img id out: 2309\n",
      "img id in: 2310\n",
      "img id out: 2310\n",
      "img id in: 2311\n",
      "img id out: 2311\n",
      "img id in: 2312\n",
      "img id out: 2312\n",
      "img id in: 2313\n",
      "img id out: 2313\n",
      "img id in: 2314\n",
      "img id out: 2314\n",
      "img id in: 2315\n",
      "img id out: 2315\n",
      "img id in: 2316\n",
      "img id out: 2316\n",
      "img id in: 2317\n",
      "img id out: 2317\n",
      "img id in: 2318\n",
      "img id out: 2318\n",
      "img id in: 2319\n",
      "img id out: 2319\n",
      "img id in: 2320\n",
      "img id out: 2320\n",
      "img id in: 2321\n",
      "img id out: 2321\n",
      "img id in: 2322\n",
      "img id out: 2322\n",
      "img id in: 2323\n",
      "img id out: 2323\n",
      "img id in: 2324\n",
      "img id out: 2324\n",
      "img id in: 2325\n",
      "img id out: 2325\n",
      "img id in: 2326\n",
      "img id out: 2326\n",
      "img id in: 2327\n",
      "img id out: 2327\n",
      "img id in: 2328\n",
      "img id out: 2328\n",
      "img id in: 2329\n",
      "img id out: 2329\n",
      "img id in: 2330\n",
      "img id out: 2330\n",
      "img id in: 2331\n",
      "img id out: 2331\n",
      "img id in: 2332\n",
      "img id out: 2332\n",
      "img id in: 2333\n",
      "img id out: 2333\n",
      "img id in: 2334\n",
      "img id out: 2334\n",
      "img id in: 2335\n",
      "img id out: 2335\n",
      "img id in: 2336\n",
      "img id out: 2336\n",
      "img id in: 2337\n",
      "img id out: 2337\n",
      "img id in: 2338\n",
      "img id out: 2338\n",
      "img id in: 2339\n",
      "img id out: 2339\n",
      "img id in: 2340\n",
      "img id out: 2340\n",
      "img id in: 2341\n",
      "img id out: 2341\n",
      "img id in: 2342\n",
      "img id out: 2342\n",
      "img id in: 2343\n",
      "img id out: 2343\n",
      "img id in: 2344\n",
      "img id out: 2344\n",
      "img id in: 2345\n",
      "img id out: 2345\n",
      "img id in: 2346\n",
      "img id out: 2346\n",
      "img id in: 2347\n",
      "img id out: 2347\n",
      "img id in: 2348\n",
      "img id out: 2348\n",
      "img id in: 2349\n",
      "img id out: 2349\n",
      "img id in: 2350\n",
      "img id out: 2350\n",
      "img id in: 2351\n",
      "img id out: 2351\n",
      "img id in: 2352\n",
      "img id out: 2352\n",
      "img id in: 2353\n",
      "img id out: 2353\n",
      "img id in: 2354\n",
      "img id out: 2354\n",
      "img id in: 2355\n",
      "img id out: 2355\n",
      "img id in: 2356\n",
      "img id out: 2356\n",
      "img id in: 2357\n",
      "img id out: 2357\n",
      "img id in: 2358\n",
      "img id out: 2358\n",
      "img id in: 2359\n",
      "img id out: 2359\n",
      "img id in: 2360\n",
      "img id out: 2360\n",
      "img id in: 2361\n",
      "img id out: 2361\n",
      "img id in: 2362\n",
      "img id out: 2362\n",
      "img id in: 2363\n",
      "img id out: 2363\n",
      "img id in: 2364\n",
      "img id out: 2364\n",
      "img id in: 2365\n",
      "img id out: 2365\n",
      "img id in: 2366\n",
      "img id out: 2366\n",
      "img id in: 2367\n",
      "img id out: 2367\n",
      "img id in: 2368\n",
      "img id out: 2368\n",
      "img id in: 2369\n",
      "img id out: 2369\n",
      "img id in: 2370\n",
      "img id out: 2370\n",
      "img id in: 2371\n",
      "img id out: 2371\n",
      "img id in: 2372\n",
      "img id out: 2372\n",
      "img id in: 2373\n",
      "img id out: 2373\n",
      "img id in: 2374\n",
      "img id out: 2374\n",
      "img id in: 2375\n",
      "img id out: 2375\n",
      "img id in: 2376\n",
      "img id out: 2376\n",
      "img id in: 2377\n",
      "img id out: 2377\n",
      "img id in: 2378\n",
      "img id out: 2378\n",
      "img id in: 2379\n",
      "img id out: 2379\n",
      "img id in: 2380\n",
      "img id out: 2380\n",
      "img id in: 2381\n",
      "img id out: 2381\n",
      "img id in: 2382\n",
      "img id out: 2382\n",
      "img id in: 2383\n",
      "img id out: 2383\n",
      "img id in: 2384\n",
      "img id out: 2384\n",
      "img id in: 2385\n",
      "img id out: 2385\n",
      "img id in: 2386\n",
      "img id out: 2386\n",
      "img id in: 2387\n",
      "img id out: 2387\n",
      "img id in: 2388\n",
      "img id out: 2388\n",
      "img id in: 2389\n",
      "img id out: 2389\n",
      "img id in: 2390\n",
      "img id out: 2390\n",
      "img id in: 2391\n",
      "img id out: 2391\n",
      "img id in: 2392\n",
      "img id out: 2392\n",
      "img id in: 2393\n",
      "img id out: 2393\n",
      "img id in: 2394\n",
      "img id out: 2394\n",
      "img id in: 2395\n",
      "img id out: 2395\n",
      "img id in: 2396\n",
      "img id out: 2396\n",
      "img id in: 2397\n",
      "img id out: 2397\n",
      "img id in: 2398\n",
      "img id out: 2398\n",
      "img id in: 2399\n",
      "img id out: 2399\n",
      "img id in: 2400\n",
      "img id out: 2400\n",
      "img id in: 2401\n",
      "img id out: 2401\n",
      "img id in: 2402\n",
      "img id out: 2402\n",
      "img id in: 2403\n",
      "img id out: 2403\n",
      "img id in: 2404\n",
      "img id out: 2404\n",
      "img id in: 2405\n",
      "img id out: 2405\n",
      "img id in: 2406\n",
      "img id out: 2406\n",
      "img id in: 2407\n",
      "img id out: 2407\n",
      "img id in: 2408\n",
      "img id out: 2408\n",
      "img id in: 2409\n",
      "img id out: 2409\n",
      "img id in: 2410\n",
      "img id out: 2410\n",
      "img id in: 2411\n",
      "img id out: 2411\n",
      "img id in: 2412\n",
      "img id out: 2412\n",
      "img id in: 2413\n",
      "img id out: 2413\n",
      "img id in: 2414\n",
      "img id out: 2414\n",
      "img id in: 2415\n",
      "img id out: 2415\n",
      "img id in: 2416\n",
      "img id out: 2416\n",
      "img id in: 2417\n",
      "img id out: 2417\n",
      "img id in: 2418\n",
      "img id out: 2418\n",
      "img id in: 2419\n",
      "img id out: 2419\n",
      "img id in: 2420\n",
      "img id out: 2420\n",
      "img id in: 2421\n",
      "img id out: 2421\n",
      "img id in: 2422\n",
      "img id out: 2422\n",
      "img id in: 2423\n",
      "img id out: 2423\n",
      "img id in: 2424\n",
      "img id out: 2424\n",
      "img id in: 2425\n",
      "img id out: 2425\n",
      "img id in: 2426\n",
      "img id out: 2426\n",
      "img id in: 2427\n",
      "img id out: 2427\n",
      "img id in: 2428\n",
      "img id out: 2428\n",
      "img id in: 2429\n",
      "img id out: 2429\n",
      "img id in: 2430\n",
      "img id out: 2430\n",
      "img id in: 2431\n",
      "img id out: 2431\n",
      "img id in: 2432\n",
      "img id out: 2432\n",
      "img id in: 2433\n",
      "img id out: 2433\n",
      "img id in: 2434\n",
      "img id out: 2434\n",
      "img id in: 2435\n",
      "img id out: 2435\n",
      "img id in: 2436\n",
      "img id out: 2436\n",
      "img id in: 2437\n",
      "img id out: 2437\n",
      "img id in: 2438\n",
      "img id out: 2438\n",
      "img id in: 2439\n",
      "img id out: 2439\n",
      "img id in: 2440\n",
      "img id out: 2440\n",
      "img id in: 2441\n",
      "img id out: 2441\n",
      "img id in: 2442\n",
      "img id out: 2442\n",
      "img id in: 2443\n",
      "img id out: 2443\n",
      "img id in: 2444\n",
      "img id out: 2444\n",
      "img id in: 2445\n",
      "img id out: 2445\n",
      "img id in: 2446\n",
      "img id out: 2446\n",
      "img id in: 2447\n",
      "img id out: 2447\n",
      "img id in: 2448\n",
      "img id out: 2448\n",
      "img id in: 2449\n",
      "img id out: 2449\n",
      "img id in: 2450\n",
      "img id out: 2450\n",
      "img id in: 2451\n",
      "img id out: 2451\n",
      "img id in: 2452\n",
      "img id out: 2452\n",
      "img id in: 2453\n",
      "img id out: 2453\n",
      "img id in: 2454\n",
      "img id out: 2454\n",
      "img id in: 2455\n",
      "img id out: 2455\n",
      "img id in: 2456\n",
      "img id out: 2456\n",
      "img id in: 2457\n",
      "img id out: 2457\n",
      "img id in: 2458\n",
      "img id out: 2458\n",
      "img id in: 2459\n",
      "img id out: 2459\n",
      "img id in: 2460\n",
      "img id out: 2460\n",
      "img id in: 2461\n",
      "img id out: 2461\n",
      "img id in: 2462\n",
      "img id out: 2462\n",
      "img id in: 2463\n",
      "img id out: 2463\n",
      "img id in: 2464\n",
      "img id out: 2464\n",
      "img id in: 2465\n",
      "img id out: 2465\n",
      "img id in: 2466\n",
      "img id out: 2466\n",
      "img id in: 2467\n",
      "img id out: 2467\n",
      "img id in: 2468\n",
      "img id out: 2468\n",
      "img id in: 2469\n",
      "img id out: 2469\n",
      "img id in: 2470\n",
      "img id out: 2470\n",
      "img id in: 2471\n",
      "img id out: 2471\n",
      "img id in: 2472\n",
      "img id out: 2472\n",
      "img id in: 2473\n",
      "img id out: 2473\n",
      "img id in: 2474\n",
      "img id out: 2474\n",
      "img id in: 2475\n",
      "img id out: 2475\n",
      "img id in: 2476\n",
      "img id out: 2476\n",
      "img id in: 2477\n",
      "img id out: 2477\n",
      "img id in: 2478\n",
      "img id out: 2478\n",
      "img id in: 2479\n",
      "img id out: 2479\n",
      "img id in: 2480\n",
      "img id out: 2480\n",
      "img id in: 2481\n",
      "img id out: 2481\n",
      "img id in: 2482\n",
      "img id out: 2482\n",
      "img id in: 2483\n",
      "img id out: 2483\n",
      "img id in: 2484\n",
      "img id out: 2484\n",
      "img id in: 2485\n",
      "img id out: 2485\n",
      "img id in: 2486\n",
      "img id out: 2486\n",
      "img id in: 2487\n",
      "img id out: 2487\n",
      "img id in: 2488\n",
      "img id out: 2488\n",
      "img id in: 2489\n",
      "img id out: 2489\n",
      "img id in: 2490\n",
      "img id out: 2490\n",
      "img id in: 2491\n",
      "img id out: 2491\n",
      "img id in: 2492\n",
      "img id out: 2492\n",
      "img id in: 2493\n",
      "img id out: 2493\n",
      "img id in: 2494\n",
      "img id out: 2494\n",
      "img id in: 2495\n",
      "img id out: 2495\n",
      "img id in: 2496\n",
      "img id out: 2496\n",
      "img id in: 2497\n",
      "img id out: 2497\n",
      "img id in: 2498\n",
      "img id out: 2498\n",
      "img id in: 2499\n",
      "img id out: 2499\n",
      "img id in: 2500\n",
      "img id out: 2500\n",
      "img id in: 2501\n",
      "img id out: 2501\n",
      "img id in: 2502\n",
      "img id out: 2502\n",
      "img id in: 2503\n",
      "img id out: 2503\n",
      "img id in: 2504\n",
      "img id out: 2504\n",
      "img id in: 2505\n",
      "img id out: 2505\n",
      "img id in: 2506\n",
      "img id out: 2506\n",
      "img id in: 2507\n",
      "img id out: 2507\n",
      "img id in: 2508\n",
      "img id out: 2508\n",
      "img id in: 2509\n",
      "img id out: 2509\n",
      "img id in: 2510\n",
      "img id out: 2510\n",
      "img id in: 2511\n",
      "img id out: 2511\n",
      "img id in: 2512\n",
      "img id out: 2512\n",
      "img id in: 2513\n",
      "img id out: 2513\n",
      "img id in: 2514\n",
      "img id out: 2514\n",
      "img id in: 2515\n",
      "img id out: 2515\n",
      "img id in: 2516\n",
      "img id out: 2516\n",
      "img id in: 2517\n",
      "img id out: 2517\n",
      "img id in: 2518\n",
      "img id out: 2518\n",
      "img id in: 2519\n",
      "img id out: 2519\n",
      "img id in: 2520\n",
      "img id out: 2520\n",
      "img id in: 2521\n",
      "img id out: 2521\n",
      "img id in: 2522\n",
      "img id out: 2522\n",
      "img id in: 2523\n",
      "img id out: 2523\n",
      "img id in: 2524\n",
      "img id out: 2524\n",
      "img id in: 2525\n",
      "img id out: 2525\n",
      "img id in: 2526\n",
      "img id out: 2526\n",
      "img id in: 2527\n",
      "img id out: 2527\n",
      "img id in: 2528\n",
      "img id out: 2528\n",
      "img id in: 2529\n",
      "img id out: 2529\n",
      "img id in: 2530\n",
      "img id out: 2530\n",
      "img id in: 2531\n",
      "img id out: 2531\n",
      "img id in: 2532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 2532\n",
      "img id in: 2533\n",
      "img id out: 2533\n",
      "img id in: 2534\n",
      "img id out: 2534\n",
      "img id in: 2535\n",
      "img id out: 2535\n",
      "img id in: 2536\n",
      "img id out: 2536\n",
      "img id in: 2537\n",
      "img id out: 2537\n",
      "img id in: 2538\n",
      "img id out: 2538\n",
      "img id in: 2539\n",
      "img id out: 2539\n",
      "img id in: 2540\n",
      "img id out: 2540\n",
      "img id in: 2541\n",
      "img id out: 2541\n",
      "img id in: 2542\n",
      "img id out: 2542\n",
      "img id in: 2543\n",
      "img id out: 2543\n",
      "img id in: 2544\n",
      "img id out: 2544\n",
      "img id in: 2545\n",
      "img id out: 2545\n",
      "img id in: 2546\n",
      "img id out: 2546\n",
      "img id in: 2547\n",
      "img id out: 2547\n",
      "img id in: 2548\n",
      "img id out: 2548\n",
      "img id in: 2549\n",
      "img id out: 2549\n",
      "img id in: 2550\n",
      "img id out: 2550\n",
      "img id in: 2551\n",
      "img id out: 2551\n",
      "img id in: 2552\n",
      "img id out: 2552\n",
      "img id in: 2553\n",
      "img id out: 2553\n",
      "img id in: 2554\n",
      "img id out: 2554\n",
      "img id in: 2555\n",
      "img id out: 2555\n",
      "img id in: 2556\n",
      "img id out: 2556\n",
      "img id in: 2557\n",
      "img id out: 2557\n",
      "img id in: 2558\n",
      "img id out: 2558\n",
      "img id in: 2559\n",
      "img id out: 2559\n",
      "img id in: 2560\n",
      "img id out: 2560\n",
      "img id in: 2561\n",
      "img id out: 2561\n",
      "img id in: 2562\n",
      "img id out: 2562\n",
      "img id in: 2563\n",
      "img id out: 2563\n",
      "img id in: 2564\n",
      "img id out: 2564\n",
      "img id in: 2565\n",
      "img id out: 2565\n",
      "img id in: 2566\n",
      "img id out: 2566\n",
      "img id in: 2567\n",
      "img id out: 2567\n",
      "img id in: 2568\n",
      "img id out: 2568\n",
      "img id in: 2569\n",
      "img id out: 2569\n",
      "img id in: 2570\n",
      "img id out: 2570\n",
      "img id in: 2571\n",
      "img id out: 2571\n",
      "img id in: 2572\n",
      "img id out: 2572\n",
      "img id in: 2573\n",
      "img id out: 2573\n",
      "img id in: 2574\n",
      "img id out: 2574\n",
      "img id in: 2575\n",
      "img id out: 2575\n",
      "img id in: 2576\n",
      "img id out: 2576\n",
      "img id in: 2577\n",
      "img id out: 2577\n",
      "img id in: 2578\n",
      "img id out: 2578\n",
      "img id in: 2579\n",
      "img id out: 2579\n",
      "img id in: 2580\n",
      "img id out: 2580\n",
      "img id in: 2581\n",
      "img id out: 2581\n",
      "img id in: 2582\n",
      "img id out: 2582\n",
      "img id in: 2583\n",
      "img id out: 2583\n",
      "img id in: 2584\n",
      "img id out: 2584\n",
      "img id in: 2585\n",
      "img id out: 2585\n",
      "img id in: 2586\n",
      "img id out: 2586\n",
      "img id in: 2587\n",
      "img id out: 2587\n",
      "img id in: 2588\n",
      "img id out: 2588\n",
      "img id in: 2589\n",
      "img id out: 2589\n",
      "img id in: 2590\n",
      "img id out: 2590\n",
      "img id in: 2591\n",
      "img id out: 2591\n",
      "img id in: 2592\n",
      "img id out: 2592\n",
      "img id in: 2593\n",
      "img id out: 2593\n",
      "img id in: 2594\n",
      "img id out: 2594\n",
      "img id in: 2595\n",
      "img id out: 2595\n",
      "img id in: 2596\n",
      "img id out: 2596\n",
      "img id in: 2597\n",
      "img id out: 2597\n",
      "img id in: 2598\n",
      "img id out: 2598\n",
      "img id in: 2599\n",
      "img id out: 2599\n",
      "img id in: 2600\n",
      "img id out: 2600\n",
      "img id in: 2601\n",
      "img id out: 2601\n",
      "img id in: 2602\n",
      "img id out: 2602\n",
      "img id in: 2603\n",
      "img id out: 2603\n",
      "img id in: 2604\n",
      "img id out: 2604\n",
      "img id in: 2605\n",
      "img id out: 2605\n",
      "img id in: 2606\n",
      "img id out: 2606\n",
      "img id in: 2607\n",
      "img id out: 2607\n",
      "img id in: 2608\n",
      "img id out: 2608\n",
      "img id in: 2609\n",
      "img id out: 2609\n",
      "img id in: 2610\n",
      "img id out: 2610\n",
      "img id in: 2611\n",
      "img id out: 2611\n",
      "img id in: 2612\n",
      "img id out: 2612\n",
      "img id in: 2613\n",
      "img id out: 2613\n",
      "img id in: 2614\n",
      "img id out: 2614\n",
      "img id in: 2615\n",
      "img id out: 2615\n",
      "img id in: 2616\n",
      "img id out: 2616\n",
      "img id in: 2617\n",
      "img id out: 2617\n",
      "img id in: 2618\n",
      "img id out: 2618\n",
      "img id in: 2619\n",
      "img id out: 2619\n",
      "img id in: 2620\n",
      "img id out: 2620\n",
      "img id in: 2621\n",
      "img id out: 2621\n",
      "img id in: 2622\n",
      "img id out: 2622\n",
      "img id in: 2623\n",
      "img id out: 2623\n",
      "img id in: 2624\n",
      "img id out: 2624\n",
      "img id in: 2625\n",
      "img id out: 2625\n",
      "img id in: 2626\n",
      "img id out: 2626\n",
      "img id in: 2627\n",
      "img id out: 2627\n",
      "img id in: 2628\n",
      "img id out: 2628\n",
      "img id in: 2629\n",
      "img id out: 2629\n",
      "img id in: 2630\n",
      "img id out: 2630\n",
      "img id in: 2631\n",
      "img id out: 2631\n",
      "img id in: 2632\n",
      "img id out: 2632\n",
      "img id in: 2633\n",
      "img id out: 2633\n",
      "img id in: 2634\n",
      "img id out: 2634\n",
      "img id in: 2635\n",
      "img id out: 2635\n",
      "img id in: 2636\n",
      "img id out: 2636\n",
      "img id in: 2637\n",
      "img id out: 2637\n",
      "img id in: 2638\n",
      "img id out: 2638\n",
      "img id in: 2639\n",
      "img id out: 2639\n",
      "img id in: 2640\n",
      "img id out: 2640\n",
      "img id in: 2641\n",
      "img id out: 2641\n",
      "img id in: 2642\n",
      "img id out: 2642\n",
      "img id in: 2643\n",
      "img id out: 2643\n",
      "img id in: 2644\n",
      "img id out: 2644\n",
      "img id in: 2645\n",
      "img id out: 2645\n",
      "img id in: 2646\n",
      "img id out: 2646\n",
      "img id in: 2647\n",
      "img id out: 2647\n",
      "img id in: 2648\n",
      "img id out: 2648\n",
      "img id in: 2649\n",
      "img id out: 2649\n",
      "img id in: 2650\n",
      "img id out: 2650\n",
      "img id in: 2651\n",
      "img id out: 2651\n",
      "img id in: 2652\n",
      "img id out: 2652\n",
      "img id in: 2653\n",
      "img id out: 2653\n",
      "img id in: 2654\n",
      "img id out: 2654\n",
      "img id in: 2655\n",
      "img id out: 2655\n",
      "img id in: 2656\n",
      "img id out: 2656\n",
      "img id in: 2657\n",
      "img id out: 2657\n",
      "img id in: 2658\n",
      "img id out: 2658\n",
      "img id in: 2659\n",
      "img id out: 2659\n",
      "img id in: 2660\n",
      "img id out: 2660\n",
      "img id in: 2661\n",
      "img id out: 2661\n",
      "img id in: 2662\n",
      "img id out: 2662\n",
      "img id in: 2663\n",
      "img id out: 2663\n",
      "img id in: 2664\n",
      "img id out: 2664\n",
      "img id in: 2665\n",
      "img id out: 2665\n",
      "img id in: 2666\n",
      "img id out: 2666\n",
      "img id in: 2667\n",
      "img id out: 2667\n",
      "img id in: 2668\n",
      "img id out: 2668\n",
      "img id in: 2669\n",
      "img id out: 2669\n",
      "img id in: 2670\n",
      "img id out: 2670\n",
      "img id in: 2671\n",
      "img id out: 2671\n",
      "img id in: 2672\n",
      "img id out: 2672\n",
      "img id in: 2673\n",
      "img id out: 2673\n",
      "img id in: 2674\n",
      "img id out: 2674\n",
      "img id in: 2675\n",
      "img id out: 2675\n",
      "img id in: 2676\n",
      "img id out: 2676\n",
      "img id in: 2677\n",
      "img id out: 2677\n",
      "img id in: 2678\n",
      "img id out: 2678\n",
      "img id in: 2679\n",
      "img id out: 2679\n",
      "img id in: 2680\n",
      "img id out: 2680\n",
      "img id in: 2681\n",
      "img id out: 2681\n",
      "img id in: 2682\n",
      "img id out: 2682\n",
      "img id in: 2683\n",
      "img id out: 2683\n",
      "img id in: 2684\n",
      "img id out: 2684\n",
      "img id in: 2685\n",
      "img id out: 2685\n",
      "img id in: 2686\n",
      "img id out: 2686\n",
      "img id in: 2687\n",
      "img id out: 2687\n",
      "img id in: 2688\n",
      "img id out: 2688\n",
      "img id in: 2689\n",
      "img id out: 2689\n",
      "img id in: 2690\n",
      "img id out: 2690\n",
      "img id in: 2691\n",
      "img id out: 2691\n",
      "img id in: 2692\n",
      "img id out: 2692\n",
      "img id in: 2693\n",
      "img id out: 2693\n",
      "img id in: 2694\n",
      "img id out: 2694\n",
      "img id in: 2695\n",
      "img id out: 2695\n",
      "img id in: 2696\n",
      "img id out: 2696\n",
      "img id in: 2697\n",
      "img id out: 2697\n",
      "img id in: 2698\n",
      "img id out: 2698\n",
      "img id in: 2699\n",
      "img id out: 2699\n",
      "img id in: 2700\n",
      "img id out: 2700\n",
      "img id in: 2701\n",
      "img id out: 2701\n",
      "img id in: 2702\n",
      "img id out: 2702\n",
      "img id in: 2703\n",
      "img id out: 2703\n",
      "img id in: 2704\n",
      "img id out: 2704\n",
      "img id in: 2705\n",
      "img id out: 2705\n",
      "img id in: 2706\n",
      "img id out: 2706\n",
      "img id in: 2707\n",
      "img id out: 2707\n",
      "img id in: 2708\n",
      "img id out: 2708\n",
      "img id in: 2709\n",
      "img id out: 2709\n",
      "img id in: 2710\n",
      "img id out: 2710\n",
      "img id in: 2711\n",
      "img id out: 2711\n",
      "img id in: 2712\n",
      "img id out: 2712\n",
      "img id in: 2713\n",
      "img id out: 2713\n",
      "img id in: 2714\n",
      "img id out: 2714\n",
      "img id in: 2715\n",
      "img id out: 2715\n",
      "img id in: 2716\n",
      "img id out: 2716\n",
      "img id in: 2717\n",
      "img id out: 2717\n",
      "img id in: 2718\n",
      "img id out: 2718\n",
      "img id in: 2719\n",
      "img id out: 2719\n",
      "img id in: 2720\n",
      "img id out: 2720\n",
      "img id in: 2721\n",
      "img id out: 2721\n",
      "img id in: 2722\n",
      "img id out: 2722\n",
      "img id in: 2723\n",
      "img id out: 2723\n",
      "img id in: 2724\n",
      "img id out: 2724\n",
      "img id in: 2725\n",
      "img id out: 2725\n",
      "img id in: 2726\n",
      "img id out: 2726\n",
      "img id in: 2727\n",
      "img id out: 2727\n",
      "img id in: 2728\n",
      "img id out: 2728\n",
      "img id in: 2729\n",
      "img id out: 2729\n",
      "img id in: 2730\n",
      "img id out: 2730\n",
      "img id in: 2731\n",
      "img id out: 2731\n",
      "img id in: 2732\n",
      "img id out: 2732\n",
      "img id in: 2733\n",
      "img id out: 2733\n",
      "img id in: 2734\n",
      "img id out: 2734\n",
      "img id in: 2735\n",
      "img id out: 2735\n",
      "img id in: 2736\n",
      "img id out: 2736\n",
      "img id in: 2737\n",
      "img id out: 2737\n",
      "img id in: 2738\n",
      "img id out: 2738\n",
      "img id in: 2739\n",
      "img id out: 2739\n",
      "img id in: 2740\n",
      "img id out: 2740\n",
      "img id in: 2741\n",
      "img id out: 2741\n",
      "img id in: 2742\n",
      "img id out: 2742\n",
      "img id in: 2743\n",
      "img id out: 2743\n",
      "img id in: 2744\n",
      "img id out: 2744\n",
      "img id in: 2745\n",
      "img id out: 2745\n",
      "img id in: 2746\n",
      "img id out: 2746\n",
      "img id in: 2747\n",
      "img id out: 2747\n",
      "img id in: 2748\n",
      "img id out: 2748\n",
      "img id in: 2749\n",
      "img id out: 2749\n",
      "img id in: 2750\n",
      "img id out: 2750\n",
      "img id in: 2751\n",
      "img id out: 2751\n",
      "img id in: 2752\n",
      "img id out: 2752\n",
      "img id in: 2753\n",
      "img id out: 2753\n",
      "img id in: 2754\n",
      "img id out: 2754\n",
      "img id in: 2755\n",
      "img id out: 2755\n",
      "img id in: 2756\n",
      "img id out: 2756\n",
      "img id in: 2757\n",
      "img id out: 2757\n",
      "img id in: 2758\n",
      "img id out: 2758\n",
      "img id in: 2759\n",
      "img id out: 2759\n",
      "img id in: 2760\n",
      "img id out: 2760\n",
      "img id in: 2761\n",
      "img id out: 2761\n",
      "img id in: 2762\n",
      "img id out: 2762\n",
      "img id in: 2763\n",
      "img id out: 2763\n",
      "img id in: 2764\n",
      "img id out: 2764\n",
      "img id in: 2765\n",
      "img id out: 2765\n",
      "img id in: 2766\n",
      "img id out: 2766\n",
      "img id in: 2767\n",
      "img id out: 2767\n",
      "img id in: 2768\n",
      "img id out: 2768\n",
      "img id in: 2769\n",
      "img id out: 2769\n",
      "img id in: 2770\n",
      "img id out: 2770\n",
      "img id in: 2771\n",
      "img id out: 2771\n",
      "img id in: 2772\n",
      "img id out: 2772\n",
      "img id in: 2773\n",
      "img id out: 2773\n",
      "img id in: 2774\n",
      "img id out: 2774\n",
      "img id in: 2775\n",
      "img id out: 2775\n",
      "img id in: 2776\n",
      "img id out: 2776\n",
      "img id in: 2777\n",
      "img id out: 2777\n",
      "img id in: 2778\n",
      "img id out: 2778\n",
      "img id in: 2779\n",
      "img id out: 2779\n",
      "img id in: 2780\n",
      "img id out: 2780\n",
      "img id in: 2781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 2781\n",
      "img id in: 2782\n",
      "img id out: 2782\n",
      "img id in: 2783\n",
      "img id out: 2783\n",
      "img id in: 2784\n",
      "img id out: 2784\n",
      "img id in: 2785\n",
      "img id out: 2785\n",
      "img id in: 2786\n",
      "img id out: 2786\n",
      "img id in: 2787\n",
      "img id out: 2787\n",
      "img id in: 2788\n",
      "img id out: 2788\n",
      "img id in: 2789\n",
      "img id out: 2789\n",
      "img id in: 2790\n",
      "img id out: 2790\n",
      "img id in: 2791\n",
      "img id out: 2791\n",
      "img id in: 2792\n",
      "img id out: 2792\n",
      "img id in: 2793\n",
      "img id out: 2793\n",
      "img id in: 2794\n",
      "img id out: 2794\n",
      "img id in: 2795\n",
      "img id out: 2795\n",
      "img id in: 2796\n",
      "img id out: 2796\n",
      "img id in: 2797\n",
      "img id out: 2797\n",
      "img id in: 2798\n",
      "img id out: 2798\n",
      "img id in: 2799\n",
      "img id out: 2799\n",
      "img id in: 2800\n",
      "img id out: 2800\n",
      "img id in: 2801\n",
      "img id out: 2801\n",
      "img id in: 2802\n",
      "img id out: 2802\n",
      "img id in: 2803\n",
      "img id out: 2803\n",
      "img id in: 2804\n",
      "img id out: 2804\n",
      "img id in: 2805\n",
      "img id out: 2805\n",
      "img id in: 2806\n",
      "img id out: 2806\n",
      "img id in: 2807\n",
      "img id out: 2807\n",
      "img id in: 2808\n",
      "img id out: 2808\n",
      "img id in: 2809\n",
      "img id out: 2809\n",
      "img id in: 2810\n",
      "img id out: 2810\n",
      "img id in: 2811\n",
      "img id out: 2811\n",
      "img id in: 2812\n",
      "img id out: 2812\n",
      "img id in: 2813\n",
      "img id out: 2813\n",
      "img id in: 2814\n",
      "img id out: 2814\n",
      "img id in: 2815\n",
      "img id out: 2815\n",
      "img id in: 2816\n",
      "img id out: 2816\n",
      "img id in: 2817\n",
      "img id out: 2817\n",
      "img id in: 2818\n",
      "img id out: 2818\n",
      "img id in: 2819\n",
      "img id out: 2819\n",
      "img id in: 2820\n",
      "img id out: 2820\n",
      "img id in: 2821\n",
      "img id out: 2821\n",
      "img id in: 2822\n",
      "img id out: 2822\n",
      "img id in: 2823\n",
      "img id out: 2823\n",
      "img id in: 2824\n",
      "img id out: 2824\n",
      "img id in: 2825\n",
      "img id out: 2825\n",
      "img id in: 2826\n",
      "img id out: 2826\n",
      "img id in: 2827\n",
      "img id out: 2827\n",
      "img id in: 2828\n",
      "img id out: 2828\n",
      "img id in: 2829\n",
      "img id out: 2829\n",
      "img id in: 2830\n",
      "img id out: 2830\n",
      "img id in: 2831\n",
      "img id out: 2831\n",
      "img id in: 2832\n",
      "img id out: 2832\n",
      "img id in: 2833\n",
      "img id out: 2833\n",
      "img id in: 2834\n",
      "img id out: 2834\n",
      "img id in: 2835\n",
      "img id out: 2835\n",
      "img id in: 2836\n",
      "img id out: 2836\n",
      "img id in: 2837\n",
      "img id out: 2837\n",
      "img id in: 2838\n",
      "img id out: 2838\n",
      "img id in: 2839\n",
      "img id out: 2839\n",
      "img id in: 2840\n",
      "img id out: 2840\n",
      "img id in: 2841\n",
      "img id out: 2841\n",
      "img id in: 2842\n",
      "img id out: 2842\n",
      "img id in: 2843\n",
      "img id out: 2843\n",
      "img id in: 2844\n",
      "img id out: 2844\n",
      "img id in: 2845\n",
      "img id out: 2845\n",
      "img id in: 2846\n",
      "img id out: 2846\n",
      "img id in: 2847\n",
      "img id out: 2847\n",
      "img id in: 2848\n",
      "img id out: 2848\n",
      "img id in: 2849\n",
      "img id out: 2849\n",
      "img id in: 2850\n",
      "img id out: 2850\n",
      "img id in: 2851\n",
      "img id out: 2851\n",
      "img id in: 2852\n",
      "img id out: 2852\n",
      "img id in: 2853\n",
      "img id out: 2853\n",
      "img id in: 2854\n",
      "img id out: 2854\n",
      "img id in: 2855\n",
      "img id out: 2855\n",
      "img id in: 2856\n",
      "img id out: 2856\n",
      "img id in: 2857\n",
      "img id out: 2857\n",
      "img id in: 2858\n",
      "img id out: 2858\n",
      "img id in: 2859\n",
      "img id out: 2859\n",
      "img id in: 2860\n",
      "img id out: 2860\n",
      "img id in: 2861\n",
      "img id out: 2861\n",
      "img id in: 2862\n",
      "img id out: 2862\n",
      "img id in: 2863\n",
      "img id out: 2863\n",
      "img id in: 2864\n",
      "img id out: 2864\n",
      "img id in: 2865\n",
      "img id out: 2865\n",
      "img id in: 2866\n",
      "img id out: 2866\n",
      "img id in: 2867\n",
      "img id out: 2867\n",
      "img id in: 2868\n",
      "img id out: 2868\n",
      "img id in: 2869\n",
      "img id out: 2869\n",
      "img id in: 2870\n",
      "img id out: 2870\n",
      "img id in: 2871\n",
      "img id out: 2871\n",
      "img id in: 2872\n",
      "img id out: 2872\n",
      "img id in: 2873\n",
      "img id out: 2873\n",
      "img id in: 2874\n",
      "img id out: 2874\n",
      "img id in: 2875\n",
      "img id out: 2875\n",
      "img id in: 2876\n",
      "img id out: 2876\n",
      "img id in: 2877\n",
      "img id out: 2877\n",
      "img id in: 2878\n",
      "img id out: 2878\n",
      "img id in: 2879\n",
      "img id out: 2879\n",
      "img id in: 2880\n",
      "img id out: 2880\n",
      "img id in: 2881\n",
      "img id out: 2881\n",
      "img id in: 2882\n",
      "img id out: 2882\n",
      "img id in: 2883\n",
      "img id out: 2883\n",
      "img id in: 2884\n",
      "img id out: 2884\n",
      "img id in: 2885\n",
      "img id out: 2885\n",
      "img id in: 2886\n",
      "img id out: 2886\n",
      "img id in: 2887\n",
      "img id out: 2887\n",
      "img id in: 2888\n",
      "img id out: 2888\n",
      "img id in: 2889\n",
      "img id out: 2889\n",
      "img id in: 2890\n",
      "img id out: 2890\n",
      "img id in: 2891\n",
      "img id out: 2891\n",
      "img id in: 2892\n",
      "img id out: 2892\n",
      "img id in: 2893\n",
      "img id out: 2893\n",
      "img id in: 2894\n",
      "img id out: 2894\n",
      "img id in: 2895\n",
      "img id out: 2895\n",
      "img id in: 2896\n",
      "img id out: 2896\n",
      "img id in: 2897\n",
      "img id out: 2897\n",
      "img id in: 2898\n",
      "img id out: 2898\n",
      "img id in: 2899\n",
      "img id out: 2899\n",
      "img id in: 2900\n",
      "img id out: 2900\n",
      "img id in: 2901\n",
      "img id out: 2901\n",
      "img id in: 2902\n",
      "img id out: 2902\n",
      "img id in: 2903\n",
      "img id out: 2903\n",
      "img id in: 2904\n",
      "img id out: 2904\n",
      "img id in: 2905\n",
      "img id out: 2905\n",
      "img id in: 2906\n",
      "img id out: 2906\n",
      "img id in: 2907\n",
      "img id out: 2907\n",
      "img id in: 2908\n",
      "img id out: 2908\n",
      "img id in: 2909\n",
      "img id out: 2909\n",
      "img id in: 2910\n",
      "img id out: 2910\n",
      "img id in: 2911\n",
      "img id out: 2911\n",
      "img id in: 2912\n",
      "img id out: 2912\n",
      "img id in: 2913\n",
      "img id out: 2913\n",
      "img id in: 2914\n",
      "img id out: 2914\n",
      "img id in: 2915\n",
      "img id out: 2915\n",
      "img id in: 2916\n",
      "img id out: 2916\n",
      "img id in: 2917\n",
      "img id out: 2917\n",
      "img id in: 2918\n",
      "img id out: 2918\n",
      "img id in: 2919\n",
      "img id out: 2919\n",
      "img id in: 2920\n",
      "img id out: 2920\n",
      "img id in: 2921\n",
      "img id out: 2921\n",
      "img id in: 2922\n",
      "img id out: 2922\n",
      "img id in: 2923\n",
      "img id out: 2923\n",
      "img id in: 2924\n",
      "img id out: 2924\n",
      "img id in: 2925\n",
      "img id out: 2925\n",
      "img id in: 2926\n",
      "img id out: 2926\n",
      "img id in: 2927\n",
      "img id out: 2927\n",
      "img id in: 2928\n",
      "img id out: 2928\n",
      "img id in: 2929\n",
      "img id out: 2929\n",
      "img id in: 2930\n",
      "img id out: 2930\n",
      "img id in: 2931\n",
      "img id out: 2931\n",
      "img id in: 2932\n",
      "img id out: 2932\n",
      "img id in: 2933\n",
      "img id out: 2933\n",
      "img id in: 2934\n",
      "img id out: 2934\n",
      "img id in: 2935\n",
      "img id out: 2935\n",
      "img id in: 2936\n",
      "img id out: 2936\n",
      "img id in: 2937\n",
      "img id out: 2937\n",
      "img id in: 2938\n",
      "img id out: 2938\n",
      "img id in: 2939\n",
      "img id out: 2939\n",
      "img id in: 2940\n",
      "img id out: 2940\n",
      "img id in: 2941\n",
      "img id out: 2941\n",
      "img id in: 2942\n",
      "img id out: 2942\n",
      "img id in: 2943\n",
      "img id out: 2943\n",
      "img id in: 2944\n",
      "img id out: 2944\n",
      "img id in: 2945\n",
      "img id out: 2945\n",
      "img id in: 2946\n",
      "img id out: 2946\n",
      "img id in: 2947\n",
      "img id out: 2947\n",
      "img id in: 2948\n",
      "img id out: 2948\n",
      "img id in: 2949\n",
      "img id out: 2949\n",
      "img id in: 2950\n",
      "img id out: 2950\n",
      "img id in: 2951\n",
      "img id out: 2951\n",
      "img id in: 2952\n",
      "img id out: 2952\n",
      "img id in: 2953\n",
      "img id out: 2953\n",
      "img id in: 2954\n",
      "img id out: 2954\n",
      "img id in: 2955\n",
      "img id out: 2955\n",
      "img id in: 2956\n",
      "img id out: 2956\n",
      "img id in: 2957\n",
      "img id out: 2957\n",
      "img id in: 2958\n",
      "img id out: 2958\n",
      "img id in: 2959\n",
      "img id out: 2959\n",
      "img id in: 2960\n",
      "img id out: 2960\n",
      "img id in: 2961\n",
      "img id out: 2961\n",
      "img id in: 2962\n",
      "img id out: 2962\n",
      "img id in: 2963\n",
      "img id out: 2963\n",
      "img id in: 2964\n",
      "img id out: 2964\n",
      "img id in: 2965\n",
      "img id out: 2965\n",
      "img id in: 2966\n",
      "img id out: 2966\n",
      "img id in: 2967\n",
      "img id out: 2967\n",
      "img id in: 2968\n",
      "img id out: 2968\n",
      "img id in: 2969\n",
      "img id out: 2969\n",
      "img id in: 2970\n",
      "img id out: 2970\n",
      "img id in: 2971\n",
      "img id out: 2971\n",
      "img id in: 2972\n",
      "img id out: 2972\n",
      "img id in: 2973\n",
      "img id out: 2973\n",
      "img id in: 2974\n",
      "img id out: 2974\n",
      "img id in: 2975\n",
      "img id out: 2975\n",
      "img id in: 2976\n",
      "img id out: 2976\n",
      "img id in: 2977\n",
      "img id out: 2977\n",
      "img id in: 2978\n",
      "img id out: 2978\n",
      "img id in: 2979\n",
      "img id out: 2979\n",
      "img id in: 2980\n",
      "img id out: 2980\n",
      "img id in: 2981\n",
      "img id out: 2981\n",
      "img id in: 2982\n",
      "img id out: 2982\n",
      "img id in: 2983\n",
      "img id out: 2983\n",
      "img id in: 2984\n",
      "img id out: 2984\n",
      "img id in: 2985\n",
      "img id out: 2985\n",
      "img id in: 2986\n",
      "img id out: 2986\n",
      "img id in: 2987\n",
      "img id out: 2987\n",
      "img id in: 2988\n",
      "img id out: 2988\n",
      "img id in: 2989\n",
      "img id out: 2989\n",
      "img id in: 2990\n",
      "img id out: 2990\n",
      "img id in: 2991\n",
      "img id out: 2991\n",
      "img id in: 2992\n",
      "img id out: 2992\n",
      "img id in: 2993\n",
      "img id out: 2993\n",
      "img id in: 2994\n",
      "img id out: 2994\n",
      "img id in: 2995\n",
      "img id out: 2995\n",
      "img id in: 2996\n",
      "img id out: 2996\n",
      "img id in: 2997\n",
      "img id out: 2997\n",
      "img id in: 2998\n",
      "img id out: 2998\n",
      "img id in: 2999\n",
      "img id out: 2999\n",
      "img id in: 3000\n",
      "img id out: 3000\n",
      "img id in: 3001\n",
      "img id out: 3001\n",
      "img id in: 3002\n",
      "img id out: 3002\n",
      "img id in: 3003\n",
      "img id out: 3003\n",
      "img id in: 3004\n",
      "img id out: 3004\n",
      "img id in: 3005\n",
      "img id out: 3005\n",
      "img id in: 3006\n",
      "img id out: 3006\n",
      "img id in: 3007\n",
      "img id out: 3007\n",
      "img id in: 3008\n",
      "img id out: 3008\n",
      "img id in: 3009\n",
      "img id out: 3009\n",
      "img id in: 3010\n",
      "img id out: 3010\n",
      "img id in: 3011\n",
      "img id out: 3011\n",
      "img id in: 3012\n",
      "img id out: 3012\n",
      "img id in: 3013\n",
      "img id out: 3013\n",
      "img id in: 3014\n",
      "img id out: 3014\n",
      "img id in: 3015\n",
      "img id out: 3015\n",
      "img id in: 3016\n",
      "img id out: 3016\n",
      "img id in: 3017\n",
      "img id out: 3017\n",
      "img id in: 3018\n",
      "img id out: 3018\n",
      "img id in: 3019\n",
      "img id out: 3019\n",
      "img id in: 3020\n",
      "img id out: 3020\n",
      "img id in: 3021\n",
      "img id out: 3021\n",
      "img id in: 3022\n",
      "img id out: 3022\n",
      "img id in: 3023\n",
      "img id out: 3023\n",
      "img id in: 3024\n",
      "img id out: 3024\n",
      "img id in: 3025\n",
      "img id out: 3025\n",
      "img id in: 3026\n",
      "img id out: 3026\n",
      "img id in: 3027\n",
      "img id out: 3027\n",
      "img id in: 3028\n",
      "img id out: 3028\n",
      "img id in: 3029\n",
      "img id out: 3029\n",
      "img id in: 3030\n",
      "img id out: 3030\n",
      "img id in: 3031\n",
      "img id out: 3031\n",
      "img id in: 3032\n",
      "img id out: 3032\n",
      "img id in: 3033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 3033\n",
      "img id in: 3034\n",
      "img id out: 3034\n",
      "img id in: 3035\n",
      "img id out: 3035\n",
      "img id in: 3036\n",
      "img id out: 3036\n",
      "img id in: 3037\n",
      "img id out: 3037\n",
      "img id in: 3038\n",
      "img id out: 3038\n",
      "img id in: 3039\n",
      "img id out: 3039\n",
      "img id in: 3040\n",
      "img id out: 3040\n",
      "img id in: 3041\n",
      "img id out: 3041\n",
      "img id in: 3042\n",
      "img id out: 3042\n",
      "img id in: 3043\n",
      "img id out: 3043\n",
      "img id in: 3044\n",
      "img id out: 3044\n",
      "img id in: 3045\n",
      "img id out: 3045\n",
      "img id in: 3046\n",
      "img id out: 3046\n",
      "img id in: 3047\n",
      "img id out: 3047\n",
      "img id in: 3048\n",
      "img id out: 3048\n",
      "img id in: 3049\n",
      "img id out: 3049\n",
      "img id in: 3050\n",
      "img id out: 3050\n",
      "img id in: 3051\n",
      "img id out: 3051\n",
      "img id in: 3052\n",
      "img id out: 3052\n",
      "img id in: 3053\n",
      "img id out: 3053\n",
      "img id in: 3054\n",
      "img id out: 3054\n",
      "img id in: 3055\n",
      "img id out: 3055\n",
      "img id in: 3056\n",
      "img id out: 3056\n",
      "img id in: 3057\n",
      "img id out: 3057\n",
      "img id in: 3058\n",
      "img id out: 3058\n",
      "img id in: 3059\n",
      "img id out: 3059\n",
      "img id in: 3060\n",
      "img id out: 3060\n",
      "img id in: 3061\n",
      "img id out: 3061\n",
      "img id in: 3062\n",
      "img id out: 3062\n",
      "img id in: 3063\n",
      "img id out: 3063\n",
      "img id in: 3064\n",
      "img id out: 3064\n",
      "img id in: 3065\n",
      "img id out: 3065\n",
      "img id in: 3066\n",
      "img id out: 3066\n",
      "img id in: 3067\n",
      "img id out: 3067\n",
      "img id in: 3068\n",
      "img id out: 3068\n",
      "img id in: 3069\n",
      "img id out: 3069\n",
      "img id in: 3070\n",
      "img id out: 3070\n",
      "img id in: 3071\n",
      "img id out: 3071\n",
      "img id in: 3072\n",
      "img id out: 3072\n",
      "img id in: 3073\n",
      "img id out: 3073\n",
      "img id in: 3074\n",
      "img id out: 3074\n",
      "img id in: 3075\n",
      "img id out: 3075\n",
      "img id in: 3076\n",
      "img id out: 3076\n",
      "img id in: 3077\n",
      "img id out: 3077\n",
      "img id in: 3078\n",
      "img id out: 3078\n",
      "img id in: 3079\n",
      "img id out: 3079\n",
      "img id in: 3080\n",
      "img id out: 3080\n",
      "img id in: 3081\n",
      "img id out: 3081\n",
      "img id in: 3082\n",
      "img id out: 3082\n",
      "img id in: 3083\n",
      "img id out: 3083\n",
      "img id in: 3084\n",
      "img id out: 3084\n",
      "img id in: 3085\n",
      "img id out: 3085\n",
      "img id in: 3086\n",
      "img id out: 3086\n",
      "img id in: 3087\n",
      "img id out: 3087\n",
      "img id in: 3088\n",
      "img id out: 3088\n",
      "img id in: 3089\n",
      "img id out: 3089\n",
      "img id in: 3090\n",
      "img id out: 3090\n",
      "img id in: 3091\n",
      "img id out: 3091\n",
      "img id in: 3092\n",
      "img id out: 3092\n",
      "img id in: 3093\n",
      "img id out: 3093\n",
      "img id in: 3094\n",
      "img id out: 3094\n",
      "img id in: 3095\n",
      "img id out: 3095\n",
      "img id in: 3096\n",
      "img id out: 3096\n",
      "img id in: 3097\n",
      "img id out: 3097\n",
      "img id in: 3098\n",
      "img id out: 3098\n",
      "img id in: 3099\n",
      "img id out: 3099\n",
      "img id in: 3100\n",
      "img id out: 3100\n",
      "img id in: 3101\n",
      "img id out: 3101\n",
      "img id in: 3102\n",
      "img id out: 3102\n",
      "img id in: 3103\n",
      "img id out: 3103\n",
      "img id in: 3104\n",
      "img id out: 3104\n",
      "img id in: 3105\n",
      "img id out: 3105\n",
      "img id in: 3106\n",
      "img id out: 3106\n",
      "img id in: 3107\n",
      "img id out: 3107\n",
      "img id in: 3108\n",
      "img id out: 3108\n",
      "img id in: 3109\n",
      "img id out: 3109\n",
      "img id in: 3110\n",
      "img id out: 3110\n",
      "img id in: 3111\n",
      "img id out: 3111\n",
      "img id in: 3112\n",
      "img id out: 3112\n",
      "img id in: 3113\n",
      "img id out: 3113\n",
      "img id in: 3114\n",
      "img id out: 3114\n",
      "img id in: 3115\n",
      "img id out: 3115\n",
      "img id in: 3116\n",
      "img id out: 3116\n",
      "img id in: 3117\n",
      "img id out: 3117\n",
      "img id in: 3118\n",
      "img id out: 3118\n",
      "img id in: 3119\n",
      "img id out: 3119\n",
      "img id in: 3120\n",
      "img id out: 3120\n",
      "img id in: 3121\n",
      "img id out: 3121\n",
      "img id in: 3122\n",
      "img id out: 3122\n",
      "img id in: 3123\n",
      "img id out: 3123\n",
      "img id in: 3124\n",
      "img id out: 3124\n",
      "img id in: 3125\n",
      "img id out: 3125\n",
      "img id in: 3126\n",
      "img id out: 3126\n",
      "img id in: 3127\n",
      "img id out: 3127\n",
      "img id in: 3128\n",
      "img id out: 3128\n",
      "img id in: 3129\n",
      "img id out: 3129\n",
      "img id in: 3130\n",
      "img id out: 3130\n",
      "img id in: 3131\n",
      "img id out: 3131\n",
      "img id in: 3132\n",
      "img id out: 3132\n",
      "img id in: 3133\n",
      "img id out: 3133\n",
      "img id in: 3134\n",
      "img id out: 3134\n",
      "img id in: 3135\n",
      "img id out: 3135\n",
      "img id in: 3136\n",
      "img id out: 3136\n",
      "img id in: 3137\n",
      "img id out: 3137\n",
      "img id in: 3138\n",
      "img id out: 3138\n",
      "img id in: 3139\n",
      "img id out: 3139\n",
      "img id in: 3140\n",
      "img id out: 3140\n",
      "img id in: 3141\n",
      "img id out: 3141\n",
      "img id in: 3142\n",
      "img id out: 3142\n",
      "img id in: 3143\n",
      "img id out: 3143\n",
      "img id in: 3144\n",
      "img id out: 3144\n",
      "img id in: 3145\n",
      "img id out: 3145\n",
      "img id in: 3146\n",
      "img id out: 3146\n",
      "img id in: 3147\n",
      "img id out: 3147\n",
      "img id in: 3148\n",
      "img id out: 3148\n",
      "img id in: 3149\n",
      "img id out: 3149\n",
      "img id in: 3150\n",
      "img id out: 3150\n",
      "img id in: 3151\n",
      "img id out: 3151\n",
      "img id in: 3152\n",
      "img id out: 3152\n",
      "img id in: 3153\n",
      "img id out: 3153\n",
      "img id in: 3154\n",
      "img id out: 3154\n",
      "img id in: 3155\n",
      "img id out: 3155\n",
      "img id in: 3156\n",
      "img id out: 3156\n",
      "img id in: 3157\n",
      "img id out: 3157\n",
      "img id in: 3158\n",
      "img id out: 3158\n",
      "img id in: 3159\n",
      "img id out: 3159\n",
      "img id in: 3160\n",
      "img id out: 3160\n",
      "img id in: 3161\n",
      "img id out: 3161\n",
      "img id in: 3162\n",
      "img id out: 3162\n",
      "img id in: 3163\n",
      "img id out: 3163\n",
      "img id in: 3164\n",
      "img id out: 3164\n",
      "img id in: 3165\n",
      "img id out: 3165\n",
      "img id in: 3166\n",
      "img id out: 3166\n",
      "img id in: 3167\n",
      "img id out: 3167\n",
      "img id in: 3168\n",
      "img id out: 3168\n",
      "img id in: 3169\n",
      "img id out: 3169\n",
      "img id in: 3170\n",
      "img id out: 3170\n",
      "img id in: 3171\n",
      "img id out: 3171\n",
      "img id in: 3172\n",
      "img id out: 3172\n",
      "img id in: 3173\n",
      "img id out: 3173\n",
      "img id in: 3174\n",
      "img id out: 3174\n",
      "img id in: 3175\n",
      "img id out: 3175\n",
      "img id in: 3176\n",
      "img id out: 3176\n",
      "img id in: 3177\n",
      "img id out: 3177\n",
      "img id in: 3178\n",
      "img id out: 3178\n",
      "img id in: 3179\n",
      "img id out: 3179\n",
      "img id in: 3180\n",
      "img id out: 3180\n",
      "img id in: 3181\n",
      "img id out: 3181\n",
      "img id in: 3182\n",
      "img id out: 3182\n",
      "img id in: 3183\n",
      "img id out: 3183\n",
      "img id in: 3184\n",
      "img id out: 3184\n",
      "img id in: 3185\n",
      "img id out: 3185\n",
      "img id in: 3186\n",
      "img id out: 3186\n",
      "img id in: 3187\n",
      "img id out: 3187\n",
      "img id in: 3188\n",
      "img id out: 3188\n",
      "img id in: 3189\n",
      "img id out: 3189\n",
      "img id in: 3190\n",
      "img id out: 3190\n",
      "img id in: 3191\n",
      "img id out: 3191\n",
      "img id in: 3192\n",
      "img id out: 3192\n",
      "img id in: 3193\n",
      "img id out: 3193\n",
      "img id in: 3194\n",
      "img id out: 3194\n",
      "img id in: 3195\n",
      "img id out: 3195\n",
      "img id in: 3196\n",
      "img id out: 3196\n",
      "img id in: 3197\n",
      "img id out: 3197\n",
      "img id in: 3198\n",
      "img id out: 3198\n",
      "img id in: 3199\n",
      "img id out: 3199\n",
      "img id in: 3200\n",
      "img id out: 3200\n",
      "img id in: 3201\n",
      "img id out: 3201\n",
      "img id in: 3202\n",
      "img id out: 3202\n",
      "img id in: 3203\n",
      "img id out: 3203\n",
      "img id in: 3204\n",
      "img id out: 3204\n",
      "img id in: 3205\n",
      "img id out: 3205\n",
      "img id in: 3206\n",
      "img id out: 3206\n",
      "img id in: 3207\n",
      "img id out: 3207\n",
      "img id in: 3208\n",
      "img id out: 3208\n",
      "img id in: 3209\n",
      "img id out: 3209\n",
      "img id in: 3210\n",
      "img id out: 3210\n",
      "img id in: 3211\n",
      "img id out: 3211\n",
      "img id in: 3212\n",
      "img id out: 3212\n",
      "img id in: 3213\n",
      "img id out: 3213\n",
      "img id in: 3214\n",
      "img id out: 3214\n",
      "img id in: 3215\n",
      "img id out: 3215\n",
      "img id in: 3216\n",
      "img id out: 3216\n",
      "img id in: 3217\n",
      "img id out: 3217\n",
      "img id in: 3218\n",
      "img id out: 3218\n",
      "img id in: 3219\n",
      "img id out: 3219\n",
      "img id in: 3220\n",
      "img id out: 3220\n",
      "img id in: 3221\n",
      "img id out: 3221\n",
      "img id in: 3222\n",
      "img id out: 3222\n",
      "img id in: 3223\n",
      "img id out: 3223\n",
      "img id in: 3224\n",
      "img id out: 3224\n",
      "img id in: 3225\n",
      "img id out: 3225\n",
      "img id in: 3226\n",
      "img id out: 3226\n",
      "img id in: 3227\n",
      "img id out: 3227\n",
      "img id in: 3228\n",
      "img id out: 3228\n",
      "img id in: 3229\n",
      "img id out: 3229\n",
      "img id in: 3230\n",
      "img id out: 3230\n",
      "img id in: 3231\n",
      "img id out: 3231\n",
      "img id in: 3232\n",
      "img id out: 3232\n",
      "img id in: 3233\n",
      "img id out: 3233\n",
      "img id in: 3234\n",
      "img id out: 3234\n",
      "img id in: 3235\n",
      "img id out: 3235\n",
      "img id in: 3236\n",
      "img id out: 3236\n",
      "img id in: 3237\n",
      "img id out: 3237\n",
      "img id in: 3238\n",
      "img id out: 3238\n",
      "img id in: 3239\n",
      "img id out: 3239\n",
      "img id in: 3240\n",
      "img id out: 3240\n",
      "img id in: 3241\n",
      "img id out: 3241\n",
      "img id in: 3242\n",
      "img id out: 3242\n",
      "img id in: 3243\n",
      "img id out: 3243\n",
      "img id in: 3244\n",
      "img id out: 3244\n",
      "img id in: 3245\n",
      "img id out: 3245\n",
      "img id in: 3246\n",
      "img id out: 3246\n",
      "img id in: 3247\n",
      "img id out: 3247\n",
      "img id in: 3248\n",
      "img id out: 3248\n",
      "img id in: 3249\n",
      "img id out: 3249\n",
      "img id in: 3250\n",
      "img id out: 3250\n",
      "img id in: 3251\n",
      "img id out: 3251\n",
      "img id in: 3252\n",
      "img id out: 3252\n",
      "img id in: 3253\n",
      "img id out: 3253\n",
      "img id in: 3254\n",
      "img id out: 3254\n",
      "img id in: 3255\n",
      "img id out: 3255\n",
      "img id in: 3256\n",
      "img id out: 3256\n",
      "img id in: 3257\n",
      "img id out: 3257\n",
      "img id in: 3258\n",
      "img id out: 3258\n",
      "img id in: 3259\n",
      "img id out: 3259\n",
      "img id in: 3260\n",
      "img id out: 3260\n",
      "img id in: 3261\n",
      "img id out: 3261\n",
      "img id in: 3262\n",
      "img id out: 3262\n",
      "img id in: 3263\n",
      "img id out: 3263\n",
      "img id in: 3264\n",
      "img id out: 3264\n",
      "img id in: 3265\n",
      "img id out: 3265\n",
      "img id in: 3266\n",
      "img id out: 3266\n",
      "img id in: 3267\n",
      "img id out: 3267\n",
      "img id in: 3268\n",
      "img id out: 3268\n",
      "img id in: 3269\n",
      "img id out: 3269\n",
      "img id in: 3270\n",
      "img id out: 3270\n",
      "img id in: 3271\n",
      "img id out: 3271\n",
      "img id in: 3272\n",
      "img id out: 3272\n",
      "img id in: 3273\n",
      "img id out: 3273\n",
      "img id in: 3274\n",
      "img id out: 3274\n",
      "img id in: 3275\n",
      "img id out: 3275\n",
      "img id in: 3276\n",
      "img id out: 3276\n",
      "img id in: 3277\n",
      "img id out: 3277\n",
      "img id in: 3278\n",
      "img id out: 3278\n",
      "img id in: 3279\n",
      "img id out: 3279\n",
      "img id in: 3280\n",
      "img id out: 3280\n",
      "img id in: 3281\n",
      "img id out: 3281\n",
      "img id in: 3282\n",
      "img id out: 3282\n",
      "img id in: 3283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 3283\n",
      "img id in: 3284\n",
      "img id out: 3284\n",
      "img id in: 3285\n",
      "img id out: 3285\n",
      "img id in: 3286\n",
      "img id out: 3286\n",
      "img id in: 3287\n",
      "img id out: 3287\n",
      "img id in: 3288\n",
      "img id out: 3288\n",
      "img id in: 3289\n",
      "img id out: 3289\n",
      "img id in: 3290\n",
      "img id out: 3290\n",
      "img id in: 3291\n",
      "img id out: 3291\n",
      "img id in: 3292\n",
      "img id out: 3292\n",
      "img id in: 3293\n",
      "img id out: 3293\n",
      "img id in: 3294\n",
      "img id out: 3294\n",
      "img id in: 3295\n",
      "img id out: 3295\n",
      "img id in: 3296\n",
      "img id out: 3296\n",
      "img id in: 3297\n",
      "img id out: 3297\n",
      "img id in: 3298\n",
      "img id out: 3298\n",
      "img id in: 3299\n",
      "img id out: 3299\n",
      "img id in: 3300\n",
      "img id out: 3300\n",
      "img id in: 3301\n",
      "img id out: 3301\n",
      "img id in: 3302\n",
      "img id out: 3302\n",
      "img id in: 3303\n",
      "img id out: 3303\n",
      "img id in: 3304\n",
      "img id out: 3304\n",
      "img id in: 3305\n",
      "img id out: 3305\n",
      "img id in: 3306\n",
      "img id out: 3306\n",
      "img id in: 3307\n",
      "img id out: 3307\n",
      "img id in: 3308\n",
      "img id out: 3308\n",
      "img id in: 3309\n",
      "img id out: 3309\n",
      "img id in: 3310\n",
      "img id out: 3310\n",
      "img id in: 3311\n",
      "img id out: 3311\n",
      "img id in: 3312\n",
      "img id out: 3312\n",
      "img id in: 3313\n",
      "img id out: 3313\n",
      "img id in: 3314\n",
      "img id out: 3314\n",
      "img id in: 3315\n",
      "img id out: 3315\n",
      "img id in: 3316\n",
      "img id out: 3316\n",
      "img id in: 3317\n",
      "img id out: 3317\n",
      "img id in: 3318\n",
      "img id out: 3318\n",
      "img id in: 3319\n",
      "img id out: 3319\n",
      "img id in: 3320\n",
      "img id out: 3320\n",
      "img id in: 3321\n",
      "img id out: 3321\n",
      "img id in: 3322\n",
      "img id out: 3322\n",
      "img id in: 3323\n",
      "img id out: 3323\n",
      "img id in: 3324\n",
      "img id out: 3324\n",
      "img id in: 3325\n",
      "img id out: 3325\n",
      "img id in: 3326\n",
      "img id out: 3326\n",
      "img id in: 3327\n",
      "img id out: 3327\n",
      "img id in: 3328\n",
      "img id out: 3328\n",
      "img id in: 3329\n",
      "img id out: 3329\n",
      "img id in: 3330\n",
      "img id out: 3330\n",
      "img id in: 3331\n",
      "img id out: 3331\n",
      "img id in: 3332\n",
      "img id out: 3332\n",
      "img id in: 3333\n",
      "img id out: 3333\n",
      "img id in: 3334\n",
      "img id out: 3334\n",
      "img id in: 3335\n",
      "img id out: 3335\n",
      "img id in: 3336\n",
      "img id out: 3336\n",
      "img id in: 3337\n",
      "img id out: 3337\n",
      "img id in: 3338\n",
      "img id out: 3338\n",
      "img id in: 3339\n",
      "img id out: 3339\n",
      "img id in: 3340\n",
      "img id out: 3340\n",
      "img id in: 3341\n",
      "img id out: 3341\n",
      "img id in: 3342\n",
      "img id out: 3342\n",
      "img id in: 3343\n",
      "img id out: 3343\n",
      "img id in: 3344\n",
      "img id out: 3344\n",
      "img id in: 3345\n",
      "img id out: 3345\n",
      "img id in: 3346\n",
      "img id out: 3346\n",
      "img id in: 3347\n",
      "img id out: 3347\n",
      "img id in: 3348\n",
      "img id out: 3348\n",
      "img id in: 3349\n",
      "img id out: 3349\n",
      "img id in: 3350\n",
      "img id out: 3350\n",
      "img id in: 3351\n",
      "img id out: 3351\n",
      "img id in: 3352\n",
      "img id out: 3352\n",
      "img id in: 3353\n",
      "img id out: 3353\n",
      "img id in: 3354\n",
      "img id out: 3354\n",
      "img id in: 3355\n",
      "img id out: 3355\n",
      "img id in: 3356\n",
      "img id out: 3356\n",
      "img id in: 3357\n",
      "img id out: 3357\n",
      "img id in: 3358\n",
      "img id out: 3358\n",
      "img id in: 3359\n",
      "img id out: 3359\n",
      "img id in: 3360\n",
      "img id out: 3360\n",
      "img id in: 3361\n",
      "img id out: 3361\n",
      "img id in: 3362\n",
      "img id out: 3362\n",
      "img id in: 3363\n",
      "img id out: 3363\n",
      "img id in: 3364\n",
      "img id out: 3364\n",
      "img id in: 3365\n",
      "img id out: 3365\n",
      "img id in: 3366\n",
      "img id out: 3366\n",
      "img id in: 3367\n",
      "img id out: 3367\n",
      "img id in: 3368\n",
      "img id out: 3368\n",
      "img id in: 3369\n",
      "img id out: 3369\n",
      "img id in: 3370\n",
      "img id out: 3370\n",
      "img id in: 3371\n",
      "img id out: 3371\n",
      "img id in: 3372\n",
      "img id out: 3372\n",
      "img id in: 3373\n",
      "img id out: 3373\n",
      "img id in: 3374\n",
      "img id out: 3374\n",
      "img id in: 3375\n",
      "img id out: 3375\n",
      "img id in: 3376\n",
      "img id out: 3376\n",
      "img id in: 3377\n",
      "img id out: 3377\n",
      "img id in: 3378\n",
      "img id out: 3378\n",
      "img id in: 3379\n",
      "img id out: 3379\n",
      "img id in: 3380\n",
      "img id out: 3380\n",
      "img id in: 3381\n",
      "img id out: 3381\n",
      "img id in: 3382\n",
      "img id out: 3382\n",
      "img id in: 3383\n",
      "img id out: 3383\n",
      "img id in: 3384\n",
      "img id out: 3384\n",
      "img id in: 3385\n",
      "img id out: 3385\n",
      "img id in: 3386\n",
      "img id out: 3386\n",
      "img id in: 3387\n",
      "img id out: 3387\n",
      "img id in: 3388\n",
      "img id out: 3388\n",
      "img id in: 3389\n",
      "img id out: 3389\n",
      "img id in: 3390\n",
      "img id out: 3390\n",
      "img id in: 3391\n",
      "img id out: 3391\n",
      "img id in: 3392\n",
      "img id out: 3392\n",
      "img id in: 3393\n",
      "img id out: 3393\n",
      "img id in: 3394\n",
      "img id out: 3394\n",
      "img id in: 3395\n",
      "img id out: 3395\n",
      "img id in: 3396\n",
      "img id out: 3396\n",
      "img id in: 3397\n",
      "img id out: 3397\n",
      "img id in: 3398\n",
      "img id out: 3398\n",
      "img id in: 3399\n",
      "img id out: 3399\n",
      "img id in: 3400\n",
      "img id out: 3400\n",
      "img id in: 3401\n",
      "img id out: 3401\n",
      "img id in: 3402\n",
      "img id out: 3402\n",
      "img id in: 3403\n",
      "img id out: 3403\n",
      "img id in: 3404\n",
      "img id out: 3404\n",
      "img id in: 3405\n",
      "img id out: 3405\n",
      "img id in: 3406\n",
      "img id out: 3406\n",
      "img id in: 3407\n",
      "img id out: 3407\n",
      "img id in: 3408\n",
      "img id out: 3408\n",
      "img id in: 3409\n",
      "img id out: 3409\n",
      "img id in: 3410\n",
      "img id out: 3410\n",
      "img id in: 3411\n",
      "img id out: 3411\n",
      "img id in: 3412\n",
      "img id out: 3412\n",
      "img id in: 3413\n",
      "img id out: 3413\n",
      "img id in: 3414\n",
      "img id out: 3414\n",
      "img id in: 3415\n",
      "img id out: 3415\n",
      "img id in: 3416\n",
      "img id out: 3416\n",
      "img id in: 3417\n",
      "img id out: 3417\n",
      "img id in: 3418\n",
      "img id out: 3418\n",
      "img id in: 3419\n",
      "img id out: 3419\n",
      "img id in: 3420\n",
      "img id out: 3420\n",
      "img id in: 3421\n",
      "img id out: 3421\n",
      "img id in: 3422\n",
      "img id out: 3422\n",
      "img id in: 3423\n",
      "img id out: 3423\n",
      "img id in: 3424\n",
      "img id out: 3424\n",
      "img id in: 3425\n",
      "img id out: 3425\n",
      "img id in: 3426\n",
      "img id out: 3426\n",
      "img id in: 3427\n",
      "img id out: 3427\n",
      "img id in: 3428\n",
      "img id out: 3428\n",
      "img id in: 3429\n",
      "img id out: 3429\n",
      "img id in: 3430\n",
      "img id out: 3430\n",
      "img id in: 3431\n",
      "img id out: 3431\n",
      "img id in: 3432\n",
      "img id out: 3432\n",
      "img id in: 3433\n",
      "img id out: 3433\n",
      "img id in: 3434\n",
      "img id out: 3434\n",
      "img id in: 3435\n",
      "img id out: 3435\n",
      "img id in: 3436\n",
      "img id out: 3436\n",
      "img id in: 3437\n",
      "img id out: 3437\n",
      "img id in: 3438\n",
      "img id out: 3438\n",
      "img id in: 3439\n",
      "img id out: 3439\n",
      "img id in: 3440\n",
      "img id out: 3440\n",
      "img id in: 3441\n",
      "img id out: 3441\n",
      "img id in: 3442\n",
      "img id out: 3442\n",
      "img id in: 3443\n",
      "img id out: 3443\n",
      "img id in: 3444\n",
      "img id out: 3444\n",
      "img id in: 3445\n",
      "img id out: 3445\n",
      "img id in: 3446\n",
      "img id out: 3446\n",
      "img id in: 3447\n",
      "img id out: 3447\n",
      "img id in: 3448\n",
      "img id out: 3448\n",
      "img id in: 3449\n",
      "img id out: 3449\n",
      "img id in: 3450\n",
      "img id out: 3450\n",
      "img id in: 3451\n",
      "img id out: 3451\n",
      "img id in: 3452\n",
      "img id out: 3452\n",
      "img id in: 3453\n",
      "img id out: 3453\n",
      "img id in: 3454\n",
      "img id out: 3454\n",
      "img id in: 3455\n",
      "img id out: 3455\n",
      "img id in: 3456\n",
      "img id out: 3456\n",
      "img id in: 3457\n",
      "img id out: 3457\n",
      "img id in: 3458\n",
      "img id out: 3458\n",
      "img id in: 3459\n",
      "img id out: 3459\n",
      "img id in: 3460\n",
      "img id out: 3460\n",
      "img id in: 3461\n",
      "img id out: 3461\n",
      "img id in: 3462\n",
      "img id out: 3462\n",
      "img id in: 3463\n",
      "img id out: 3463\n",
      "img id in: 3464\n",
      "img id out: 3464\n",
      "img id in: 3465\n",
      "img id out: 3465\n",
      "img id in: 3466\n",
      "img id out: 3466\n",
      "img id in: 3467\n",
      "img id out: 3467\n",
      "img id in: 3468\n",
      "img id out: 3468\n",
      "img id in: 3469\n",
      "img id out: 3469\n",
      "img id in: 3470\n",
      "img id out: 3470\n",
      "img id in: 3471\n",
      "img id out: 3471\n",
      "img id in: 3472\n",
      "img id out: 3472\n",
      "img id in: 3473\n",
      "img id out: 3473\n",
      "img id in: 3474\n",
      "img id out: 3474\n",
      "img id in: 3475\n",
      "img id out: 3475\n",
      "img id in: 3476\n",
      "img id out: 3476\n",
      "img id in: 3477\n",
      "img id out: 3477\n",
      "img id in: 3478\n",
      "img id out: 3478\n",
      "img id in: 3479\n",
      "img id out: 3479\n",
      "img id in: 3480\n",
      "img id out: 3480\n",
      "img id in: 3481\n",
      "img id out: 3481\n",
      "img id in: 3482\n",
      "img id out: 3482\n",
      "img id in: 3483\n",
      "img id out: 3483\n",
      "img id in: 3484\n",
      "img id out: 3484\n",
      "img id in: 3485\n",
      "img id out: 3485\n",
      "img id in: 3486\n",
      "img id out: 3486\n",
      "img id in: 3487\n",
      "img id out: 3487\n",
      "img id in: 3488\n",
      "img id out: 3488\n",
      "img id in: 3489\n",
      "img id out: 3489\n",
      "img id in: 3490\n",
      "img id out: 3490\n",
      "img id in: 3491\n",
      "img id out: 3491\n",
      "img id in: 3492\n",
      "img id out: 3492\n",
      "img id in: 3493\n",
      "img id out: 3493\n",
      "img id in: 3494\n",
      "img id out: 3494\n",
      "img id in: 3495\n",
      "img id out: 3495\n",
      "img id in: 3496\n",
      "img id out: 3496\n",
      "img id in: 3497\n",
      "img id out: 3497\n",
      "img id in: 3498\n",
      "img id out: 3498\n",
      "img id in: 3499\n",
      "img id out: 3499\n",
      "img id in: 3500\n",
      "img id out: 3500\n",
      "img id in: 3501\n",
      "img id out: 3501\n",
      "img id in: 3502\n",
      "img id out: 3502\n",
      "img id in: 3503\n",
      "img id out: 3503\n",
      "img id in: 3504\n",
      "img id out: 3504\n",
      "img id in: 3505\n",
      "img id out: 3505\n",
      "img id in: 3506\n",
      "img id out: 3506\n",
      "img id in: 3507\n",
      "img id out: 3507\n",
      "img id in: 3508\n",
      "img id out: 3508\n",
      "img id in: 3509\n",
      "img id out: 3509\n",
      "img id in: 3510\n",
      "img id out: 3510\n",
      "img id in: 3511\n",
      "img id out: 3511\n",
      "img id in: 3512\n",
      "img id out: 3512\n",
      "img id in: 3513\n",
      "img id out: 3513\n",
      "img id in: 3514\n",
      "img id out: 3514\n",
      "img id in: 3515\n",
      "img id out: 3515\n",
      "img id in: 3516\n",
      "img id out: 3516\n",
      "img id in: 3517\n",
      "img id out: 3517\n",
      "img id in: 3518\n",
      "img id out: 3518\n",
      "img id in: 3519\n",
      "img id out: 3519\n",
      "img id in: 3520\n",
      "img id out: 3520\n",
      "img id in: 3521\n",
      "img id out: 3521\n",
      "img id in: 3522\n",
      "img id out: 3522\n",
      "img id in: 3523\n",
      "img id out: 3523\n",
      "img id in: 3524\n",
      "img id out: 3524\n",
      "img id in: 3525\n",
      "img id out: 3525\n",
      "img id in: 3526\n",
      "img id out: 3526\n",
      "img id in: 3527\n",
      "img id out: 3527\n",
      "img id in: 3528\n",
      "img id out: 3528\n",
      "img id in: 3529\n",
      "img id out: 3529\n",
      "img id in: 3530\n",
      "img id out: 3530\n",
      "img id in: 3531\n",
      "img id out: 3531\n",
      "img id in: 3532\n",
      "img id out: 3532\n",
      "img id in: 3533\n",
      "img id out: 3533\n",
      "img id in: 3534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 3534\n",
      "img id in: 3535\n",
      "img id out: 3535\n",
      "img id in: 3536\n",
      "img id out: 3536\n",
      "img id in: 3537\n",
      "img id out: 3537\n",
      "img id in: 3538\n",
      "img id out: 3538\n",
      "img id in: 3539\n",
      "img id out: 3539\n",
      "img id in: 3540\n",
      "img id out: 3540\n",
      "img id in: 3541\n",
      "img id out: 3541\n",
      "img id in: 3542\n",
      "img id out: 3542\n",
      "img id in: 3543\n",
      "img id out: 3543\n",
      "img id in: 3544\n",
      "img id out: 3544\n",
      "img id in: 3545\n",
      "img id out: 3545\n",
      "img id in: 3546\n",
      "img id out: 3546\n",
      "img id in: 3547\n",
      "img id out: 3547\n",
      "img id in: 3548\n",
      "img id out: 3548\n",
      "img id in: 3549\n",
      "img id out: 3549\n",
      "img id in: 3550\n",
      "img id out: 3550\n",
      "img id in: 3551\n",
      "img id out: 3551\n",
      "img id in: 3552\n",
      "img id out: 3552\n",
      "img id in: 3553\n",
      "img id out: 3553\n",
      "img id in: 3554\n",
      "img id out: 3554\n",
      "img id in: 3555\n",
      "img id out: 3555\n",
      "img id in: 3556\n",
      "img id out: 3556\n",
      "img id in: 3557\n",
      "img id out: 3557\n",
      "img id in: 3558\n",
      "img id out: 3558\n",
      "img id in: 3559\n",
      "img id out: 3559\n",
      "img id in: 3560\n",
      "img id out: 3560\n",
      "img id in: 3561\n",
      "img id out: 3561\n",
      "img id in: 3562\n",
      "img id out: 3562\n",
      "img id in: 3563\n",
      "img id out: 3563\n",
      "img id in: 3564\n",
      "img id out: 3564\n",
      "img id in: 3565\n",
      "img id out: 3565\n",
      "img id in: 3566\n",
      "img id out: 3566\n",
      "img id in: 3567\n",
      "img id out: 3567\n",
      "img id in: 3568\n",
      "img id out: 3568\n",
      "img id in: 3569\n",
      "img id out: 3569\n",
      "img id in: 3570\n",
      "img id out: 3570\n",
      "img id in: 3571\n",
      "img id out: 3571\n",
      "img id in: 3572\n",
      "img id out: 3572\n",
      "img id in: 3573\n",
      "img id out: 3573\n",
      "img id in: 3574\n",
      "img id out: 3574\n",
      "img id in: 3575\n",
      "img id out: 3575\n",
      "img id in: 3576\n",
      "img id out: 3576\n",
      "img id in: 3577\n",
      "img id out: 3577\n",
      "img id in: 3578\n",
      "img id out: 3578\n",
      "img id in: 3579\n",
      "img id out: 3579\n",
      "img id in: 3580\n",
      "img id out: 3580\n",
      "img id in: 3581\n",
      "img id out: 3581\n",
      "img id in: 3582\n",
      "img id out: 3582\n",
      "img id in: 3583\n",
      "img id out: 3583\n",
      "img id in: 3584\n",
      "img id out: 3584\n",
      "img id in: 3585\n",
      "img id out: 3585\n",
      "img id in: 3586\n",
      "img id out: 3586\n",
      "img id in: 3587\n",
      "img id out: 3587\n",
      "img id in: 3588\n",
      "img id out: 3588\n",
      "img id in: 3589\n",
      "img id out: 3589\n",
      "img id in: 3590\n",
      "img id out: 3590\n",
      "img id in: 3591\n",
      "img id out: 3591\n",
      "img id in: 3592\n",
      "img id out: 3592\n",
      "img id in: 3593\n",
      "img id out: 3593\n",
      "img id in: 3594\n",
      "img id out: 3594\n",
      "img id in: 3595\n",
      "img id out: 3595\n",
      "img id in: 3596\n",
      "img id out: 3596\n",
      "img id in: 3597\n",
      "img id out: 3597\n",
      "img id in: 3598\n",
      "img id out: 3598\n",
      "img id in: 3599\n",
      "img id out: 3599\n",
      "img id in: 3600\n",
      "img id out: 3600\n",
      "img id in: 3601\n",
      "img id out: 3601\n",
      "img id in: 3602\n",
      "img id out: 3602\n",
      "img id in: 3603\n",
      "img id out: 3603\n",
      "img id in: 3604\n",
      "img id out: 3604\n",
      "img id in: 3605\n",
      "img id out: 3605\n",
      "img id in: 3606\n",
      "img id out: 3606\n",
      "img id in: 3607\n",
      "img id out: 3607\n",
      "img id in: 3608\n",
      "img id out: 3608\n",
      "img id in: 3609\n",
      "img id out: 3609\n",
      "img id in: 3610\n",
      "img id out: 3610\n",
      "img id in: 3611\n",
      "img id out: 3611\n",
      "img id in: 3612\n",
      "img id out: 3612\n",
      "img id in: 3613\n",
      "img id out: 3613\n",
      "img id in: 3614\n",
      "img id out: 3614\n",
      "img id in: 3615\n",
      "img id out: 3615\n",
      "img id in: 3616\n",
      "img id out: 3616\n",
      "img id in: 3617\n",
      "img id out: 3617\n",
      "img id in: 3618\n",
      "img id out: 3618\n",
      "img id in: 3619\n",
      "img id out: 3619\n",
      "img id in: 3620\n",
      "img id out: 3620\n",
      "img id in: 3621\n",
      "img id out: 3621\n",
      "img id in: 3622\n",
      "img id out: 3622\n",
      "img id in: 3623\n",
      "img id out: 3623\n",
      "img id in: 3624\n",
      "img id out: 3624\n",
      "img id in: 3625\n",
      "img id out: 3625\n",
      "img id in: 3626\n",
      "img id out: 3626\n",
      "img id in: 3627\n",
      "img id out: 3627\n",
      "img id in: 3628\n",
      "img id out: 3628\n",
      "img id in: 3629\n",
      "img id out: 3629\n",
      "img id in: 3630\n",
      "img id out: 3630\n",
      "img id in: 3631\n",
      "img id out: 3631\n",
      "img id in: 3632\n",
      "img id out: 3632\n",
      "img id in: 3633\n",
      "img id out: 3633\n",
      "img id in: 3634\n",
      "img id out: 3634\n",
      "img id in: 3635\n",
      "img id out: 3635\n",
      "img id in: 3636\n",
      "img id out: 3636\n",
      "img id in: 3637\n",
      "img id out: 3637\n",
      "img id in: 3638\n",
      "img id out: 3638\n",
      "img id in: 3639\n",
      "img id out: 3639\n",
      "img id in: 3640\n",
      "img id out: 3640\n",
      "img id in: 3641\n",
      "img id out: 3641\n",
      "img id in: 3642\n",
      "img id out: 3642\n",
      "img id in: 3643\n",
      "img id out: 3643\n",
      "img id in: 3644\n",
      "img id out: 3644\n",
      "img id in: 3645\n",
      "img id out: 3645\n",
      "img id in: 3646\n",
      "img id out: 3646\n",
      "img id in: 3647\n",
      "img id out: 3647\n",
      "img id in: 3648\n",
      "img id out: 3648\n",
      "img id in: 3649\n",
      "img id out: 3649\n",
      "img id in: 3650\n",
      "img id out: 3650\n",
      "img id in: 3651\n",
      "img id out: 3651\n",
      "img id in: 3652\n",
      "img id out: 3652\n",
      "img id in: 3653\n",
      "img id out: 3653\n",
      "img id in: 3654\n",
      "img id out: 3654\n",
      "img id in: 3655\n",
      "img id out: 3655\n",
      "img id in: 3656\n",
      "img id out: 3656\n",
      "img id in: 3657\n",
      "img id out: 3657\n",
      "img id in: 3658\n",
      "img id out: 3658\n",
      "img id in: 3659\n",
      "img id out: 3659\n",
      "img id in: 3660\n",
      "img id out: 3660\n",
      "img id in: 3661\n",
      "img id out: 3661\n",
      "img id in: 3662\n",
      "img id out: 3662\n",
      "img id in: 3663\n",
      "img id out: 3663\n",
      "img id in: 3664\n",
      "img id out: 3664\n",
      "img id in: 3665\n",
      "img id out: 3665\n",
      "img id in: 3666\n",
      "img id out: 3666\n",
      "img id in: 3667\n",
      "img id out: 3667\n",
      "img id in: 3668\n",
      "img id out: 3668\n",
      "img id in: 3669\n",
      "img id out: 3669\n",
      "img id in: 3670\n",
      "img id out: 3670\n",
      "img id in: 3671\n",
      "img id out: 3671\n",
      "img id in: 3672\n",
      "img id out: 3672\n",
      "img id in: 3673\n",
      "img id out: 3673\n",
      "img id in: 3674\n",
      "img id out: 3674\n",
      "img id in: 3675\n",
      "img id out: 3675\n",
      "img id in: 3676\n",
      "img id out: 3676\n",
      "img id in: 3677\n",
      "img id out: 3677\n",
      "img id in: 3678\n",
      "img id out: 3678\n",
      "img id in: 3679\n",
      "img id out: 3679\n",
      "img id in: 3680\n",
      "img id out: 3680\n",
      "img id in: 3681\n",
      "img id out: 3681\n",
      "img id in: 3682\n",
      "img id out: 3682\n",
      "img id in: 3683\n",
      "img id out: 3683\n",
      "img id in: 3684\n",
      "img id out: 3684\n",
      "img id in: 3685\n",
      "img id out: 3685\n",
      "img id in: 3686\n",
      "img id out: 3686\n",
      "img id in: 3687\n",
      "img id out: 3687\n",
      "img id in: 3688\n",
      "img id out: 3688\n",
      "img id in: 3689\n",
      "img id out: 3689\n",
      "img id in: 3690\n",
      "img id out: 3690\n",
      "img id in: 3691\n",
      "img id out: 3691\n",
      "img id in: 3692\n",
      "img id out: 3692\n",
      "img id in: 3693\n",
      "img id out: 3693\n",
      "img id in: 3694\n",
      "img id out: 3694\n",
      "img id in: 3695\n",
      "img id out: 3695\n",
      "img id in: 3696\n",
      "img id out: 3696\n",
      "img id in: 3697\n",
      "img id out: 3697\n",
      "img id in: 3698\n",
      "img id out: 3698\n",
      "img id in: 3699\n",
      "img id out: 3699\n",
      "img id in: 3700\n",
      "img id out: 3700\n",
      "img id in: 3701\n",
      "img id out: 3701\n",
      "img id in: 3702\n",
      "img id out: 3702\n",
      "img id in: 3703\n",
      "img id out: 3703\n",
      "img id in: 3704\n",
      "img id out: 3704\n",
      "img id in: 3705\n",
      "img id out: 3705\n",
      "img id in: 3706\n",
      "img id out: 3706\n",
      "img id in: 3707\n",
      "img id out: 3707\n",
      "img id in: 3708\n",
      "img id out: 3708\n",
      "img id in: 3709\n",
      "img id out: 3709\n",
      "img id in: 3710\n",
      "img id out: 3710\n",
      "img id in: 3711\n",
      "img id out: 3711\n",
      "img id in: 3712\n",
      "img id out: 3712\n",
      "img id in: 3713\n",
      "img id out: 3713\n",
      "img id in: 3714\n",
      "img id out: 3714\n",
      "img id in: 3715\n",
      "img id out: 3715\n",
      "img id in: 3716\n",
      "img id out: 3716\n",
      "img id in: 3717\n",
      "img id out: 3717\n",
      "img id in: 3718\n",
      "img id out: 3718\n",
      "img id in: 3719\n",
      "img id out: 3719\n",
      "img id in: 3720\n",
      "img id out: 3720\n",
      "img id in: 3721\n",
      "img id out: 3721\n",
      "img id in: 3722\n",
      "img id out: 3722\n",
      "img id in: 3723\n",
      "img id out: 3723\n",
      "img id in: 3724\n",
      "img id out: 3724\n",
      "img id in: 3725\n",
      "img id out: 3725\n",
      "img id in: 3726\n",
      "img id out: 3726\n",
      "img id in: 3727\n",
      "img id out: 3727\n",
      "img id in: 3728\n",
      "img id out: 3728\n",
      "img id in: 3729\n",
      "img id out: 3729\n",
      "img id in: 3730\n",
      "img id out: 3730\n",
      "img id in: 3731\n",
      "img id out: 3731\n",
      "img id in: 3732\n",
      "img id out: 3732\n",
      "img id in: 3733\n",
      "img id out: 3733\n",
      "img id in: 3734\n",
      "img id out: 3734\n",
      "img id in: 3735\n",
      "img id out: 3735\n",
      "img id in: 3736\n",
      "img id out: 3736\n",
      "img id in: 3737\n",
      "img id out: 3737\n",
      "img id in: 3738\n",
      "img id out: 3738\n",
      "img id in: 3739\n",
      "img id out: 3739\n",
      "img id in: 3740\n",
      "img id out: 3740\n",
      "img id in: 3741\n",
      "img id out: 3741\n",
      "img id in: 3742\n",
      "img id out: 3742\n",
      "img id in: 3743\n",
      "img id out: 3743\n",
      "img id in: 3744\n",
      "img id out: 3744\n",
      "img id in: 3745\n",
      "img id out: 3745\n",
      "img id in: 3746\n",
      "img id out: 3746\n",
      "img id in: 3747\n",
      "img id out: 3747\n",
      "img id in: 3748\n",
      "img id out: 3748\n",
      "img id in: 3749\n",
      "img id out: 3749\n",
      "img id in: 3750\n",
      "img id out: 3750\n",
      "img id in: 3751\n",
      "img id out: 3751\n",
      "img id in: 3752\n",
      "img id out: 3752\n",
      "img id in: 3753\n",
      "img id out: 3753\n",
      "img id in: 3754\n",
      "img id out: 3754\n",
      "img id in: 3755\n",
      "img id out: 3755\n",
      "img id in: 3756\n",
      "img id out: 3756\n",
      "img id in: 3757\n",
      "img id out: 3757\n",
      "img id in: 3758\n",
      "img id out: 3758\n",
      "img id in: 3759\n",
      "img id out: 3759\n",
      "img id in: 3760\n",
      "img id out: 3760\n",
      "img id in: 3761\n",
      "img id out: 3761\n",
      "img id in: 3762\n",
      "img id out: 3762\n",
      "img id in: 3763\n",
      "img id out: 3763\n",
      "img id in: 3764\n",
      "img id out: 3764\n",
      "img id in: 3765\n",
      "img id out: 3765\n",
      "img id in: 3766\n",
      "img id out: 3766\n",
      "img id in: 3767\n",
      "img id out: 3767\n",
      "img id in: 3768\n",
      "img id out: 3768\n",
      "img id in: 3769\n",
      "img id out: 3769\n",
      "img id in: 3770\n",
      "img id out: 3770\n",
      "img id in: 3771\n",
      "img id out: 3771\n",
      "img id in: 3772\n",
      "img id out: 3772\n",
      "img id in: 3773\n",
      "img id out: 3773\n",
      "img id in: 3774\n",
      "img id out: 3774\n",
      "img id in: 3775\n",
      "img id out: 3775\n",
      "img id in: 3776\n",
      "img id out: 3776\n",
      "img id in: 3777\n",
      "img id out: 3777\n",
      "img id in: 3778\n",
      "img id out: 3778\n",
      "img id in: 3779\n",
      "img id out: 3779\n",
      "img id in: 3780\n",
      "img id out: 3780\n",
      "img id in: 3781\n",
      "img id out: 3781\n",
      "img id in: 3782\n",
      "img id out: 3782\n",
      "img id in: 3783\n",
      "img id out: 3783\n",
      "img id in: 3784\n",
      "img id out: 3784\n",
      "img id in: 3785\n",
      "img id out: 3785\n",
      "img id in: 3786\n",
      "img id out: 3786\n",
      "img id in: 3787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 3787\n",
      "img id in: 3788\n",
      "img id out: 3788\n",
      "img id in: 3789\n",
      "img id out: 3789\n",
      "img id in: 3790\n",
      "img id out: 3790\n",
      "img id in: 3791\n",
      "img id out: 3791\n",
      "img id in: 3792\n",
      "img id out: 3792\n",
      "img id in: 3793\n",
      "img id out: 3793\n",
      "img id in: 3794\n",
      "img id out: 3794\n",
      "img id in: 3795\n",
      "img id out: 3795\n",
      "img id in: 3796\n",
      "img id out: 3796\n",
      "img id in: 3797\n",
      "img id out: 3797\n",
      "img id in: 3798\n",
      "img id out: 3798\n",
      "img id in: 3799\n",
      "img id out: 3799\n",
      "img id in: 3800\n",
      "img id out: 3800\n",
      "img id in: 3801\n",
      "img id out: 3801\n",
      "img id in: 3802\n",
      "img id out: 3802\n",
      "img id in: 3803\n",
      "img id out: 3803\n",
      "img id in: 3804\n",
      "img id out: 3804\n",
      "img id in: 3805\n",
      "img id out: 3805\n",
      "img id in: 3806\n",
      "img id out: 3806\n",
      "img id in: 3807\n",
      "img id out: 3807\n",
      "img id in: 3808\n",
      "img id out: 3808\n",
      "img id in: 3809\n",
      "img id out: 3809\n",
      "img id in: 3810\n",
      "img id out: 3810\n",
      "img id in: 3811\n",
      "img id out: 3811\n",
      "img id in: 3812\n",
      "img id out: 3812\n",
      "img id in: 3813\n",
      "img id out: 3813\n",
      "img id in: 3814\n",
      "img id out: 3814\n",
      "img id in: 3815\n",
      "img id out: 3815\n",
      "img id in: 3816\n",
      "img id out: 3816\n",
      "img id in: 3817\n",
      "img id out: 3817\n",
      "img id in: 3818\n",
      "img id out: 3818\n",
      "img id in: 3819\n",
      "img id out: 3819\n",
      "img id in: 3820\n",
      "img id out: 3820\n",
      "img id in: 3821\n",
      "img id out: 3821\n",
      "img id in: 3822\n",
      "img id out: 3822\n",
      "img id in: 3823\n",
      "img id out: 3823\n",
      "img id in: 3824\n",
      "img id out: 3824\n",
      "img id in: 3825\n",
      "img id out: 3825\n",
      "img id in: 3826\n",
      "img id out: 3826\n",
      "img id in: 3827\n",
      "img id out: 3827\n",
      "img id in: 3828\n",
      "img id out: 3828\n",
      "img id in: 3829\n",
      "img id out: 3829\n",
      "img id in: 3830\n",
      "img id out: 3830\n",
      "img id in: 3831\n",
      "img id out: 3831\n",
      "img id in: 3832\n",
      "img id out: 3832\n",
      "img id in: 3833\n",
      "img id out: 3833\n",
      "img id in: 3834\n",
      "img id out: 3834\n",
      "img id in: 3835\n",
      "img id out: 3835\n",
      "img id in: 3836\n",
      "img id out: 3836\n",
      "img id in: 3837\n",
      "img id out: 3837\n",
      "img id in: 3838\n",
      "img id out: 3838\n",
      "img id in: 3839\n",
      "img id out: 3839\n",
      "img id in: 3840\n",
      "img id out: 3840\n",
      "img id in: 3841\n",
      "img id out: 3841\n",
      "img id in: 3842\n",
      "img id out: 3842\n",
      "img id in: 3843\n",
      "img id out: 3843\n",
      "img id in: 3844\n",
      "img id out: 3844\n",
      "img id in: 3845\n",
      "img id out: 3845\n",
      "img id in: 3846\n",
      "img id out: 3846\n",
      "img id in: 3847\n",
      "img id out: 3847\n",
      "img id in: 3848\n",
      "img id out: 3848\n",
      "img id in: 3849\n",
      "img id out: 3849\n",
      "img id in: 3850\n",
      "img id out: 3850\n",
      "img id in: 3851\n",
      "img id out: 3851\n",
      "img id in: 3852\n",
      "img id out: 3852\n",
      "img id in: 3853\n",
      "img id out: 3853\n",
      "img id in: 3854\n",
      "img id out: 3854\n",
      "img id in: 3855\n",
      "img id out: 3855\n",
      "img id in: 3856\n",
      "img id out: 3856\n",
      "img id in: 3857\n",
      "img id out: 3857\n",
      "img id in: 3858\n",
      "img id out: 3858\n",
      "img id in: 3859\n",
      "img id out: 3859\n",
      "img id in: 3860\n",
      "img id out: 3860\n",
      "img id in: 3861\n",
      "img id out: 3861\n",
      "img id in: 3862\n",
      "img id out: 3862\n",
      "img id in: 3863\n",
      "img id out: 3863\n",
      "img id in: 3864\n",
      "img id out: 3864\n",
      "img id in: 3865\n",
      "img id out: 3865\n",
      "img id in: 3866\n",
      "img id out: 3866\n",
      "img id in: 3867\n",
      "img id out: 3867\n",
      "img id in: 3868\n",
      "img id out: 3868\n",
      "img id in: 3869\n",
      "img id out: 3869\n",
      "img id in: 3870\n",
      "img id out: 3870\n",
      "img id in: 3871\n",
      "img id out: 3871\n",
      "img id in: 3872\n",
      "img id out: 3872\n",
      "img id in: 3873\n",
      "img id out: 3873\n",
      "img id in: 3874\n",
      "img id out: 3874\n",
      "img id in: 3875\n",
      "img id out: 3875\n",
      "img id in: 3876\n",
      "img id out: 3876\n",
      "img id in: 3877\n",
      "img id out: 3877\n",
      "img id in: 3878\n",
      "img id out: 3878\n",
      "img id in: 3879\n",
      "img id out: 3879\n",
      "img id in: 3880\n",
      "img id out: 3880\n",
      "img id in: 3881\n",
      "img id out: 3881\n",
      "img id in: 3882\n",
      "img id out: 3882\n",
      "img id in: 3883\n",
      "img id out: 3883\n",
      "img id in: 3884\n",
      "img id out: 3884\n",
      "img id in: 3885\n",
      "img id out: 3885\n",
      "img id in: 3886\n",
      "img id out: 3886\n",
      "img id in: 3887\n",
      "img id out: 3887\n",
      "img id in: 3888\n",
      "img id out: 3888\n",
      "img id in: 3889\n",
      "img id out: 3889\n",
      "img id in: 3890\n",
      "img id out: 3890\n",
      "img id in: 3891\n",
      "img id out: 3891\n",
      "img id in: 3892\n",
      "img id out: 3892\n",
      "img id in: 3893\n",
      "img id out: 3893\n",
      "img id in: 3894\n",
      "img id out: 3894\n",
      "img id in: 3895\n",
      "img id out: 3895\n",
      "img id in: 3896\n",
      "img id out: 3896\n",
      "img id in: 3897\n",
      "img id out: 3897\n",
      "img id in: 3898\n",
      "img id out: 3898\n",
      "img id in: 3899\n",
      "img id out: 3899\n",
      "img id in: 3900\n",
      "img id out: 3900\n",
      "img id in: 3901\n",
      "img id out: 3901\n",
      "img id in: 3902\n",
      "img id out: 3902\n",
      "img id in: 3903\n",
      "img id out: 3903\n",
      "img id in: 3904\n",
      "img id out: 3904\n",
      "img id in: 3905\n",
      "img id out: 3905\n",
      "img id in: 3906\n",
      "img id out: 3906\n",
      "img id in: 3907\n",
      "img id out: 3907\n",
      "img id in: 3908\n",
      "img id out: 3908\n",
      "img id in: 3909\n",
      "img id out: 3909\n",
      "img id in: 3910\n",
      "img id out: 3910\n",
      "img id in: 3911\n",
      "img id out: 3911\n",
      "img id in: 3912\n",
      "img id out: 3912\n",
      "img id in: 3913\n",
      "img id out: 3913\n",
      "img id in: 3914\n",
      "img id out: 3914\n",
      "img id in: 3915\n",
      "img id out: 3915\n",
      "img id in: 3916\n",
      "img id out: 3916\n",
      "img id in: 3917\n",
      "img id out: 3917\n",
      "img id in: 3918\n",
      "img id out: 3918\n",
      "img id in: 3919\n",
      "img id out: 3919\n",
      "img id in: 3920\n",
      "img id out: 3920\n",
      "img id in: 3921\n",
      "img id out: 3921\n",
      "img id in: 3922\n",
      "img id out: 3922\n",
      "img id in: 3923\n",
      "img id out: 3923\n",
      "img id in: 3924\n",
      "img id out: 3924\n",
      "img id in: 3925\n",
      "img id out: 3925\n",
      "img id in: 3926\n",
      "img id out: 3926\n",
      "img id in: 3927\n",
      "img id out: 3927\n",
      "img id in: 3928\n",
      "img id out: 3928\n",
      "img id in: 3929\n",
      "img id out: 3929\n",
      "img id in: 3930\n",
      "img id out: 3930\n",
      "img id in: 3931\n",
      "img id out: 3931\n",
      "img id in: 3932\n",
      "img id out: 3932\n",
      "img id in: 3933\n",
      "img id out: 3933\n",
      "img id in: 3934\n",
      "img id out: 3934\n",
      "img id in: 3935\n",
      "img id out: 3935\n",
      "img id in: 3936\n",
      "img id out: 3936\n",
      "img id in: 3937\n",
      "img id out: 3937\n",
      "img id in: 3938\n",
      "img id out: 3938\n",
      "img id in: 3939\n",
      "img id out: 3939\n",
      "img id in: 3940\n",
      "img id out: 3940\n",
      "img id in: 3941\n",
      "img id out: 3941\n",
      "img id in: 3942\n",
      "img id out: 3942\n",
      "img id in: 3943\n",
      "img id out: 3943\n",
      "img id in: 3944\n",
      "img id out: 3944\n",
      "img id in: 3945\n",
      "img id out: 3945\n",
      "img id in: 3946\n",
      "img id out: 3946\n",
      "img id in: 3947\n",
      "img id out: 3947\n",
      "img id in: 3948\n",
      "img id out: 3948\n",
      "img id in: 3949\n",
      "img id out: 3949\n",
      "img id in: 3950\n",
      "img id out: 3950\n",
      "img id in: 3951\n",
      "img id out: 3951\n",
      "img id in: 3952\n",
      "img id out: 3952\n",
      "img id in: 3953\n",
      "img id out: 3953\n",
      "img id in: 3954\n",
      "img id out: 3954\n",
      "img id in: 3955\n",
      "img id out: 3955\n",
      "img id in: 3956\n",
      "img id out: 3956\n",
      "img id in: 3957\n",
      "img id out: 3957\n",
      "img id in: 3958\n",
      "img id out: 3958\n",
      "img id in: 3959\n",
      "img id out: 3959\n",
      "img id in: 3960\n",
      "img id out: 3960\n",
      "img id in: 3961\n",
      "img id out: 3961\n",
      "img id in: 3962\n",
      "img id out: 3962\n",
      "img id in: 3963\n",
      "img id out: 3963\n",
      "img id in: 3964\n",
      "img id out: 3964\n",
      "img id in: 3965\n",
      "img id out: 3965\n",
      "img id in: 3966\n",
      "img id out: 3966\n",
      "img id in: 3967\n",
      "img id out: 3967\n",
      "img id in: 3968\n",
      "img id out: 3968\n",
      "img id in: 3969\n",
      "img id out: 3969\n",
      "img id in: 3970\n",
      "img id out: 3970\n",
      "img id in: 3971\n",
      "img id out: 3971\n",
      "img id in: 3972\n",
      "img id out: 3972\n",
      "img id in: 3973\n",
      "img id out: 3973\n",
      "img id in: 3974\n",
      "img id out: 3974\n",
      "img id in: 3975\n",
      "img id out: 3975\n",
      "img id in: 3976\n",
      "img id out: 3976\n",
      "img id in: 3977\n",
      "img id out: 3977\n",
      "img id in: 3978\n",
      "img id out: 3978\n",
      "img id in: 3979\n",
      "img id out: 3979\n",
      "img id in: 3980\n",
      "img id out: 3980\n",
      "img id in: 3981\n",
      "img id out: 3981\n",
      "img id in: 3982\n",
      "img id out: 3982\n",
      "img id in: 3983\n",
      "img id out: 3983\n",
      "img id in: 3984\n",
      "img id out: 3984\n",
      "img id in: 3985\n",
      "img id out: 3985\n",
      "img id in: 3986\n",
      "img id out: 3986\n",
      "img id in: 3987\n",
      "img id out: 3987\n",
      "img id in: 3988\n",
      "img id out: 3988\n",
      "img id in: 3989\n",
      "img id out: 3989\n",
      "img id in: 3990\n",
      "img id out: 3990\n",
      "img id in: 3991\n",
      "img id out: 3991\n",
      "img id in: 3992\n",
      "img id out: 3992\n",
      "img id in: 3993\n",
      "img id out: 3993\n",
      "img id in: 3994\n",
      "img id out: 3994\n",
      "img id in: 3995\n",
      "img id out: 3995\n",
      "img id in: 3996\n",
      "img id out: 3996\n",
      "img id in: 3997\n",
      "img id out: 3997\n",
      "img id in: 3998\n",
      "img id out: 3998\n",
      "img id in: 3999\n",
      "img id out: 3999\n",
      "img id in: 4000\n",
      "img id out: 4000\n",
      "img id in: 4001\n",
      "img id out: 4001\n",
      "img id in: 4002\n",
      "img id out: 4002\n",
      "img id in: 4003\n",
      "img id out: 4003\n",
      "img id in: 4004\n",
      "img id out: 4004\n",
      "img id in: 4005\n",
      "img id out: 4005\n",
      "img id in: 4006\n",
      "img id out: 4006\n",
      "img id in: 4007\n",
      "img id out: 4007\n",
      "img id in: 4008\n",
      "img id out: 4008\n",
      "img id in: 4009\n",
      "img id out: 4009\n",
      "img id in: 4010\n",
      "img id out: 4010\n",
      "img id in: 4011\n",
      "img id out: 4011\n",
      "img id in: 4012\n",
      "img id out: 4012\n",
      "img id in: 4013\n",
      "img id out: 4013\n",
      "img id in: 4014\n",
      "img id out: 4014\n",
      "img id in: 4015\n",
      "img id out: 4015\n",
      "img id in: 4016\n",
      "img id out: 4016\n",
      "img id in: 4017\n",
      "img id out: 4017\n",
      "img id in: 4018\n",
      "img id out: 4018\n",
      "img id in: 4019\n",
      "img id out: 4019\n",
      "img id in: 4020\n",
      "img id out: 4020\n",
      "img id in: 4021\n",
      "img id out: 4021\n",
      "img id in: 4022\n",
      "img id out: 4022\n",
      "img id in: 4023\n",
      "img id out: 4023\n",
      "img id in: 4024\n",
      "img id out: 4024\n",
      "img id in: 4025\n",
      "img id out: 4025\n",
      "img id in: 4026\n",
      "img id out: 4026\n",
      "img id in: 4027\n",
      "img id out: 4027\n",
      "img id in: 4028\n",
      "img id out: 4028\n",
      "img id in: 4029\n",
      "img id out: 4029\n",
      "img id in: 4030\n",
      "img id out: 4030\n",
      "img id in: 4031\n",
      "img id out: 4031\n",
      "img id in: 4032\n",
      "img id out: 4032\n",
      "img id in: 4033\n",
      "img id out: 4033\n",
      "img id in: 4034\n",
      "img id out: 4034\n",
      "img id in: 4035\n",
      "img id out: 4035\n",
      "img id in: 4036\n",
      "img id out: 4036\n",
      "img id in: 4037\n",
      "img id out: 4037\n",
      "img id in: 4038\n",
      "img id out: 4038\n",
      "img id in: 4039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 4039\n",
      "img id in: 4040\n",
      "img id out: 4040\n",
      "img id in: 4041\n",
      "img id out: 4041\n",
      "img id in: 4042\n",
      "img id out: 4042\n",
      "img id in: 4043\n",
      "img id out: 4043\n",
      "img id in: 4044\n",
      "img id out: 4044\n",
      "img id in: 4045\n",
      "img id out: 4045\n",
      "img id in: 4046\n",
      "img id out: 4046\n",
      "img id in: 4047\n",
      "img id out: 4047\n",
      "img id in: 4048\n",
      "img id out: 4048\n",
      "img id in: 4049\n",
      "img id out: 4049\n",
      "img id in: 4050\n",
      "img id out: 4050\n",
      "img id in: 4051\n",
      "img id out: 4051\n",
      "img id in: 4052\n",
      "img id out: 4052\n",
      "img id in: 4053\n",
      "img id out: 4053\n",
      "img id in: 4054\n",
      "img id out: 4054\n",
      "img id in: 4055\n",
      "img id out: 4055\n",
      "img id in: 4056\n",
      "img id out: 4056\n",
      "img id in: 4057\n",
      "img id out: 4057\n",
      "img id in: 4058\n",
      "img id out: 4058\n",
      "img id in: 4059\n",
      "img id out: 4059\n",
      "img id in: 4060\n",
      "img id out: 4060\n",
      "img id in: 4061\n",
      "img id out: 4061\n",
      "img id in: 4062\n",
      "img id out: 4062\n",
      "img id in: 4063\n",
      "img id out: 4063\n",
      "img id in: 4064\n",
      "img id out: 4064\n",
      "img id in: 4065\n",
      "img id out: 4065\n",
      "img id in: 4066\n",
      "img id out: 4066\n",
      "img id in: 4067\n",
      "img id out: 4067\n",
      "img id in: 4068\n",
      "img id out: 4068\n",
      "img id in: 4069\n",
      "img id out: 4069\n",
      "img id in: 4070\n",
      "img id out: 4070\n",
      "img id in: 4071\n",
      "img id out: 4071\n",
      "img id in: 4072\n",
      "img id out: 4072\n",
      "img id in: 4073\n",
      "img id out: 4073\n",
      "img id in: 4074\n",
      "img id out: 4074\n",
      "img id in: 4075\n",
      "img id out: 4075\n",
      "img id in: 4076\n",
      "img id out: 4076\n",
      "img id in: 4077\n",
      "img id out: 4077\n",
      "img id in: 4078\n",
      "img id out: 4078\n",
      "img id in: 4079\n",
      "img id out: 4079\n",
      "img id in: 4080\n",
      "img id out: 4080\n",
      "img id in: 4081\n",
      "img id out: 4081\n",
      "img id in: 4082\n",
      "img id out: 4082\n",
      "img id in: 4083\n",
      "img id out: 4083\n",
      "img id in: 4084\n",
      "img id out: 4084\n",
      "img id in: 4085\n",
      "img id out: 4085\n",
      "img id in: 4086\n",
      "img id out: 4086\n",
      "img id in: 4087\n",
      "img id out: 4087\n",
      "img id in: 4088\n",
      "img id out: 4088\n",
      "img id in: 4089\n",
      "img id out: 4089\n",
      "img id in: 4090\n",
      "img id out: 4090\n",
      "img id in: 4091\n",
      "img id out: 4091\n",
      "img id in: 4092\n",
      "img id out: 4092\n",
      "img id in: 4093\n",
      "img id out: 4093\n",
      "img id in: 4094\n",
      "img id out: 4094\n",
      "img id in: 4095\n",
      "img id out: 4095\n",
      "img id in: 4096\n",
      "img id out: 4096\n",
      "img id in: 4097\n",
      "img id out: 4097\n",
      "img id in: 4098\n",
      "img id out: 4098\n",
      "img id in: 4099\n",
      "img id out: 4099\n",
      "img id in: 4100\n",
      "img id out: 4100\n",
      "img id in: 4101\n",
      "img id out: 4101\n",
      "img id in: 4102\n",
      "img id out: 4102\n",
      "img id in: 4103\n",
      "img id out: 4103\n",
      "img id in: 4104\n",
      "img id out: 4104\n",
      "img id in: 4105\n",
      "img id out: 4105\n",
      "img id in: 4106\n",
      "img id out: 4106\n",
      "img id in: 4107\n",
      "img id out: 4107\n",
      "img id in: 4108\n",
      "img id out: 4108\n",
      "img id in: 4109\n",
      "img id out: 4109\n",
      "img id in: 4110\n",
      "img id out: 4110\n",
      "img id in: 4111\n",
      "img id out: 4111\n",
      "img id in: 4112\n",
      "img id out: 4112\n",
      "img id in: 4113\n",
      "img id out: 4113\n",
      "img id in: 4114\n",
      "img id out: 4114\n",
      "img id in: 4115\n",
      "img id out: 4115\n",
      "img id in: 4116\n",
      "img id out: 4116\n",
      "img id in: 4117\n",
      "img id out: 4117\n",
      "img id in: 4118\n",
      "img id out: 4118\n",
      "img id in: 4119\n",
      "img id out: 4119\n",
      "img id in: 4120\n",
      "img id out: 4120\n",
      "img id in: 4121\n",
      "img id out: 4121\n",
      "img id in: 4122\n",
      "img id out: 4122\n",
      "img id in: 4123\n",
      "img id out: 4123\n",
      "img id in: 4124\n",
      "img id out: 4124\n",
      "img id in: 4125\n",
      "img id out: 4125\n",
      "img id in: 4126\n",
      "img id out: 4126\n",
      "img id in: 4127\n",
      "img id out: 4127\n",
      "img id in: 4128\n",
      "img id out: 4128\n",
      "img id in: 4129\n",
      "img id out: 4129\n",
      "img id in: 4130\n",
      "img id out: 4130\n",
      "img id in: 4131\n",
      "img id out: 4131\n",
      "img id in: 4132\n",
      "img id out: 4132\n",
      "img id in: 4133\n",
      "img id out: 4133\n",
      "img id in: 4134\n",
      "img id out: 4134\n",
      "img id in: 4135\n",
      "img id out: 4135\n",
      "img id in: 4136\n",
      "img id out: 4136\n",
      "img id in: 4137\n",
      "img id out: 4137\n",
      "img id in: 4138\n",
      "img id out: 4138\n",
      "img id in: 4139\n",
      "img id out: 4139\n",
      "img id in: 4140\n",
      "img id out: 4140\n",
      "img id in: 4141\n",
      "img id out: 4141\n",
      "img id in: 4142\n",
      "img id out: 4142\n",
      "img id in: 4143\n",
      "img id out: 4143\n",
      "img id in: 4144\n",
      "img id out: 4144\n",
      "img id in: 4145\n",
      "img id out: 4145\n",
      "img id in: 4146\n",
      "img id out: 4146\n",
      "img id in: 4147\n",
      "img id out: 4147\n",
      "img id in: 4148\n",
      "img id out: 4148\n",
      "img id in: 4149\n",
      "img id out: 4149\n",
      "img id in: 4150\n",
      "img id out: 4150\n",
      "img id in: 4151\n",
      "img id out: 4151\n",
      "img id in: 4152\n",
      "img id out: 4152\n",
      "img id in: 4153\n",
      "img id out: 4153\n",
      "img id in: 4154\n",
      "img id out: 4154\n",
      "img id in: 4155\n",
      "img id out: 4155\n",
      "img id in: 4156\n",
      "img id out: 4156\n",
      "img id in: 4157\n",
      "img id out: 4157\n",
      "img id in: 4158\n",
      "img id out: 4158\n",
      "img id in: 4159\n",
      "img id out: 4159\n",
      "img id in: 4160\n",
      "img id out: 4160\n",
      "img id in: 4161\n",
      "img id out: 4161\n",
      "img id in: 4162\n",
      "img id out: 4162\n",
      "img id in: 4163\n",
      "img id out: 4163\n",
      "img id in: 4164\n",
      "img id out: 4164\n",
      "img id in: 4165\n",
      "img id out: 4165\n",
      "img id in: 4166\n",
      "img id out: 4166\n",
      "img id in: 4167\n",
      "img id out: 4167\n",
      "img id in: 4168\n",
      "img id out: 4168\n",
      "img id in: 4169\n",
      "img id out: 4169\n",
      "img id in: 4170\n",
      "img id out: 4170\n",
      "img id in: 4171\n",
      "img id out: 4171\n",
      "img id in: 4172\n",
      "img id out: 4172\n",
      "img id in: 4173\n",
      "img id out: 4173\n",
      "img id in: 4174\n",
      "img id out: 4174\n",
      "img id in: 4175\n",
      "img id out: 4175\n",
      "img id in: 4176\n",
      "img id out: 4176\n",
      "img id in: 4177\n",
      "img id out: 4177\n",
      "img id in: 4178\n",
      "img id out: 4178\n",
      "img id in: 4179\n",
      "img id out: 4179\n",
      "img id in: 4180\n",
      "img id out: 4180\n",
      "img id in: 4181\n",
      "img id out: 4181\n",
      "img id in: 4182\n",
      "img id out: 4182\n",
      "img id in: 4183\n",
      "img id out: 4183\n",
      "img id in: 4184\n",
      "img id out: 4184\n",
      "img id in: 4185\n",
      "img id out: 4185\n",
      "img id in: 4186\n",
      "img id out: 4186\n",
      "img id in: 4187\n",
      "img id out: 4187\n",
      "img id in: 4188\n",
      "img id out: 4188\n",
      "img id in: 4189\n",
      "img id out: 4189\n",
      "img id in: 4190\n",
      "img id out: 4190\n",
      "img id in: 4191\n",
      "img id out: 4191\n",
      "img id in: 4192\n",
      "img id out: 4192\n",
      "img id in: 4193\n",
      "img id out: 4193\n",
      "img id in: 4194\n",
      "img id out: 4194\n",
      "img id in: 4195\n",
      "img id out: 4195\n",
      "img id in: 4196\n",
      "img id out: 4196\n",
      "img id in: 4197\n",
      "img id out: 4197\n",
      "img id in: 4198\n",
      "img id out: 4198\n",
      "img id in: 4199\n",
      "img id out: 4199\n",
      "img id in: 4200\n",
      "img id out: 4200\n",
      "img id in: 4201\n",
      "img id out: 4201\n",
      "img id in: 4202\n",
      "img id out: 4202\n",
      "img id in: 4203\n",
      "img id out: 4203\n",
      "img id in: 4204\n",
      "img id out: 4204\n",
      "img id in: 4205\n",
      "img id out: 4205\n",
      "img id in: 4206\n",
      "img id out: 4206\n",
      "img id in: 4207\n",
      "img id out: 4207\n",
      "img id in: 4208\n",
      "img id out: 4208\n",
      "img id in: 4209\n",
      "img id out: 4209\n",
      "img id in: 4210\n",
      "img id out: 4210\n",
      "img id in: 4211\n",
      "img id out: 4211\n",
      "img id in: 4212\n",
      "img id out: 4212\n",
      "img id in: 4213\n",
      "img id out: 4213\n",
      "img id in: 4214\n",
      "img id out: 4214\n",
      "img id in: 4215\n",
      "img id out: 4215\n",
      "img id in: 4216\n",
      "img id out: 4216\n",
      "img id in: 4217\n",
      "img id out: 4217\n",
      "img id in: 4218\n",
      "img id out: 4218\n",
      "img id in: 4219\n",
      "img id out: 4219\n",
      "img id in: 4220\n",
      "img id out: 4220\n",
      "img id in: 4221\n",
      "img id out: 4221\n",
      "img id in: 4222\n",
      "img id out: 4222\n",
      "img id in: 4223\n",
      "img id out: 4223\n",
      "img id in: 4224\n",
      "img id out: 4224\n",
      "img id in: 4225\n",
      "img id out: 4225\n",
      "img id in: 4226\n",
      "img id out: 4226\n",
      "img id in: 4227\n",
      "img id out: 4227\n",
      "img id in: 4228\n",
      "img id out: 4228\n",
      "img id in: 4229\n",
      "img id out: 4229\n",
      "img id in: 4230\n",
      "img id out: 4230\n",
      "img id in: 4231\n",
      "img id out: 4231\n",
      "img id in: 4232\n",
      "img id out: 4232\n",
      "img id in: 4233\n",
      "img id out: 4233\n",
      "img id in: 4234\n",
      "img id out: 4234\n",
      "img id in: 4235\n",
      "img id out: 4235\n",
      "img id in: 4236\n",
      "img id out: 4236\n",
      "img id in: 4237\n",
      "img id out: 4237\n",
      "img id in: 4238\n",
      "img id out: 4238\n",
      "img id in: 4239\n",
      "img id out: 4239\n",
      "img id in: 4240\n",
      "img id out: 4240\n",
      "img id in: 4241\n",
      "img id out: 4241\n",
      "img id in: 4242\n",
      "img id out: 4242\n",
      "img id in: 4243\n",
      "img id out: 4243\n",
      "img id in: 4244\n",
      "img id out: 4244\n",
      "img id in: 4245\n",
      "img id out: 4245\n",
      "img id in: 4246\n",
      "img id out: 4246\n",
      "img id in: 4247\n",
      "img id out: 4247\n",
      "img id in: 4248\n",
      "img id out: 4248\n",
      "img id in: 4249\n",
      "img id out: 4249\n",
      "img id in: 4250\n",
      "img id out: 4250\n",
      "img id in: 4251\n",
      "img id out: 4251\n",
      "img id in: 4252\n",
      "img id out: 4252\n",
      "img id in: 4253\n",
      "img id out: 4253\n",
      "img id in: 4254\n",
      "img id out: 4254\n",
      "img id in: 4255\n",
      "img id out: 4255\n",
      "img id in: 4256\n",
      "img id out: 4256\n",
      "img id in: 4257\n",
      "img id out: 4257\n",
      "img id in: 4258\n",
      "img id out: 4258\n",
      "img id in: 4259\n",
      "img id out: 4259\n",
      "img id in: 4260\n",
      "img id out: 4260\n",
      "img id in: 4261\n",
      "img id out: 4261\n",
      "img id in: 4262\n",
      "img id out: 4262\n",
      "img id in: 4263\n",
      "img id out: 4263\n",
      "img id in: 4264\n",
      "img id out: 4264\n",
      "img id in: 4265\n",
      "img id out: 4265\n",
      "img id in: 4266\n",
      "img id out: 4266\n",
      "img id in: 4267\n",
      "img id out: 4267\n",
      "img id in: 4268\n",
      "img id out: 4268\n",
      "img id in: 4269\n",
      "img id out: 4269\n",
      "img id in: 4270\n",
      "img id out: 4270\n",
      "img id in: 4271\n",
      "img id out: 4271\n",
      "img id in: 4272\n",
      "img id out: 4272\n",
      "img id in: 4273\n",
      "img id out: 4273\n",
      "img id in: 4274\n",
      "img id out: 4274\n",
      "img id in: 4275\n",
      "img id out: 4275\n",
      "img id in: 4276\n",
      "img id out: 4276\n",
      "img id in: 4277\n",
      "img id out: 4277\n",
      "img id in: 4278\n",
      "img id out: 4278\n",
      "img id in: 4279\n",
      "img id out: 4279\n",
      "img id in: 4280\n",
      "img id out: 4280\n",
      "img id in: 4281\n",
      "img id out: 4281\n",
      "img id in: 4282\n",
      "img id out: 4282\n",
      "img id in: 4283\n",
      "img id out: 4283\n",
      "img id in: 4284\n",
      "img id out: 4284\n",
      "img id in: 4285\n",
      "img id out: 4285\n",
      "img id in: 4286\n",
      "img id out: 4286\n",
      "img id in: 4287\n",
      "img id out: 4287\n",
      "img id in: 4288\n",
      "img id out: 4288\n",
      "img id in: 4289\n",
      "img id out: 4289\n",
      "img id in: 4290\n",
      "img id out: 4290\n",
      "img id in: 4291\n",
      "img id out: 4291\n",
      "img id in: 4292\n",
      "img id out: 4292\n",
      "img id in: 4293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 4293\n",
      "img id in: 4294\n",
      "img id out: 4294\n",
      "img id in: 4295\n",
      "img id out: 4295\n",
      "img id in: 4296\n",
      "img id out: 4296\n",
      "img id in: 4297\n",
      "img id out: 4297\n",
      "img id in: 4298\n",
      "img id out: 4298\n",
      "img id in: 4299\n",
      "img id out: 4299\n",
      "img id in: 4300\n",
      "img id out: 4300\n",
      "img id in: 4301\n",
      "img id out: 4301\n",
      "img id in: 4302\n",
      "img id out: 4302\n",
      "img id in: 4303\n",
      "img id out: 4303\n",
      "img id in: 4304\n",
      "img id out: 4304\n",
      "img id in: 4305\n",
      "img id out: 4305\n",
      "img id in: 4306\n",
      "img id out: 4306\n",
      "img id in: 4307\n",
      "img id out: 4307\n",
      "img id in: 4308\n",
      "img id out: 4308\n",
      "img id in: 4309\n",
      "img id out: 4309\n",
      "img id in: 4310\n",
      "img id out: 4310\n",
      "img id in: 4311\n",
      "img id out: 4311\n",
      "img id in: 4312\n",
      "img id out: 4312\n",
      "img id in: 4313\n",
      "img id out: 4313\n",
      "img id in: 4314\n",
      "img id out: 4314\n",
      "img id in: 4315\n",
      "img id out: 4315\n",
      "img id in: 4316\n",
      "img id out: 4316\n",
      "img id in: 4317\n",
      "img id out: 4317\n",
      "img id in: 4318\n",
      "img id out: 4318\n",
      "img id in: 4319\n",
      "img id out: 4319\n",
      "img id in: 4320\n",
      "img id out: 4320\n",
      "img id in: 4321\n",
      "img id out: 4321\n",
      "img id in: 4322\n",
      "img id out: 4322\n",
      "img id in: 4323\n",
      "img id out: 4323\n",
      "img id in: 4324\n",
      "img id out: 4324\n",
      "img id in: 4325\n",
      "img id out: 4325\n",
      "img id in: 4326\n",
      "img id out: 4326\n",
      "img id in: 4327\n",
      "img id out: 4327\n",
      "img id in: 4328\n",
      "img id out: 4328\n",
      "img id in: 4329\n",
      "img id out: 4329\n",
      "img id in: 4330\n",
      "img id out: 4330\n",
      "img id in: 4331\n",
      "img id out: 4331\n",
      "img id in: 4332\n",
      "img id out: 4332\n",
      "img id in: 4333\n",
      "img id out: 4333\n",
      "img id in: 4334\n",
      "img id out: 4334\n",
      "img id in: 4335\n",
      "img id out: 4335\n",
      "img id in: 4336\n",
      "img id out: 4336\n",
      "img id in: 4337\n",
      "img id out: 4337\n",
      "img id in: 4338\n",
      "img id out: 4338\n",
      "img id in: 4339\n",
      "img id out: 4339\n",
      "img id in: 4340\n",
      "img id out: 4340\n",
      "img id in: 4341\n",
      "img id out: 4341\n",
      "img id in: 4342\n",
      "img id out: 4342\n",
      "img id in: 4343\n",
      "img id out: 4343\n",
      "img id in: 4344\n",
      "img id out: 4344\n",
      "img id in: 4345\n",
      "img id out: 4345\n",
      "img id in: 4346\n",
      "img id out: 4346\n",
      "img id in: 4347\n",
      "img id out: 4347\n",
      "img id in: 4348\n",
      "img id out: 4348\n",
      "img id in: 4349\n",
      "img id out: 4349\n",
      "img id in: 4350\n",
      "img id out: 4350\n",
      "img id in: 4351\n",
      "img id out: 4351\n",
      "img id in: 4352\n",
      "img id out: 4352\n",
      "img id in: 4353\n",
      "img id out: 4353\n",
      "img id in: 4354\n",
      "img id out: 4354\n",
      "img id in: 4355\n",
      "img id out: 4355\n",
      "img id in: 4356\n",
      "img id out: 4356\n",
      "img id in: 4357\n",
      "img id out: 4357\n",
      "img id in: 4358\n",
      "img id out: 4358\n",
      "img id in: 4359\n",
      "img id out: 4359\n",
      "img id in: 4360\n",
      "img id out: 4360\n",
      "img id in: 4361\n",
      "img id out: 4361\n",
      "img id in: 4362\n",
      "img id out: 4362\n",
      "img id in: 4363\n",
      "img id out: 4363\n",
      "img id in: 4364\n",
      "img id out: 4364\n",
      "img id in: 4365\n",
      "img id out: 4365\n",
      "img id in: 4366\n",
      "img id out: 4366\n",
      "img id in: 4367\n",
      "img id out: 4367\n",
      "img id in: 4368\n",
      "img id out: 4368\n",
      "img id in: 4369\n",
      "img id out: 4369\n",
      "img id in: 4370\n",
      "img id out: 4370\n",
      "img id in: 4371\n",
      "img id out: 4371\n",
      "img id in: 4372\n",
      "img id out: 4372\n",
      "img id in: 4373\n",
      "img id out: 4373\n",
      "img id in: 4374\n",
      "img id out: 4374\n",
      "img id in: 4375\n",
      "img id out: 4375\n",
      "img id in: 4376\n",
      "img id out: 4376\n",
      "img id in: 4377\n",
      "img id out: 4377\n",
      "img id in: 4378\n",
      "img id out: 4378\n",
      "img id in: 4379\n",
      "img id out: 4379\n",
      "img id in: 4380\n",
      "img id out: 4380\n",
      "img id in: 4381\n",
      "img id out: 4381\n",
      "img id in: 4382\n",
      "img id out: 4382\n",
      "img id in: 4383\n",
      "img id out: 4383\n",
      "img id in: 4384\n",
      "img id out: 4384\n",
      "img id in: 4385\n",
      "img id out: 4385\n",
      "img id in: 4386\n",
      "img id out: 4386\n",
      "img id in: 4387\n",
      "img id out: 4387\n",
      "img id in: 4388\n",
      "img id out: 4388\n",
      "img id in: 4389\n",
      "img id out: 4389\n",
      "img id in: 4390\n",
      "img id out: 4390\n",
      "img id in: 4391\n",
      "img id out: 4391\n",
      "img id in: 4392\n",
      "img id out: 4392\n",
      "img id in: 4393\n",
      "img id out: 4393\n",
      "img id in: 4394\n",
      "img id out: 4394\n",
      "img id in: 4395\n",
      "img id out: 4395\n",
      "img id in: 4396\n",
      "img id out: 4396\n",
      "img id in: 4397\n",
      "img id out: 4397\n",
      "img id in: 4398\n",
      "img id out: 4398\n",
      "img id in: 4399\n",
      "img id out: 4399\n",
      "img id in: 4400\n",
      "img id out: 4400\n",
      "img id in: 4401\n",
      "img id out: 4401\n",
      "img id in: 4402\n",
      "img id out: 4402\n",
      "img id in: 4403\n",
      "img id out: 4403\n",
      "img id in: 4404\n",
      "img id out: 4404\n",
      "img id in: 4405\n",
      "img id out: 4405\n",
      "img id in: 4406\n",
      "img id out: 4406\n",
      "img id in: 4407\n",
      "img id out: 4407\n",
      "img id in: 4408\n",
      "img id out: 4408\n",
      "img id in: 4409\n",
      "img id out: 4409\n",
      "img id in: 4410\n",
      "img id out: 4410\n",
      "img id in: 4411\n",
      "img id out: 4411\n",
      "img id in: 4412\n",
      "img id out: 4412\n",
      "img id in: 4413\n",
      "img id out: 4413\n",
      "img id in: 4414\n",
      "img id out: 4414\n",
      "img id in: 4415\n",
      "img id out: 4415\n",
      "img id in: 4416\n",
      "img id out: 4416\n",
      "img id in: 4417\n",
      "img id out: 4417\n",
      "img id in: 4418\n",
      "img id out: 4418\n",
      "img id in: 4419\n",
      "img id out: 4419\n",
      "img id in: 4420\n",
      "img id out: 4420\n",
      "img id in: 4421\n",
      "img id out: 4421\n",
      "img id in: 4422\n",
      "img id out: 4422\n",
      "img id in: 4423\n",
      "img id out: 4423\n",
      "img id in: 4424\n",
      "img id out: 4424\n",
      "img id in: 4425\n",
      "img id out: 4425\n",
      "img id in: 4426\n",
      "img id out: 4426\n",
      "img id in: 4427\n",
      "img id out: 4427\n",
      "img id in: 4428\n",
      "img id out: 4428\n",
      "img id in: 4429\n",
      "img id out: 4429\n",
      "img id in: 4430\n",
      "img id out: 4430\n",
      "img id in: 4431\n",
      "img id out: 4431\n",
      "img id in: 4432\n",
      "img id out: 4432\n",
      "img id in: 4433\n",
      "img id out: 4433\n",
      "img id in: 4434\n",
      "img id out: 4434\n",
      "img id in: 4435\n",
      "img id out: 4435\n",
      "img id in: 4436\n",
      "img id out: 4436\n",
      "img id in: 4437\n",
      "img id out: 4437\n",
      "img id in: 4438\n",
      "img id out: 4438\n",
      "img id in: 4439\n",
      "img id out: 4439\n",
      "img id in: 4440\n",
      "img id out: 4440\n",
      "img id in: 4441\n",
      "img id out: 4441\n",
      "img id in: 4442\n",
      "img id out: 4442\n",
      "img id in: 4443\n",
      "img id out: 4443\n",
      "img id in: 4444\n",
      "img id out: 4444\n",
      "img id in: 4445\n",
      "img id out: 4445\n",
      "img id in: 4446\n",
      "img id out: 4446\n",
      "img id in: 4447\n",
      "img id out: 4447\n",
      "img id in: 4448\n",
      "img id out: 4448\n",
      "img id in: 4449\n",
      "img id out: 4449\n",
      "img id in: 4450\n",
      "img id out: 4450\n",
      "img id in: 4451\n",
      "img id out: 4451\n",
      "img id in: 4452\n",
      "img id out: 4452\n",
      "img id in: 4453\n",
      "img id out: 4453\n",
      "img id in: 4454\n",
      "img id out: 4454\n",
      "img id in: 4455\n",
      "img id out: 4455\n",
      "img id in: 4456\n",
      "img id out: 4456\n",
      "img id in: 4457\n",
      "img id out: 4457\n",
      "img id in: 4458\n",
      "img id out: 4458\n",
      "img id in: 4459\n",
      "img id out: 4459\n",
      "img id in: 4460\n",
      "img id out: 4460\n",
      "img id in: 4461\n",
      "img id out: 4461\n",
      "img id in: 4462\n",
      "img id out: 4462\n",
      "img id in: 4463\n",
      "img id out: 4463\n",
      "img id in: 4464\n",
      "img id out: 4464\n",
      "img id in: 4465\n",
      "img id out: 4465\n",
      "img id in: 4466\n",
      "img id out: 4466\n",
      "img id in: 4467\n",
      "img id out: 4467\n",
      "img id in: 4468\n",
      "img id out: 4468\n",
      "img id in: 4469\n",
      "img id out: 4469\n",
      "img id in: 4470\n",
      "img id out: 4470\n",
      "img id in: 4471\n",
      "img id out: 4471\n",
      "img id in: 4472\n",
      "img id out: 4472\n",
      "img id in: 4473\n",
      "img id out: 4473\n",
      "img id in: 4474\n",
      "img id out: 4474\n",
      "img id in: 4475\n",
      "img id out: 4475\n",
      "img id in: 4476\n",
      "img id out: 4476\n",
      "img id in: 4477\n",
      "img id out: 4477\n",
      "img id in: 4478\n",
      "img id out: 4478\n",
      "img id in: 4479\n",
      "img id out: 4479\n",
      "img id in: 4480\n",
      "img id out: 4480\n",
      "img id in: 4481\n",
      "img id out: 4481\n",
      "img id in: 4482\n",
      "img id out: 4482\n",
      "img id in: 4483\n",
      "img id out: 4483\n",
      "img id in: 4484\n",
      "img id out: 4484\n",
      "img id in: 4485\n",
      "img id out: 4485\n",
      "img id in: 4486\n",
      "img id out: 4486\n",
      "img id in: 4487\n",
      "img id out: 4487\n",
      "img id in: 4488\n",
      "img id out: 4488\n",
      "img id in: 4489\n",
      "img id out: 4489\n",
      "img id in: 4490\n",
      "img id out: 4490\n",
      "img id in: 4491\n",
      "img id out: 4491\n",
      "img id in: 4492\n",
      "img id out: 4492\n",
      "img id in: 4493\n",
      "img id out: 4493\n",
      "img id in: 4494\n",
      "img id out: 4494\n",
      "img id in: 4495\n",
      "img id out: 4495\n",
      "img id in: 4496\n",
      "img id out: 4496\n",
      "img id in: 4497\n",
      "img id out: 4497\n",
      "img id in: 4498\n",
      "img id out: 4498\n",
      "img id in: 4499\n",
      "img id out: 4499\n",
      "img id in: 4500\n",
      "img id out: 4500\n",
      "img id in: 4501\n",
      "img id out: 4501\n",
      "img id in: 4502\n",
      "img id out: 4502\n",
      "img id in: 4503\n",
      "img id out: 4503\n",
      "img id in: 4504\n",
      "img id out: 4504\n",
      "img id in: 4505\n",
      "img id out: 4505\n",
      "img id in: 4506\n",
      "img id out: 4506\n",
      "img id in: 4507\n",
      "img id out: 4507\n",
      "img id in: 4508\n",
      "img id out: 4508\n",
      "img id in: 4509\n",
      "img id out: 4509\n",
      "img id in: 4510\n",
      "img id out: 4510\n",
      "img id in: 4511\n",
      "img id out: 4511\n",
      "img id in: 4512\n",
      "img id out: 4512\n",
      "img id in: 4513\n",
      "img id out: 4513\n",
      "img id in: 4514\n",
      "img id out: 4514\n",
      "img id in: 4515\n",
      "img id out: 4515\n",
      "img id in: 4516\n",
      "img id out: 4516\n",
      "img id in: 4517\n",
      "img id out: 4517\n",
      "img id in: 4518\n",
      "img id out: 4518\n",
      "img id in: 4519\n",
      "img id out: 4519\n",
      "img id in: 4520\n",
      "img id out: 4520\n",
      "img id in: 4521\n",
      "img id out: 4521\n",
      "img id in: 4522\n",
      "img id out: 4522\n",
      "img id in: 4523\n",
      "img id out: 4523\n",
      "img id in: 4524\n",
      "img id out: 4524\n",
      "img id in: 4525\n",
      "img id out: 4525\n",
      "img id in: 4526\n",
      "img id out: 4526\n",
      "img id in: 4527\n",
      "img id out: 4527\n",
      "img id in: 4528\n",
      "img id out: 4528\n",
      "img id in: 4529\n",
      "img id out: 4529\n",
      "img id in: 4530\n",
      "img id out: 4530\n",
      "img id in: 4531\n",
      "img id out: 4531\n",
      "img id in: 4532\n",
      "img id out: 4532\n",
      "img id in: 4533\n",
      "img id out: 4533\n",
      "img id in: 4534\n",
      "img id out: 4534\n",
      "img id in: 4535\n",
      "img id out: 4535\n",
      "img id in: 4536\n",
      "img id out: 4536\n",
      "img id in: 4537\n",
      "img id out: 4537\n",
      "img id in: 4538\n",
      "img id out: 4538\n",
      "img id in: 4539\n",
      "img id out: 4539\n",
      "img id in: 4540\n",
      "img id out: 4540\n",
      "img id in: 4541\n",
      "img id out: 4541\n",
      "img id in: 4542\n",
      "img id out: 4542\n",
      "img id in: 4543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 4543\n",
      "img id in: 4544\n",
      "img id out: 4544\n",
      "img id in: 4545\n",
      "img id out: 4545\n",
      "img id in: 4546\n",
      "img id out: 4546\n",
      "img id in: 4547\n",
      "img id out: 4547\n",
      "img id in: 4548\n",
      "img id out: 4548\n",
      "img id in: 4549\n",
      "img id out: 4549\n",
      "img id in: 4550\n",
      "img id out: 4550\n",
      "img id in: 4551\n",
      "img id out: 4551\n",
      "img id in: 4552\n",
      "img id out: 4552\n",
      "img id in: 4553\n",
      "img id out: 4553\n",
      "img id in: 4554\n",
      "img id out: 4554\n",
      "img id in: 4555\n",
      "img id out: 4555\n",
      "img id in: 4556\n",
      "img id out: 4556\n",
      "img id in: 4557\n",
      "img id out: 4557\n",
      "img id in: 4558\n",
      "img id out: 4558\n",
      "img id in: 4559\n",
      "img id out: 4559\n",
      "img id in: 4560\n",
      "img id out: 4560\n",
      "img id in: 4561\n",
      "img id out: 4561\n",
      "img id in: 4562\n",
      "img id out: 4562\n",
      "img id in: 4563\n",
      "img id out: 4563\n",
      "img id in: 4564\n",
      "img id out: 4564\n",
      "img id in: 4565\n",
      "img id out: 4565\n",
      "img id in: 4566\n",
      "img id out: 4566\n",
      "img id in: 4567\n",
      "img id out: 4567\n",
      "img id in: 4568\n",
      "img id out: 4568\n",
      "img id in: 4569\n",
      "img id out: 4569\n",
      "img id in: 4570\n",
      "img id out: 4570\n",
      "img id in: 4571\n",
      "img id out: 4571\n",
      "img id in: 4572\n",
      "img id out: 4572\n",
      "img id in: 4573\n",
      "img id out: 4573\n",
      "img id in: 4574\n",
      "img id out: 4574\n",
      "img id in: 4575\n",
      "img id out: 4575\n",
      "img id in: 4576\n",
      "img id out: 4576\n",
      "img id in: 4577\n",
      "img id out: 4577\n",
      "img id in: 4578\n",
      "img id out: 4578\n",
      "img id in: 4579\n",
      "img id out: 4579\n",
      "img id in: 4580\n",
      "img id out: 4580\n",
      "img id in: 4581\n",
      "img id out: 4581\n",
      "img id in: 4582\n",
      "img id out: 4582\n",
      "img id in: 4583\n",
      "img id out: 4583\n",
      "img id in: 4584\n",
      "img id out: 4584\n",
      "img id in: 4585\n",
      "img id out: 4585\n",
      "img id in: 4586\n",
      "img id out: 4586\n",
      "img id in: 4587\n",
      "img id out: 4587\n",
      "img id in: 4588\n",
      "img id out: 4588\n",
      "img id in: 4589\n",
      "img id out: 4589\n",
      "img id in: 4590\n",
      "img id out: 4590\n",
      "img id in: 4591\n",
      "img id out: 4591\n",
      "img id in: 4592\n",
      "img id out: 4592\n",
      "img id in: 4593\n",
      "img id out: 4593\n",
      "img id in: 4594\n",
      "img id out: 4594\n",
      "img id in: 4595\n",
      "img id out: 4595\n",
      "img id in: 4596\n",
      "img id out: 4596\n",
      "img id in: 4597\n",
      "img id out: 4597\n",
      "img id in: 4598\n",
      "img id out: 4598\n",
      "img id in: 4599\n",
      "img id out: 4599\n",
      "img id in: 4600\n",
      "img id out: 4600\n",
      "img id in: 4601\n",
      "img id out: 4601\n",
      "img id in: 4602\n",
      "img id out: 4602\n",
      "img id in: 4603\n",
      "img id out: 4603\n",
      "img id in: 4604\n",
      "img id out: 4604\n",
      "img id in: 4605\n",
      "img id out: 4605\n",
      "img id in: 4606\n",
      "img id out: 4606\n",
      "img id in: 4607\n",
      "img id out: 4607\n",
      "img id in: 4608\n",
      "img id out: 4608\n",
      "img id in: 4609\n",
      "img id out: 4609\n",
      "img id in: 4610\n",
      "img id out: 4610\n",
      "img id in: 4611\n",
      "img id out: 4611\n",
      "img id in: 4612\n",
      "img id out: 4612\n",
      "img id in: 4613\n",
      "img id out: 4613\n",
      "img id in: 4614\n",
      "img id out: 4614\n",
      "img id in: 4615\n",
      "img id out: 4615\n",
      "img id in: 4616\n",
      "img id out: 4616\n",
      "img id in: 4617\n",
      "img id out: 4617\n",
      "img id in: 4618\n",
      "img id out: 4618\n",
      "img id in: 4619\n",
      "img id out: 4619\n",
      "img id in: 4620\n",
      "img id out: 4620\n",
      "img id in: 4621\n",
      "img id out: 4621\n",
      "img id in: 4622\n",
      "img id out: 4622\n",
      "img id in: 4623\n",
      "img id out: 4623\n",
      "img id in: 4624\n",
      "img id out: 4624\n",
      "img id in: 4625\n",
      "img id out: 4625\n",
      "img id in: 4626\n",
      "img id out: 4626\n",
      "img id in: 4627\n",
      "img id out: 4627\n",
      "img id in: 4628\n",
      "img id out: 4628\n",
      "img id in: 4629\n",
      "img id out: 4629\n",
      "img id in: 4630\n",
      "img id out: 4630\n",
      "img id in: 4631\n",
      "img id out: 4631\n",
      "img id in: 4632\n",
      "img id out: 4632\n",
      "img id in: 4633\n",
      "img id out: 4633\n",
      "img id in: 4634\n",
      "img id out: 4634\n",
      "img id in: 4635\n",
      "img id out: 4635\n",
      "img id in: 4636\n",
      "img id out: 4636\n",
      "img id in: 4637\n",
      "img id out: 4637\n",
      "img id in: 4638\n",
      "img id out: 4638\n",
      "img id in: 4639\n",
      "img id out: 4639\n",
      "img id in: 4640\n",
      "img id out: 4640\n",
      "img id in: 4641\n",
      "img id out: 4641\n",
      "img id in: 4642\n",
      "img id out: 4642\n",
      "img id in: 4643\n",
      "img id out: 4643\n",
      "img id in: 4644\n",
      "img id out: 4644\n",
      "img id in: 4645\n",
      "img id out: 4645\n",
      "img id in: 4646\n",
      "img id out: 4646\n",
      "img id in: 4647\n",
      "img id out: 4647\n",
      "img id in: 4648\n",
      "img id out: 4648\n",
      "img id in: 4649\n",
      "img id out: 4649\n",
      "img id in: 4650\n",
      "img id out: 4650\n",
      "img id in: 4651\n",
      "img id out: 4651\n",
      "img id in: 4652\n",
      "img id out: 4652\n",
      "img id in: 4653\n",
      "img id out: 4653\n",
      "img id in: 4654\n",
      "img id out: 4654\n",
      "img id in: 4655\n",
      "img id out: 4655\n",
      "img id in: 4656\n",
      "img id out: 4656\n",
      "img id in: 4657\n",
      "img id out: 4657\n",
      "img id in: 4658\n",
      "img id out: 4658\n",
      "img id in: 4659\n",
      "img id out: 4659\n",
      "img id in: 4660\n",
      "img id out: 4660\n",
      "img id in: 4661\n",
      "img id out: 4661\n",
      "img id in: 4662\n",
      "img id out: 4662\n",
      "img id in: 4663\n",
      "img id out: 4663\n",
      "img id in: 4664\n",
      "img id out: 4664\n",
      "img id in: 4665\n",
      "img id out: 4665\n",
      "img id in: 4666\n",
      "img id out: 4666\n",
      "img id in: 4667\n",
      "img id out: 4667\n",
      "img id in: 4668\n",
      "img id out: 4668\n",
      "img id in: 4669\n",
      "img id out: 4669\n",
      "img id in: 4670\n",
      "img id out: 4670\n",
      "img id in: 4671\n",
      "img id out: 4671\n",
      "img id in: 4672\n",
      "img id out: 4672\n",
      "img id in: 4673\n",
      "img id out: 4673\n",
      "img id in: 4674\n",
      "img id out: 4674\n",
      "img id in: 4675\n",
      "img id out: 4675\n",
      "img id in: 4676\n",
      "img id out: 4676\n",
      "img id in: 4677\n",
      "img id out: 4677\n",
      "img id in: 4678\n",
      "img id out: 4678\n",
      "img id in: 4679\n",
      "img id out: 4679\n",
      "img id in: 4680\n",
      "img id out: 4680\n",
      "img id in: 4681\n",
      "img id out: 4681\n",
      "img id in: 4682\n",
      "img id out: 4682\n",
      "img id in: 4683\n",
      "img id out: 4683\n",
      "img id in: 4684\n",
      "img id out: 4684\n",
      "img id in: 4685\n",
      "img id out: 4685\n",
      "img id in: 4686\n",
      "img id out: 4686\n",
      "img id in: 4687\n",
      "img id out: 4687\n",
      "img id in: 4688\n",
      "img id out: 4688\n",
      "img id in: 4689\n",
      "img id out: 4689\n",
      "img id in: 4690\n",
      "img id out: 4690\n",
      "img id in: 4691\n",
      "img id out: 4691\n",
      "img id in: 4692\n",
      "img id out: 4692\n",
      "img id in: 4693\n",
      "img id out: 4693\n",
      "img id in: 4694\n",
      "img id out: 4694\n",
      "img id in: 4695\n",
      "img id out: 4695\n",
      "img id in: 4696\n",
      "img id out: 4696\n",
      "img id in: 4697\n",
      "img id out: 4697\n",
      "img id in: 4698\n",
      "img id out: 4698\n",
      "img id in: 4699\n",
      "img id out: 4699\n",
      "img id in: 4700\n",
      "img id out: 4700\n",
      "img id in: 4701\n",
      "img id out: 4701\n",
      "img id in: 4702\n",
      "img id out: 4702\n",
      "img id in: 4703\n",
      "img id out: 4703\n",
      "img id in: 4704\n",
      "img id out: 4704\n",
      "img id in: 4705\n",
      "img id out: 4705\n",
      "img id in: 4706\n",
      "img id out: 4706\n",
      "img id in: 4707\n",
      "img id out: 4707\n",
      "img id in: 4708\n",
      "img id out: 4708\n",
      "img id in: 4709\n",
      "img id out: 4709\n",
      "img id in: 4710\n",
      "img id out: 4710\n",
      "img id in: 4711\n",
      "img id out: 4711\n",
      "img id in: 4712\n",
      "img id out: 4712\n",
      "img id in: 4713\n",
      "img id out: 4713\n",
      "img id in: 4714\n",
      "img id out: 4714\n",
      "img id in: 4715\n",
      "img id out: 4715\n",
      "img id in: 4716\n",
      "img id out: 4716\n",
      "img id in: 4717\n",
      "img id out: 4717\n",
      "img id in: 4718\n",
      "img id out: 4718\n",
      "img id in: 4719\n",
      "img id out: 4719\n",
      "img id in: 4720\n",
      "img id out: 4720\n",
      "img id in: 4721\n",
      "img id out: 4721\n",
      "img id in: 4722\n",
      "img id out: 4722\n",
      "img id in: 4723\n",
      "img id out: 4723\n",
      "img id in: 4724\n",
      "img id out: 4724\n",
      "img id in: 4725\n",
      "img id out: 4725\n",
      "img id in: 4726\n",
      "img id out: 4726\n",
      "img id in: 4727\n",
      "img id out: 4727\n",
      "img id in: 4728\n",
      "img id out: 4728\n",
      "img id in: 4729\n",
      "img id out: 4729\n",
      "img id in: 4730\n",
      "img id out: 4730\n",
      "img id in: 4731\n",
      "img id out: 4731\n",
      "img id in: 4732\n",
      "img id out: 4732\n",
      "img id in: 4733\n",
      "img id out: 4733\n",
      "img id in: 4734\n",
      "img id out: 4734\n",
      "img id in: 4735\n",
      "img id out: 4735\n",
      "img id in: 4736\n",
      "img id out: 4736\n",
      "img id in: 4737\n",
      "img id out: 4737\n",
      "img id in: 4738\n",
      "img id out: 4738\n",
      "img id in: 4739\n",
      "img id out: 4739\n",
      "img id in: 4740\n",
      "img id out: 4740\n",
      "img id in: 4741\n",
      "img id out: 4741\n",
      "img id in: 4742\n",
      "img id out: 4742\n",
      "img id in: 4743\n",
      "img id out: 4743\n",
      "img id in: 4744\n",
      "img id out: 4744\n",
      "img id in: 4745\n",
      "img id out: 4745\n",
      "img id in: 4746\n",
      "img id out: 4746\n",
      "img id in: 4747\n",
      "img id out: 4747\n",
      "img id in: 4748\n",
      "img id out: 4748\n",
      "img id in: 4749\n",
      "img id out: 4749\n",
      "img id in: 4750\n",
      "img id out: 4750\n",
      "img id in: 4751\n",
      "img id out: 4751\n",
      "img id in: 4752\n",
      "img id out: 4752\n",
      "img id in: 4753\n",
      "img id out: 4753\n",
      "img id in: 4754\n",
      "img id out: 4754\n",
      "img id in: 4755\n",
      "img id out: 4755\n",
      "img id in: 4756\n",
      "img id out: 4756\n",
      "img id in: 4757\n",
      "img id out: 4757\n",
      "img id in: 4758\n",
      "img id out: 4758\n",
      "img id in: 4759\n",
      "img id out: 4759\n",
      "img id in: 4760\n",
      "img id out: 4760\n",
      "img id in: 4761\n",
      "img id out: 4761\n",
      "img id in: 4762\n",
      "img id out: 4762\n",
      "img id in: 4763\n",
      "img id out: 4763\n",
      "img id in: 4764\n",
      "img id out: 4764\n",
      "img id in: 4765\n",
      "img id out: 4765\n",
      "img id in: 4766\n",
      "img id out: 4766\n",
      "img id in: 4767\n",
      "img id out: 4767\n",
      "img id in: 4768\n",
      "img id out: 4768\n",
      "img id in: 4769\n",
      "img id out: 4769\n",
      "img id in: 4770\n",
      "img id out: 4770\n",
      "img id in: 4771\n",
      "img id out: 4771\n",
      "img id in: 4772\n",
      "img id out: 4772\n",
      "img id in: 4773\n",
      "img id out: 4773\n",
      "img id in: 4774\n",
      "img id out: 4774\n",
      "img id in: 4775\n",
      "img id out: 4775\n",
      "img id in: 4776\n",
      "img id out: 4776\n",
      "img id in: 4777\n",
      "img id out: 4777\n",
      "img id in: 4778\n",
      "img id out: 4778\n",
      "img id in: 4779\n",
      "img id out: 4779\n",
      "img id in: 4780\n",
      "img id out: 4780\n",
      "img id in: 4781\n",
      "img id out: 4781\n",
      "img id in: 4782\n",
      "img id out: 4782\n",
      "img id in: 4783\n",
      "img id out: 4783\n",
      "img id in: 4784\n",
      "img id out: 4784\n",
      "img id in: 4785\n",
      "img id out: 4785\n",
      "img id in: 4786\n",
      "img id out: 4786\n",
      "img id in: 4787\n",
      "img id out: 4787\n",
      "img id in: 4788\n",
      "img id out: 4788\n",
      "img id in: 4789\n",
      "img id out: 4789\n",
      "img id in: 4790\n",
      "img id out: 4790\n",
      "img id in: 4791\n",
      "img id out: 4791\n",
      "img id in: 4792\n",
      "img id out: 4792\n",
      "img id in: 4793\n",
      "img id out: 4793\n",
      "img id in: 4794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 4794\n",
      "img id in: 4795\n",
      "img id out: 4795\n",
      "img id in: 4796\n",
      "img id out: 4796\n",
      "img id in: 4797\n",
      "img id out: 4797\n",
      "img id in: 4798\n",
      "img id out: 4798\n",
      "img id in: 4799\n",
      "img id out: 4799\n",
      "img id in: 4800\n",
      "img id out: 4800\n",
      "img id in: 4801\n",
      "img id out: 4801\n",
      "img id in: 4802\n",
      "img id out: 4802\n",
      "img id in: 4803\n",
      "img id out: 4803\n",
      "img id in: 4804\n",
      "img id out: 4804\n",
      "img id in: 4805\n",
      "img id out: 4805\n",
      "img id in: 4806\n",
      "img id out: 4806\n",
      "img id in: 4807\n",
      "img id out: 4807\n",
      "img id in: 4808\n",
      "img id out: 4808\n",
      "img id in: 4809\n",
      "img id out: 4809\n",
      "img id in: 4810\n",
      "img id out: 4810\n",
      "img id in: 4811\n",
      "img id out: 4811\n",
      "img id in: 4812\n",
      "img id out: 4812\n",
      "img id in: 4813\n",
      "img id out: 4813\n",
      "img id in: 4814\n",
      "img id out: 4814\n",
      "img id in: 4815\n",
      "img id out: 4815\n",
      "img id in: 4816\n",
      "img id out: 4816\n",
      "img id in: 4817\n",
      "img id out: 4817\n",
      "img id in: 4818\n",
      "img id out: 4818\n",
      "img id in: 4819\n",
      "img id out: 4819\n",
      "img id in: 4820\n",
      "img id out: 4820\n",
      "img id in: 4821\n",
      "img id out: 4821\n",
      "img id in: 4822\n",
      "img id out: 4822\n",
      "img id in: 4823\n",
      "img id out: 4823\n",
      "img id in: 4824\n",
      "img id out: 4824\n",
      "img id in: 4825\n",
      "img id out: 4825\n",
      "img id in: 4826\n",
      "img id out: 4826\n",
      "img id in: 4827\n",
      "img id out: 4827\n",
      "img id in: 4828\n",
      "img id out: 4828\n",
      "img id in: 4829\n",
      "img id out: 4829\n",
      "img id in: 4830\n",
      "img id out: 4830\n",
      "img id in: 4831\n",
      "img id out: 4831\n",
      "img id in: 4832\n",
      "img id out: 4832\n",
      "img id in: 4833\n",
      "img id out: 4833\n",
      "img id in: 4834\n",
      "img id out: 4834\n",
      "img id in: 4835\n",
      "img id out: 4835\n",
      "img id in: 4836\n",
      "img id out: 4836\n",
      "img id in: 4837\n",
      "img id out: 4837\n",
      "img id in: 4838\n",
      "img id out: 4838\n",
      "img id in: 4839\n",
      "img id out: 4839\n",
      "img id in: 4840\n",
      "img id out: 4840\n",
      "img id in: 4841\n",
      "img id out: 4841\n",
      "img id in: 4842\n",
      "img id out: 4842\n",
      "img id in: 4843\n",
      "img id out: 4843\n",
      "img id in: 4844\n",
      "img id out: 4844\n",
      "img id in: 4845\n",
      "img id out: 4845\n",
      "img id in: 4846\n",
      "img id out: 4846\n",
      "img id in: 4847\n",
      "img id out: 4847\n",
      "img id in: 4848\n",
      "img id out: 4848\n",
      "img id in: 4849\n",
      "img id out: 4849\n",
      "img id in: 4850\n",
      "img id out: 4850\n",
      "img id in: 4851\n",
      "img id out: 4851\n",
      "img id in: 4852\n",
      "img id out: 4852\n",
      "img id in: 4853\n",
      "img id out: 4853\n",
      "img id in: 4854\n",
      "img id out: 4854\n",
      "img id in: 4855\n",
      "img id out: 4855\n",
      "img id in: 4856\n",
      "img id out: 4856\n",
      "img id in: 4857\n",
      "img id out: 4857\n",
      "img id in: 4858\n",
      "img id out: 4858\n",
      "img id in: 4859\n",
      "img id out: 4859\n",
      "img id in: 4860\n",
      "img id out: 4860\n",
      "img id in: 4861\n",
      "img id out: 4861\n",
      "img id in: 4862\n",
      "img id out: 4862\n",
      "img id in: 4863\n",
      "img id out: 4863\n",
      "img id in: 4864\n",
      "img id out: 4864\n",
      "img id in: 4865\n",
      "img id out: 4865\n",
      "img id in: 4866\n",
      "img id out: 4866\n",
      "img id in: 4867\n",
      "img id out: 4867\n",
      "img id in: 4868\n",
      "img id out: 4868\n",
      "img id in: 4869\n",
      "img id out: 4869\n",
      "img id in: 4870\n",
      "img id out: 4870\n",
      "img id in: 4871\n",
      "img id out: 4871\n",
      "img id in: 4872\n",
      "img id out: 4872\n",
      "img id in: 4873\n",
      "img id out: 4873\n",
      "img id in: 4874\n",
      "img id out: 4874\n",
      "img id in: 4875\n",
      "img id out: 4875\n",
      "img id in: 4876\n",
      "img id out: 4876\n",
      "img id in: 4877\n",
      "img id out: 4877\n",
      "img id in: 4878\n",
      "img id out: 4878\n",
      "img id in: 4879\n",
      "img id out: 4879\n",
      "img id in: 4880\n",
      "img id out: 4880\n",
      "img id in: 4881\n",
      "img id out: 4881\n",
      "img id in: 4882\n",
      "img id out: 4882\n",
      "img id in: 4883\n",
      "img id out: 4883\n",
      "img id in: 4884\n",
      "img id out: 4884\n",
      "img id in: 4885\n",
      "img id out: 4885\n",
      "img id in: 4886\n",
      "img id out: 4886\n",
      "img id in: 4887\n",
      "img id out: 4887\n",
      "img id in: 4888\n",
      "img id out: 4888\n",
      "img id in: 4889\n",
      "img id out: 4889\n",
      "img id in: 4890\n",
      "img id out: 4890\n",
      "img id in: 4891\n",
      "img id out: 4891\n",
      "img id in: 4892\n",
      "img id out: 4892\n",
      "img id in: 4893\n",
      "img id out: 4893\n",
      "img id in: 4894\n",
      "img id out: 4894\n",
      "img id in: 4895\n",
      "img id out: 4895\n",
      "img id in: 4896\n",
      "img id out: 4896\n",
      "img id in: 4897\n",
      "img id out: 4897\n",
      "img id in: 4898\n",
      "img id out: 4898\n",
      "img id in: 4899\n",
      "img id out: 4899\n",
      "img id in: 4900\n",
      "img id out: 4900\n",
      "img id in: 4901\n",
      "img id out: 4901\n",
      "img id in: 4902\n",
      "img id out: 4902\n",
      "img id in: 4903\n",
      "img id out: 4903\n",
      "img id in: 4904\n",
      "img id out: 4904\n",
      "img id in: 4905\n",
      "img id out: 4905\n",
      "img id in: 4906\n",
      "img id out: 4906\n",
      "img id in: 4907\n",
      "img id out: 4907\n",
      "img id in: 4908\n",
      "img id out: 4908\n",
      "img id in: 4909\n",
      "img id out: 4909\n",
      "img id in: 4910\n",
      "img id out: 4910\n",
      "img id in: 4911\n",
      "img id out: 4911\n",
      "img id in: 4912\n",
      "img id out: 4912\n",
      "img id in: 4913\n",
      "img id out: 4913\n",
      "img id in: 4914\n",
      "img id out: 4914\n",
      "img id in: 4915\n",
      "img id out: 4915\n",
      "img id in: 4916\n",
      "img id out: 4916\n",
      "img id in: 4917\n",
      "img id out: 4917\n",
      "img id in: 4918\n",
      "img id out: 4918\n",
      "img id in: 4919\n",
      "img id out: 4919\n",
      "img id in: 4920\n",
      "img id out: 4920\n",
      "img id in: 4921\n",
      "img id out: 4921\n",
      "img id in: 4922\n",
      "img id out: 4922\n",
      "img id in: 4923\n",
      "img id out: 4923\n",
      "img id in: 4924\n",
      "img id out: 4924\n",
      "img id in: 4925\n",
      "img id out: 4925\n",
      "img id in: 4926\n",
      "img id out: 4926\n",
      "img id in: 4927\n",
      "img id out: 4927\n",
      "img id in: 4928\n",
      "img id out: 4928\n",
      "img id in: 4929\n",
      "img id out: 4929\n",
      "img id in: 4930\n",
      "img id out: 4930\n",
      "img id in: 4931\n",
      "img id out: 4931\n",
      "img id in: 4932\n",
      "img id out: 4932\n",
      "img id in: 4933\n",
      "img id out: 4933\n",
      "img id in: 4934\n",
      "img id out: 4934\n",
      "img id in: 4935\n",
      "img id out: 4935\n",
      "img id in: 4936\n",
      "img id out: 4936\n",
      "img id in: 4937\n",
      "img id out: 4937\n",
      "img id in: 4938\n",
      "img id out: 4938\n",
      "img id in: 4939\n",
      "img id out: 4939\n",
      "img id in: 4940\n",
      "img id out: 4940\n",
      "img id in: 4941\n",
      "img id out: 4941\n",
      "img id in: 4942\n",
      "img id out: 4942\n",
      "img id in: 4943\n",
      "img id out: 4943\n",
      "img id in: 4944\n",
      "img id out: 4944\n",
      "img id in: 4945\n",
      "img id out: 4945\n",
      "img id in: 4946\n",
      "img id out: 4946\n",
      "img id in: 4947\n",
      "img id out: 4947\n",
      "img id in: 4948\n",
      "img id out: 4948\n",
      "img id in: 4949\n",
      "img id out: 4949\n",
      "img id in: 4950\n",
      "img id out: 4950\n",
      "img id in: 4951\n",
      "img id out: 4951\n",
      "img id in: 4952\n",
      "img id out: 4952\n",
      "img id in: 4953\n",
      "img id out: 4953\n",
      "img id in: 4954\n",
      "img id out: 4954\n",
      "img id in: 4955\n",
      "img id out: 4955\n",
      "img id in: 4956\n",
      "img id out: 4956\n",
      "img id in: 4957\n",
      "img id out: 4957\n",
      "img id in: 4958\n",
      "img id out: 4958\n",
      "img id in: 4959\n",
      "img id out: 4959\n",
      "img id in: 4960\n",
      "img id out: 4960\n",
      "img id in: 4961\n",
      "img id out: 4961\n",
      "img id in: 4962\n",
      "img id out: 4962\n",
      "img id in: 4963\n",
      "img id out: 4963\n",
      "img id in: 4964\n",
      "img id out: 4964\n",
      "img id in: 4965\n",
      "img id out: 4965\n",
      "img id in: 4966\n",
      "img id out: 4966\n",
      "img id in: 4967\n",
      "img id out: 4967\n",
      "img id in: 4968\n",
      "img id out: 4968\n",
      "img id in: 4969\n",
      "img id out: 4969\n",
      "img id in: 4970\n",
      "img id out: 4970\n",
      "img id in: 4971\n",
      "img id out: 4971\n",
      "img id in: 4972\n",
      "img id out: 4972\n",
      "img id in: 4973\n",
      "img id out: 4973\n",
      "img id in: 4974\n",
      "img id out: 4974\n",
      "img id in: 4975\n",
      "img id out: 4975\n",
      "img id in: 4976\n",
      "img id out: 4976\n",
      "img id in: 4977\n",
      "img id out: 4977\n",
      "img id in: 4978\n",
      "img id out: 4978\n",
      "img id in: 4979\n",
      "img id out: 4979\n",
      "img id in: 4980\n",
      "img id out: 4980\n",
      "img id in: 4981\n",
      "img id out: 4981\n",
      "img id in: 4982\n",
      "img id out: 4982\n",
      "img id in: 4983\n",
      "img id out: 4983\n",
      "img id in: 4984\n",
      "img id out: 4984\n",
      "img id in: 4985\n",
      "img id out: 4985\n",
      "img id in: 4986\n",
      "img id out: 4986\n",
      "img id in: 4987\n",
      "img id out: 4987\n",
      "img id in: 4988\n",
      "img id out: 4988\n",
      "img id in: 4989\n",
      "img id out: 4989\n",
      "img id in: 4990\n",
      "img id out: 4990\n",
      "img id in: 4991\n",
      "img id out: 4991\n",
      "img id in: 4992\n",
      "img id out: 4992\n",
      "img id in: 4993\n",
      "img id out: 4993\n",
      "img id in: 4994\n",
      "img id out: 4994\n",
      "img id in: 4995\n",
      "img id out: 4995\n",
      "img id in: 4996\n",
      "img id out: 4996\n",
      "img id in: 4997\n",
      "img id out: 4997\n",
      "img id in: 4998\n",
      "img id out: 4998\n",
      "img id in: 4999\n",
      "img id out: 4999\n",
      "img id in: 5000\n",
      "img id out: 5000\n",
      "img id in: 5001\n",
      "img id out: 5001\n",
      "img id in: 5002\n",
      "img id out: 5002\n",
      "img id in: 5003\n",
      "img id out: 5003\n",
      "img id in: 5004\n",
      "img id out: 5004\n",
      "img id in: 5005\n",
      "img id out: 5005\n",
      "img id in: 5006\n",
      "img id out: 5006\n",
      "img id in: 5007\n",
      "img id out: 5007\n",
      "img id in: 5008\n",
      "img id out: 5008\n",
      "img id in: 5009\n",
      "img id out: 5009\n",
      "img id in: 5010\n",
      "img id out: 5010\n",
      "img id in: 5011\n",
      "img id out: 5011\n",
      "img id in: 5012\n",
      "img id out: 5012\n",
      "img id in: 5013\n",
      "img id out: 5013\n",
      "img id in: 5014\n",
      "img id out: 5014\n",
      "img id in: 5015\n",
      "img id out: 5015\n",
      "img id in: 5016\n",
      "img id out: 5016\n",
      "img id in: 5017\n",
      "img id out: 5017\n",
      "img id in: 5018\n",
      "img id out: 5018\n",
      "img id in: 5019\n",
      "img id out: 5019\n",
      "img id in: 5020\n",
      "img id out: 5020\n",
      "img id in: 5021\n",
      "img id out: 5021\n",
      "img id in: 5022\n",
      "img id out: 5022\n",
      "img id in: 5023\n",
      "img id out: 5023\n",
      "img id in: 5024\n",
      "img id out: 5024\n",
      "img id in: 5025\n",
      "img id out: 5025\n",
      "img id in: 5026\n",
      "img id out: 5026\n",
      "img id in: 5027\n",
      "img id out: 5027\n",
      "img id in: 5028\n",
      "img id out: 5028\n",
      "img id in: 5029\n",
      "img id out: 5029\n",
      "img id in: 5030\n",
      "img id out: 5030\n",
      "img id in: 5031\n",
      "img id out: 5031\n",
      "img id in: 5032\n",
      "img id out: 5032\n",
      "img id in: 5033\n",
      "img id out: 5033\n",
      "img id in: 5034\n",
      "img id out: 5034\n",
      "img id in: 5035\n",
      "img id out: 5035\n",
      "img id in: 5036\n",
      "img id out: 5036\n",
      "img id in: 5037\n",
      "img id out: 5037\n",
      "img id in: 5038\n",
      "img id out: 5038\n",
      "img id in: 5039\n",
      "img id out: 5039\n",
      "img id in: 5040\n",
      "img id out: 5040\n",
      "img id in: 5041\n",
      "img id out: 5041\n",
      "img id in: 5042\n",
      "img id out: 5042\n",
      "img id in: 5043\n",
      "img id out: 5043\n",
      "img id in: 5044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 5044\n",
      "img id in: 5045\n",
      "img id out: 5045\n",
      "img id in: 5046\n",
      "img id out: 5046\n",
      "img id in: 5047\n",
      "img id out: 5047\n",
      "img id in: 5048\n",
      "img id out: 5048\n",
      "img id in: 5049\n",
      "img id out: 5049\n",
      "img id in: 5050\n",
      "img id out: 5050\n",
      "img id in: 5051\n",
      "img id out: 5051\n",
      "img id in: 5052\n",
      "img id out: 5052\n",
      "img id in: 5053\n",
      "img id out: 5053\n",
      "img id in: 5054\n",
      "img id out: 5054\n",
      "img id in: 5055\n",
      "img id out: 5055\n",
      "img id in: 5056\n",
      "img id out: 5056\n",
      "img id in: 5057\n",
      "img id out: 5057\n",
      "img id in: 5058\n",
      "img id out: 5058\n",
      "img id in: 5059\n",
      "img id out: 5059\n",
      "img id in: 5060\n",
      "img id out: 5060\n",
      "img id in: 5061\n",
      "img id out: 5061\n",
      "img id in: 5062\n",
      "img id out: 5062\n",
      "img id in: 5063\n",
      "img id out: 5063\n",
      "img id in: 5064\n",
      "img id out: 5064\n",
      "img id in: 5065\n",
      "img id out: 5065\n",
      "img id in: 5066\n",
      "img id out: 5066\n",
      "img id in: 5067\n",
      "img id out: 5067\n",
      "img id in: 5068\n",
      "img id out: 5068\n",
      "img id in: 5069\n",
      "img id out: 5069\n",
      "img id in: 5070\n",
      "img id out: 5070\n",
      "img id in: 5071\n",
      "img id out: 5071\n",
      "img id in: 5072\n",
      "img id out: 5072\n",
      "img id in: 5073\n",
      "img id out: 5073\n",
      "img id in: 5074\n",
      "img id out: 5074\n",
      "img id in: 5075\n",
      "img id out: 5075\n",
      "img id in: 5076\n",
      "img id out: 5076\n",
      "img id in: 5077\n",
      "img id out: 5077\n",
      "img id in: 5078\n",
      "img id out: 5078\n",
      "img id in: 5079\n",
      "img id out: 5079\n",
      "img id in: 5080\n",
      "img id out: 5080\n",
      "img id in: 5081\n",
      "img id out: 5081\n",
      "img id in: 5082\n",
      "img id out: 5082\n",
      "img id in: 5083\n",
      "img id out: 5083\n",
      "img id in: 5084\n",
      "img id out: 5084\n",
      "img id in: 5085\n",
      "img id out: 5085\n",
      "img id in: 5086\n",
      "img id out: 5086\n",
      "img id in: 5087\n",
      "img id out: 5087\n",
      "img id in: 5088\n",
      "img id out: 5088\n",
      "img id in: 5089\n",
      "img id out: 5089\n",
      "img id in: 5090\n",
      "img id out: 5090\n",
      "img id in: 5091\n",
      "img id out: 5091\n",
      "img id in: 5092\n",
      "img id out: 5092\n",
      "img id in: 5093\n",
      "img id out: 5093\n",
      "img id in: 5094\n",
      "img id out: 5094\n",
      "img id in: 5095\n",
      "img id out: 5095\n",
      "img id in: 5096\n",
      "img id out: 5096\n",
      "img id in: 5097\n",
      "img id out: 5097\n",
      "img id in: 5098\n",
      "img id out: 5098\n",
      "img id in: 5099\n",
      "img id out: 5099\n",
      "img id in: 5100\n",
      "img id out: 5100\n",
      "img id in: 5101\n",
      "img id out: 5101\n",
      "img id in: 5102\n",
      "img id out: 5102\n",
      "img id in: 5103\n",
      "img id out: 5103\n",
      "img id in: 5104\n",
      "img id out: 5104\n",
      "img id in: 5105\n",
      "img id out: 5105\n",
      "img id in: 5106\n",
      "img id out: 5106\n",
      "img id in: 5107\n",
      "img id out: 5107\n",
      "img id in: 5108\n",
      "img id out: 5108\n",
      "img id in: 5109\n",
      "img id out: 5109\n",
      "img id in: 5110\n",
      "img id out: 5110\n",
      "img id in: 5111\n",
      "img id out: 5111\n",
      "img id in: 5112\n",
      "img id out: 5112\n",
      "img id in: 5113\n",
      "img id out: 5113\n",
      "img id in: 5114\n",
      "img id out: 5114\n",
      "img id in: 5115\n",
      "img id out: 5115\n",
      "img id in: 5116\n",
      "img id out: 5116\n",
      "img id in: 5117\n",
      "img id out: 5117\n",
      "img id in: 5118\n",
      "img id out: 5118\n",
      "img id in: 5119\n",
      "img id out: 5119\n",
      "img id in: 5120\n",
      "img id out: 5120\n",
      "img id in: 5121\n",
      "img id out: 5121\n",
      "img id in: 5122\n",
      "img id out: 5122\n",
      "img id in: 5123\n",
      "img id out: 5123\n",
      "img id in: 5124\n",
      "img id out: 5124\n",
      "img id in: 5125\n",
      "img id out: 5125\n",
      "img id in: 5126\n",
      "img id out: 5126\n",
      "img id in: 5127\n",
      "img id out: 5127\n",
      "img id in: 5128\n",
      "img id out: 5128\n",
      "img id in: 5129\n",
      "img id out: 5129\n",
      "img id in: 5130\n",
      "img id out: 5130\n",
      "img id in: 5131\n",
      "img id out: 5131\n",
      "img id in: 5132\n",
      "img id out: 5132\n",
      "img id in: 5133\n",
      "img id out: 5133\n",
      "img id in: 5134\n",
      "img id out: 5134\n",
      "img id in: 5135\n",
      "img id out: 5135\n",
      "img id in: 5136\n",
      "img id out: 5136\n",
      "img id in: 5137\n",
      "img id out: 5137\n",
      "img id in: 5138\n",
      "img id out: 5138\n",
      "img id in: 5139\n",
      "img id out: 5139\n",
      "img id in: 5140\n",
      "img id out: 5140\n",
      "img id in: 5141\n",
      "img id out: 5141\n",
      "img id in: 5142\n",
      "img id out: 5142\n",
      "img id in: 5143\n",
      "img id out: 5143\n",
      "img id in: 5144\n",
      "img id out: 5144\n",
      "img id in: 5145\n",
      "img id out: 5145\n",
      "img id in: 5146\n",
      "img id out: 5146\n",
      "img id in: 5147\n",
      "img id out: 5147\n",
      "img id in: 5148\n",
      "img id out: 5148\n",
      "img id in: 5149\n",
      "img id out: 5149\n",
      "img id in: 5150\n",
      "img id out: 5150\n",
      "img id in: 5151\n",
      "img id out: 5151\n",
      "img id in: 5152\n",
      "img id out: 5152\n",
      "img id in: 5153\n",
      "img id out: 5153\n",
      "img id in: 5154\n",
      "img id out: 5154\n",
      "img id in: 5155\n",
      "img id out: 5155\n",
      "img id in: 5156\n",
      "img id out: 5156\n",
      "img id in: 5157\n",
      "img id out: 5157\n",
      "img id in: 5158\n",
      "img id out: 5158\n",
      "img id in: 5159\n",
      "img id out: 5159\n",
      "img id in: 5160\n",
      "img id out: 5160\n",
      "img id in: 5161\n",
      "img id out: 5161\n",
      "img id in: 5162\n",
      "img id out: 5162\n",
      "img id in: 5163\n",
      "img id out: 5163\n",
      "img id in: 5164\n",
      "img id out: 5164\n",
      "img id in: 5165\n",
      "img id out: 5165\n",
      "img id in: 5166\n",
      "img id out: 5166\n",
      "img id in: 5167\n",
      "img id out: 5167\n",
      "img id in: 5168\n",
      "img id out: 5168\n",
      "img id in: 5169\n",
      "img id out: 5169\n",
      "img id in: 5170\n",
      "img id out: 5170\n",
      "img id in: 5171\n",
      "img id out: 5171\n",
      "img id in: 5172\n",
      "img id out: 5172\n",
      "img id in: 5173\n",
      "img id out: 5173\n",
      "img id in: 5174\n",
      "img id out: 5174\n",
      "img id in: 5175\n",
      "img id out: 5175\n",
      "img id in: 5176\n",
      "img id out: 5176\n",
      "img id in: 5177\n",
      "img id out: 5177\n",
      "img id in: 5178\n",
      "img id out: 5178\n",
      "img id in: 5179\n",
      "img id out: 5179\n",
      "img id in: 5180\n",
      "img id out: 5180\n",
      "img id in: 5181\n",
      "img id out: 5181\n",
      "img id in: 5182\n",
      "img id out: 5182\n",
      "img id in: 5183\n",
      "img id out: 5183\n",
      "img id in: 5184\n",
      "img id out: 5184\n",
      "img id in: 5185\n",
      "img id out: 5185\n",
      "img id in: 5186\n",
      "img id out: 5186\n",
      "img id in: 5187\n",
      "img id out: 5187\n",
      "img id in: 5188\n",
      "img id out: 5188\n",
      "img id in: 5189\n",
      "img id out: 5189\n",
      "img id in: 5190\n",
      "img id out: 5190\n",
      "img id in: 5191\n",
      "img id out: 5191\n",
      "img id in: 5192\n",
      "img id out: 5192\n",
      "img id in: 5193\n",
      "img id out: 5193\n",
      "img id in: 5194\n",
      "img id out: 5194\n",
      "img id in: 5195\n",
      "img id out: 5195\n",
      "img id in: 5196\n",
      "img id out: 5196\n",
      "img id in: 5197\n",
      "img id out: 5197\n",
      "img id in: 5198\n",
      "img id out: 5198\n",
      "img id in: 5199\n",
      "img id out: 5199\n",
      "img id in: 5200\n",
      "img id out: 5200\n",
      "img id in: 5201\n",
      "img id out: 5201\n",
      "img id in: 5202\n",
      "img id out: 5202\n",
      "img id in: 5203\n",
      "img id out: 5203\n",
      "img id in: 5204\n",
      "img id out: 5204\n",
      "img id in: 5205\n",
      "img id out: 5205\n",
      "img id in: 5206\n",
      "img id out: 5206\n",
      "img id in: 5207\n",
      "img id out: 5207\n",
      "img id in: 5208\n",
      "img id out: 5208\n",
      "img id in: 5209\n",
      "img id out: 5209\n",
      "img id in: 5210\n",
      "img id out: 5210\n",
      "img id in: 5211\n",
      "img id out: 5211\n",
      "img id in: 5212\n",
      "img id out: 5212\n",
      "img id in: 5213\n",
      "img id out: 5213\n",
      "img id in: 5214\n",
      "img id out: 5214\n",
      "img id in: 5215\n",
      "img id out: 5215\n",
      "img id in: 5216\n",
      "img id out: 5216\n",
      "img id in: 5217\n",
      "img id out: 5217\n",
      "img id in: 5218\n",
      "img id out: 5218\n",
      "img id in: 5219\n",
      "img id out: 5219\n",
      "img id in: 5220\n",
      "img id out: 5220\n",
      "img id in: 5221\n",
      "img id out: 5221\n",
      "img id in: 5222\n",
      "img id out: 5222\n",
      "img id in: 5223\n",
      "img id out: 5223\n",
      "img id in: 5224\n",
      "img id out: 5224\n",
      "img id in: 5225\n",
      "img id out: 5225\n",
      "img id in: 5226\n",
      "img id out: 5226\n",
      "img id in: 5227\n",
      "img id out: 5227\n",
      "img id in: 5228\n",
      "img id out: 5228\n",
      "img id in: 5229\n",
      "img id out: 5229\n",
      "img id in: 5230\n",
      "img id out: 5230\n",
      "img id in: 5231\n",
      "img id out: 5231\n",
      "img id in: 5232\n",
      "img id out: 5232\n",
      "img id in: 5233\n",
      "img id out: 5233\n",
      "img id in: 5234\n",
      "img id out: 5234\n",
      "img id in: 5235\n",
      "img id out: 5235\n",
      "img id in: 5236\n",
      "img id out: 5236\n",
      "img id in: 5237\n",
      "img id out: 5237\n",
      "img id in: 5238\n",
      "img id out: 5238\n",
      "img id in: 5239\n",
      "img id out: 5239\n",
      "img id in: 5240\n",
      "img id out: 5240\n",
      "img id in: 5241\n",
      "img id out: 5241\n",
      "img id in: 5242\n",
      "img id out: 5242\n",
      "img id in: 5243\n",
      "img id out: 5243\n",
      "img id in: 5244\n",
      "img id out: 5244\n",
      "img id in: 5245\n",
      "img id out: 5245\n",
      "img id in: 5246\n",
      "img id out: 5246\n",
      "img id in: 5247\n",
      "img id out: 5247\n",
      "img id in: 5248\n",
      "img id out: 5248\n",
      "img id in: 5249\n",
      "img id out: 5249\n",
      "img id in: 5250\n",
      "img id out: 5250\n",
      "img id in: 5251\n",
      "img id out: 5251\n",
      "img id in: 5252\n",
      "img id out: 5252\n",
      "img id in: 5253\n",
      "img id out: 5253\n",
      "img id in: 5254\n",
      "img id out: 5254\n",
      "img id in: 5255\n",
      "img id out: 5255\n",
      "img id in: 5256\n",
      "img id out: 5256\n",
      "img id in: 5257\n",
      "img id out: 5257\n",
      "img id in: 5258\n",
      "img id out: 5258\n",
      "img id in: 5259\n",
      "img id out: 5259\n",
      "img id in: 5260\n",
      "img id out: 5260\n",
      "img id in: 5261\n",
      "img id out: 5261\n",
      "img id in: 5262\n",
      "img id out: 5262\n",
      "img id in: 5263\n",
      "img id out: 5263\n",
      "img id in: 5264\n",
      "img id out: 5264\n",
      "img id in: 5265\n",
      "img id out: 5265\n",
      "img id in: 5266\n",
      "img id out: 5266\n",
      "img id in: 5267\n",
      "img id out: 5267\n",
      "img id in: 5268\n",
      "img id out: 5268\n",
      "img id in: 5269\n",
      "img id out: 5269\n",
      "img id in: 5270\n",
      "img id out: 5270\n",
      "img id in: 5271\n",
      "img id out: 5271\n",
      "img id in: 5272\n",
      "img id out: 5272\n",
      "img id in: 5273\n",
      "img id out: 5273\n",
      "img id in: 5274\n",
      "img id out: 5274\n",
      "img id in: 5275\n",
      "img id out: 5275\n",
      "img id in: 5276\n",
      "img id out: 5276\n",
      "img id in: 5277\n",
      "img id out: 5277\n",
      "img id in: 5278\n",
      "img id out: 5278\n",
      "img id in: 5279\n",
      "img id out: 5279\n",
      "img id in: 5280\n",
      "img id out: 5280\n",
      "img id in: 5281\n",
      "img id out: 5281\n",
      "img id in: 5282\n",
      "img id out: 5282\n",
      "img id in: 5283\n",
      "img id out: 5283\n",
      "img id in: 5284\n",
      "img id out: 5284\n",
      "img id in: 5285\n",
      "img id out: 5285\n",
      "img id in: 5286\n",
      "img id out: 5286\n",
      "img id in: 5287\n",
      "img id out: 5287\n",
      "img id in: 5288\n",
      "img id out: 5288\n",
      "img id in: 5289\n",
      "img id out: 5289\n",
      "img id in: 5290\n",
      "img id out: 5290\n",
      "img id in: 5291\n",
      "img id out: 5291\n",
      "img id in: 5292\n",
      "img id out: 5292\n",
      "img id in: 5293\n",
      "img id out: 5293\n",
      "img id in: 5294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 5294\n",
      "img id in: 5295\n",
      "img id out: 5295\n",
      "img id in: 5296\n",
      "img id out: 5296\n",
      "img id in: 5297\n",
      "img id out: 5297\n",
      "img id in: 5298\n",
      "img id out: 5298\n",
      "img id in: 5299\n",
      "img id out: 5299\n",
      "img id in: 5300\n",
      "img id out: 5300\n",
      "img id in: 5301\n",
      "img id out: 5301\n",
      "img id in: 5302\n",
      "img id out: 5302\n",
      "img id in: 5303\n",
      "img id out: 5303\n",
      "img id in: 5304\n",
      "img id out: 5304\n",
      "img id in: 5305\n",
      "img id out: 5305\n",
      "img id in: 5306\n",
      "img id out: 5306\n",
      "img id in: 5307\n",
      "img id out: 5307\n",
      "img id in: 5308\n",
      "img id out: 5308\n",
      "img id in: 5309\n",
      "img id out: 5309\n",
      "img id in: 5310\n",
      "img id out: 5310\n",
      "img id in: 5311\n",
      "img id out: 5311\n",
      "img id in: 5312\n",
      "img id out: 5312\n",
      "img id in: 5313\n",
      "img id out: 5313\n",
      "img id in: 5314\n",
      "img id out: 5314\n",
      "img id in: 5315\n",
      "img id out: 5315\n",
      "img id in: 5316\n",
      "img id out: 5316\n",
      "img id in: 5317\n",
      "img id out: 5317\n",
      "img id in: 5318\n",
      "img id out: 5318\n",
      "img id in: 5319\n",
      "img id out: 5319\n",
      "img id in: 5320\n",
      "img id out: 5320\n",
      "img id in: 5321\n",
      "img id out: 5321\n",
      "img id in: 5322\n",
      "img id out: 5322\n",
      "img id in: 5323\n",
      "img id out: 5323\n",
      "img id in: 5324\n",
      "img id out: 5324\n",
      "img id in: 5325\n",
      "img id out: 5325\n",
      "img id in: 5326\n",
      "img id out: 5326\n",
      "img id in: 5327\n",
      "img id out: 5327\n",
      "img id in: 5328\n",
      "img id out: 5328\n",
      "img id in: 5329\n",
      "img id out: 5329\n",
      "img id in: 5330\n",
      "img id out: 5330\n",
      "img id in: 5331\n",
      "img id out: 5331\n",
      "img id in: 5332\n",
      "img id out: 5332\n",
      "img id in: 5333\n",
      "img id out: 5333\n",
      "img id in: 5334\n",
      "img id out: 5334\n",
      "img id in: 5335\n",
      "img id out: 5335\n",
      "img id in: 5336\n",
      "img id out: 5336\n",
      "img id in: 5337\n",
      "img id out: 5337\n",
      "img id in: 5338\n",
      "img id out: 5338\n",
      "img id in: 5339\n",
      "img id out: 5339\n",
      "img id in: 5340\n",
      "img id out: 5340\n",
      "img id in: 5341\n",
      "img id out: 5341\n",
      "img id in: 5342\n",
      "img id out: 5342\n",
      "img id in: 5343\n",
      "img id out: 5343\n",
      "img id in: 5344\n",
      "img id out: 5344\n",
      "img id in: 5345\n",
      "img id out: 5345\n",
      "img id in: 5346\n",
      "img id out: 5346\n",
      "img id in: 5347\n",
      "img id out: 5347\n",
      "img id in: 5348\n",
      "img id out: 5348\n",
      "img id in: 5349\n",
      "img id out: 5349\n",
      "img id in: 5350\n",
      "img id out: 5350\n",
      "img id in: 5351\n",
      "img id out: 5351\n",
      "img id in: 5352\n",
      "img id out: 5352\n",
      "img id in: 5353\n",
      "img id out: 5353\n",
      "img id in: 5354\n",
      "img id out: 5354\n",
      "img id in: 5355\n",
      "img id out: 5355\n",
      "img id in: 5356\n",
      "img id out: 5356\n",
      "img id in: 5357\n",
      "img id out: 5357\n",
      "img id in: 5358\n",
      "img id out: 5358\n",
      "img id in: 5359\n",
      "img id out: 5359\n",
      "img id in: 5360\n",
      "img id out: 5360\n",
      "img id in: 5361\n",
      "img id out: 5361\n",
      "img id in: 5362\n",
      "img id out: 5362\n",
      "img id in: 5363\n",
      "img id out: 5363\n",
      "img id in: 5364\n",
      "img id out: 5364\n",
      "img id in: 5365\n",
      "img id out: 5365\n",
      "img id in: 5366\n",
      "img id out: 5366\n",
      "img id in: 5367\n",
      "img id out: 5367\n",
      "img id in: 5368\n",
      "img id out: 5368\n",
      "img id in: 5369\n",
      "img id out: 5369\n",
      "img id in: 5370\n",
      "img id out: 5370\n",
      "img id in: 5371\n",
      "img id out: 5371\n",
      "img id in: 5372\n",
      "img id out: 5372\n",
      "img id in: 5373\n",
      "img id out: 5373\n",
      "img id in: 5374\n",
      "img id out: 5374\n",
      "img id in: 5375\n",
      "img id out: 5375\n",
      "img id in: 5376\n",
      "img id out: 5376\n",
      "img id in: 5377\n",
      "img id out: 5377\n",
      "img id in: 5378\n",
      "img id out: 5378\n",
      "img id in: 5379\n",
      "img id out: 5379\n",
      "img id in: 5380\n",
      "img id out: 5380\n",
      "img id in: 5381\n",
      "img id out: 5381\n",
      "img id in: 5382\n",
      "img id out: 5382\n",
      "img id in: 5383\n",
      "img id out: 5383\n",
      "img id in: 5384\n",
      "img id out: 5384\n",
      "img id in: 5385\n",
      "img id out: 5385\n",
      "img id in: 5386\n",
      "img id out: 5386\n",
      "img id in: 5387\n",
      "img id out: 5387\n",
      "img id in: 5388\n",
      "img id out: 5388\n",
      "img id in: 5389\n",
      "img id out: 5389\n",
      "img id in: 5390\n",
      "img id out: 5390\n",
      "img id in: 5391\n",
      "img id out: 5391\n",
      "img id in: 5392\n",
      "img id out: 5392\n",
      "img id in: 5393\n",
      "img id out: 5393\n",
      "img id in: 5394\n",
      "img id out: 5394\n",
      "img id in: 5395\n",
      "img id out: 5395\n",
      "img id in: 5396\n",
      "img id out: 5396\n",
      "img id in: 5397\n",
      "img id out: 5397\n",
      "img id in: 5398\n",
      "img id out: 5398\n",
      "img id in: 5399\n",
      "img id out: 5399\n",
      "img id in: 5400\n",
      "img id out: 5400\n",
      "img id in: 5401\n",
      "img id out: 5401\n",
      "img id in: 5402\n",
      "img id out: 5402\n",
      "img id in: 5403\n",
      "img id out: 5403\n",
      "img id in: 5404\n",
      "img id out: 5404\n",
      "img id in: 5405\n",
      "img id out: 5405\n",
      "img id in: 5406\n",
      "img id out: 5406\n",
      "img id in: 5407\n",
      "img id out: 5407\n",
      "img id in: 5408\n",
      "img id out: 5408\n",
      "img id in: 5409\n",
      "img id out: 5409\n",
      "img id in: 5410\n",
      "img id out: 5410\n",
      "img id in: 5411\n",
      "img id out: 5411\n",
      "img id in: 5412\n",
      "img id out: 5412\n",
      "img id in: 5413\n",
      "img id out: 5413\n",
      "img id in: 5414\n",
      "img id out: 5414\n",
      "img id in: 5415\n",
      "img id out: 5415\n",
      "img id in: 5416\n",
      "img id out: 5416\n",
      "img id in: 5417\n",
      "img id out: 5417\n",
      "img id in: 5418\n",
      "img id out: 5418\n",
      "img id in: 5419\n",
      "img id out: 5419\n",
      "img id in: 5420\n",
      "img id out: 5420\n",
      "img id in: 5421\n",
      "img id out: 5421\n",
      "img id in: 5422\n",
      "img id out: 5422\n",
      "img id in: 5423\n",
      "img id out: 5423\n",
      "img id in: 5424\n",
      "img id out: 5424\n",
      "img id in: 5425\n",
      "img id out: 5425\n",
      "img id in: 5426\n",
      "img id out: 5426\n",
      "img id in: 5427\n",
      "img id out: 5427\n",
      "img id in: 5428\n",
      "img id out: 5428\n",
      "img id in: 5429\n",
      "img id out: 5429\n",
      "img id in: 5430\n",
      "img id out: 5430\n",
      "img id in: 5431\n",
      "img id out: 5431\n",
      "img id in: 5432\n",
      "img id out: 5432\n",
      "img id in: 5433\n",
      "img id out: 5433\n",
      "img id in: 5434\n",
      "img id out: 5434\n",
      "img id in: 5435\n",
      "img id out: 5435\n",
      "img id in: 5436\n",
      "img id out: 5436\n",
      "img id in: 5437\n",
      "img id out: 5437\n",
      "img id in: 5438\n",
      "img id out: 5438\n",
      "img id in: 5439\n",
      "img id out: 5439\n",
      "img id in: 5440\n",
      "img id out: 5440\n",
      "img id in: 5441\n",
      "img id out: 5441\n",
      "img id in: 5442\n",
      "img id out: 5442\n",
      "img id in: 5443\n",
      "img id out: 5443\n",
      "img id in: 5444\n",
      "img id out: 5444\n",
      "img id in: 5445\n",
      "img id out: 5445\n",
      "img id in: 5446\n",
      "img id out: 5446\n",
      "img id in: 5447\n",
      "img id out: 5447\n",
      "img id in: 5448\n",
      "img id out: 5448\n",
      "img id in: 5449\n",
      "img id out: 5449\n",
      "img id in: 5450\n",
      "img id out: 5450\n",
      "img id in: 5451\n",
      "img id out: 5451\n",
      "img id in: 5452\n",
      "img id out: 5452\n",
      "img id in: 5453\n",
      "img id out: 5453\n",
      "img id in: 5454\n",
      "img id out: 5454\n",
      "img id in: 5455\n",
      "img id out: 5455\n",
      "img id in: 5456\n",
      "img id out: 5456\n",
      "img id in: 5457\n",
      "img id out: 5457\n",
      "img id in: 5458\n",
      "img id out: 5458\n",
      "img id in: 5459\n",
      "img id out: 5459\n",
      "img id in: 5460\n",
      "img id out: 5460\n",
      "img id in: 5461\n",
      "img id out: 5461\n",
      "img id in: 5462\n",
      "img id out: 5462\n",
      "img id in: 5463\n",
      "img id out: 5463\n",
      "img id in: 5464\n",
      "img id out: 5464\n",
      "img id in: 5465\n",
      "img id out: 5465\n",
      "img id in: 5466\n",
      "img id out: 5466\n",
      "img id in: 5467\n",
      "img id out: 5467\n",
      "img id in: 5468\n",
      "img id out: 5468\n",
      "img id in: 5469\n",
      "img id out: 5469\n",
      "img id in: 5470\n",
      "img id out: 5470\n",
      "img id in: 5471\n",
      "img id out: 5471\n",
      "img id in: 5472\n",
      "img id out: 5472\n",
      "img id in: 5473\n",
      "img id out: 5473\n",
      "img id in: 5474\n",
      "img id out: 5474\n",
      "img id in: 5475\n",
      "img id out: 5475\n",
      "img id in: 5476\n",
      "img id out: 5476\n",
      "img id in: 5477\n",
      "img id out: 5477\n",
      "img id in: 5478\n",
      "img id out: 5478\n",
      "img id in: 5479\n",
      "img id out: 5479\n",
      "img id in: 5480\n",
      "img id out: 5480\n",
      "img id in: 5481\n",
      "img id out: 5481\n",
      "img id in: 5482\n",
      "img id out: 5482\n",
      "img id in: 5483\n",
      "img id out: 5483\n",
      "img id in: 5484\n",
      "img id out: 5484\n",
      "img id in: 5485\n",
      "img id out: 5485\n",
      "img id in: 5486\n",
      "img id out: 5486\n",
      "img id in: 5487\n",
      "img id out: 5487\n",
      "img id in: 5488\n",
      "img id out: 5488\n",
      "img id in: 5489\n",
      "img id out: 5489\n",
      "img id in: 5490\n",
      "img id out: 5490\n",
      "img id in: 5491\n",
      "img id out: 5491\n",
      "img id in: 5492\n",
      "img id out: 5492\n",
      "img id in: 5493\n",
      "img id out: 5493\n",
      "img id in: 5494\n",
      "img id out: 5494\n",
      "img id in: 5495\n",
      "img id out: 5495\n",
      "img id in: 5496\n",
      "img id out: 5496\n",
      "img id in: 5497\n",
      "img id out: 5497\n",
      "img id in: 5498\n",
      "img id out: 5498\n",
      "img id in: 5499\n",
      "img id out: 5499\n",
      "img id in: 5500\n",
      "img id out: 5500\n",
      "img id in: 5501\n",
      "img id out: 5501\n",
      "img id in: 5502\n",
      "img id out: 5502\n",
      "img id in: 5503\n",
      "img id out: 5503\n",
      "img id in: 5504\n",
      "img id out: 5504\n",
      "img id in: 5505\n",
      "img id out: 5505\n",
      "img id in: 5506\n",
      "img id out: 5506\n",
      "img id in: 5507\n",
      "img id out: 5507\n",
      "img id in: 5508\n",
      "img id out: 5508\n",
      "img id in: 5509\n",
      "img id out: 5509\n",
      "img id in: 5510\n",
      "img id out: 5510\n",
      "img id in: 5511\n",
      "img id out: 5511\n",
      "img id in: 5512\n",
      "img id out: 5512\n",
      "img id in: 5513\n",
      "img id out: 5513\n",
      "img id in: 5514\n",
      "img id out: 5514\n",
      "img id in: 5515\n",
      "img id out: 5515\n",
      "img id in: 5516\n",
      "img id out: 5516\n",
      "img id in: 5517\n",
      "img id out: 5517\n",
      "img id in: 5518\n",
      "img id out: 5518\n",
      "img id in: 5519\n",
      "img id out: 5519\n",
      "img id in: 5520\n",
      "img id out: 5520\n",
      "img id in: 5521\n",
      "img id out: 5521\n",
      "img id in: 5522\n",
      "img id out: 5522\n",
      "img id in: 5523\n",
      "img id out: 5523\n",
      "img id in: 5524\n",
      "img id out: 5524\n",
      "img id in: 5525\n",
      "img id out: 5525\n",
      "img id in: 5526\n",
      "img id out: 5526\n",
      "img id in: 5527\n",
      "img id out: 5527\n",
      "img id in: 5528\n",
      "img id out: 5528\n",
      "img id in: 5529\n",
      "img id out: 5529\n",
      "img id in: 5530\n",
      "img id out: 5530\n",
      "img id in: 5531\n",
      "img id out: 5531\n",
      "img id in: 5532\n",
      "img id out: 5532\n",
      "img id in: 5533\n",
      "img id out: 5533\n",
      "img id in: 5534\n",
      "img id out: 5534\n",
      "img id in: 5535\n",
      "img id out: 5535\n",
      "img id in: 5536\n",
      "img id out: 5536\n",
      "img id in: 5537\n",
      "img id out: 5537\n",
      "img id in: 5538\n",
      "img id out: 5538\n",
      "img id in: 5539\n",
      "img id out: 5539\n",
      "img id in: 5540\n",
      "img id out: 5540\n",
      "img id in: 5541\n",
      "img id out: 5541\n",
      "img id in: 5542\n",
      "img id out: 5542\n",
      "img id in: 5543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 5543\n",
      "img id in: 5544\n",
      "img id out: 5544\n",
      "img id in: 5545\n",
      "img id out: 5545\n",
      "img id in: 5546\n",
      "img id out: 5546\n",
      "img id in: 5547\n",
      "img id out: 5547\n",
      "img id in: 5548\n",
      "img id out: 5548\n",
      "img id in: 5549\n",
      "img id out: 5549\n",
      "img id in: 5550\n",
      "img id out: 5550\n",
      "img id in: 5551\n",
      "img id out: 5551\n",
      "img id in: 5552\n",
      "img id out: 5552\n",
      "img id in: 5553\n",
      "img id out: 5553\n",
      "img id in: 5554\n",
      "img id out: 5554\n",
      "img id in: 5555\n",
      "img id out: 5555\n",
      "img id in: 5556\n",
      "img id out: 5556\n",
      "img id in: 5557\n",
      "img id out: 5557\n",
      "img id in: 5558\n",
      "img id out: 5558\n",
      "img id in: 5559\n",
      "img id out: 5559\n",
      "img id in: 5560\n",
      "img id out: 5560\n",
      "img id in: 5561\n",
      "img id out: 5561\n",
      "img id in: 5562\n",
      "img id out: 5562\n",
      "img id in: 5563\n",
      "img id out: 5563\n",
      "img id in: 5564\n",
      "img id out: 5564\n",
      "img id in: 5565\n",
      "img id out: 5565\n",
      "img id in: 5566\n",
      "img id out: 5566\n",
      "img id in: 5567\n",
      "img id out: 5567\n",
      "img id in: 5568\n",
      "img id out: 5568\n",
      "img id in: 5569\n",
      "img id out: 5569\n",
      "img id in: 5570\n",
      "img id out: 5570\n",
      "img id in: 5571\n",
      "img id out: 5571\n",
      "img id in: 5572\n",
      "img id out: 5572\n",
      "img id in: 5573\n",
      "img id out: 5573\n",
      "img id in: 5574\n",
      "img id out: 5574\n",
      "img id in: 5575\n",
      "img id out: 5575\n",
      "img id in: 5576\n",
      "img id out: 5576\n",
      "img id in: 5577\n",
      "img id out: 5577\n",
      "img id in: 5578\n",
      "img id out: 5578\n",
      "img id in: 5579\n",
      "img id out: 5579\n",
      "img id in: 5580\n",
      "img id out: 5580\n",
      "img id in: 5581\n",
      "img id out: 5581\n",
      "img id in: 5582\n",
      "img id out: 5582\n",
      "img id in: 5583\n",
      "img id out: 5583\n",
      "img id in: 5584\n",
      "img id out: 5584\n",
      "img id in: 5585\n",
      "img id out: 5585\n",
      "img id in: 5586\n",
      "img id out: 5586\n",
      "img id in: 5587\n",
      "img id out: 5587\n",
      "img id in: 5588\n",
      "img id out: 5588\n",
      "img id in: 5589\n",
      "img id out: 5589\n",
      "img id in: 5590\n",
      "img id out: 5590\n",
      "img id in: 5591\n",
      "img id out: 5591\n",
      "img id in: 5592\n",
      "img id out: 5592\n",
      "img id in: 5593\n",
      "img id out: 5593\n",
      "img id in: 5594\n",
      "img id out: 5594\n",
      "img id in: 5595\n",
      "img id out: 5595\n",
      "img id in: 5596\n",
      "img id out: 5596\n",
      "img id in: 5597\n",
      "img id out: 5597\n",
      "img id in: 5598\n",
      "img id out: 5598\n",
      "img id in: 5599\n",
      "img id out: 5599\n",
      "img id in: 5600\n",
      "img id out: 5600\n",
      "img id in: 5601\n",
      "img id out: 5601\n",
      "img id in: 5602\n",
      "img id out: 5602\n",
      "img id in: 5603\n",
      "img id out: 5603\n",
      "img id in: 5604\n",
      "img id out: 5604\n",
      "img id in: 5605\n",
      "img id out: 5605\n",
      "img id in: 5606\n",
      "img id out: 5606\n",
      "img id in: 5607\n",
      "img id out: 5607\n",
      "img id in: 5608\n",
      "img id out: 5608\n",
      "img id in: 5609\n",
      "img id out: 5609\n",
      "img id in: 5610\n",
      "img id out: 5610\n",
      "img id in: 5611\n",
      "img id out: 5611\n",
      "img id in: 5612\n",
      "img id out: 5612\n",
      "img id in: 5613\n",
      "img id out: 5613\n",
      "img id in: 5614\n",
      "img id out: 5614\n",
      "img id in: 5615\n",
      "img id out: 5615\n",
      "img id in: 5616\n",
      "img id out: 5616\n",
      "img id in: 5617\n",
      "img id out: 5617\n",
      "img id in: 5618\n",
      "img id out: 5618\n",
      "img id in: 5619\n",
      "img id out: 5619\n",
      "img id in: 5620\n",
      "img id out: 5620\n",
      "img id in: 5621\n",
      "img id out: 5621\n",
      "img id in: 5622\n",
      "img id out: 5622\n",
      "img id in: 5623\n",
      "img id out: 5623\n",
      "img id in: 5624\n",
      "img id out: 5624\n",
      "img id in: 5625\n",
      "img id out: 5625\n",
      "img id in: 5626\n",
      "img id out: 5626\n",
      "img id in: 5627\n",
      "img id out: 5627\n",
      "img id in: 5628\n",
      "img id out: 5628\n",
      "img id in: 5629\n",
      "img id out: 5629\n",
      "img id in: 5630\n",
      "img id out: 5630\n",
      "img id in: 5631\n",
      "img id out: 5631\n",
      "img id in: 5632\n",
      "img id out: 5632\n",
      "img id in: 5633\n",
      "img id out: 5633\n",
      "img id in: 5634\n",
      "img id out: 5634\n",
      "img id in: 5635\n",
      "img id out: 5635\n",
      "img id in: 5636\n",
      "img id out: 5636\n",
      "img id in: 5637\n",
      "img id out: 5637\n",
      "img id in: 5638\n",
      "img id out: 5638\n",
      "img id in: 5639\n",
      "img id out: 5639\n",
      "img id in: 5640\n",
      "img id out: 5640\n",
      "img id in: 5641\n",
      "img id out: 5641\n",
      "img id in: 5642\n",
      "img id out: 5642\n",
      "img id in: 5643\n",
      "img id out: 5643\n",
      "img id in: 5644\n",
      "img id out: 5644\n",
      "img id in: 5645\n",
      "img id out: 5645\n",
      "img id in: 5646\n",
      "img id out: 5646\n",
      "img id in: 5647\n",
      "img id out: 5647\n",
      "img id in: 5648\n",
      "img id out: 5648\n",
      "img id in: 5649\n",
      "img id out: 5649\n",
      "img id in: 5650\n",
      "img id out: 5650\n",
      "img id in: 5651\n",
      "img id out: 5651\n",
      "img id in: 5652\n",
      "img id out: 5652\n",
      "img id in: 5653\n",
      "img id out: 5653\n",
      "img id in: 5654\n",
      "img id out: 5654\n",
      "img id in: 5655\n",
      "img id out: 5655\n",
      "img id in: 5656\n",
      "img id out: 5656\n",
      "img id in: 5657\n",
      "img id out: 5657\n",
      "img id in: 5658\n",
      "img id out: 5658\n",
      "img id in: 5659\n",
      "img id out: 5659\n",
      "img id in: 5660\n",
      "img id out: 5660\n",
      "img id in: 5661\n",
      "img id out: 5661\n",
      "img id in: 5662\n",
      "img id out: 5662\n",
      "img id in: 5663\n",
      "img id out: 5663\n",
      "img id in: 5664\n",
      "img id out: 5664\n",
      "img id in: 5665\n",
      "img id out: 5665\n",
      "img id in: 5666\n",
      "img id out: 5666\n",
      "img id in: 5667\n",
      "img id out: 5667\n",
      "img id in: 5668\n",
      "img id out: 5668\n",
      "img id in: 5669\n",
      "img id out: 5669\n",
      "img id in: 5670\n",
      "img id out: 5670\n",
      "img id in: 5671\n",
      "img id out: 5671\n",
      "img id in: 5672\n",
      "img id out: 5672\n",
      "img id in: 5673\n",
      "img id out: 5673\n",
      "img id in: 5674\n",
      "img id out: 5674\n",
      "img id in: 5675\n",
      "img id out: 5675\n",
      "img id in: 5676\n",
      "img id out: 5676\n",
      "img id in: 5677\n",
      "img id out: 5677\n",
      "img id in: 5678\n",
      "img id out: 5678\n",
      "img id in: 5679\n",
      "img id out: 5679\n",
      "img id in: 5680\n",
      "img id out: 5680\n",
      "img id in: 5681\n",
      "img id out: 5681\n",
      "img id in: 5682\n",
      "img id out: 5682\n",
      "img id in: 5683\n",
      "img id out: 5683\n",
      "img id in: 5684\n",
      "img id out: 5684\n",
      "img id in: 5685\n",
      "img id out: 5685\n",
      "img id in: 5686\n",
      "img id out: 5686\n",
      "img id in: 5687\n",
      "img id out: 5687\n",
      "img id in: 5688\n",
      "img id out: 5688\n",
      "img id in: 5689\n",
      "img id out: 5689\n",
      "img id in: 5690\n",
      "img id out: 5690\n",
      "img id in: 5691\n",
      "img id out: 5691\n",
      "img id in: 5692\n",
      "img id out: 5692\n",
      "img id in: 5693\n",
      "img id out: 5693\n",
      "img id in: 5694\n",
      "img id out: 5694\n",
      "img id in: 5695\n",
      "img id out: 5695\n",
      "img id in: 5696\n",
      "img id out: 5696\n",
      "img id in: 5697\n",
      "img id out: 5697\n",
      "img id in: 5698\n",
      "img id out: 5698\n",
      "img id in: 5699\n",
      "img id out: 5699\n",
      "img id in: 5700\n",
      "img id out: 5700\n",
      "img id in: 5701\n",
      "img id out: 5701\n",
      "img id in: 5702\n",
      "img id out: 5702\n",
      "img id in: 5703\n",
      "img id out: 5703\n",
      "img id in: 5704\n",
      "img id out: 5704\n",
      "img id in: 5705\n",
      "img id out: 5705\n",
      "img id in: 5706\n",
      "img id out: 5706\n",
      "img id in: 5707\n",
      "img id out: 5707\n",
      "img id in: 5708\n",
      "img id out: 5708\n",
      "img id in: 5709\n",
      "img id out: 5709\n",
      "img id in: 5710\n",
      "img id out: 5710\n",
      "img id in: 5711\n",
      "img id out: 5711\n",
      "img id in: 5712\n",
      "img id out: 5712\n",
      "img id in: 5713\n",
      "img id out: 5713\n",
      "img id in: 5714\n",
      "img id out: 5714\n",
      "img id in: 5715\n",
      "img id out: 5715\n",
      "img id in: 5716\n",
      "img id out: 5716\n",
      "img id in: 5717\n",
      "img id out: 5717\n",
      "img id in: 5718\n",
      "img id out: 5718\n",
      "img id in: 5719\n",
      "img id out: 5719\n",
      "img id in: 5720\n",
      "img id out: 5720\n",
      "img id in: 5721\n",
      "img id out: 5721\n",
      "img id in: 5722\n",
      "img id out: 5722\n",
      "img id in: 5723\n",
      "img id out: 5723\n",
      "img id in: 5724\n",
      "img id out: 5724\n",
      "img id in: 5725\n",
      "img id out: 5725\n",
      "img id in: 5726\n",
      "img id out: 5726\n",
      "img id in: 5727\n",
      "img id out: 5727\n",
      "img id in: 5728\n",
      "img id out: 5728\n",
      "img id in: 5729\n",
      "img id out: 5729\n",
      "img id in: 5730\n",
      "img id out: 5730\n",
      "img id in: 5731\n",
      "img id out: 5731\n",
      "img id in: 5732\n",
      "img id out: 5732\n",
      "img id in: 5733\n",
      "img id out: 5733\n",
      "img id in: 5734\n",
      "img id out: 5734\n",
      "img id in: 5735\n",
      "img id out: 5735\n",
      "img id in: 5736\n",
      "img id out: 5736\n",
      "img id in: 5737\n",
      "img id out: 5737\n",
      "img id in: 5738\n",
      "img id out: 5738\n",
      "img id in: 5739\n",
      "img id out: 5739\n",
      "img id in: 5740\n",
      "img id out: 5740\n",
      "img id in: 5741\n",
      "img id out: 5741\n",
      "img id in: 5742\n",
      "img id out: 5742\n",
      "img id in: 5743\n",
      "img id out: 5743\n",
      "img id in: 5744\n",
      "img id out: 5744\n",
      "img id in: 5745\n",
      "img id out: 5745\n",
      "img id in: 5746\n",
      "img id out: 5746\n",
      "img id in: 5747\n",
      "img id out: 5747\n",
      "img id in: 5748\n",
      "img id out: 5748\n",
      "img id in: 5749\n",
      "img id out: 5749\n",
      "img id in: 5750\n",
      "img id out: 5750\n",
      "img id in: 5751\n",
      "img id out: 5751\n",
      "img id in: 5752\n",
      "img id out: 5752\n",
      "img id in: 5753\n",
      "img id out: 5753\n",
      "img id in: 5754\n",
      "img id out: 5754\n",
      "img id in: 5755\n",
      "img id out: 5755\n",
      "img id in: 5756\n",
      "img id out: 5756\n",
      "img id in: 5757\n",
      "img id out: 5757\n",
      "img id in: 5758\n",
      "img id out: 5758\n",
      "img id in: 5759\n",
      "img id out: 5759\n",
      "img id in: 5760\n",
      "img id out: 5760\n",
      "img id in: 5761\n",
      "img id out: 5761\n",
      "img id in: 5762\n",
      "img id out: 5762\n",
      "img id in: 5763\n",
      "img id out: 5763\n",
      "img id in: 5764\n",
      "img id out: 5764\n",
      "img id in: 5765\n",
      "img id out: 5765\n",
      "img id in: 5766\n",
      "img id out: 5766\n",
      "img id in: 5767\n",
      "img id out: 5767\n",
      "img id in: 5768\n",
      "img id out: 5768\n",
      "img id in: 5769\n",
      "img id out: 5769\n",
      "img id in: 5770\n",
      "img id out: 5770\n",
      "img id in: 5771\n",
      "img id out: 5771\n",
      "img id in: 5772\n",
      "img id out: 5772\n",
      "img id in: 5773\n",
      "img id out: 5773\n",
      "img id in: 5774\n",
      "img id out: 5774\n",
      "img id in: 5775\n",
      "img id out: 5775\n",
      "img id in: 5776\n",
      "img id out: 5776\n",
      "img id in: 5777\n",
      "img id out: 5777\n",
      "img id in: 5778\n",
      "img id out: 5778\n",
      "img id in: 5779\n",
      "img id out: 5779\n",
      "img id in: 5780\n",
      "img id out: 5780\n",
      "img id in: 5781\n",
      "img id out: 5781\n",
      "img id in: 5782\n",
      "img id out: 5782\n",
      "img id in: 5783\n",
      "img id out: 5783\n",
      "img id in: 5784\n",
      "img id out: 5784\n",
      "img id in: 5785\n",
      "img id out: 5785\n",
      "img id in: 5786\n",
      "img id out: 5786\n",
      "img id in: 5787\n",
      "img id out: 5787\n",
      "img id in: 5788\n",
      "img id out: 5788\n",
      "img id in: 5789\n",
      "img id out: 5789\n",
      "img id in: 5790\n",
      "img id out: 5790\n",
      "img id in: 5791\n",
      "img id out: 5791\n",
      "img id in: 5792\n",
      "img id out: 5792\n",
      "img id in: 5793\n",
      "img id out: 5793\n",
      "img id in: 5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 5794\n",
      "img id in: 5795\n",
      "img id out: 5795\n",
      "img id in: 5796\n",
      "img id out: 5796\n",
      "img id in: 5797\n",
      "img id out: 5797\n",
      "img id in: 5798\n",
      "img id out: 5798\n",
      "img id in: 5799\n",
      "img id out: 5799\n",
      "img id in: 5800\n",
      "img id out: 5800\n",
      "img id in: 5801\n",
      "img id out: 5801\n",
      "img id in: 5802\n",
      "img id out: 5802\n",
      "img id in: 5803\n",
      "img id out: 5803\n",
      "img id in: 5804\n",
      "img id out: 5804\n",
      "img id in: 5805\n",
      "img id out: 5805\n",
      "img id in: 5806\n",
      "img id out: 5806\n",
      "img id in: 5807\n",
      "img id out: 5807\n",
      "img id in: 5808\n",
      "img id out: 5808\n",
      "img id in: 5809\n",
      "img id out: 5809\n",
      "img id in: 5810\n",
      "img id out: 5810\n",
      "img id in: 5811\n",
      "img id out: 5811\n",
      "img id in: 5812\n",
      "img id out: 5812\n",
      "img id in: 5813\n",
      "img id out: 5813\n",
      "img id in: 5814\n",
      "img id out: 5814\n",
      "img id in: 5815\n",
      "img id out: 5815\n",
      "img id in: 5816\n",
      "img id out: 5816\n",
      "img id in: 5817\n",
      "img id out: 5817\n",
      "img id in: 5818\n",
      "img id out: 5818\n",
      "img id in: 5819\n",
      "img id out: 5819\n",
      "img id in: 5820\n",
      "img id out: 5820\n",
      "img id in: 5821\n",
      "img id out: 5821\n",
      "img id in: 5822\n",
      "img id out: 5822\n",
      "img id in: 5823\n",
      "img id out: 5823\n",
      "img id in: 5824\n",
      "img id out: 5824\n",
      "img id in: 5825\n",
      "img id out: 5825\n",
      "img id in: 5826\n",
      "img id out: 5826\n",
      "img id in: 5827\n",
      "img id out: 5827\n",
      "img id in: 5828\n",
      "img id out: 5828\n",
      "img id in: 5829\n",
      "img id out: 5829\n",
      "img id in: 5830\n",
      "img id out: 5830\n",
      "img id in: 5831\n",
      "img id out: 5831\n",
      "img id in: 5832\n",
      "img id out: 5832\n",
      "img id in: 5833\n",
      "img id out: 5833\n",
      "img id in: 5834\n",
      "img id out: 5834\n",
      "img id in: 5835\n",
      "img id out: 5835\n",
      "img id in: 5836\n",
      "img id out: 5836\n",
      "img id in: 5837\n",
      "img id out: 5837\n",
      "img id in: 5838\n",
      "img id out: 5838\n",
      "img id in: 5839\n",
      "img id out: 5839\n",
      "img id in: 5840\n",
      "img id out: 5840\n",
      "img id in: 5841\n",
      "img id out: 5841\n",
      "img id in: 5842\n",
      "img id out: 5842\n",
      "img id in: 5843\n",
      "img id out: 5843\n",
      "img id in: 5844\n",
      "img id out: 5844\n",
      "img id in: 5845\n",
      "img id out: 5845\n",
      "img id in: 5846\n",
      "img id out: 5846\n",
      "img id in: 5847\n",
      "img id out: 5847\n",
      "img id in: 5848\n",
      "img id out: 5848\n",
      "img id in: 5849\n",
      "img id out: 5849\n",
      "img id in: 5850\n",
      "img id out: 5850\n",
      "img id in: 5851\n",
      "img id out: 5851\n",
      "img id in: 5852\n",
      "img id out: 5852\n",
      "img id in: 5853\n",
      "img id out: 5853\n",
      "img id in: 5854\n",
      "img id out: 5854\n",
      "img id in: 5855\n",
      "img id out: 5855\n",
      "img id in: 5856\n",
      "img id out: 5856\n",
      "img id in: 5857\n",
      "img id out: 5857\n",
      "img id in: 5858\n",
      "img id out: 5858\n",
      "img id in: 5859\n",
      "img id out: 5859\n",
      "img id in: 5860\n",
      "img id out: 5860\n",
      "img id in: 5861\n",
      "img id out: 5861\n",
      "img id in: 5862\n",
      "img id out: 5862\n",
      "img id in: 5863\n",
      "img id out: 5863\n",
      "img id in: 5864\n",
      "img id out: 5864\n",
      "img id in: 5865\n",
      "img id out: 5865\n",
      "img id in: 5866\n",
      "img id out: 5866\n",
      "img id in: 5867\n",
      "img id out: 5867\n",
      "img id in: 5868\n",
      "img id out: 5868\n",
      "img id in: 5869\n",
      "img id out: 5869\n",
      "img id in: 5870\n",
      "img id out: 5870\n",
      "img id in: 5871\n",
      "img id out: 5871\n",
      "img id in: 5872\n",
      "img id out: 5872\n",
      "img id in: 5873\n",
      "img id out: 5873\n",
      "img id in: 5874\n",
      "img id out: 5874\n",
      "img id in: 5875\n",
      "img id out: 5875\n",
      "img id in: 5876\n",
      "img id out: 5876\n",
      "img id in: 5877\n",
      "img id out: 5877\n",
      "img id in: 5878\n",
      "img id out: 5878\n",
      "img id in: 5879\n",
      "img id out: 5879\n",
      "img id in: 5880\n",
      "img id out: 5880\n",
      "img id in: 5881\n",
      "img id out: 5881\n",
      "img id in: 5882\n",
      "img id out: 5882\n",
      "img id in: 5883\n",
      "img id out: 5883\n",
      "img id in: 5884\n",
      "img id out: 5884\n",
      "img id in: 5885\n",
      "img id out: 5885\n",
      "img id in: 5886\n",
      "img id out: 5886\n",
      "img id in: 5887\n",
      "img id out: 5887\n",
      "img id in: 5888\n",
      "img id out: 5888\n",
      "img id in: 5889\n",
      "img id out: 5889\n",
      "img id in: 5890\n",
      "img id out: 5890\n",
      "img id in: 5891\n",
      "img id out: 5891\n",
      "img id in: 5892\n",
      "img id out: 5892\n",
      "img id in: 5893\n",
      "img id out: 5893\n",
      "img id in: 5894\n",
      "img id out: 5894\n",
      "img id in: 5895\n",
      "img id out: 5895\n",
      "img id in: 5896\n",
      "img id out: 5896\n",
      "img id in: 5897\n",
      "img id out: 5897\n",
      "img id in: 5898\n",
      "img id out: 5898\n",
      "img id in: 5899\n",
      "img id out: 5899\n",
      "img id in: 5900\n",
      "img id out: 5900\n",
      "img id in: 5901\n",
      "img id out: 5901\n",
      "img id in: 5902\n",
      "img id out: 5902\n",
      "img id in: 5903\n",
      "img id out: 5903\n",
      "img id in: 5904\n",
      "img id out: 5904\n",
      "img id in: 5905\n",
      "img id out: 5905\n",
      "img id in: 5906\n",
      "img id out: 5906\n",
      "img id in: 5907\n",
      "img id out: 5907\n",
      "img id in: 5908\n",
      "img id out: 5908\n",
      "img id in: 5909\n",
      "img id out: 5909\n",
      "img id in: 5910\n",
      "img id out: 5910\n",
      "img id in: 5911\n",
      "img id out: 5911\n",
      "img id in: 5912\n",
      "img id out: 5912\n",
      "img id in: 5913\n",
      "img id out: 5913\n",
      "img id in: 5914\n",
      "img id out: 5914\n",
      "img id in: 5915\n",
      "img id out: 5915\n",
      "img id in: 5916\n",
      "img id out: 5916\n",
      "img id in: 5917\n",
      "img id out: 5917\n",
      "img id in: 5918\n",
      "img id out: 5918\n",
      "img id in: 5919\n",
      "img id out: 5919\n",
      "img id in: 5920\n",
      "img id out: 5920\n",
      "img id in: 5921\n",
      "img id out: 5921\n",
      "img id in: 5922\n",
      "img id out: 5922\n",
      "img id in: 5923\n",
      "img id out: 5923\n",
      "img id in: 5924\n",
      "img id out: 5924\n",
      "img id in: 5925\n",
      "img id out: 5925\n",
      "img id in: 5926\n",
      "img id out: 5926\n",
      "img id in: 5927\n",
      "img id out: 5927\n",
      "img id in: 5928\n",
      "img id out: 5928\n",
      "img id in: 5929\n",
      "img id out: 5929\n",
      "img id in: 5930\n",
      "img id out: 5930\n",
      "img id in: 5931\n",
      "img id out: 5931\n",
      "img id in: 5932\n",
      "img id out: 5932\n",
      "img id in: 5933\n",
      "img id out: 5933\n",
      "img id in: 5934\n",
      "img id out: 5934\n",
      "img id in: 5935\n",
      "img id out: 5935\n",
      "img id in: 5936\n",
      "img id out: 5936\n",
      "img id in: 5937\n",
      "img id out: 5937\n",
      "img id in: 5938\n",
      "img id out: 5938\n",
      "img id in: 5939\n",
      "img id out: 5939\n",
      "img id in: 5940\n",
      "img id out: 5940\n",
      "img id in: 5941\n",
      "img id out: 5941\n",
      "img id in: 5942\n",
      "img id out: 5942\n",
      "img id in: 5943\n",
      "img id out: 5943\n",
      "img id in: 5944\n",
      "img id out: 5944\n",
      "img id in: 5945\n",
      "img id out: 5945\n",
      "img id in: 5946\n",
      "img id out: 5946\n",
      "img id in: 5947\n",
      "img id out: 5947\n",
      "img id in: 5948\n",
      "img id out: 5948\n",
      "img id in: 5949\n",
      "img id out: 5949\n",
      "img id in: 5950\n",
      "img id out: 5950\n",
      "img id in: 5951\n",
      "img id out: 5951\n",
      "img id in: 5952\n",
      "img id out: 5952\n",
      "img id in: 5953\n",
      "img id out: 5953\n",
      "img id in: 5954\n",
      "img id out: 5954\n",
      "img id in: 5955\n",
      "img id out: 5955\n",
      "img id in: 5956\n",
      "img id out: 5956\n",
      "img id in: 5957\n",
      "img id out: 5957\n",
      "img id in: 5958\n",
      "img id out: 5958\n",
      "img id in: 5959\n",
      "img id out: 5959\n",
      "img id in: 5960\n",
      "img id out: 5960\n",
      "img id in: 5961\n",
      "img id out: 5961\n",
      "img id in: 5962\n",
      "img id out: 5962\n",
      "img id in: 5963\n",
      "img id out: 5963\n",
      "img id in: 5964\n",
      "img id out: 5964\n",
      "img id in: 5965\n",
      "img id out: 5965\n",
      "img id in: 5966\n",
      "img id out: 5966\n",
      "img id in: 5967\n",
      "img id out: 5967\n",
      "img id in: 5968\n",
      "img id out: 5968\n",
      "img id in: 5969\n",
      "img id out: 5969\n",
      "img id in: 5970\n",
      "img id out: 5970\n",
      "img id in: 5971\n",
      "img id out: 5971\n",
      "img id in: 5972\n",
      "img id out: 5972\n",
      "img id in: 5973\n",
      "img id out: 5973\n",
      "img id in: 5974\n",
      "img id out: 5974\n",
      "img id in: 5975\n",
      "img id out: 5975\n",
      "img id in: 5976\n",
      "img id out: 5976\n",
      "img id in: 5977\n",
      "img id out: 5977\n",
      "img id in: 5978\n",
      "img id out: 5978\n",
      "img id in: 5979\n",
      "img id out: 5979\n",
      "img id in: 5980\n",
      "img id out: 5980\n",
      "img id in: 5981\n",
      "img id out: 5981\n",
      "img id in: 5982\n",
      "img id out: 5982\n",
      "img id in: 5983\n",
      "img id out: 5983\n",
      "img id in: 5984\n",
      "img id out: 5984\n",
      "img id in: 5985\n",
      "img id out: 5985\n",
      "img id in: 5986\n",
      "img id out: 5986\n",
      "img id in: 5987\n",
      "img id out: 5987\n",
      "img id in: 5988\n",
      "img id out: 5988\n",
      "img id in: 5989\n",
      "img id out: 5989\n",
      "img id in: 5990\n",
      "img id out: 5990\n",
      "img id in: 5991\n",
      "img id out: 5991\n",
      "img id in: 5992\n",
      "img id out: 5992\n",
      "img id in: 5993\n",
      "img id out: 5993\n",
      "img id in: 5994\n",
      "img id out: 5994\n",
      "img id in: 5995\n",
      "img id out: 5995\n",
      "img id in: 5996\n",
      "img id out: 5996\n",
      "img id in: 5997\n",
      "img id out: 5997\n",
      "img id in: 5998\n",
      "img id out: 5998\n",
      "img id in: 5999\n",
      "img id out: 5999\n",
      "img id in: 6000\n",
      "img id out: 6000\n",
      "img id in: 6001\n",
      "img id out: 6001\n",
      "img id in: 6002\n",
      "img id out: 6002\n",
      "img id in: 6003\n",
      "img id out: 6003\n",
      "img id in: 6004\n",
      "img id out: 6004\n",
      "img id in: 6005\n",
      "img id out: 6005\n",
      "img id in: 6006\n",
      "img id out: 6006\n",
      "img id in: 6007\n",
      "img id out: 6007\n",
      "img id in: 6008\n",
      "img id out: 6008\n",
      "img id in: 6009\n",
      "img id out: 6009\n",
      "img id in: 6010\n",
      "img id out: 6010\n",
      "img id in: 6011\n",
      "img id out: 6011\n",
      "img id in: 6012\n",
      "img id out: 6012\n",
      "img id in: 6013\n",
      "img id out: 6013\n",
      "img id in: 6014\n",
      "img id out: 6014\n",
      "img id in: 6015\n",
      "img id out: 6015\n",
      "img id in: 6016\n",
      "img id out: 6016\n",
      "img id in: 6017\n",
      "img id out: 6017\n",
      "img id in: 6018\n",
      "img id out: 6018\n",
      "img id in: 6019\n",
      "img id out: 6019\n",
      "img id in: 6020\n",
      "img id out: 6020\n",
      "img id in: 6021\n",
      "img id out: 6021\n",
      "img id in: 6022\n",
      "img id out: 6022\n",
      "img id in: 6023\n",
      "img id out: 6023\n",
      "img id in: 6024\n",
      "img id out: 6024\n",
      "img id in: 6025\n",
      "img id out: 6025\n",
      "img id in: 6026\n",
      "img id out: 6026\n",
      "img id in: 6027\n",
      "img id out: 6027\n",
      "img id in: 6028\n",
      "img id out: 6028\n",
      "img id in: 6029\n",
      "img id out: 6029\n",
      "img id in: 6030\n",
      "img id out: 6030\n",
      "img id in: 6031\n",
      "img id out: 6031\n",
      "img id in: 6032\n",
      "img id out: 6032\n",
      "img id in: 6033\n",
      "img id out: 6033\n",
      "img id in: 6034\n",
      "img id out: 6034\n",
      "img id in: 6035\n",
      "img id out: 6035\n",
      "img id in: 6036\n",
      "img id out: 6036\n",
      "img id in: 6037\n",
      "img id out: 6037\n",
      "img id in: 6038\n",
      "img id out: 6038\n",
      "img id in: 6039\n",
      "img id out: 6039\n",
      "img id in: 6040\n",
      "img id out: 6040\n",
      "img id in: 6041\n",
      "img id out: 6041\n",
      "img id in: 6042\n",
      "img id out: 6042\n",
      "img id in: 6043\n",
      "img id out: 6043\n",
      "img id in: 6044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 6044\n",
      "img id in: 6045\n",
      "img id out: 6045\n",
      "img id in: 6046\n",
      "img id out: 6046\n",
      "img id in: 6047\n",
      "img id out: 6047\n",
      "img id in: 6048\n",
      "img id out: 6048\n",
      "img id in: 6049\n",
      "img id out: 6049\n",
      "img id in: 6050\n",
      "img id out: 6050\n",
      "img id in: 6051\n",
      "img id out: 6051\n",
      "img id in: 6052\n",
      "img id out: 6052\n",
      "img id in: 6053\n",
      "img id out: 6053\n",
      "img id in: 6054\n",
      "img id out: 6054\n",
      "img id in: 6055\n",
      "img id out: 6055\n",
      "img id in: 6056\n",
      "img id out: 6056\n",
      "img id in: 6057\n",
      "img id out: 6057\n",
      "img id in: 6058\n",
      "img id out: 6058\n",
      "img id in: 6059\n",
      "img id out: 6059\n",
      "img id in: 6060\n",
      "img id out: 6060\n",
      "img id in: 6061\n",
      "img id out: 6061\n",
      "img id in: 6062\n",
      "img id out: 6062\n",
      "img id in: 6063\n",
      "img id out: 6063\n",
      "img id in: 6064\n",
      "img id out: 6064\n",
      "img id in: 6065\n",
      "img id out: 6065\n",
      "img id in: 6066\n",
      "img id out: 6066\n",
      "img id in: 6067\n",
      "img id out: 6067\n",
      "img id in: 6068\n",
      "img id out: 6068\n",
      "img id in: 6069\n",
      "img id out: 6069\n",
      "img id in: 6070\n",
      "img id out: 6070\n",
      "img id in: 6071\n",
      "img id out: 6071\n",
      "img id in: 6072\n",
      "img id out: 6072\n",
      "img id in: 6073\n",
      "img id out: 6073\n",
      "img id in: 6074\n",
      "img id out: 6074\n",
      "img id in: 6075\n",
      "img id out: 6075\n",
      "img id in: 6076\n",
      "img id out: 6076\n",
      "img id in: 6077\n",
      "img id out: 6077\n",
      "img id in: 6078\n",
      "img id out: 6078\n",
      "img id in: 6079\n",
      "img id out: 6079\n",
      "img id in: 6080\n",
      "img id out: 6080\n",
      "img id in: 6081\n",
      "img id out: 6081\n",
      "img id in: 6082\n",
      "img id out: 6082\n",
      "img id in: 6083\n",
      "img id out: 6083\n",
      "img id in: 6084\n",
      "img id out: 6084\n",
      "img id in: 6085\n",
      "img id out: 6085\n",
      "img id in: 6086\n",
      "img id out: 6086\n",
      "img id in: 6087\n",
      "img id out: 6087\n",
      "img id in: 6088\n",
      "img id out: 6088\n",
      "img id in: 6089\n",
      "img id out: 6089\n",
      "img id in: 6090\n",
      "img id out: 6090\n",
      "img id in: 6091\n",
      "img id out: 6091\n",
      "img id in: 6092\n",
      "img id out: 6092\n",
      "img id in: 6093\n",
      "img id out: 6093\n",
      "img id in: 6094\n",
      "img id out: 6094\n",
      "img id in: 6095\n",
      "img id out: 6095\n",
      "img id in: 6096\n",
      "img id out: 6096\n",
      "img id in: 6097\n",
      "img id out: 6097\n",
      "img id in: 6098\n",
      "img id out: 6098\n",
      "img id in: 6099\n",
      "img id out: 6099\n",
      "img id in: 6100\n",
      "img id out: 6100\n",
      "img id in: 6101\n",
      "img id out: 6101\n",
      "img id in: 6102\n",
      "img id out: 6102\n",
      "img id in: 6103\n",
      "img id out: 6103\n",
      "img id in: 6104\n",
      "img id out: 6104\n",
      "img id in: 6105\n",
      "img id out: 6105\n",
      "img id in: 6106\n",
      "img id out: 6106\n",
      "img id in: 6107\n",
      "img id out: 6107\n",
      "img id in: 6108\n",
      "img id out: 6108\n",
      "img id in: 6109\n",
      "img id out: 6109\n",
      "img id in: 6110\n",
      "img id out: 6110\n",
      "img id in: 6111\n",
      "img id out: 6111\n",
      "img id in: 6112\n",
      "img id out: 6112\n",
      "img id in: 6113\n",
      "img id out: 6113\n",
      "img id in: 6114\n",
      "img id out: 6114\n",
      "img id in: 6115\n",
      "img id out: 6115\n",
      "img id in: 6116\n",
      "img id out: 6116\n",
      "img id in: 6117\n",
      "img id out: 6117\n",
      "img id in: 6118\n",
      "img id out: 6118\n",
      "img id in: 6119\n",
      "img id out: 6119\n",
      "img id in: 6120\n",
      "img id out: 6120\n",
      "img id in: 6121\n",
      "img id out: 6121\n",
      "img id in: 6122\n",
      "img id out: 6122\n",
      "img id in: 6123\n",
      "img id out: 6123\n",
      "img id in: 6124\n",
      "img id out: 6124\n",
      "img id in: 6125\n",
      "img id out: 6125\n",
      "img id in: 6126\n",
      "img id out: 6126\n",
      "img id in: 6127\n",
      "img id out: 6127\n",
      "img id in: 6128\n",
      "img id out: 6128\n",
      "img id in: 6129\n",
      "img id out: 6129\n",
      "img id in: 6130\n",
      "img id out: 6130\n",
      "img id in: 6131\n",
      "img id out: 6131\n",
      "img id in: 6132\n",
      "img id out: 6132\n",
      "img id in: 6133\n",
      "img id out: 6133\n",
      "img id in: 6134\n",
      "img id out: 6134\n",
      "img id in: 6135\n",
      "img id out: 6135\n",
      "img id in: 6136\n",
      "img id out: 6136\n",
      "img id in: 6137\n",
      "img id out: 6137\n",
      "img id in: 6138\n",
      "img id out: 6138\n",
      "img id in: 6139\n",
      "img id out: 6139\n",
      "img id in: 6140\n",
      "img id out: 6140\n",
      "img id in: 6141\n",
      "img id out: 6141\n",
      "img id in: 6142\n",
      "img id out: 6142\n",
      "img id in: 6143\n",
      "img id out: 6143\n",
      "img id in: 6144\n",
      "img id out: 6144\n",
      "img id in: 6145\n",
      "img id out: 6145\n",
      "img id in: 6146\n",
      "img id out: 6146\n",
      "img id in: 6147\n",
      "img id out: 6147\n",
      "img id in: 6148\n",
      "img id out: 6148\n",
      "img id in: 6149\n",
      "img id out: 6149\n",
      "img id in: 6150\n",
      "img id out: 6150\n",
      "img id in: 6151\n",
      "img id out: 6151\n",
      "img id in: 6152\n",
      "img id out: 6152\n",
      "img id in: 6153\n",
      "img id out: 6153\n",
      "img id in: 6154\n",
      "img id out: 6154\n",
      "img id in: 6155\n",
      "img id out: 6155\n",
      "img id in: 6156\n",
      "img id out: 6156\n",
      "img id in: 6157\n",
      "img id out: 6157\n",
      "img id in: 6158\n",
      "img id out: 6158\n",
      "img id in: 6159\n",
      "img id out: 6159\n",
      "img id in: 6160\n",
      "img id out: 6160\n",
      "img id in: 6161\n",
      "img id out: 6161\n",
      "img id in: 6162\n",
      "img id out: 6162\n",
      "img id in: 6163\n",
      "img id out: 6163\n",
      "img id in: 6164\n",
      "img id out: 6164\n",
      "img id in: 6165\n",
      "img id out: 6165\n",
      "img id in: 6166\n",
      "img id out: 6166\n",
      "img id in: 6167\n",
      "img id out: 6167\n",
      "img id in: 6168\n",
      "img id out: 6168\n",
      "img id in: 6169\n",
      "img id out: 6169\n",
      "img id in: 6170\n",
      "img id out: 6170\n",
      "img id in: 6171\n",
      "img id out: 6171\n",
      "img id in: 6172\n",
      "img id out: 6172\n",
      "img id in: 6173\n",
      "img id out: 6173\n",
      "img id in: 6174\n",
      "img id out: 6174\n",
      "img id in: 6175\n",
      "img id out: 6175\n",
      "img id in: 6176\n",
      "img id out: 6176\n",
      "img id in: 6177\n",
      "img id out: 6177\n",
      "img id in: 6178\n",
      "img id out: 6178\n",
      "img id in: 6179\n",
      "img id out: 6179\n",
      "img id in: 6180\n",
      "img id out: 6180\n",
      "img id in: 6181\n",
      "img id out: 6181\n",
      "img id in: 6182\n",
      "img id out: 6182\n",
      "img id in: 6183\n",
      "img id out: 6183\n",
      "img id in: 6184\n",
      "img id out: 6184\n",
      "img id in: 6185\n",
      "img id out: 6185\n",
      "img id in: 6186\n",
      "img id out: 6186\n",
      "img id in: 6187\n",
      "img id out: 6187\n",
      "img id in: 6188\n",
      "img id out: 6188\n",
      "img id in: 6189\n",
      "img id out: 6189\n",
      "img id in: 6190\n",
      "img id out: 6190\n",
      "img id in: 6191\n",
      "img id out: 6191\n",
      "img id in: 6192\n",
      "img id out: 6192\n",
      "img id in: 6193\n",
      "img id out: 6193\n",
      "img id in: 6194\n",
      "img id out: 6194\n",
      "img id in: 6195\n",
      "img id out: 6195\n",
      "img id in: 6196\n",
      "img id out: 6196\n",
      "img id in: 6197\n",
      "img id out: 6197\n",
      "img id in: 6198\n",
      "img id out: 6198\n",
      "img id in: 6199\n",
      "img id out: 6199\n",
      "img id in: 6200\n",
      "img id out: 6200\n",
      "img id in: 6201\n",
      "img id out: 6201\n",
      "img id in: 6202\n",
      "img id out: 6202\n",
      "img id in: 6203\n",
      "img id out: 6203\n",
      "img id in: 6204\n",
      "img id out: 6204\n",
      "img id in: 6205\n",
      "img id out: 6205\n",
      "img id in: 6206\n",
      "img id out: 6206\n",
      "img id in: 6207\n",
      "img id out: 6207\n",
      "img id in: 6208\n",
      "img id out: 6208\n",
      "img id in: 6209\n",
      "img id out: 6209\n",
      "img id in: 6210\n",
      "img id out: 6210\n",
      "img id in: 6211\n",
      "img id out: 6211\n",
      "img id in: 6212\n",
      "img id out: 6212\n",
      "img id in: 6213\n",
      "img id out: 6213\n",
      "img id in: 6214\n",
      "img id out: 6214\n",
      "img id in: 6215\n",
      "img id out: 6215\n",
      "img id in: 6216\n",
      "img id out: 6216\n",
      "img id in: 6217\n",
      "img id out: 6217\n",
      "img id in: 6218\n",
      "img id out: 6218\n",
      "img id in: 6219\n",
      "img id out: 6219\n",
      "img id in: 6220\n",
      "img id out: 6220\n",
      "img id in: 6221\n",
      "img id out: 6221\n",
      "img id in: 6222\n",
      "img id out: 6222\n",
      "img id in: 6223\n",
      "img id out: 6223\n",
      "img id in: 6224\n",
      "img id out: 6224\n",
      "img id in: 6225\n",
      "img id out: 6225\n",
      "img id in: 6226\n",
      "img id out: 6226\n",
      "img id in: 6227\n",
      "img id out: 6227\n",
      "img id in: 6228\n",
      "img id out: 6228\n",
      "img id in: 6229\n",
      "img id out: 6229\n",
      "img id in: 6230\n",
      "img id out: 6230\n",
      "img id in: 6231\n",
      "img id out: 6231\n",
      "img id in: 6232\n",
      "img id out: 6232\n",
      "img id in: 6233\n",
      "img id out: 6233\n",
      "img id in: 6234\n",
      "img id out: 6234\n",
      "img id in: 6235\n",
      "img id out: 6235\n",
      "img id in: 6236\n",
      "img id out: 6236\n",
      "img id in: 6237\n",
      "img id out: 6237\n",
      "img id in: 6238\n",
      "img id out: 6238\n",
      "img id in: 6239\n",
      "img id out: 6239\n",
      "img id in: 6240\n",
      "img id out: 6240\n",
      "img id in: 6241\n",
      "img id out: 6241\n",
      "img id in: 6242\n",
      "img id out: 6242\n",
      "img id in: 6243\n",
      "img id out: 6243\n",
      "img id in: 6244\n",
      "img id out: 6244\n",
      "img id in: 6245\n",
      "img id out: 6245\n",
      "img id in: 6246\n",
      "img id out: 6246\n",
      "img id in: 6247\n",
      "img id out: 6247\n",
      "img id in: 6248\n",
      "img id out: 6248\n",
      "img id in: 6249\n",
      "img id out: 6249\n",
      "img id in: 6250\n",
      "img id out: 6250\n",
      "img id in: 6251\n",
      "img id out: 6251\n",
      "img id in: 6252\n",
      "img id out: 6252\n",
      "img id in: 6253\n",
      "img id out: 6253\n",
      "img id in: 6254\n",
      "img id out: 6254\n",
      "img id in: 6255\n",
      "img id out: 6255\n",
      "img id in: 6256\n",
      "img id out: 6256\n",
      "img id in: 6257\n",
      "img id out: 6257\n",
      "img id in: 6258\n",
      "img id out: 6258\n",
      "img id in: 6259\n",
      "img id out: 6259\n",
      "img id in: 6260\n",
      "img id out: 6260\n",
      "img id in: 6261\n",
      "img id out: 6261\n",
      "img id in: 6262\n",
      "img id out: 6262\n",
      "img id in: 6263\n",
      "img id out: 6263\n",
      "img id in: 6264\n",
      "img id out: 6264\n",
      "img id in: 6265\n",
      "img id out: 6265\n",
      "img id in: 6266\n",
      "img id out: 6266\n",
      "img id in: 6267\n",
      "img id out: 6267\n",
      "img id in: 6268\n",
      "img id out: 6268\n",
      "img id in: 6269\n",
      "img id out: 6269\n",
      "img id in: 6270\n",
      "img id out: 6270\n",
      "img id in: 6271\n",
      "img id out: 6271\n",
      "img id in: 6272\n",
      "img id out: 6272\n",
      "img id in: 6273\n",
      "img id out: 6273\n",
      "img id in: 6274\n",
      "img id out: 6274\n",
      "img id in: 6275\n",
      "img id out: 6275\n",
      "img id in: 6276\n",
      "img id out: 6276\n",
      "img id in: 6277\n",
      "img id out: 6277\n",
      "img id in: 6278\n",
      "img id out: 6278\n",
      "img id in: 6279\n",
      "img id out: 6279\n",
      "img id in: 6280\n",
      "img id out: 6280\n",
      "img id in: 6281\n",
      "img id out: 6281\n",
      "img id in: 6282\n",
      "img id out: 6282\n",
      "img id in: 6283\n",
      "img id out: 6283\n",
      "img id in: 6284\n",
      "img id out: 6284\n",
      "img id in: 6285\n",
      "img id out: 6285\n",
      "img id in: 6286\n",
      "img id out: 6286\n",
      "img id in: 6287\n",
      "img id out: 6287\n",
      "img id in: 6288\n",
      "img id out: 6288\n",
      "img id in: 6289\n",
      "img id out: 6289\n",
      "img id in: 6290\n",
      "img id out: 6290\n",
      "img id in: 6291\n",
      "img id out: 6291\n",
      "img id in: 6292\n",
      "img id out: 6292\n",
      "img id in: 6293\n",
      "img id out: 6293\n",
      "img id in: 6294\n",
      "img id out: 6294\n",
      "img id in: 6295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 6295\n",
      "img id in: 6296\n",
      "img id out: 6296\n",
      "img id in: 6297\n",
      "img id out: 6297\n",
      "img id in: 6298\n",
      "img id out: 6298\n",
      "img id in: 6299\n",
      "img id out: 6299\n",
      "img id in: 6300\n",
      "img id out: 6300\n",
      "img id in: 6301\n",
      "img id out: 6301\n",
      "img id in: 6302\n",
      "img id out: 6302\n",
      "img id in: 6303\n",
      "img id out: 6303\n",
      "img id in: 6304\n",
      "img id out: 6304\n",
      "img id in: 6305\n",
      "img id out: 6305\n",
      "img id in: 6306\n",
      "img id out: 6306\n",
      "img id in: 6307\n",
      "img id out: 6307\n",
      "img id in: 6308\n",
      "img id out: 6308\n",
      "img id in: 6309\n",
      "img id out: 6309\n",
      "img id in: 6310\n",
      "img id out: 6310\n",
      "img id in: 6311\n",
      "img id out: 6311\n",
      "img id in: 6312\n",
      "img id out: 6312\n",
      "img id in: 6313\n",
      "img id out: 6313\n",
      "img id in: 6314\n",
      "img id out: 6314\n",
      "img id in: 6315\n",
      "img id out: 6315\n",
      "img id in: 6316\n",
      "img id out: 6316\n",
      "img id in: 6317\n",
      "img id out: 6317\n",
      "img id in: 6318\n",
      "img id out: 6318\n",
      "img id in: 6319\n",
      "img id out: 6319\n",
      "img id in: 6320\n",
      "img id out: 6320\n",
      "img id in: 6321\n",
      "img id out: 6321\n",
      "img id in: 6322\n",
      "img id out: 6322\n",
      "img id in: 6323\n",
      "img id out: 6323\n",
      "img id in: 6324\n",
      "img id out: 6324\n",
      "img id in: 6325\n",
      "img id out: 6325\n",
      "img id in: 6326\n",
      "img id out: 6326\n",
      "img id in: 6327\n",
      "img id out: 6327\n",
      "img id in: 6328\n",
      "img id out: 6328\n",
      "img id in: 6329\n",
      "img id out: 6329\n",
      "img id in: 6330\n",
      "img id out: 6330\n",
      "img id in: 6331\n",
      "img id out: 6331\n",
      "img id in: 6332\n",
      "img id out: 6332\n",
      "img id in: 6333\n",
      "img id out: 6333\n",
      "img id in: 6334\n",
      "img id out: 6334\n",
      "img id in: 6335\n",
      "img id out: 6335\n",
      "img id in: 6336\n",
      "img id out: 6336\n",
      "img id in: 6337\n",
      "img id out: 6337\n",
      "img id in: 6338\n",
      "img id out: 6338\n",
      "img id in: 6339\n",
      "img id out: 6339\n",
      "img id in: 6340\n",
      "img id out: 6340\n",
      "img id in: 6341\n",
      "img id out: 6341\n",
      "img id in: 6342\n",
      "img id out: 6342\n",
      "img id in: 6343\n",
      "img id out: 6343\n",
      "img id in: 6344\n",
      "img id out: 6344\n",
      "img id in: 6345\n",
      "img id out: 6345\n",
      "img id in: 6346\n",
      "img id out: 6346\n",
      "img id in: 6347\n",
      "img id out: 6347\n",
      "img id in: 6348\n",
      "img id out: 6348\n",
      "img id in: 6349\n",
      "img id out: 6349\n",
      "img id in: 6350\n",
      "img id out: 6350\n",
      "img id in: 6351\n",
      "img id out: 6351\n",
      "img id in: 6352\n",
      "img id out: 6352\n",
      "img id in: 6353\n",
      "img id out: 6353\n",
      "img id in: 6354\n",
      "img id out: 6354\n",
      "img id in: 6355\n",
      "img id out: 6355\n",
      "img id in: 6356\n",
      "img id out: 6356\n",
      "img id in: 6357\n",
      "img id out: 6357\n",
      "img id in: 6358\n",
      "img id out: 6358\n",
      "img id in: 6359\n",
      "img id out: 6359\n",
      "img id in: 6360\n",
      "img id out: 6360\n",
      "img id in: 6361\n",
      "img id out: 6361\n",
      "img id in: 6362\n",
      "img id out: 6362\n",
      "img id in: 6363\n",
      "img id out: 6363\n",
      "img id in: 6364\n",
      "img id out: 6364\n",
      "img id in: 6365\n",
      "img id out: 6365\n",
      "img id in: 6366\n",
      "img id out: 6366\n",
      "img id in: 6367\n",
      "img id out: 6367\n",
      "img id in: 6368\n",
      "img id out: 6368\n",
      "img id in: 6369\n",
      "img id out: 6369\n",
      "img id in: 6370\n",
      "img id out: 6370\n",
      "img id in: 6371\n",
      "img id out: 6371\n",
      "img id in: 6372\n",
      "img id out: 6372\n",
      "img id in: 6373\n",
      "img id out: 6373\n",
      "img id in: 6374\n",
      "img id out: 6374\n",
      "img id in: 6375\n",
      "img id out: 6375\n",
      "img id in: 6376\n",
      "img id out: 6376\n",
      "img id in: 6377\n",
      "img id out: 6377\n",
      "img id in: 6378\n",
      "img id out: 6378\n",
      "img id in: 6379\n",
      "img id out: 6379\n",
      "img id in: 6380\n",
      "img id out: 6380\n",
      "img id in: 6381\n",
      "img id out: 6381\n",
      "img id in: 6382\n",
      "img id out: 6382\n",
      "img id in: 6383\n",
      "img id out: 6383\n",
      "img id in: 6384\n",
      "img id out: 6384\n",
      "img id in: 6385\n",
      "img id out: 6385\n",
      "img id in: 6386\n",
      "img id out: 6386\n",
      "img id in: 6387\n",
      "img id out: 6387\n",
      "img id in: 6388\n",
      "img id out: 6388\n",
      "img id in: 6389\n",
      "img id out: 6389\n",
      "img id in: 6390\n",
      "img id out: 6390\n",
      "img id in: 6391\n",
      "img id out: 6391\n",
      "img id in: 6392\n",
      "img id out: 6392\n",
      "img id in: 6393\n",
      "img id out: 6393\n",
      "img id in: 6394\n",
      "img id out: 6394\n",
      "img id in: 6395\n",
      "img id out: 6395\n",
      "img id in: 6396\n",
      "img id out: 6396\n",
      "img id in: 6397\n",
      "img id out: 6397\n",
      "img id in: 6398\n",
      "img id out: 6398\n",
      "img id in: 6399\n",
      "img id out: 6399\n",
      "img id in: 6400\n",
      "img id out: 6400\n",
      "img id in: 6401\n",
      "img id out: 6401\n",
      "img id in: 6402\n",
      "img id out: 6402\n",
      "img id in: 6403\n",
      "img id out: 6403\n",
      "img id in: 6404\n",
      "img id out: 6404\n",
      "img id in: 6405\n",
      "img id out: 6405\n",
      "img id in: 6406\n",
      "img id out: 6406\n",
      "img id in: 6407\n",
      "img id out: 6407\n",
      "img id in: 6408\n",
      "img id out: 6408\n",
      "img id in: 6409\n",
      "img id out: 6409\n",
      "img id in: 6410\n",
      "img id out: 6410\n",
      "img id in: 6411\n",
      "img id out: 6411\n",
      "img id in: 6412\n",
      "img id out: 6412\n",
      "img id in: 6413\n",
      "img id out: 6413\n",
      "img id in: 6414\n",
      "img id out: 6414\n",
      "img id in: 6415\n",
      "img id out: 6415\n",
      "img id in: 6416\n",
      "img id out: 6416\n",
      "img id in: 6417\n",
      "img id out: 6417\n",
      "img id in: 6418\n",
      "img id out: 6418\n",
      "img id in: 6419\n",
      "img id out: 6419\n",
      "img id in: 6420\n",
      "img id out: 6420\n",
      "img id in: 6421\n",
      "img id out: 6421\n",
      "img id in: 6422\n",
      "img id out: 6422\n",
      "img id in: 6423\n",
      "img id out: 6423\n",
      "img id in: 6424\n",
      "img id out: 6424\n",
      "img id in: 6425\n",
      "img id out: 6425\n",
      "img id in: 6426\n",
      "img id out: 6426\n",
      "img id in: 6427\n",
      "img id out: 6427\n",
      "img id in: 6428\n",
      "img id out: 6428\n",
      "img id in: 6429\n",
      "img id out: 6429\n",
      "img id in: 6430\n",
      "img id out: 6430\n",
      "img id in: 6431\n",
      "img id out: 6431\n",
      "img id in: 6432\n",
      "img id out: 6432\n",
      "img id in: 6433\n",
      "img id out: 6433\n",
      "img id in: 6434\n",
      "img id out: 6434\n",
      "img id in: 6435\n",
      "img id out: 6435\n",
      "img id in: 6436\n",
      "img id out: 6436\n",
      "img id in: 6437\n",
      "img id out: 6437\n",
      "img id in: 6438\n",
      "img id out: 6438\n",
      "img id in: 6439\n",
      "img id out: 6439\n",
      "img id in: 6440\n",
      "img id out: 6440\n",
      "img id in: 6441\n",
      "img id out: 6441\n",
      "img id in: 6442\n",
      "img id out: 6442\n",
      "img id in: 6443\n",
      "img id out: 6443\n",
      "img id in: 6444\n",
      "img id out: 6444\n",
      "img id in: 6445\n",
      "img id out: 6445\n",
      "img id in: 6446\n",
      "img id out: 6446\n",
      "img id in: 6447\n",
      "img id out: 6447\n",
      "img id in: 6448\n",
      "img id out: 6448\n",
      "img id in: 6449\n",
      "img id out: 6449\n",
      "img id in: 6450\n",
      "img id out: 6450\n",
      "img id in: 6451\n",
      "img id out: 6451\n",
      "img id in: 6452\n",
      "img id out: 6452\n",
      "img id in: 6453\n",
      "img id out: 6453\n",
      "img id in: 6454\n",
      "img id out: 6454\n",
      "img id in: 6455\n",
      "img id out: 6455\n",
      "img id in: 6456\n",
      "img id out: 6456\n",
      "img id in: 6457\n",
      "img id out: 6457\n",
      "img id in: 6458\n",
      "img id out: 6458\n",
      "img id in: 6459\n",
      "img id out: 6459\n",
      "img id in: 6460\n",
      "img id out: 6460\n",
      "img id in: 6461\n",
      "img id out: 6461\n",
      "img id in: 6462\n",
      "img id out: 6462\n",
      "img id in: 6463\n",
      "img id out: 6463\n",
      "img id in: 6464\n",
      "img id out: 6464\n",
      "img id in: 6465\n",
      "img id out: 6465\n",
      "img id in: 6466\n",
      "img id out: 6466\n",
      "img id in: 6467\n",
      "img id out: 6467\n",
      "img id in: 6468\n",
      "img id out: 6468\n",
      "img id in: 6469\n",
      "img id out: 6469\n",
      "img id in: 6470\n",
      "img id out: 6470\n",
      "img id in: 6471\n",
      "img id out: 6471\n",
      "img id in: 6472\n",
      "img id out: 6472\n",
      "img id in: 6473\n",
      "img id out: 6473\n",
      "img id in: 6474\n",
      "img id out: 6474\n",
      "img id in: 6475\n",
      "img id out: 6475\n",
      "img id in: 6476\n",
      "img id out: 6476\n",
      "img id in: 6477\n",
      "img id out: 6477\n",
      "img id in: 6478\n",
      "img id out: 6478\n",
      "img id in: 6479\n",
      "img id out: 6479\n",
      "img id in: 6480\n",
      "img id out: 6480\n",
      "img id in: 6481\n",
      "img id out: 6481\n",
      "img id in: 6482\n",
      "img id out: 6482\n",
      "img id in: 6483\n",
      "img id out: 6483\n",
      "img id in: 6484\n",
      "img id out: 6484\n",
      "img id in: 6485\n",
      "img id out: 6485\n",
      "img id in: 6486\n",
      "img id out: 6486\n",
      "img id in: 6487\n",
      "img id out: 6487\n",
      "img id in: 6488\n",
      "img id out: 6488\n",
      "img id in: 6489\n",
      "img id out: 6489\n",
      "img id in: 6490\n",
      "img id out: 6490\n",
      "img id in: 6491\n",
      "img id out: 6491\n",
      "img id in: 6492\n",
      "img id out: 6492\n",
      "img id in: 6493\n",
      "img id out: 6493\n",
      "img id in: 6494\n",
      "img id out: 6494\n",
      "img id in: 6495\n",
      "img id out: 6495\n",
      "img id in: 6496\n",
      "img id out: 6496\n",
      "img id in: 6497\n",
      "img id out: 6497\n",
      "img id in: 6498\n",
      "img id out: 6498\n",
      "img id in: 6499\n",
      "img id out: 6499\n",
      "img id in: 6500\n",
      "img id out: 6500\n",
      "img id in: 6501\n",
      "img id out: 6501\n",
      "img id in: 6502\n",
      "img id out: 6502\n",
      "img id in: 6503\n",
      "img id out: 6503\n",
      "img id in: 6504\n",
      "img id out: 6504\n",
      "img id in: 6505\n",
      "img id out: 6505\n",
      "img id in: 6506\n",
      "img id out: 6506\n",
      "img id in: 6507\n",
      "img id out: 6507\n",
      "img id in: 6508\n",
      "img id out: 6508\n",
      "img id in: 6509\n",
      "img id out: 6509\n",
      "img id in: 6510\n",
      "img id out: 6510\n",
      "img id in: 6511\n",
      "img id out: 6511\n",
      "img id in: 6512\n",
      "img id out: 6512\n",
      "img id in: 6513\n",
      "img id out: 6513\n",
      "img id in: 6514\n",
      "img id out: 6514\n",
      "img id in: 6515\n",
      "img id out: 6515\n",
      "img id in: 6516\n",
      "img id out: 6516\n",
      "img id in: 6517\n",
      "img id out: 6517\n",
      "img id in: 6518\n",
      "img id out: 6518\n",
      "img id in: 6519\n",
      "img id out: 6519\n",
      "img id in: 6520\n",
      "img id out: 6520\n",
      "img id in: 6521\n",
      "img id out: 6521\n",
      "img id in: 6522\n",
      "img id out: 6522\n",
      "img id in: 6523\n",
      "img id out: 6523\n",
      "img id in: 6524\n",
      "img id out: 6524\n",
      "img id in: 6525\n",
      "img id out: 6525\n",
      "img id in: 6526\n",
      "img id out: 6526\n",
      "img id in: 6527\n",
      "img id out: 6527\n",
      "img id in: 6528\n",
      "img id out: 6528\n",
      "img id in: 6529\n",
      "img id out: 6529\n",
      "img id in: 6530\n",
      "img id out: 6530\n",
      "img id in: 6531\n",
      "img id out: 6531\n",
      "img id in: 6532\n",
      "img id out: 6532\n",
      "img id in: 6533\n",
      "img id out: 6533\n",
      "img id in: 6534\n",
      "img id out: 6534\n",
      "img id in: 6535\n",
      "img id out: 6535\n",
      "img id in: 6536\n",
      "img id out: 6536\n",
      "img id in: 6537\n",
      "img id out: 6537\n",
      "img id in: 6538\n",
      "img id out: 6538\n",
      "img id in: 6539\n",
      "img id out: 6539\n",
      "img id in: 6540\n",
      "img id out: 6540\n",
      "img id in: 6541\n",
      "img id out: 6541\n",
      "img id in: 6542\n",
      "img id out: 6542\n",
      "img id in: 6543\n",
      "img id out: 6543\n",
      "img id in: 6544\n",
      "img id out: 6544\n",
      "img id in: 6545\n",
      "img id out: 6545\n",
      "img id in: 6546\n",
      "img id out: 6546\n",
      "img id in: 6547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 6547\n",
      "img id in: 6548\n",
      "img id out: 6548\n",
      "img id in: 6549\n",
      "img id out: 6549\n",
      "img id in: 6550\n",
      "img id out: 6550\n",
      "img id in: 6551\n",
      "img id out: 6551\n",
      "img id in: 6552\n",
      "img id out: 6552\n",
      "img id in: 6553\n",
      "img id out: 6553\n",
      "img id in: 6554\n",
      "img id out: 6554\n",
      "img id in: 6555\n",
      "img id out: 6555\n",
      "img id in: 6556\n",
      "img id out: 6556\n",
      "img id in: 6557\n",
      "img id out: 6557\n",
      "img id in: 6558\n",
      "img id out: 6558\n",
      "img id in: 6559\n",
      "img id out: 6559\n",
      "img id in: 6560\n",
      "img id out: 6560\n",
      "img id in: 6561\n",
      "img id out: 6561\n",
      "img id in: 6562\n",
      "img id out: 6562\n",
      "img id in: 6563\n",
      "img id out: 6563\n",
      "img id in: 6564\n",
      "img id out: 6564\n",
      "img id in: 6565\n",
      "img id out: 6565\n",
      "img id in: 6566\n",
      "img id out: 6566\n",
      "img id in: 6567\n",
      "img id out: 6567\n",
      "img id in: 6568\n",
      "img id out: 6568\n",
      "img id in: 6569\n",
      "img id out: 6569\n",
      "img id in: 6570\n",
      "img id out: 6570\n",
      "img id in: 6571\n",
      "img id out: 6571\n",
      "img id in: 6572\n",
      "img id out: 6572\n",
      "img id in: 6573\n",
      "img id out: 6573\n",
      "img id in: 6574\n",
      "img id out: 6574\n",
      "img id in: 6575\n",
      "img id out: 6575\n",
      "img id in: 6576\n",
      "img id out: 6576\n",
      "img id in: 6577\n",
      "img id out: 6577\n",
      "img id in: 6578\n",
      "img id out: 6578\n",
      "img id in: 6579\n",
      "img id out: 6579\n",
      "img id in: 6580\n",
      "img id out: 6580\n",
      "img id in: 6581\n",
      "img id out: 6581\n",
      "img id in: 6582\n",
      "img id out: 6582\n",
      "img id in: 6583\n",
      "img id out: 6583\n",
      "img id in: 6584\n",
      "img id out: 6584\n",
      "img id in: 6585\n",
      "img id out: 6585\n",
      "img id in: 6586\n",
      "img id out: 6586\n",
      "img id in: 6587\n",
      "img id out: 6587\n",
      "img id in: 6588\n",
      "img id out: 6588\n",
      "img id in: 6589\n",
      "img id out: 6589\n",
      "img id in: 6590\n",
      "img id out: 6590\n",
      "img id in: 6591\n",
      "img id out: 6591\n",
      "img id in: 6592\n",
      "img id out: 6592\n",
      "img id in: 6593\n",
      "img id out: 6593\n",
      "img id in: 6594\n",
      "img id out: 6594\n",
      "img id in: 6595\n",
      "img id out: 6595\n",
      "img id in: 6596\n",
      "img id out: 6596\n",
      "img id in: 6597\n",
      "img id out: 6597\n",
      "img id in: 6598\n",
      "img id out: 6598\n",
      "img id in: 6599\n",
      "img id out: 6599\n",
      "img id in: 6600\n",
      "img id out: 6600\n",
      "img id in: 6601\n",
      "img id out: 6601\n",
      "img id in: 6602\n",
      "img id out: 6602\n",
      "img id in: 6603\n",
      "img id out: 6603\n",
      "img id in: 6604\n",
      "img id out: 6604\n",
      "img id in: 6605\n",
      "img id out: 6605\n",
      "img id in: 6606\n",
      "img id out: 6606\n",
      "img id in: 6607\n",
      "img id out: 6607\n",
      "img id in: 6608\n",
      "img id out: 6608\n",
      "img id in: 6609\n",
      "img id out: 6609\n",
      "img id in: 6610\n",
      "img id out: 6610\n",
      "img id in: 6611\n",
      "img id out: 6611\n",
      "img id in: 6612\n",
      "img id out: 6612\n",
      "img id in: 6613\n",
      "img id out: 6613\n",
      "img id in: 6614\n",
      "img id out: 6614\n",
      "img id in: 6615\n",
      "img id out: 6615\n",
      "img id in: 6616\n",
      "img id out: 6616\n",
      "img id in: 6617\n",
      "img id out: 6617\n",
      "img id in: 6618\n",
      "img id out: 6618\n",
      "img id in: 6619\n",
      "img id out: 6619\n",
      "img id in: 6620\n",
      "img id out: 6620\n",
      "img id in: 6621\n",
      "img id out: 6621\n",
      "img id in: 6622\n",
      "img id out: 6622\n",
      "img id in: 6623\n",
      "img id out: 6623\n",
      "img id in: 6624\n",
      "img id out: 6624\n",
      "img id in: 6625\n",
      "img id out: 6625\n",
      "img id in: 6626\n",
      "img id out: 6626\n",
      "img id in: 6627\n",
      "img id out: 6627\n",
      "img id in: 6628\n",
      "img id out: 6628\n",
      "img id in: 6629\n",
      "img id out: 6629\n",
      "img id in: 6630\n",
      "img id out: 6630\n",
      "img id in: 6631\n",
      "img id out: 6631\n",
      "img id in: 6632\n",
      "img id out: 6632\n",
      "img id in: 6633\n",
      "img id out: 6633\n",
      "img id in: 6634\n",
      "img id out: 6634\n",
      "img id in: 6635\n",
      "img id out: 6635\n",
      "img id in: 6636\n",
      "img id out: 6636\n",
      "img id in: 6637\n",
      "img id out: 6637\n",
      "img id in: 6638\n",
      "img id out: 6638\n",
      "img id in: 6639\n",
      "img id out: 6639\n",
      "img id in: 6640\n",
      "img id out: 6640\n",
      "img id in: 6641\n",
      "img id out: 6641\n",
      "img id in: 6642\n",
      "img id out: 6642\n",
      "img id in: 6643\n",
      "img id out: 6643\n",
      "img id in: 6644\n",
      "img id out: 6644\n",
      "img id in: 6645\n",
      "img id out: 6645\n",
      "img id in: 6646\n",
      "img id out: 6646\n",
      "img id in: 6647\n",
      "img id out: 6647\n",
      "img id in: 6648\n",
      "img id out: 6648\n",
      "img id in: 6649\n",
      "img id out: 6649\n",
      "img id in: 6650\n",
      "img id out: 6650\n",
      "img id in: 6651\n",
      "img id out: 6651\n",
      "img id in: 6652\n",
      "img id out: 6652\n",
      "img id in: 6653\n",
      "img id out: 6653\n",
      "img id in: 6654\n",
      "img id out: 6654\n",
      "img id in: 6655\n",
      "img id out: 6655\n",
      "img id in: 6656\n",
      "img id out: 6656\n",
      "img id in: 6657\n",
      "img id out: 6657\n",
      "img id in: 6658\n",
      "img id out: 6658\n",
      "img id in: 6659\n",
      "img id out: 6659\n",
      "img id in: 6660\n",
      "img id out: 6660\n",
      "img id in: 6661\n",
      "img id out: 6661\n",
      "img id in: 6662\n",
      "img id out: 6662\n",
      "img id in: 6663\n",
      "img id out: 6663\n",
      "img id in: 6664\n",
      "img id out: 6664\n",
      "img id in: 6665\n",
      "img id out: 6665\n",
      "img id in: 6666\n",
      "img id out: 6666\n",
      "img id in: 6667\n",
      "img id out: 6667\n",
      "img id in: 6668\n",
      "img id out: 6668\n",
      "img id in: 6669\n",
      "img id out: 6669\n",
      "img id in: 6670\n",
      "img id out: 6670\n",
      "img id in: 6671\n",
      "img id out: 6671\n",
      "img id in: 6672\n",
      "img id out: 6672\n",
      "img id in: 6673\n",
      "img id out: 6673\n",
      "img id in: 6674\n",
      "img id out: 6674\n",
      "img id in: 6675\n",
      "img id out: 6675\n",
      "img id in: 6676\n",
      "img id out: 6676\n",
      "img id in: 6677\n",
      "img id out: 6677\n",
      "img id in: 6678\n",
      "img id out: 6678\n",
      "img id in: 6679\n",
      "img id out: 6679\n",
      "img id in: 6680\n",
      "img id out: 6680\n",
      "img id in: 6681\n",
      "img id out: 6681\n",
      "img id in: 6682\n",
      "img id out: 6682\n",
      "img id in: 6683\n",
      "img id out: 6683\n",
      "img id in: 6684\n",
      "img id out: 6684\n",
      "img id in: 6685\n",
      "img id out: 6685\n",
      "img id in: 6686\n",
      "img id out: 6686\n",
      "img id in: 6687\n",
      "img id out: 6687\n",
      "img id in: 6688\n",
      "img id out: 6688\n",
      "img id in: 6689\n",
      "img id out: 6689\n",
      "img id in: 6690\n",
      "img id out: 6690\n",
      "img id in: 6691\n",
      "img id out: 6691\n",
      "img id in: 6692\n",
      "img id out: 6692\n",
      "img id in: 6693\n",
      "img id out: 6693\n",
      "img id in: 6694\n",
      "img id out: 6694\n",
      "img id in: 6695\n",
      "img id out: 6695\n",
      "img id in: 6696\n",
      "img id out: 6696\n",
      "img id in: 6697\n",
      "img id out: 6697\n",
      "img id in: 6698\n",
      "img id out: 6698\n",
      "img id in: 6699\n",
      "img id out: 6699\n",
      "img id in: 6700\n",
      "img id out: 6700\n",
      "img id in: 6701\n",
      "img id out: 6701\n",
      "img id in: 6702\n",
      "img id out: 6702\n",
      "img id in: 6703\n",
      "img id out: 6703\n",
      "img id in: 6704\n",
      "img id out: 6704\n",
      "img id in: 6705\n",
      "img id out: 6705\n",
      "img id in: 6706\n",
      "img id out: 6706\n",
      "img id in: 6707\n",
      "img id out: 6707\n",
      "img id in: 6708\n",
      "img id out: 6708\n",
      "img id in: 6709\n",
      "img id out: 6709\n",
      "img id in: 6710\n",
      "img id out: 6710\n",
      "img id in: 6711\n",
      "img id out: 6711\n",
      "img id in: 6712\n",
      "img id out: 6712\n",
      "img id in: 6713\n",
      "img id out: 6713\n",
      "img id in: 6714\n",
      "img id out: 6714\n",
      "img id in: 6715\n",
      "img id out: 6715\n",
      "img id in: 6716\n",
      "img id out: 6716\n",
      "img id in: 6717\n",
      "img id out: 6717\n",
      "img id in: 6718\n",
      "img id out: 6718\n",
      "img id in: 6719\n",
      "img id out: 6719\n",
      "img id in: 6720\n",
      "img id out: 6720\n",
      "img id in: 6721\n",
      "img id out: 6721\n",
      "img id in: 6722\n",
      "img id out: 6722\n",
      "img id in: 6723\n",
      "img id out: 6723\n",
      "img id in: 6724\n",
      "img id out: 6724\n",
      "img id in: 6725\n",
      "img id out: 6725\n",
      "img id in: 6726\n",
      "img id out: 6726\n",
      "img id in: 6727\n",
      "img id out: 6727\n",
      "img id in: 6728\n",
      "img id out: 6728\n",
      "img id in: 6729\n",
      "img id out: 6729\n",
      "img id in: 6730\n",
      "img id out: 6730\n",
      "img id in: 6731\n",
      "img id out: 6731\n",
      "img id in: 6732\n",
      "img id out: 6732\n",
      "img id in: 6733\n",
      "img id out: 6733\n",
      "img id in: 6734\n",
      "img id out: 6734\n",
      "img id in: 6735\n",
      "img id out: 6735\n",
      "img id in: 6736\n",
      "img id out: 6736\n",
      "img id in: 6737\n",
      "img id out: 6737\n",
      "img id in: 6738\n",
      "img id out: 6738\n",
      "img id in: 6739\n",
      "img id out: 6739\n",
      "img id in: 6740\n",
      "img id out: 6740\n",
      "img id in: 6741\n",
      "img id out: 6741\n",
      "img id in: 6742\n",
      "img id out: 6742\n",
      "img id in: 6743\n",
      "img id out: 6743\n",
      "img id in: 6744\n",
      "img id out: 6744\n",
      "img id in: 6745\n",
      "img id out: 6745\n",
      "img id in: 6746\n",
      "img id out: 6746\n",
      "img id in: 6747\n",
      "img id out: 6747\n",
      "img id in: 6748\n",
      "img id out: 6748\n",
      "img id in: 6749\n",
      "img id out: 6749\n",
      "img id in: 6750\n",
      "img id out: 6750\n",
      "img id in: 6751\n",
      "img id out: 6751\n",
      "img id in: 6752\n",
      "img id out: 6752\n",
      "img id in: 6753\n",
      "img id out: 6753\n",
      "img id in: 6754\n",
      "img id out: 6754\n",
      "img id in: 6755\n",
      "img id out: 6755\n",
      "img id in: 6756\n",
      "img id out: 6756\n",
      "img id in: 6757\n",
      "img id out: 6757\n",
      "img id in: 6758\n",
      "img id out: 6758\n",
      "img id in: 6759\n",
      "img id out: 6759\n",
      "img id in: 6760\n",
      "img id out: 6760\n",
      "img id in: 6761\n",
      "img id out: 6761\n",
      "img id in: 6762\n",
      "img id out: 6762\n",
      "img id in: 6763\n",
      "img id out: 6763\n",
      "img id in: 6764\n",
      "img id out: 6764\n",
      "img id in: 6765\n",
      "img id out: 6765\n",
      "img id in: 6766\n",
      "img id out: 6766\n",
      "img id in: 6767\n",
      "img id out: 6767\n",
      "img id in: 6768\n",
      "img id out: 6768\n",
      "img id in: 6769\n",
      "img id out: 6769\n",
      "img id in: 6770\n",
      "img id out: 6770\n",
      "img id in: 6771\n",
      "img id out: 6771\n",
      "img id in: 6772\n",
      "img id out: 6772\n",
      "img id in: 6773\n",
      "img id out: 6773\n",
      "img id in: 6774\n",
      "img id out: 6774\n",
      "img id in: 6775\n",
      "img id out: 6775\n",
      "img id in: 6776\n",
      "img id out: 6776\n",
      "img id in: 6777\n",
      "img id out: 6777\n",
      "img id in: 6778\n",
      "img id out: 6778\n",
      "img id in: 6779\n",
      "img id out: 6779\n",
      "img id in: 6780\n",
      "img id out: 6780\n",
      "img id in: 6781\n",
      "img id out: 6781\n",
      "img id in: 6782\n",
      "img id out: 6782\n",
      "img id in: 6783\n",
      "img id out: 6783\n",
      "img id in: 6784\n",
      "img id out: 6784\n",
      "img id in: 6785\n",
      "img id out: 6785\n",
      "img id in: 6786\n",
      "img id out: 6786\n",
      "img id in: 6787\n",
      "img id out: 6787\n",
      "img id in: 6788\n",
      "img id out: 6788\n",
      "img id in: 6789\n",
      "img id out: 6789\n",
      "img id in: 6790\n",
      "img id out: 6790\n",
      "img id in: 6791\n",
      "img id out: 6791\n",
      "img id in: 6792\n",
      "img id out: 6792\n",
      "img id in: 6793\n",
      "img id out: 6793\n",
      "img id in: 6794\n",
      "img id out: 6794\n",
      "img id in: 6795\n",
      "img id out: 6795\n",
      "img id in: 6796\n",
      "img id out: 6796\n",
      "img id in: 6797\n",
      "img id out: 6797\n",
      "img id in: 6798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 6798\n",
      "img id in: 6799\n",
      "img id out: 6799\n",
      "img id in: 6800\n",
      "img id out: 6800\n",
      "img id in: 6801\n",
      "img id out: 6801\n",
      "img id in: 6802\n",
      "img id out: 6802\n",
      "img id in: 6803\n",
      "img id out: 6803\n",
      "img id in: 6804\n",
      "img id out: 6804\n",
      "img id in: 6805\n",
      "img id out: 6805\n",
      "img id in: 6806\n",
      "img id out: 6806\n",
      "img id in: 6807\n",
      "img id out: 6807\n",
      "img id in: 6808\n",
      "img id out: 6808\n",
      "img id in: 6809\n",
      "img id out: 6809\n",
      "img id in: 6810\n",
      "img id out: 6810\n",
      "img id in: 6811\n",
      "img id out: 6811\n",
      "img id in: 6812\n",
      "img id out: 6812\n",
      "img id in: 6813\n",
      "img id out: 6813\n",
      "img id in: 6814\n",
      "img id out: 6814\n",
      "img id in: 6815\n",
      "img id out: 6815\n",
      "img id in: 6816\n",
      "img id out: 6816\n",
      "img id in: 6817\n",
      "img id out: 6817\n",
      "img id in: 6818\n",
      "img id out: 6818\n",
      "img id in: 6819\n",
      "img id out: 6819\n",
      "img id in: 6820\n",
      "img id out: 6820\n",
      "img id in: 6821\n",
      "img id out: 6821\n",
      "img id in: 6822\n",
      "img id out: 6822\n",
      "img id in: 6823\n",
      "img id out: 6823\n",
      "img id in: 6824\n",
      "img id out: 6824\n",
      "img id in: 6825\n",
      "img id out: 6825\n",
      "img id in: 6826\n",
      "img id out: 6826\n",
      "img id in: 6827\n",
      "img id out: 6827\n",
      "img id in: 6828\n",
      "img id out: 6828\n",
      "img id in: 6829\n",
      "img id out: 6829\n",
      "img id in: 6830\n",
      "img id out: 6830\n",
      "img id in: 6831\n",
      "img id out: 6831\n",
      "img id in: 6832\n",
      "img id out: 6832\n",
      "img id in: 6833\n",
      "img id out: 6833\n",
      "img id in: 6834\n",
      "img id out: 6834\n",
      "img id in: 6835\n",
      "img id out: 6835\n",
      "img id in: 6836\n",
      "img id out: 6836\n",
      "img id in: 6837\n",
      "img id out: 6837\n",
      "img id in: 6838\n",
      "img id out: 6838\n",
      "img id in: 6839\n",
      "img id out: 6839\n",
      "img id in: 6840\n",
      "img id out: 6840\n",
      "img id in: 6841\n",
      "img id out: 6841\n",
      "img id in: 6842\n",
      "img id out: 6842\n",
      "img id in: 6843\n",
      "img id out: 6843\n",
      "img id in: 6844\n",
      "img id out: 6844\n",
      "img id in: 6845\n",
      "img id out: 6845\n",
      "img id in: 6846\n",
      "img id out: 6846\n",
      "img id in: 6847\n",
      "img id out: 6847\n",
      "img id in: 6848\n",
      "img id out: 6848\n",
      "img id in: 6849\n",
      "img id out: 6849\n",
      "img id in: 6850\n",
      "img id out: 6850\n",
      "img id in: 6851\n",
      "img id out: 6851\n",
      "img id in: 6852\n",
      "img id out: 6852\n",
      "img id in: 6853\n",
      "img id out: 6853\n",
      "img id in: 6854\n",
      "img id out: 6854\n",
      "img id in: 6855\n",
      "img id out: 6855\n",
      "img id in: 6856\n",
      "img id out: 6856\n",
      "img id in: 6857\n",
      "img id out: 6857\n",
      "img id in: 6858\n",
      "img id out: 6858\n",
      "img id in: 6859\n",
      "img id out: 6859\n",
      "img id in: 6860\n",
      "img id out: 6860\n",
      "img id in: 6861\n",
      "img id out: 6861\n",
      "img id in: 6862\n",
      "img id out: 6862\n",
      "img id in: 6863\n",
      "img id out: 6863\n",
      "img id in: 6864\n",
      "img id out: 6864\n",
      "img id in: 6865\n",
      "img id out: 6865\n",
      "img id in: 6866\n",
      "img id out: 6866\n",
      "img id in: 6867\n",
      "img id out: 6867\n",
      "img id in: 6868\n",
      "img id out: 6868\n",
      "img id in: 6869\n",
      "img id out: 6869\n",
      "img id in: 6870\n",
      "img id out: 6870\n",
      "img id in: 6871\n",
      "img id out: 6871\n",
      "img id in: 6872\n",
      "img id out: 6872\n",
      "img id in: 6873\n",
      "img id out: 6873\n",
      "img id in: 6874\n",
      "img id out: 6874\n",
      "img id in: 6875\n",
      "img id out: 6875\n",
      "img id in: 6876\n",
      "img id out: 6876\n",
      "img id in: 6877\n",
      "img id out: 6877\n",
      "img id in: 6878\n",
      "img id out: 6878\n",
      "img id in: 6879\n",
      "img id out: 6879\n",
      "img id in: 6880\n",
      "img id out: 6880\n",
      "img id in: 6881\n",
      "img id out: 6881\n",
      "img id in: 6882\n",
      "img id out: 6882\n",
      "img id in: 6883\n",
      "img id out: 6883\n",
      "img id in: 6884\n",
      "img id out: 6884\n",
      "img id in: 6885\n",
      "img id out: 6885\n",
      "img id in: 6886\n",
      "img id out: 6886\n",
      "img id in: 6887\n",
      "img id out: 6887\n",
      "img id in: 6888\n",
      "img id out: 6888\n",
      "img id in: 6889\n",
      "img id out: 6889\n",
      "img id in: 6890\n",
      "img id out: 6890\n",
      "img id in: 6891\n",
      "img id out: 6891\n",
      "img id in: 6892\n",
      "img id out: 6892\n",
      "img id in: 6893\n",
      "img id out: 6893\n",
      "img id in: 6894\n",
      "img id out: 6894\n",
      "img id in: 6895\n",
      "img id out: 6895\n",
      "img id in: 6896\n",
      "img id out: 6896\n",
      "img id in: 6897\n",
      "img id out: 6897\n",
      "img id in: 6898\n",
      "img id out: 6898\n",
      "img id in: 6899\n",
      "img id out: 6899\n",
      "img id in: 6900\n",
      "img id out: 6900\n",
      "img id in: 6901\n",
      "img id out: 6901\n",
      "img id in: 6902\n",
      "img id out: 6902\n",
      "img id in: 6903\n",
      "img id out: 6903\n",
      "img id in: 6904\n",
      "img id out: 6904\n",
      "img id in: 6905\n",
      "img id out: 6905\n",
      "img id in: 6906\n",
      "img id out: 6906\n",
      "img id in: 6907\n",
      "img id out: 6907\n",
      "img id in: 6908\n",
      "img id out: 6908\n",
      "img id in: 6909\n",
      "img id out: 6909\n",
      "img id in: 6910\n",
      "img id out: 6910\n",
      "img id in: 6911\n",
      "img id out: 6911\n",
      "img id in: 6912\n",
      "img id out: 6912\n",
      "img id in: 6913\n",
      "img id out: 6913\n",
      "img id in: 6914\n",
      "img id out: 6914\n",
      "img id in: 6915\n",
      "img id out: 6915\n",
      "img id in: 6916\n",
      "img id out: 6916\n",
      "img id in: 6917\n",
      "img id out: 6917\n",
      "img id in: 6918\n",
      "img id out: 6918\n",
      "img id in: 6919\n",
      "img id out: 6919\n",
      "img id in: 6920\n",
      "img id out: 6920\n",
      "img id in: 6921\n",
      "img id out: 6921\n",
      "img id in: 6922\n",
      "img id out: 6922\n",
      "img id in: 6923\n",
      "img id out: 6923\n",
      "img id in: 6924\n",
      "img id out: 6924\n",
      "img id in: 6925\n",
      "img id out: 6925\n",
      "img id in: 6926\n",
      "img id out: 6926\n",
      "img id in: 6927\n",
      "img id out: 6927\n",
      "img id in: 6928\n",
      "img id out: 6928\n",
      "img id in: 6929\n",
      "img id out: 6929\n",
      "img id in: 6930\n",
      "img id out: 6930\n",
      "img id in: 6931\n",
      "img id out: 6931\n",
      "img id in: 6932\n",
      "img id out: 6932\n",
      "img id in: 6933\n",
      "img id out: 6933\n",
      "img id in: 6934\n",
      "img id out: 6934\n",
      "img id in: 6935\n",
      "img id out: 6935\n",
      "img id in: 6936\n",
      "img id out: 6936\n",
      "img id in: 6937\n",
      "img id out: 6937\n",
      "img id in: 6938\n",
      "img id out: 6938\n",
      "img id in: 6939\n",
      "img id out: 6939\n",
      "img id in: 6940\n",
      "img id out: 6940\n",
      "img id in: 6941\n",
      "img id out: 6941\n",
      "img id in: 6942\n",
      "img id out: 6942\n",
      "img id in: 6943\n",
      "img id out: 6943\n",
      "img id in: 6944\n",
      "img id out: 6944\n",
      "img id in: 6945\n",
      "img id out: 6945\n",
      "img id in: 6946\n",
      "img id out: 6946\n",
      "img id in: 6947\n",
      "img id out: 6947\n",
      "img id in: 6948\n",
      "img id out: 6948\n",
      "img id in: 6949\n",
      "img id out: 6949\n",
      "img id in: 6950\n",
      "img id out: 6950\n",
      "img id in: 6951\n",
      "img id out: 6951\n",
      "img id in: 6952\n",
      "img id out: 6952\n",
      "img id in: 6953\n",
      "img id out: 6953\n",
      "img id in: 6954\n",
      "img id out: 6954\n",
      "img id in: 6955\n",
      "img id out: 6955\n",
      "img id in: 6956\n",
      "img id out: 6956\n",
      "img id in: 6957\n",
      "img id out: 6957\n",
      "img id in: 6958\n",
      "img id out: 6958\n",
      "img id in: 6959\n",
      "img id out: 6959\n",
      "img id in: 6960\n",
      "img id out: 6960\n",
      "img id in: 6961\n",
      "img id out: 6961\n",
      "img id in: 6962\n",
      "img id out: 6962\n",
      "img id in: 6963\n",
      "img id out: 6963\n",
      "img id in: 6964\n",
      "img id out: 6964\n",
      "img id in: 6965\n",
      "img id out: 6965\n",
      "img id in: 6966\n",
      "img id out: 6966\n",
      "img id in: 6967\n",
      "img id out: 6967\n",
      "img id in: 6968\n",
      "img id out: 6968\n",
      "img id in: 6969\n",
      "img id out: 6969\n",
      "img id in: 6970\n",
      "img id out: 6970\n",
      "img id in: 6971\n",
      "img id out: 6971\n",
      "img id in: 6972\n",
      "img id out: 6972\n",
      "img id in: 6973\n",
      "img id out: 6973\n",
      "img id in: 6974\n",
      "img id out: 6974\n",
      "img id in: 6975\n",
      "img id out: 6975\n",
      "img id in: 6976\n",
      "img id out: 6976\n",
      "img id in: 6977\n",
      "img id out: 6977\n",
      "img id in: 6978\n",
      "img id out: 6978\n",
      "img id in: 6979\n",
      "img id out: 6979\n",
      "img id in: 6980\n",
      "img id out: 6980\n",
      "img id in: 6981\n",
      "img id out: 6981\n",
      "img id in: 6982\n",
      "img id out: 6982\n",
      "img id in: 6983\n",
      "img id out: 6983\n",
      "img id in: 6984\n",
      "img id out: 6984\n",
      "img id in: 6985\n",
      "img id out: 6985\n",
      "img id in: 6986\n",
      "img id out: 6986\n",
      "img id in: 6987\n",
      "img id out: 6987\n",
      "img id in: 6988\n",
      "img id out: 6988\n",
      "img id in: 6989\n",
      "img id out: 6989\n",
      "img id in: 6990\n",
      "img id out: 6990\n",
      "img id in: 6991\n",
      "img id out: 6991\n",
      "img id in: 6992\n",
      "img id out: 6992\n",
      "img id in: 6993\n",
      "img id out: 6993\n",
      "img id in: 6994\n",
      "img id out: 6994\n",
      "img id in: 6995\n",
      "img id out: 6995\n",
      "img id in: 6996\n",
      "img id out: 6996\n",
      "img id in: 6997\n",
      "img id out: 6997\n",
      "img id in: 6998\n",
      "img id out: 6998\n",
      "img id in: 6999\n",
      "img id out: 6999\n",
      "img id in: 7000\n",
      "img id out: 7000\n",
      "img id in: 7001\n",
      "img id out: 7001\n",
      "img id in: 7002\n",
      "img id out: 7002\n",
      "img id in: 7003\n",
      "img id out: 7003\n",
      "img id in: 7004\n",
      "img id out: 7004\n",
      "img id in: 7005\n",
      "img id out: 7005\n",
      "img id in: 7006\n",
      "img id out: 7006\n",
      "img id in: 7007\n",
      "img id out: 7007\n",
      "img id in: 7008\n",
      "img id out: 7008\n",
      "img id in: 7009\n",
      "img id out: 7009\n",
      "img id in: 7010\n",
      "img id out: 7010\n",
      "img id in: 7011\n",
      "img id out: 7011\n",
      "img id in: 7012\n",
      "img id out: 7012\n",
      "img id in: 7013\n",
      "img id out: 7013\n",
      "img id in: 7014\n",
      "img id out: 7014\n",
      "img id in: 7015\n",
      "img id out: 7015\n",
      "img id in: 7016\n",
      "img id out: 7016\n",
      "img id in: 7017\n",
      "img id out: 7017\n",
      "img id in: 7018\n",
      "img id out: 7018\n",
      "img id in: 7019\n",
      "img id out: 7019\n",
      "img id in: 7020\n",
      "img id out: 7020\n",
      "img id in: 7021\n",
      "img id out: 7021\n",
      "img id in: 7022\n",
      "img id out: 7022\n",
      "img id in: 7023\n",
      "img id out: 7023\n",
      "img id in: 7024\n",
      "img id out: 7024\n",
      "img id in: 7025\n",
      "img id out: 7025\n",
      "img id in: 7026\n",
      "img id out: 7026\n",
      "img id in: 7027\n",
      "img id out: 7027\n",
      "img id in: 7028\n",
      "img id out: 7028\n",
      "img id in: 7029\n",
      "img id out: 7029\n",
      "img id in: 7030\n",
      "img id out: 7030\n",
      "img id in: 7031\n",
      "img id out: 7031\n",
      "img id in: 7032\n",
      "img id out: 7032\n",
      "img id in: 7033\n",
      "img id out: 7033\n",
      "img id in: 7034\n",
      "img id out: 7034\n",
      "img id in: 7035\n",
      "img id out: 7035\n",
      "img id in: 7036\n",
      "img id out: 7036\n",
      "img id in: 7037\n",
      "img id out: 7037\n",
      "img id in: 7038\n",
      "img id out: 7038\n",
      "img id in: 7039\n",
      "img id out: 7039\n",
      "img id in: 7040\n",
      "img id out: 7040\n",
      "img id in: 7041\n",
      "img id out: 7041\n",
      "img id in: 7042\n",
      "img id out: 7042\n",
      "img id in: 7043\n",
      "img id out: 7043\n",
      "img id in: 7044\n",
      "img id out: 7044\n",
      "img id in: 7045\n",
      "img id out: 7045\n",
      "img id in: 7046\n",
      "img id out: 7046\n",
      "img id in: 7047\n",
      "img id out: 7047\n",
      "img id in: 7048\n",
      "img id out: 7048\n",
      "img id in: 7049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 7049\n",
      "img id in: 7050\n",
      "img id out: 7050\n",
      "img id in: 7051\n",
      "img id out: 7051\n",
      "img id in: 7052\n",
      "img id out: 7052\n",
      "img id in: 7053\n",
      "img id out: 7053\n",
      "img id in: 7054\n",
      "img id out: 7054\n",
      "img id in: 7055\n",
      "img id out: 7055\n",
      "img id in: 7056\n",
      "img id out: 7056\n",
      "img id in: 7057\n",
      "img id out: 7057\n",
      "img id in: 7058\n",
      "img id out: 7058\n",
      "img id in: 7059\n",
      "img id out: 7059\n",
      "img id in: 7060\n",
      "img id out: 7060\n",
      "img id in: 7061\n",
      "img id out: 7061\n",
      "img id in: 7062\n",
      "img id out: 7062\n",
      "img id in: 7063\n",
      "img id out: 7063\n",
      "img id in: 7064\n",
      "img id out: 7064\n",
      "img id in: 7065\n",
      "img id out: 7065\n",
      "img id in: 7066\n",
      "img id out: 7066\n",
      "img id in: 7067\n",
      "img id out: 7067\n",
      "img id in: 7068\n",
      "img id out: 7068\n",
      "img id in: 7069\n",
      "img id out: 7069\n",
      "img id in: 7070\n",
      "img id out: 7070\n",
      "img id in: 7071\n",
      "img id out: 7071\n",
      "img id in: 7072\n",
      "img id out: 7072\n",
      "img id in: 7073\n",
      "img id out: 7073\n",
      "img id in: 7074\n",
      "img id out: 7074\n",
      "img id in: 7075\n",
      "img id out: 7075\n",
      "img id in: 7076\n",
      "img id out: 7076\n",
      "img id in: 7077\n",
      "img id out: 7077\n",
      "img id in: 7078\n",
      "img id out: 7078\n",
      "img id in: 7079\n",
      "img id out: 7079\n",
      "img id in: 7080\n",
      "img id out: 7080\n",
      "img id in: 7081\n",
      "img id out: 7081\n",
      "img id in: 7082\n",
      "img id out: 7082\n",
      "img id in: 7083\n",
      "img id out: 7083\n",
      "img id in: 7084\n",
      "img id out: 7084\n",
      "img id in: 7085\n",
      "img id out: 7085\n",
      "img id in: 7086\n",
      "img id out: 7086\n",
      "img id in: 7087\n",
      "img id out: 7087\n",
      "img id in: 7088\n",
      "img id out: 7088\n",
      "img id in: 7089\n",
      "img id out: 7089\n",
      "img id in: 7090\n",
      "img id out: 7090\n",
      "img id in: 7091\n",
      "img id out: 7091\n",
      "img id in: 7092\n",
      "img id out: 7092\n",
      "img id in: 7093\n",
      "img id out: 7093\n",
      "img id in: 7094\n",
      "img id out: 7094\n",
      "img id in: 7095\n",
      "img id out: 7095\n",
      "img id in: 7096\n",
      "img id out: 7096\n",
      "img id in: 7097\n",
      "img id out: 7097\n",
      "img id in: 7098\n",
      "img id out: 7098\n",
      "img id in: 7099\n",
      "img id out: 7099\n",
      "img id in: 7100\n",
      "img id out: 7100\n",
      "img id in: 7101\n",
      "img id out: 7101\n",
      "img id in: 7102\n",
      "img id out: 7102\n",
      "img id in: 7103\n",
      "img id out: 7103\n",
      "img id in: 7104\n",
      "img id out: 7104\n",
      "img id in: 7105\n",
      "img id out: 7105\n",
      "img id in: 7106\n",
      "img id out: 7106\n",
      "img id in: 7107\n",
      "img id out: 7107\n",
      "img id in: 7108\n",
      "img id out: 7108\n",
      "img id in: 7109\n",
      "img id out: 7109\n",
      "img id in: 7110\n",
      "img id out: 7110\n",
      "img id in: 7111\n",
      "img id out: 7111\n",
      "img id in: 7112\n",
      "img id out: 7112\n",
      "img id in: 7113\n",
      "img id out: 7113\n",
      "img id in: 7114\n",
      "img id out: 7114\n",
      "img id in: 7115\n",
      "img id out: 7115\n",
      "img id in: 7116\n",
      "img id out: 7116\n",
      "img id in: 7117\n",
      "img id out: 7117\n",
      "img id in: 7118\n",
      "img id out: 7118\n",
      "img id in: 7119\n",
      "img id out: 7119\n",
      "img id in: 7120\n",
      "img id out: 7120\n",
      "img id in: 7121\n",
      "img id out: 7121\n",
      "img id in: 7122\n",
      "img id out: 7122\n",
      "img id in: 7123\n",
      "img id out: 7123\n",
      "img id in: 7124\n",
      "img id out: 7124\n",
      "img id in: 7125\n",
      "img id out: 7125\n",
      "img id in: 7126\n",
      "img id out: 7126\n",
      "img id in: 7127\n",
      "img id out: 7127\n",
      "img id in: 7128\n",
      "img id out: 7128\n",
      "img id in: 7129\n",
      "img id out: 7129\n",
      "img id in: 7130\n",
      "img id out: 7130\n",
      "img id in: 7131\n",
      "img id out: 7131\n",
      "img id in: 7132\n",
      "img id out: 7132\n",
      "img id in: 7133\n",
      "img id out: 7133\n",
      "img id in: 7134\n",
      "img id out: 7134\n",
      "img id in: 7135\n",
      "img id out: 7135\n",
      "img id in: 7136\n",
      "img id out: 7136\n",
      "img id in: 7137\n",
      "img id out: 7137\n",
      "img id in: 7138\n",
      "img id out: 7138\n",
      "img id in: 7139\n",
      "img id out: 7139\n",
      "img id in: 7140\n",
      "img id out: 7140\n",
      "img id in: 7141\n",
      "img id out: 7141\n",
      "img id in: 7142\n",
      "img id out: 7142\n",
      "img id in: 7143\n",
      "img id out: 7143\n",
      "img id in: 7144\n",
      "img id out: 7144\n",
      "img id in: 7145\n",
      "img id out: 7145\n",
      "img id in: 7146\n",
      "img id out: 7146\n",
      "img id in: 7147\n",
      "img id out: 7147\n",
      "img id in: 7148\n",
      "img id out: 7148\n",
      "img id in: 7149\n",
      "img id out: 7149\n",
      "img id in: 7150\n",
      "img id out: 7150\n",
      "img id in: 7151\n",
      "img id out: 7151\n",
      "img id in: 7152\n",
      "img id out: 7152\n",
      "img id in: 7153\n",
      "img id out: 7153\n",
      "img id in: 7154\n",
      "img id out: 7154\n",
      "img id in: 7155\n",
      "img id out: 7155\n",
      "img id in: 7156\n",
      "img id out: 7156\n",
      "img id in: 7157\n",
      "img id out: 7157\n",
      "img id in: 7158\n",
      "img id out: 7158\n",
      "img id in: 7159\n",
      "img id out: 7159\n",
      "img id in: 7160\n",
      "img id out: 7160\n",
      "img id in: 7161\n",
      "img id out: 7161\n",
      "img id in: 7162\n",
      "img id out: 7162\n",
      "img id in: 7163\n",
      "img id out: 7163\n",
      "img id in: 7164\n",
      "img id out: 7164\n",
      "img id in: 7165\n",
      "img id out: 7165\n",
      "img id in: 7166\n",
      "img id out: 7166\n",
      "img id in: 7167\n",
      "img id out: 7167\n",
      "img id in: 7168\n",
      "img id out: 7168\n",
      "img id in: 7169\n",
      "img id out: 7169\n",
      "img id in: 7170\n",
      "img id out: 7170\n",
      "img id in: 7171\n",
      "img id out: 7171\n",
      "img id in: 7172\n",
      "img id out: 7172\n",
      "img id in: 7173\n",
      "img id out: 7173\n",
      "img id in: 7174\n",
      "img id out: 7174\n",
      "img id in: 7175\n",
      "img id out: 7175\n",
      "img id in: 7176\n",
      "img id out: 7176\n",
      "img id in: 7177\n",
      "img id out: 7177\n",
      "img id in: 7178\n",
      "img id out: 7178\n",
      "img id in: 7179\n",
      "img id out: 7179\n",
      "img id in: 7180\n",
      "img id out: 7180\n",
      "img id in: 7181\n",
      "img id out: 7181\n",
      "img id in: 7182\n",
      "img id out: 7182\n",
      "img id in: 7183\n",
      "img id out: 7183\n",
      "img id in: 7184\n",
      "img id out: 7184\n",
      "img id in: 7185\n",
      "img id out: 7185\n",
      "img id in: 7186\n",
      "img id out: 7186\n",
      "img id in: 7187\n",
      "img id out: 7187\n",
      "img id in: 7188\n",
      "img id out: 7188\n",
      "img id in: 7189\n",
      "img id out: 7189\n",
      "img id in: 7190\n",
      "img id out: 7190\n",
      "img id in: 7191\n",
      "img id out: 7191\n",
      "img id in: 7192\n",
      "img id out: 7192\n",
      "img id in: 7193\n",
      "img id out: 7193\n",
      "img id in: 7194\n",
      "img id out: 7194\n",
      "img id in: 7195\n",
      "img id out: 7195\n",
      "img id in: 7196\n",
      "img id out: 7196\n",
      "img id in: 7197\n",
      "img id out: 7197\n",
      "img id in: 7198\n",
      "img id out: 7198\n",
      "img id in: 7199\n",
      "img id out: 7199\n",
      "img id in: 7200\n",
      "img id out: 7200\n",
      "img id in: 7201\n",
      "img id out: 7201\n",
      "img id in: 7202\n",
      "img id out: 7202\n",
      "img id in: 7203\n",
      "img id out: 7203\n",
      "img id in: 7204\n",
      "img id out: 7204\n",
      "img id in: 7205\n",
      "img id out: 7205\n",
      "img id in: 7206\n",
      "img id out: 7206\n",
      "img id in: 7207\n",
      "img id out: 7207\n",
      "img id in: 7208\n",
      "img id out: 7208\n",
      "img id in: 7209\n",
      "img id out: 7209\n",
      "img id in: 7210\n",
      "img id out: 7210\n",
      "img id in: 7211\n",
      "img id out: 7211\n",
      "img id in: 7212\n",
      "img id out: 7212\n",
      "img id in: 7213\n",
      "img id out: 7213\n",
      "img id in: 7214\n",
      "img id out: 7214\n",
      "img id in: 7215\n",
      "img id out: 7215\n",
      "img id in: 7216\n",
      "img id out: 7216\n",
      "img id in: 7217\n",
      "img id out: 7217\n",
      "img id in: 7218\n",
      "img id out: 7218\n",
      "img id in: 7219\n",
      "img id out: 7219\n",
      "img id in: 7220\n",
      "img id out: 7220\n",
      "img id in: 7221\n",
      "img id out: 7221\n",
      "img id in: 7222\n",
      "img id out: 7222\n",
      "img id in: 7223\n",
      "img id out: 7223\n",
      "img id in: 7224\n",
      "img id out: 7224\n",
      "img id in: 7225\n",
      "img id out: 7225\n",
      "img id in: 7226\n",
      "img id out: 7226\n",
      "img id in: 7227\n",
      "img id out: 7227\n",
      "img id in: 7228\n",
      "img id out: 7228\n",
      "img id in: 7229\n",
      "img id out: 7229\n",
      "img id in: 7230\n",
      "img id out: 7230\n",
      "img id in: 7231\n",
      "img id out: 7231\n",
      "img id in: 7232\n",
      "img id out: 7232\n",
      "img id in: 7233\n",
      "img id out: 7233\n",
      "img id in: 7234\n",
      "img id out: 7234\n",
      "img id in: 7235\n",
      "img id out: 7235\n",
      "img id in: 7236\n",
      "img id out: 7236\n",
      "img id in: 7237\n",
      "img id out: 7237\n",
      "img id in: 7238\n",
      "img id out: 7238\n",
      "img id in: 7239\n",
      "img id out: 7239\n",
      "img id in: 7240\n",
      "img id out: 7240\n",
      "img id in: 7241\n",
      "img id out: 7241\n",
      "img id in: 7242\n",
      "img id out: 7242\n",
      "img id in: 7243\n",
      "img id out: 7243\n",
      "img id in: 7244\n",
      "img id out: 7244\n",
      "img id in: 7245\n",
      "img id out: 7245\n",
      "img id in: 7246\n",
      "img id out: 7246\n",
      "img id in: 7247\n",
      "img id out: 7247\n",
      "img id in: 7248\n",
      "img id out: 7248\n",
      "img id in: 7249\n",
      "img id out: 7249\n",
      "img id in: 7250\n",
      "img id out: 7250\n",
      "img id in: 7251\n",
      "img id out: 7251\n",
      "img id in: 7252\n",
      "img id out: 7252\n",
      "img id in: 7253\n",
      "img id out: 7253\n",
      "img id in: 7254\n",
      "img id out: 7254\n",
      "img id in: 7255\n",
      "img id out: 7255\n",
      "img id in: 7256\n",
      "img id out: 7256\n",
      "img id in: 7257\n",
      "img id out: 7257\n",
      "img id in: 7258\n",
      "img id out: 7258\n",
      "img id in: 7259\n",
      "img id out: 7259\n",
      "img id in: 7260\n",
      "img id out: 7260\n",
      "img id in: 7261\n",
      "img id out: 7261\n",
      "img id in: 7262\n",
      "img id out: 7262\n",
      "img id in: 7263\n",
      "img id out: 7263\n",
      "img id in: 7264\n",
      "img id out: 7264\n",
      "img id in: 7265\n",
      "img id out: 7265\n",
      "img id in: 7266\n",
      "img id out: 7266\n",
      "img id in: 7267\n",
      "img id out: 7267\n",
      "img id in: 7268\n",
      "img id out: 7268\n",
      "img id in: 7269\n",
      "img id out: 7269\n",
      "img id in: 7270\n",
      "img id out: 7270\n",
      "img id in: 7271\n",
      "img id out: 7271\n",
      "img id in: 7272\n",
      "img id out: 7272\n",
      "img id in: 7273\n",
      "img id out: 7273\n",
      "img id in: 7274\n",
      "img id out: 7274\n",
      "img id in: 7275\n",
      "img id out: 7275\n",
      "img id in: 7276\n",
      "img id out: 7276\n",
      "img id in: 7277\n",
      "img id out: 7277\n",
      "img id in: 7278\n",
      "img id out: 7278\n",
      "img id in: 7279\n",
      "img id out: 7279\n",
      "img id in: 7280\n",
      "img id out: 7280\n",
      "img id in: 7281\n",
      "img id out: 7281\n",
      "img id in: 7282\n",
      "img id out: 7282\n",
      "img id in: 7283\n",
      "img id out: 7283\n",
      "img id in: 7284\n",
      "img id out: 7284\n",
      "img id in: 7285\n",
      "img id out: 7285\n",
      "img id in: 7286\n",
      "img id out: 7286\n",
      "img id in: 7287\n",
      "img id out: 7287\n",
      "img id in: 7288\n",
      "img id out: 7288\n",
      "img id in: 7289\n",
      "img id out: 7289\n",
      "img id in: 7290\n",
      "img id out: 7290\n",
      "img id in: 7291\n",
      "img id out: 7291\n",
      "img id in: 7292\n",
      "img id out: 7292\n",
      "img id in: 7293\n",
      "img id out: 7293\n",
      "img id in: 7294\n",
      "img id out: 7294\n",
      "img id in: 7295\n",
      "img id out: 7295\n",
      "img id in: 7296\n",
      "img id out: 7296\n",
      "img id in: 7297\n",
      "img id out: 7297\n",
      "img id in: 7298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 7298\n",
      "img id in: 7299\n",
      "img id out: 7299\n",
      "img id in: 7300\n",
      "img id out: 7300\n",
      "img id in: 7301\n",
      "img id out: 7301\n",
      "img id in: 7302\n",
      "img id out: 7302\n",
      "img id in: 7303\n",
      "img id out: 7303\n",
      "img id in: 7304\n",
      "img id out: 7304\n",
      "img id in: 7305\n",
      "img id out: 7305\n",
      "img id in: 7306\n",
      "img id out: 7306\n",
      "img id in: 7307\n",
      "img id out: 7307\n",
      "img id in: 7308\n",
      "img id out: 7308\n",
      "img id in: 7309\n",
      "img id out: 7309\n",
      "img id in: 7310\n",
      "img id out: 7310\n",
      "img id in: 7311\n",
      "img id out: 7311\n",
      "img id in: 7312\n",
      "img id out: 7312\n",
      "img id in: 7313\n",
      "img id out: 7313\n",
      "img id in: 7314\n",
      "img id out: 7314\n",
      "img id in: 7315\n",
      "img id out: 7315\n",
      "img id in: 7316\n",
      "img id out: 7316\n",
      "img id in: 7317\n",
      "img id out: 7317\n",
      "img id in: 7318\n",
      "img id out: 7318\n",
      "img id in: 7319\n",
      "img id out: 7319\n",
      "img id in: 7320\n",
      "img id out: 7320\n",
      "img id in: 7321\n",
      "img id out: 7321\n",
      "img id in: 7322\n",
      "img id out: 7322\n",
      "img id in: 7323\n",
      "img id out: 7323\n",
      "img id in: 7324\n",
      "img id out: 7324\n",
      "img id in: 7325\n",
      "img id out: 7325\n",
      "img id in: 7326\n",
      "img id out: 7326\n",
      "img id in: 7327\n",
      "img id out: 7327\n",
      "img id in: 7328\n",
      "img id out: 7328\n",
      "img id in: 7329\n",
      "img id out: 7329\n",
      "img id in: 7330\n",
      "img id out: 7330\n",
      "img id in: 7331\n",
      "img id out: 7331\n",
      "img id in: 7332\n",
      "img id out: 7332\n",
      "img id in: 7333\n",
      "img id out: 7333\n",
      "img id in: 7334\n",
      "img id out: 7334\n",
      "img id in: 7335\n",
      "img id out: 7335\n",
      "img id in: 7336\n",
      "img id out: 7336\n",
      "img id in: 7337\n",
      "img id out: 7337\n",
      "img id in: 7338\n",
      "img id out: 7338\n",
      "img id in: 7339\n",
      "img id out: 7339\n",
      "img id in: 7340\n",
      "img id out: 7340\n",
      "img id in: 7341\n",
      "img id out: 7341\n",
      "img id in: 7342\n",
      "img id out: 7342\n",
      "img id in: 7343\n",
      "img id out: 7343\n",
      "img id in: 7344\n",
      "img id out: 7344\n",
      "img id in: 7345\n",
      "img id out: 7345\n",
      "img id in: 7346\n",
      "img id out: 7346\n",
      "img id in: 7347\n",
      "img id out: 7347\n",
      "img id in: 7348\n",
      "img id out: 7348\n",
      "img id in: 7349\n",
      "img id out: 7349\n",
      "img id in: 7350\n",
      "img id out: 7350\n",
      "img id in: 7351\n",
      "img id out: 7351\n",
      "img id in: 7352\n",
      "img id out: 7352\n",
      "img id in: 7353\n",
      "img id out: 7353\n",
      "img id in: 7354\n",
      "img id out: 7354\n",
      "img id in: 7355\n",
      "img id out: 7355\n",
      "img id in: 7356\n",
      "img id out: 7356\n",
      "img id in: 7357\n",
      "img id out: 7357\n",
      "img id in: 7358\n",
      "img id out: 7358\n",
      "img id in: 7359\n",
      "img id out: 7359\n",
      "img id in: 7360\n",
      "img id out: 7360\n",
      "img id in: 7361\n",
      "img id out: 7361\n",
      "img id in: 7362\n",
      "img id out: 7362\n",
      "img id in: 7363\n",
      "img id out: 7363\n",
      "img id in: 7364\n",
      "img id out: 7364\n",
      "img id in: 7365\n",
      "img id out: 7365\n",
      "img id in: 7366\n",
      "img id out: 7366\n",
      "img id in: 7367\n",
      "img id out: 7367\n",
      "img id in: 7368\n",
      "img id out: 7368\n",
      "img id in: 7369\n",
      "img id out: 7369\n",
      "img id in: 7370\n",
      "img id out: 7370\n",
      "img id in: 7371\n",
      "img id out: 7371\n",
      "img id in: 7372\n",
      "img id out: 7372\n",
      "img id in: 7373\n",
      "img id out: 7373\n",
      "img id in: 7374\n",
      "img id out: 7374\n",
      "img id in: 7375\n",
      "img id out: 7375\n",
      "img id in: 7376\n",
      "img id out: 7376\n",
      "img id in: 7377\n",
      "img id out: 7377\n",
      "img id in: 7378\n",
      "img id out: 7378\n",
      "img id in: 7379\n",
      "img id out: 7379\n",
      "img id in: 7380\n",
      "img id out: 7380\n",
      "img id in: 7381\n",
      "img id out: 7381\n",
      "img id in: 7382\n",
      "img id out: 7382\n",
      "img id in: 7383\n",
      "img id out: 7383\n",
      "img id in: 7384\n",
      "img id out: 7384\n",
      "img id in: 7385\n",
      "img id out: 7385\n",
      "img id in: 7386\n",
      "img id out: 7386\n",
      "img id in: 7387\n",
      "img id out: 7387\n",
      "img id in: 7388\n",
      "img id out: 7388\n",
      "img id in: 7389\n",
      "img id out: 7389\n",
      "img id in: 7390\n",
      "img id out: 7390\n",
      "img id in: 7391\n",
      "img id out: 7391\n",
      "img id in: 7392\n",
      "img id out: 7392\n",
      "img id in: 7393\n",
      "img id out: 7393\n",
      "img id in: 7394\n",
      "img id out: 7394\n",
      "img id in: 7395\n",
      "img id out: 7395\n",
      "img id in: 7396\n",
      "img id out: 7396\n",
      "img id in: 7397\n",
      "img id out: 7397\n",
      "img id in: 7398\n",
      "img id out: 7398\n",
      "img id in: 7399\n",
      "img id out: 7399\n",
      "img id in: 7400\n",
      "img id out: 7400\n",
      "img id in: 7401\n",
      "img id out: 7401\n",
      "img id in: 7402\n",
      "img id out: 7402\n",
      "img id in: 7403\n",
      "img id out: 7403\n",
      "img id in: 7404\n",
      "img id out: 7404\n",
      "img id in: 7405\n",
      "img id out: 7405\n",
      "img id in: 7406\n",
      "img id out: 7406\n",
      "img id in: 7407\n",
      "img id out: 7407\n",
      "img id in: 7408\n",
      "img id out: 7408\n",
      "img id in: 7409\n",
      "img id out: 7409\n",
      "img id in: 7410\n",
      "img id out: 7410\n",
      "img id in: 7411\n",
      "img id out: 7411\n",
      "img id in: 7412\n",
      "img id out: 7412\n",
      "img id in: 7413\n",
      "img id out: 7413\n",
      "img id in: 7414\n",
      "img id out: 7414\n",
      "img id in: 7415\n",
      "img id out: 7415\n",
      "img id in: 7416\n",
      "img id out: 7416\n",
      "img id in: 7417\n",
      "img id out: 7417\n",
      "img id in: 7418\n",
      "img id out: 7418\n",
      "img id in: 7419\n",
      "img id out: 7419\n",
      "img id in: 7420\n",
      "img id out: 7420\n",
      "img id in: 7421\n",
      "img id out: 7421\n",
      "img id in: 7422\n",
      "img id out: 7422\n",
      "img id in: 7423\n",
      "img id out: 7423\n",
      "img id in: 7424\n",
      "img id out: 7424\n",
      "img id in: 7425\n",
      "img id out: 7425\n",
      "img id in: 7426\n",
      "img id out: 7426\n",
      "img id in: 7427\n",
      "img id out: 7427\n",
      "img id in: 7428\n",
      "img id out: 7428\n",
      "img id in: 7429\n",
      "img id out: 7429\n",
      "img id in: 7430\n",
      "img id out: 7430\n",
      "img id in: 7431\n",
      "img id out: 7431\n",
      "img id in: 7432\n",
      "img id out: 7432\n",
      "img id in: 7433\n",
      "img id out: 7433\n",
      "img id in: 7434\n",
      "img id out: 7434\n",
      "img id in: 7435\n",
      "img id out: 7435\n",
      "img id in: 7436\n",
      "img id out: 7436\n",
      "img id in: 7437\n",
      "img id out: 7437\n",
      "img id in: 7438\n",
      "img id out: 7438\n",
      "img id in: 7439\n",
      "img id out: 7439\n",
      "img id in: 7440\n",
      "img id out: 7440\n",
      "img id in: 7441\n",
      "img id out: 7441\n",
      "img id in: 7442\n",
      "img id out: 7442\n",
      "img id in: 7443\n",
      "img id out: 7443\n",
      "img id in: 7444\n",
      "img id out: 7444\n",
      "img id in: 7445\n",
      "img id out: 7445\n",
      "img id in: 7446\n",
      "img id out: 7446\n",
      "img id in: 7447\n",
      "img id out: 7447\n",
      "img id in: 7448\n",
      "img id out: 7448\n",
      "img id in: 7449\n",
      "img id out: 7449\n",
      "img id in: 7450\n",
      "img id out: 7450\n",
      "img id in: 7451\n",
      "img id out: 7451\n",
      "img id in: 7452\n",
      "img id out: 7452\n",
      "img id in: 7453\n",
      "img id out: 7453\n",
      "img id in: 7454\n",
      "img id out: 7454\n",
      "img id in: 7455\n",
      "img id out: 7455\n",
      "img id in: 7456\n",
      "img id out: 7456\n",
      "img id in: 7457\n",
      "img id out: 7457\n",
      "img id in: 7458\n",
      "img id out: 7458\n",
      "img id in: 7459\n",
      "img id out: 7459\n",
      "img id in: 7460\n",
      "img id out: 7460\n",
      "img id in: 7461\n",
      "img id out: 7461\n",
      "img id in: 7462\n",
      "img id out: 7462\n",
      "img id in: 7463\n",
      "img id out: 7463\n",
      "img id in: 7464\n",
      "img id out: 7464\n",
      "img id in: 7465\n",
      "img id out: 7465\n",
      "img id in: 7466\n",
      "img id out: 7466\n",
      "img id in: 7467\n",
      "img id out: 7467\n",
      "img id in: 7468\n",
      "img id out: 7468\n",
      "img id in: 7469\n",
      "img id out: 7469\n",
      "img id in: 7470\n",
      "img id out: 7470\n",
      "img id in: 7471\n",
      "img id out: 7471\n",
      "img id in: 7472\n",
      "img id out: 7472\n",
      "img id in: 7473\n",
      "img id out: 7473\n",
      "img id in: 7474\n",
      "img id out: 7474\n",
      "img id in: 7475\n",
      "img id out: 7475\n",
      "img id in: 7476\n",
      "img id out: 7476\n",
      "img id in: 7477\n",
      "img id out: 7477\n",
      "img id in: 7478\n",
      "img id out: 7478\n",
      "img id in: 7479\n",
      "img id out: 7479\n",
      "img id in: 7480\n",
      "img id out: 7480\n",
      "img id in: 7481\n",
      "img id out: 7481\n",
      "img id in: 7482\n",
      "img id out: 7482\n",
      "img id in: 7483\n",
      "img id out: 7483\n",
      "img id in: 7484\n",
      "img id out: 7484\n",
      "img id in: 7485\n",
      "img id out: 7485\n",
      "img id in: 7486\n",
      "img id out: 7486\n",
      "img id in: 7487\n",
      "img id out: 7487\n",
      "img id in: 7488\n",
      "img id out: 7488\n",
      "img id in: 7489\n",
      "img id out: 7489\n",
      "img id in: 7490\n",
      "img id out: 7490\n",
      "img id in: 7491\n",
      "img id out: 7491\n",
      "img id in: 7492\n",
      "img id out: 7492\n",
      "img id in: 7493\n",
      "img id out: 7493\n",
      "img id in: 7494\n",
      "img id out: 7494\n",
      "img id in: 7495\n",
      "img id out: 7495\n",
      "img id in: 7496\n",
      "img id out: 7496\n",
      "img id in: 7497\n",
      "img id out: 7497\n",
      "img id in: 7498\n",
      "img id out: 7498\n",
      "img id in: 7499\n",
      "img id out: 7499\n",
      "img id in: 7500\n",
      "img id out: 7500\n",
      "img id in: 7501\n",
      "img id out: 7501\n",
      "img id in: 7502\n",
      "img id out: 7502\n",
      "img id in: 7503\n",
      "img id out: 7503\n",
      "img id in: 7504\n",
      "img id out: 7504\n",
      "img id in: 7505\n",
      "img id out: 7505\n",
      "img id in: 7506\n",
      "img id out: 7506\n",
      "img id in: 7507\n",
      "img id out: 7507\n",
      "img id in: 7508\n",
      "img id out: 7508\n",
      "img id in: 7509\n",
      "img id out: 7509\n",
      "img id in: 7510\n",
      "img id out: 7510\n",
      "img id in: 7511\n",
      "img id out: 7511\n",
      "img id in: 7512\n",
      "img id out: 7512\n",
      "img id in: 7513\n",
      "img id out: 7513\n",
      "img id in: 7514\n",
      "img id out: 7514\n",
      "img id in: 7515\n",
      "img id out: 7515\n",
      "img id in: 7516\n",
      "img id out: 7516\n",
      "img id in: 7517\n",
      "img id out: 7517\n",
      "img id in: 7518\n",
      "img id out: 7518\n",
      "img id in: 7519\n",
      "img id out: 7519\n",
      "img id in: 7520\n",
      "img id out: 7520\n",
      "img id in: 7521\n",
      "img id out: 7521\n",
      "img id in: 7522\n",
      "img id out: 7522\n",
      "img id in: 7523\n",
      "img id out: 7523\n",
      "img id in: 7524\n",
      "img id out: 7524\n",
      "img id in: 7525\n",
      "img id out: 7525\n",
      "img id in: 7526\n",
      "img id out: 7526\n",
      "img id in: 7527\n",
      "img id out: 7527\n",
      "img id in: 7528\n",
      "img id out: 7528\n",
      "img id in: 7529\n",
      "img id out: 7529\n",
      "img id in: 7530\n",
      "img id out: 7530\n",
      "img id in: 7531\n",
      "img id out: 7531\n",
      "img id in: 7532\n",
      "img id out: 7532\n",
      "img id in: 7533\n",
      "img id out: 7533\n",
      "img id in: 7534\n",
      "img id out: 7534\n",
      "img id in: 7535\n",
      "img id out: 7535\n",
      "img id in: 7536\n",
      "img id out: 7536\n",
      "img id in: 7537\n",
      "img id out: 7537\n",
      "img id in: 7538\n",
      "img id out: 7538\n",
      "img id in: 7539\n",
      "img id out: 7539\n",
      "img id in: 7540\n",
      "img id out: 7540\n",
      "img id in: 7541\n",
      "img id out: 7541\n",
      "img id in: 7542\n",
      "img id out: 7542\n",
      "img id in: 7543\n",
      "img id out: 7543\n",
      "img id in: 7544\n",
      "img id out: 7544\n",
      "img id in: 7545\n",
      "img id out: 7545\n",
      "img id in: 7546\n",
      "img id out: 7546\n",
      "img id in: 7547\n",
      "img id out: 7547\n",
      "img id in: 7548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 7548\n",
      "img id in: 7549\n",
      "img id out: 7549\n",
      "img id in: 7550\n",
      "img id out: 7550\n",
      "img id in: 7551\n",
      "img id out: 7551\n",
      "img id in: 7552\n",
      "img id out: 7552\n",
      "img id in: 7553\n",
      "img id out: 7553\n",
      "img id in: 7554\n",
      "img id out: 7554\n",
      "img id in: 7555\n",
      "img id out: 7555\n",
      "img id in: 7556\n",
      "img id out: 7556\n",
      "img id in: 7557\n",
      "img id out: 7557\n",
      "img id in: 7558\n",
      "img id out: 7558\n",
      "img id in: 7559\n",
      "img id out: 7559\n",
      "img id in: 7560\n",
      "img id out: 7560\n",
      "img id in: 7561\n",
      "img id out: 7561\n",
      "img id in: 7562\n",
      "img id out: 7562\n",
      "img id in: 7563\n",
      "img id out: 7563\n",
      "img id in: 7564\n",
      "img id out: 7564\n",
      "img id in: 7565\n",
      "img id out: 7565\n",
      "img id in: 7566\n",
      "img id out: 7566\n",
      "img id in: 7567\n",
      "img id out: 7567\n",
      "img id in: 7568\n",
      "img id out: 7568\n",
      "img id in: 7569\n",
      "img id out: 7569\n",
      "img id in: 7570\n",
      "img id out: 7570\n",
      "img id in: 7571\n",
      "img id out: 7571\n",
      "img id in: 7572\n",
      "img id out: 7572\n",
      "img id in: 7573\n",
      "img id out: 7573\n",
      "img id in: 7574\n",
      "img id out: 7574\n",
      "img id in: 7575\n",
      "img id out: 7575\n",
      "img id in: 7576\n",
      "img id out: 7576\n",
      "img id in: 7577\n",
      "img id out: 7577\n",
      "img id in: 7578\n",
      "img id out: 7578\n",
      "img id in: 7579\n",
      "img id out: 7579\n",
      "img id in: 7580\n",
      "img id out: 7580\n",
      "img id in: 7581\n",
      "img id out: 7581\n",
      "img id in: 7582\n",
      "img id out: 7582\n",
      "img id in: 7583\n",
      "img id out: 7583\n",
      "img id in: 7584\n",
      "img id out: 7584\n",
      "img id in: 7585\n",
      "img id out: 7585\n",
      "img id in: 7586\n",
      "img id out: 7586\n",
      "img id in: 7587\n",
      "img id out: 7587\n",
      "img id in: 7588\n",
      "img id out: 7588\n",
      "img id in: 7589\n",
      "img id out: 7589\n",
      "img id in: 7590\n",
      "img id out: 7590\n",
      "img id in: 7591\n",
      "img id out: 7591\n",
      "img id in: 7592\n",
      "img id out: 7592\n",
      "img id in: 7593\n",
      "img id out: 7593\n",
      "img id in: 7594\n",
      "img id out: 7594\n",
      "img id in: 7595\n",
      "img id out: 7595\n",
      "img id in: 7596\n",
      "img id out: 7596\n",
      "img id in: 7597\n",
      "img id out: 7597\n",
      "img id in: 7598\n",
      "img id out: 7598\n",
      "img id in: 7599\n",
      "img id out: 7599\n",
      "img id in: 7600\n",
      "img id out: 7600\n",
      "img id in: 7601\n",
      "img id out: 7601\n",
      "img id in: 7602\n",
      "img id out: 7602\n",
      "img id in: 7603\n",
      "img id out: 7603\n",
      "img id in: 7604\n",
      "img id out: 7604\n",
      "img id in: 7605\n",
      "img id out: 7605\n",
      "img id in: 7606\n",
      "img id out: 7606\n",
      "img id in: 7607\n",
      "img id out: 7607\n",
      "img id in: 7608\n",
      "img id out: 7608\n",
      "img id in: 7609\n",
      "img id out: 7609\n",
      "img id in: 7610\n",
      "img id out: 7610\n",
      "img id in: 7611\n",
      "img id out: 7611\n",
      "img id in: 7612\n",
      "img id out: 7612\n",
      "img id in: 7613\n",
      "img id out: 7613\n",
      "img id in: 7614\n",
      "img id out: 7614\n",
      "img id in: 7615\n",
      "img id out: 7615\n",
      "img id in: 7616\n",
      "img id out: 7616\n",
      "img id in: 7617\n",
      "img id out: 7617\n",
      "img id in: 7618\n",
      "img id out: 7618\n",
      "img id in: 7619\n",
      "img id out: 7619\n",
      "img id in: 7620\n",
      "img id out: 7620\n",
      "img id in: 7621\n",
      "img id out: 7621\n",
      "img id in: 7622\n",
      "img id out: 7622\n",
      "img id in: 7623\n",
      "img id out: 7623\n",
      "img id in: 7624\n",
      "img id out: 7624\n",
      "img id in: 7625\n",
      "img id out: 7625\n",
      "img id in: 7626\n",
      "img id out: 7626\n",
      "img id in: 7627\n",
      "img id out: 7627\n",
      "img id in: 7628\n",
      "img id out: 7628\n",
      "img id in: 7629\n",
      "img id out: 7629\n",
      "img id in: 7630\n",
      "img id out: 7630\n",
      "img id in: 7631\n",
      "img id out: 7631\n",
      "img id in: 7632\n",
      "img id out: 7632\n",
      "img id in: 7633\n",
      "img id out: 7633\n",
      "img id in: 7634\n",
      "img id out: 7634\n",
      "img id in: 7635\n",
      "img id out: 7635\n",
      "img id in: 7636\n",
      "img id out: 7636\n",
      "img id in: 7637\n",
      "img id out: 7637\n",
      "img id in: 7638\n",
      "img id out: 7638\n",
      "img id in: 7639\n",
      "img id out: 7639\n",
      "img id in: 7640\n",
      "img id out: 7640\n",
      "img id in: 7641\n",
      "img id out: 7641\n",
      "img id in: 7642\n",
      "img id out: 7642\n",
      "img id in: 7643\n",
      "img id out: 7643\n",
      "img id in: 7644\n",
      "img id out: 7644\n",
      "img id in: 7645\n",
      "img id out: 7645\n",
      "img id in: 7646\n",
      "img id out: 7646\n",
      "img id in: 7647\n",
      "img id out: 7647\n",
      "img id in: 7648\n",
      "img id out: 7648\n",
      "img id in: 7649\n",
      "img id out: 7649\n",
      "img id in: 7650\n",
      "img id out: 7650\n",
      "img id in: 7651\n",
      "img id out: 7651\n",
      "img id in: 7652\n",
      "img id out: 7652\n",
      "img id in: 7653\n",
      "img id out: 7653\n",
      "img id in: 7654\n",
      "img id out: 7654\n",
      "img id in: 7655\n",
      "img id out: 7655\n",
      "img id in: 7656\n",
      "img id out: 7656\n",
      "img id in: 7657\n",
      "img id out: 7657\n",
      "img id in: 7658\n",
      "img id out: 7658\n",
      "img id in: 7659\n",
      "img id out: 7659\n",
      "img id in: 7660\n",
      "img id out: 7660\n",
      "img id in: 7661\n",
      "img id out: 7661\n",
      "img id in: 7662\n",
      "img id out: 7662\n",
      "img id in: 7663\n",
      "img id out: 7663\n",
      "img id in: 7664\n",
      "img id out: 7664\n",
      "img id in: 7665\n",
      "img id out: 7665\n",
      "img id in: 7666\n",
      "img id out: 7666\n",
      "img id in: 7667\n",
      "img id out: 7667\n",
      "img id in: 7668\n",
      "img id out: 7668\n",
      "img id in: 7669\n",
      "img id out: 7669\n",
      "img id in: 7670\n",
      "img id out: 7670\n",
      "img id in: 7671\n",
      "img id out: 7671\n",
      "img id in: 7672\n",
      "img id out: 7672\n",
      "img id in: 7673\n",
      "img id out: 7673\n",
      "img id in: 7674\n",
      "img id out: 7674\n",
      "img id in: 7675\n",
      "img id out: 7675\n",
      "img id in: 7676\n",
      "img id out: 7676\n",
      "img id in: 7677\n",
      "img id out: 7677\n",
      "img id in: 7678\n",
      "img id out: 7678\n",
      "img id in: 7679\n",
      "img id out: 7679\n",
      "img id in: 7680\n",
      "img id out: 7680\n",
      "img id in: 7681\n",
      "img id out: 7681\n",
      "img id in: 7682\n",
      "img id out: 7682\n",
      "img id in: 7683\n",
      "img id out: 7683\n",
      "img id in: 7684\n",
      "img id out: 7684\n",
      "img id in: 7685\n",
      "img id out: 7685\n",
      "img id in: 7686\n",
      "img id out: 7686\n",
      "img id in: 7687\n",
      "img id out: 7687\n",
      "img id in: 7688\n",
      "img id out: 7688\n",
      "img id in: 7689\n",
      "img id out: 7689\n",
      "img id in: 7690\n",
      "img id out: 7690\n",
      "img id in: 7691\n",
      "img id out: 7691\n",
      "img id in: 7692\n",
      "img id out: 7692\n",
      "img id in: 7693\n",
      "img id out: 7693\n",
      "img id in: 7694\n",
      "img id out: 7694\n",
      "img id in: 7695\n",
      "img id out: 7695\n",
      "img id in: 7696\n",
      "img id out: 7696\n",
      "img id in: 7697\n",
      "img id out: 7697\n",
      "img id in: 7698\n",
      "img id out: 7698\n",
      "img id in: 7699\n",
      "img id out: 7699\n",
      "img id in: 7700\n",
      "img id out: 7700\n",
      "img id in: 7701\n",
      "img id out: 7701\n",
      "img id in: 7702\n",
      "img id out: 7702\n",
      "img id in: 7703\n",
      "img id out: 7703\n",
      "img id in: 7704\n",
      "img id out: 7704\n",
      "img id in: 7705\n",
      "img id out: 7705\n",
      "img id in: 7706\n",
      "img id out: 7706\n",
      "img id in: 7707\n",
      "img id out: 7707\n",
      "img id in: 7708\n",
      "img id out: 7708\n",
      "img id in: 7709\n",
      "img id out: 7709\n",
      "img id in: 7710\n",
      "img id out: 7710\n",
      "img id in: 7711\n",
      "img id out: 7711\n",
      "img id in: 7712\n",
      "img id out: 7712\n",
      "img id in: 7713\n",
      "img id out: 7713\n",
      "img id in: 7714\n",
      "img id out: 7714\n",
      "img id in: 7715\n",
      "img id out: 7715\n",
      "img id in: 7716\n",
      "img id out: 7716\n",
      "img id in: 7717\n",
      "img id out: 7717\n",
      "img id in: 7718\n",
      "img id out: 7718\n",
      "img id in: 7719\n",
      "img id out: 7719\n",
      "img id in: 7720\n",
      "img id out: 7720\n",
      "img id in: 7721\n",
      "img id out: 7721\n",
      "img id in: 7722\n",
      "img id out: 7722\n",
      "img id in: 7723\n",
      "img id out: 7723\n",
      "img id in: 7724\n",
      "img id out: 7724\n",
      "img id in: 7725\n",
      "img id out: 7725\n",
      "img id in: 7726\n",
      "img id out: 7726\n",
      "img id in: 7727\n",
      "img id out: 7727\n",
      "img id in: 7728\n",
      "img id out: 7728\n",
      "img id in: 7729\n",
      "img id out: 7729\n",
      "img id in: 7730\n",
      "img id out: 7730\n",
      "img id in: 7731\n",
      "img id out: 7731\n",
      "img id in: 7732\n",
      "img id out: 7732\n",
      "img id in: 7733\n",
      "img id out: 7733\n",
      "img id in: 7734\n",
      "img id out: 7734\n",
      "img id in: 7735\n",
      "img id out: 7735\n",
      "img id in: 7736\n",
      "img id out: 7736\n",
      "img id in: 7737\n",
      "img id out: 7737\n",
      "img id in: 7738\n",
      "img id out: 7738\n",
      "img id in: 7739\n",
      "img id out: 7739\n",
      "img id in: 7740\n",
      "img id out: 7740\n",
      "img id in: 7741\n",
      "img id out: 7741\n",
      "img id in: 7742\n",
      "img id out: 7742\n",
      "img id in: 7743\n",
      "img id out: 7743\n",
      "img id in: 7744\n",
      "img id out: 7744\n",
      "img id in: 7745\n",
      "img id out: 7745\n",
      "img id in: 7746\n",
      "img id out: 7746\n",
      "img id in: 7747\n",
      "img id out: 7747\n",
      "img id in: 7748\n",
      "img id out: 7748\n",
      "img id in: 7749\n",
      "img id out: 7749\n",
      "img id in: 7750\n",
      "img id out: 7750\n",
      "img id in: 7751\n",
      "img id out: 7751\n",
      "img id in: 7752\n",
      "img id out: 7752\n",
      "img id in: 7753\n",
      "img id out: 7753\n",
      "img id in: 7754\n",
      "img id out: 7754\n",
      "img id in: 7755\n",
      "img id out: 7755\n",
      "img id in: 7756\n",
      "img id out: 7756\n",
      "img id in: 7757\n",
      "img id out: 7757\n",
      "img id in: 7758\n",
      "img id out: 7758\n",
      "img id in: 7759\n",
      "img id out: 7759\n",
      "img id in: 7760\n",
      "img id out: 7760\n",
      "img id in: 7761\n",
      "img id out: 7761\n",
      "img id in: 7762\n",
      "img id out: 7762\n",
      "img id in: 7763\n",
      "img id out: 7763\n",
      "img id in: 7764\n",
      "img id out: 7764\n",
      "img id in: 7765\n",
      "img id out: 7765\n",
      "img id in: 7766\n",
      "img id out: 7766\n",
      "img id in: 7767\n",
      "img id out: 7767\n",
      "img id in: 7768\n",
      "img id out: 7768\n",
      "img id in: 7769\n",
      "img id out: 7769\n",
      "img id in: 7770\n",
      "img id out: 7770\n",
      "img id in: 7771\n",
      "img id out: 7771\n",
      "img id in: 7772\n",
      "img id out: 7772\n",
      "img id in: 7773\n",
      "img id out: 7773\n",
      "img id in: 7774\n",
      "img id out: 7774\n",
      "img id in: 7775\n",
      "img id out: 7775\n",
      "img id in: 7776\n",
      "img id out: 7776\n",
      "img id in: 7777\n",
      "img id out: 7777\n",
      "img id in: 7778\n",
      "img id out: 7778\n",
      "img id in: 7779\n",
      "img id out: 7779\n",
      "img id in: 7780\n",
      "img id out: 7780\n",
      "img id in: 7781\n",
      "img id out: 7781\n",
      "img id in: 7782\n",
      "img id out: 7782\n",
      "img id in: 7783\n",
      "img id out: 7783\n",
      "img id in: 7784\n",
      "img id out: 7784\n",
      "img id in: 7785\n",
      "img id out: 7785\n",
      "img id in: 7786\n",
      "img id out: 7786\n",
      "img id in: 7787\n",
      "img id out: 7787\n",
      "img id in: 7788\n",
      "img id out: 7788\n",
      "img id in: 7789\n",
      "img id out: 7789\n",
      "img id in: 7790\n",
      "img id out: 7790\n",
      "img id in: 7791\n",
      "img id out: 7791\n",
      "img id in: 7792\n",
      "img id out: 7792\n",
      "img id in: 7793\n",
      "img id out: 7793\n",
      "img id in: 7794\n",
      "img id out: 7794\n",
      "img id in: 7795\n",
      "img id out: 7795\n",
      "img id in: 7796\n",
      "img id out: 7796\n",
      "img id in: 7797\n",
      "img id out: 7797\n",
      "img id in: 7798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 7798\n",
      "img id in: 7799\n",
      "img id out: 7799\n",
      "img id in: 7800\n",
      "img id out: 7800\n",
      "img id in: 7801\n",
      "img id out: 7801\n",
      "img id in: 7802\n",
      "img id out: 7802\n",
      "img id in: 7803\n",
      "img id out: 7803\n",
      "img id in: 7804\n",
      "img id out: 7804\n",
      "img id in: 7805\n",
      "img id out: 7805\n",
      "img id in: 7806\n",
      "img id out: 7806\n",
      "img id in: 7807\n",
      "img id out: 7807\n",
      "img id in: 7808\n",
      "img id out: 7808\n",
      "img id in: 7809\n",
      "img id out: 7809\n",
      "img id in: 7810\n",
      "img id out: 7810\n",
      "img id in: 7811\n",
      "img id out: 7811\n",
      "img id in: 7812\n",
      "img id out: 7812\n",
      "img id in: 7813\n",
      "img id out: 7813\n",
      "img id in: 7814\n",
      "img id out: 7814\n",
      "img id in: 7815\n",
      "img id out: 7815\n",
      "img id in: 7816\n",
      "img id out: 7816\n",
      "img id in: 7817\n",
      "img id out: 7817\n",
      "img id in: 7818\n",
      "img id out: 7818\n",
      "img id in: 7819\n",
      "img id out: 7819\n",
      "img id in: 7820\n",
      "img id out: 7820\n",
      "img id in: 7821\n",
      "img id out: 7821\n",
      "img id in: 7822\n",
      "img id out: 7822\n",
      "img id in: 7823\n",
      "img id out: 7823\n",
      "img id in: 7824\n",
      "img id out: 7824\n",
      "img id in: 7825\n",
      "img id out: 7825\n",
      "img id in: 7826\n",
      "img id out: 7826\n",
      "img id in: 7827\n",
      "img id out: 7827\n",
      "img id in: 7828\n",
      "img id out: 7828\n",
      "img id in: 7829\n",
      "img id out: 7829\n",
      "img id in: 7830\n",
      "img id out: 7830\n",
      "img id in: 7831\n",
      "img id out: 7831\n",
      "img id in: 7832\n",
      "img id out: 7832\n",
      "img id in: 7833\n",
      "img id out: 7833\n",
      "img id in: 7834\n",
      "img id out: 7834\n",
      "img id in: 7835\n",
      "img id out: 7835\n",
      "img id in: 7836\n",
      "img id out: 7836\n",
      "img id in: 7837\n",
      "img id out: 7837\n",
      "img id in: 7838\n",
      "img id out: 7838\n",
      "img id in: 7839\n",
      "img id out: 7839\n",
      "img id in: 7840\n",
      "img id out: 7840\n",
      "img id in: 7841\n",
      "img id out: 7841\n",
      "img id in: 7842\n",
      "img id out: 7842\n",
      "img id in: 7843\n",
      "img id out: 7843\n",
      "img id in: 7844\n",
      "img id out: 7844\n",
      "img id in: 7845\n",
      "img id out: 7845\n",
      "img id in: 7846\n",
      "img id out: 7846\n",
      "img id in: 7847\n",
      "img id out: 7847\n",
      "img id in: 7848\n",
      "img id out: 7848\n",
      "img id in: 7849\n",
      "img id out: 7849\n",
      "img id in: 7850\n",
      "img id out: 7850\n",
      "img id in: 7851\n",
      "img id out: 7851\n",
      "img id in: 7852\n",
      "img id out: 7852\n",
      "img id in: 7853\n",
      "img id out: 7853\n",
      "img id in: 7854\n",
      "img id out: 7854\n",
      "img id in: 7855\n",
      "img id out: 7855\n",
      "img id in: 7856\n",
      "img id out: 7856\n",
      "img id in: 7857\n",
      "img id out: 7857\n",
      "img id in: 7858\n",
      "img id out: 7858\n",
      "img id in: 7859\n",
      "img id out: 7859\n",
      "img id in: 7860\n",
      "img id out: 7860\n",
      "img id in: 7861\n",
      "img id out: 7861\n",
      "img id in: 7862\n",
      "img id out: 7862\n",
      "img id in: 7863\n",
      "img id out: 7863\n",
      "img id in: 7864\n",
      "img id out: 7864\n",
      "img id in: 7865\n",
      "img id out: 7865\n",
      "img id in: 7866\n",
      "img id out: 7866\n",
      "img id in: 7867\n",
      "img id out: 7867\n",
      "img id in: 7868\n",
      "img id out: 7868\n",
      "img id in: 7869\n",
      "img id out: 7869\n",
      "img id in: 7870\n",
      "img id out: 7870\n",
      "img id in: 7871\n",
      "img id out: 7871\n",
      "img id in: 7872\n",
      "img id out: 7872\n",
      "img id in: 7873\n",
      "img id out: 7873\n",
      "img id in: 7874\n",
      "img id out: 7874\n",
      "img id in: 7875\n",
      "img id out: 7875\n",
      "img id in: 7876\n",
      "img id out: 7876\n",
      "img id in: 7877\n",
      "img id out: 7877\n",
      "img id in: 7878\n",
      "img id out: 7878\n",
      "img id in: 7879\n",
      "img id out: 7879\n",
      "img id in: 7880\n",
      "img id out: 7880\n",
      "img id in: 7881\n",
      "img id out: 7881\n",
      "img id in: 7882\n",
      "img id out: 7882\n",
      "img id in: 7883\n",
      "img id out: 7883\n",
      "img id in: 7884\n",
      "img id out: 7884\n",
      "img id in: 7885\n",
      "img id out: 7885\n",
      "img id in: 7886\n",
      "img id out: 7886\n",
      "img id in: 7887\n",
      "img id out: 7887\n",
      "img id in: 7888\n",
      "img id out: 7888\n",
      "img id in: 7889\n",
      "img id out: 7889\n",
      "img id in: 7890\n",
      "img id out: 7890\n",
      "img id in: 7891\n",
      "img id out: 7891\n",
      "img id in: 7892\n",
      "img id out: 7892\n",
      "img id in: 7893\n",
      "img id out: 7893\n",
      "img id in: 7894\n",
      "img id out: 7894\n",
      "img id in: 7895\n",
      "img id out: 7895\n",
      "img id in: 7896\n",
      "img id out: 7896\n",
      "img id in: 7897\n",
      "img id out: 7897\n",
      "img id in: 7898\n",
      "img id out: 7898\n",
      "img id in: 7899\n",
      "img id out: 7899\n",
      "img id in: 7900\n",
      "img id out: 7900\n",
      "img id in: 7901\n",
      "img id out: 7901\n",
      "img id in: 7902\n",
      "img id out: 7902\n",
      "img id in: 7903\n",
      "img id out: 7903\n",
      "img id in: 7904\n",
      "img id out: 7904\n",
      "img id in: 7905\n",
      "img id out: 7905\n",
      "img id in: 7906\n",
      "img id out: 7906\n",
      "img id in: 7907\n",
      "img id out: 7907\n",
      "img id in: 7908\n",
      "img id out: 7908\n",
      "img id in: 7909\n",
      "img id out: 7909\n",
      "img id in: 7910\n",
      "img id out: 7910\n",
      "img id in: 7911\n",
      "img id out: 7911\n",
      "img id in: 7912\n",
      "img id out: 7912\n",
      "img id in: 7913\n",
      "img id out: 7913\n",
      "img id in: 7914\n",
      "img id out: 7914\n",
      "img id in: 7915\n",
      "img id out: 7915\n",
      "img id in: 7916\n",
      "img id out: 7916\n",
      "img id in: 7917\n",
      "img id out: 7917\n",
      "img id in: 7918\n",
      "img id out: 7918\n",
      "img id in: 7919\n",
      "img id out: 7919\n",
      "img id in: 7920\n",
      "img id out: 7920\n",
      "img id in: 7921\n",
      "img id out: 7921\n",
      "img id in: 7922\n",
      "img id out: 7922\n",
      "img id in: 7923\n",
      "img id out: 7923\n",
      "img id in: 7924\n",
      "img id out: 7924\n",
      "img id in: 7925\n",
      "img id out: 7925\n",
      "img id in: 7926\n",
      "img id out: 7926\n",
      "img id in: 7927\n",
      "img id out: 7927\n",
      "img id in: 7928\n",
      "img id out: 7928\n",
      "img id in: 7929\n",
      "img id out: 7929\n",
      "img id in: 7930\n",
      "img id out: 7930\n",
      "img id in: 7931\n",
      "img id out: 7931\n",
      "img id in: 7932\n",
      "img id out: 7932\n",
      "img id in: 7933\n",
      "img id out: 7933\n",
      "img id in: 7934\n",
      "img id out: 7934\n",
      "img id in: 7935\n",
      "img id out: 7935\n",
      "img id in: 7936\n",
      "img id out: 7936\n",
      "img id in: 7937\n",
      "img id out: 7937\n",
      "img id in: 7938\n",
      "img id out: 7938\n",
      "img id in: 7939\n",
      "img id out: 7939\n",
      "img id in: 7940\n",
      "img id out: 7940\n",
      "img id in: 7941\n",
      "img id out: 7941\n",
      "img id in: 7942\n",
      "img id out: 7942\n",
      "img id in: 7943\n",
      "img id out: 7943\n",
      "img id in: 7944\n",
      "img id out: 7944\n",
      "img id in: 7945\n",
      "img id out: 7945\n",
      "img id in: 7946\n",
      "img id out: 7946\n",
      "img id in: 7947\n",
      "img id out: 7947\n",
      "img id in: 7948\n",
      "img id out: 7948\n",
      "img id in: 7949\n",
      "img id out: 7949\n",
      "img id in: 7950\n",
      "img id out: 7950\n",
      "img id in: 7951\n",
      "img id out: 7951\n",
      "img id in: 7952\n",
      "img id out: 7952\n",
      "img id in: 7953\n",
      "img id out: 7953\n",
      "img id in: 7954\n",
      "img id out: 7954\n",
      "img id in: 7955\n",
      "img id out: 7955\n",
      "img id in: 7956\n",
      "img id out: 7956\n",
      "img id in: 7957\n",
      "img id out: 7957\n",
      "img id in: 7958\n",
      "img id out: 7958\n",
      "img id in: 7959\n",
      "img id out: 7959\n",
      "img id in: 7960\n",
      "img id out: 7960\n",
      "img id in: 7961\n",
      "img id out: 7961\n",
      "img id in: 7962\n",
      "img id out: 7962\n",
      "img id in: 7963\n",
      "img id out: 7963\n",
      "img id in: 7964\n",
      "img id out: 7964\n",
      "img id in: 7965\n",
      "img id out: 7965\n",
      "img id in: 7966\n",
      "img id out: 7966\n",
      "img id in: 7967\n",
      "img id out: 7967\n",
      "img id in: 7968\n",
      "img id out: 7968\n",
      "img id in: 7969\n",
      "img id out: 7969\n",
      "img id in: 7970\n",
      "img id out: 7970\n",
      "img id in: 7971\n",
      "img id out: 7971\n",
      "img id in: 7972\n",
      "img id out: 7972\n",
      "img id in: 7973\n",
      "img id out: 7973\n",
      "img id in: 7974\n",
      "img id out: 7974\n",
      "img id in: 7975\n",
      "img id out: 7975\n",
      "img id in: 7976\n",
      "img id out: 7976\n",
      "img id in: 7977\n",
      "img id out: 7977\n",
      "img id in: 7978\n",
      "img id out: 7978\n",
      "img id in: 7979\n",
      "img id out: 7979\n",
      "img id in: 7980\n",
      "img id out: 7980\n",
      "img id in: 7981\n",
      "img id out: 7981\n",
      "img id in: 7982\n",
      "img id out: 7982\n",
      "img id in: 7983\n",
      "img id out: 7983\n",
      "img id in: 7984\n",
      "img id out: 7984\n",
      "img id in: 7985\n",
      "img id out: 7985\n",
      "img id in: 7986\n",
      "img id out: 7986\n",
      "img id in: 7987\n",
      "img id out: 7987\n",
      "img id in: 7988\n",
      "img id out: 7988\n",
      "img id in: 7989\n",
      "img id out: 7989\n",
      "img id in: 7990\n",
      "img id out: 7990\n",
      "img id in: 7991\n",
      "img id out: 7991\n",
      "img id in: 7992\n",
      "img id out: 7992\n",
      "img id in: 7993\n",
      "img id out: 7993\n",
      "img id in: 7994\n",
      "img id out: 7994\n",
      "img id in: 7995\n",
      "img id out: 7995\n",
      "img id in: 7996\n",
      "img id out: 7996\n",
      "img id in: 7997\n",
      "img id out: 7997\n",
      "img id in: 7998\n",
      "img id out: 7998\n",
      "img id in: 7999\n",
      "img id out: 7999\n",
      "img id in: 8000\n",
      "img id out: 8000\n",
      "img id in: 8001\n",
      "img id out: 8001\n",
      "img id in: 8002\n",
      "img id out: 8002\n",
      "img id in: 8003\n",
      "img id out: 8003\n",
      "img id in: 8004\n",
      "img id out: 8004\n",
      "img id in: 8005\n",
      "img id out: 8005\n",
      "img id in: 8006\n",
      "img id out: 8006\n",
      "img id in: 8007\n",
      "img id out: 8007\n",
      "img id in: 8008\n",
      "img id out: 8008\n",
      "img id in: 8009\n",
      "img id out: 8009\n",
      "img id in: 8010\n",
      "img id out: 8010\n",
      "img id in: 8011\n",
      "img id out: 8011\n",
      "img id in: 8012\n",
      "img id out: 8012\n",
      "img id in: 8013\n",
      "img id out: 8013\n",
      "img id in: 8014\n",
      "img id out: 8014\n",
      "img id in: 8015\n",
      "img id out: 8015\n",
      "img id in: 8016\n",
      "img id out: 8016\n",
      "img id in: 8017\n",
      "img id out: 8017\n",
      "img id in: 8018\n",
      "img id out: 8018\n",
      "img id in: 8019\n",
      "img id out: 8019\n",
      "img id in: 8020\n",
      "img id out: 8020\n",
      "img id in: 8021\n",
      "img id out: 8021\n",
      "img id in: 8022\n",
      "img id out: 8022\n",
      "img id in: 8023\n",
      "img id out: 8023\n",
      "img id in: 8024\n",
      "img id out: 8024\n",
      "img id in: 8025\n",
      "img id out: 8025\n",
      "img id in: 8026\n",
      "img id out: 8026\n",
      "img id in: 8027\n",
      "img id out: 8027\n",
      "img id in: 8028\n",
      "img id out: 8028\n",
      "img id in: 8029\n",
      "img id out: 8029\n",
      "img id in: 8030\n",
      "img id out: 8030\n",
      "img id in: 8031\n",
      "img id out: 8031\n",
      "img id in: 8032\n",
      "img id out: 8032\n",
      "img id in: 8033\n",
      "img id out: 8033\n",
      "img id in: 8034\n",
      "img id out: 8034\n",
      "img id in: 8035\n",
      "img id out: 8035\n",
      "img id in: 8036\n",
      "img id out: 8036\n",
      "img id in: 8037\n",
      "img id out: 8037\n",
      "img id in: 8038\n",
      "img id out: 8038\n",
      "img id in: 8039\n",
      "img id out: 8039\n",
      "img id in: 8040\n",
      "img id out: 8040\n",
      "img id in: 8041\n",
      "img id out: 8041\n",
      "img id in: 8042\n",
      "img id out: 8042\n",
      "img id in: 8043\n",
      "img id out: 8043\n",
      "img id in: 8044\n",
      "img id out: 8044\n",
      "img id in: 8045\n",
      "img id out: 8045\n",
      "img id in: 8046\n",
      "img id out: 8046\n",
      "img id in: 8047\n",
      "img id out: 8047\n",
      "img id in: 8048\n",
      "img id out: 8048\n",
      "img id in: 8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 8049\n",
      "img id in: 8050\n",
      "img id out: 8050\n",
      "img id in: 8051\n",
      "img id out: 8051\n",
      "img id in: 8052\n",
      "img id out: 8052\n",
      "img id in: 8053\n",
      "img id out: 8053\n",
      "img id in: 8054\n",
      "img id out: 8054\n",
      "img id in: 8055\n",
      "img id out: 8055\n",
      "img id in: 8056\n",
      "img id out: 8056\n",
      "img id in: 8057\n",
      "img id out: 8057\n",
      "img id in: 8058\n",
      "img id out: 8058\n",
      "img id in: 8059\n",
      "img id out: 8059\n",
      "img id in: 8060\n",
      "img id out: 8060\n",
      "img id in: 8061\n",
      "img id out: 8061\n",
      "img id in: 8062\n",
      "img id out: 8062\n",
      "img id in: 8063\n",
      "img id out: 8063\n",
      "img id in: 8064\n",
      "img id out: 8064\n",
      "img id in: 8065\n",
      "img id out: 8065\n",
      "img id in: 8066\n",
      "img id out: 8066\n",
      "img id in: 8067\n",
      "img id out: 8067\n",
      "img id in: 8068\n",
      "img id out: 8068\n",
      "img id in: 8069\n",
      "img id out: 8069\n",
      "img id in: 8070\n",
      "img id out: 8070\n",
      "img id in: 8071\n",
      "img id out: 8071\n",
      "img id in: 8072\n",
      "img id out: 8072\n",
      "img id in: 8073\n",
      "img id out: 8073\n",
      "img id in: 8074\n",
      "img id out: 8074\n",
      "img id in: 8075\n",
      "img id out: 8075\n",
      "img id in: 8076\n",
      "img id out: 8076\n",
      "img id in: 8077\n",
      "img id out: 8077\n",
      "img id in: 8078\n",
      "img id out: 8078\n",
      "img id in: 8079\n",
      "img id out: 8079\n",
      "img id in: 8080\n",
      "img id out: 8080\n",
      "img id in: 8081\n",
      "img id out: 8081\n",
      "img id in: 8082\n",
      "img id out: 8082\n",
      "img id in: 8083\n",
      "img id out: 8083\n",
      "img id in: 8084\n",
      "img id out: 8084\n",
      "img id in: 8085\n",
      "img id out: 8085\n",
      "img id in: 8086\n",
      "img id out: 8086\n",
      "img id in: 8087\n",
      "img id out: 8087\n",
      "img id in: 8088\n",
      "img id out: 8088\n",
      "img id in: 8089\n",
      "img id out: 8089\n",
      "img id in: 8090\n",
      "img id out: 8090\n",
      "img id in: 8091\n",
      "img id out: 8091\n",
      "img id in: 8092\n",
      "img id out: 8092\n",
      "img id in: 8093\n",
      "img id out: 8093\n",
      "img id in: 8094\n",
      "img id out: 8094\n",
      "img id in: 8095\n",
      "img id out: 8095\n",
      "img id in: 8096\n",
      "img id out: 8096\n",
      "img id in: 8097\n",
      "img id out: 8097\n",
      "img id in: 8098\n",
      "img id out: 8098\n",
      "img id in: 8099\n",
      "img id out: 8099\n",
      "img id in: 8100\n",
      "img id out: 8100\n",
      "img id in: 8101\n",
      "img id out: 8101\n",
      "img id in: 8102\n",
      "img id out: 8102\n",
      "img id in: 8103\n",
      "img id out: 8103\n",
      "img id in: 8104\n",
      "img id out: 8104\n",
      "img id in: 8105\n",
      "img id out: 8105\n",
      "img id in: 8106\n",
      "img id out: 8106\n",
      "img id in: 8107\n",
      "img id out: 8107\n",
      "img id in: 8108\n",
      "img id out: 8108\n",
      "img id in: 8109\n",
      "img id out: 8109\n",
      "img id in: 8110\n",
      "img id out: 8110\n",
      "img id in: 8111\n",
      "img id out: 8111\n",
      "img id in: 8112\n",
      "img id out: 8112\n",
      "img id in: 8113\n",
      "img id out: 8113\n",
      "img id in: 8114\n",
      "img id out: 8114\n",
      "img id in: 8115\n",
      "img id out: 8115\n",
      "img id in: 8116\n",
      "img id out: 8116\n",
      "img id in: 8117\n",
      "img id out: 8117\n",
      "img id in: 8118\n",
      "img id out: 8118\n",
      "img id in: 8119\n",
      "img id out: 8119\n",
      "img id in: 8120\n",
      "img id out: 8120\n",
      "img id in: 8121\n",
      "img id out: 8121\n",
      "img id in: 8122\n",
      "img id out: 8122\n",
      "img id in: 8123\n",
      "img id out: 8123\n",
      "img id in: 8124\n",
      "img id out: 8124\n",
      "img id in: 8125\n",
      "img id out: 8125\n",
      "img id in: 8126\n",
      "img id out: 8126\n",
      "img id in: 8127\n",
      "img id out: 8127\n",
      "img id in: 8128\n",
      "img id out: 8128\n",
      "img id in: 8129\n",
      "img id out: 8129\n",
      "img id in: 8130\n",
      "img id out: 8130\n",
      "img id in: 8131\n",
      "img id out: 8131\n",
      "img id in: 8132\n",
      "img id out: 8132\n",
      "img id in: 8133\n",
      "img id out: 8133\n",
      "img id in: 8134\n",
      "img id out: 8134\n",
      "img id in: 8135\n",
      "img id out: 8135\n",
      "img id in: 8136\n",
      "img id out: 8136\n",
      "img id in: 8137\n",
      "img id out: 8137\n",
      "img id in: 8138\n",
      "img id out: 8138\n",
      "img id in: 8139\n",
      "img id out: 8139\n",
      "img id in: 8140\n",
      "img id out: 8140\n",
      "img id in: 8141\n",
      "img id out: 8141\n",
      "img id in: 8142\n",
      "img id out: 8142\n",
      "img id in: 8143\n",
      "img id out: 8143\n",
      "img id in: 8144\n",
      "img id out: 8144\n",
      "img id in: 8145\n",
      "img id out: 8145\n",
      "img id in: 8146\n",
      "img id out: 8146\n",
      "img id in: 8147\n",
      "img id out: 8147\n",
      "img id in: 8148\n",
      "img id out: 8148\n",
      "img id in: 8149\n",
      "img id out: 8149\n",
      "img id in: 8150\n",
      "img id out: 8150\n",
      "img id in: 8151\n",
      "img id out: 8151\n",
      "img id in: 8152\n",
      "img id out: 8152\n",
      "img id in: 8153\n",
      "img id out: 8153\n",
      "img id in: 8154\n",
      "img id out: 8154\n",
      "img id in: 8155\n",
      "img id out: 8155\n",
      "img id in: 8156\n",
      "img id out: 8156\n",
      "img id in: 8157\n",
      "img id out: 8157\n",
      "img id in: 8158\n",
      "img id out: 8158\n",
      "img id in: 8159\n",
      "img id out: 8159\n",
      "img id in: 8160\n",
      "img id out: 8160\n",
      "img id in: 8161\n",
      "img id out: 8161\n",
      "img id in: 8162\n",
      "img id out: 8162\n",
      "img id in: 8163\n",
      "img id out: 8163\n",
      "img id in: 8164\n",
      "img id out: 8164\n",
      "img id in: 8165\n",
      "img id out: 8165\n",
      "img id in: 8166\n",
      "img id out: 8166\n",
      "img id in: 8167\n",
      "img id out: 8167\n",
      "img id in: 8168\n",
      "img id out: 8168\n",
      "img id in: 8169\n",
      "img id out: 8169\n",
      "img id in: 8170\n",
      "img id out: 8170\n",
      "img id in: 8171\n",
      "img id out: 8171\n",
      "img id in: 8172\n",
      "img id out: 8172\n",
      "img id in: 8173\n",
      "img id out: 8173\n",
      "img id in: 8174\n",
      "img id out: 8174\n",
      "img id in: 8175\n",
      "img id out: 8175\n",
      "img id in: 8176\n",
      "img id out: 8176\n",
      "img id in: 8177\n",
      "img id out: 8177\n",
      "img id in: 8178\n",
      "img id out: 8178\n",
      "img id in: 8179\n",
      "img id out: 8179\n",
      "img id in: 8180\n",
      "img id out: 8180\n",
      "img id in: 8181\n",
      "img id out: 8181\n",
      "img id in: 8182\n",
      "img id out: 8182\n",
      "img id in: 8183\n",
      "img id out: 8183\n",
      "img id in: 8184\n",
      "img id out: 8184\n",
      "img id in: 8185\n",
      "img id out: 8185\n",
      "img id in: 8186\n",
      "img id out: 8186\n",
      "img id in: 8187\n",
      "img id out: 8187\n",
      "img id in: 8188\n",
      "img id out: 8188\n",
      "img id in: 8189\n",
      "img id out: 8189\n",
      "img id in: 8190\n",
      "img id out: 8190\n",
      "img id in: 8191\n",
      "img id out: 8191\n",
      "img id in: 8192\n",
      "img id out: 8192\n",
      "img id in: 8193\n",
      "img id out: 8193\n",
      "img id in: 8194\n",
      "img id out: 8194\n",
      "img id in: 8195\n",
      "img id out: 8195\n",
      "img id in: 8196\n",
      "img id out: 8196\n",
      "img id in: 8197\n",
      "img id out: 8197\n",
      "img id in: 8198\n",
      "img id out: 8198\n",
      "img id in: 8199\n",
      "img id out: 8199\n",
      "img id in: 8200\n",
      "img id out: 8200\n",
      "img id in: 8201\n",
      "img id out: 8201\n",
      "img id in: 8202\n",
      "img id out: 8202\n",
      "img id in: 8203\n",
      "img id out: 8203\n",
      "img id in: 8204\n",
      "img id out: 8204\n",
      "img id in: 8205\n",
      "img id out: 8205\n",
      "img id in: 8206\n",
      "img id out: 8206\n",
      "img id in: 8207\n",
      "img id out: 8207\n",
      "img id in: 8208\n",
      "img id out: 8208\n",
      "img id in: 8209\n",
      "img id out: 8209\n",
      "img id in: 8210\n",
      "img id out: 8210\n",
      "img id in: 8211\n",
      "img id out: 8211\n",
      "img id in: 8212\n",
      "img id out: 8212\n",
      "img id in: 8213\n",
      "img id out: 8213\n",
      "img id in: 8214\n",
      "img id out: 8214\n",
      "img id in: 8215\n",
      "img id out: 8215\n",
      "img id in: 8216\n",
      "img id out: 8216\n",
      "img id in: 8217\n",
      "img id out: 8217\n",
      "img id in: 8218\n",
      "img id out: 8218\n",
      "img id in: 8219\n",
      "img id out: 8219\n",
      "img id in: 8220\n",
      "img id out: 8220\n",
      "img id in: 8221\n",
      "img id out: 8221\n",
      "img id in: 8222\n",
      "img id out: 8222\n",
      "img id in: 8223\n",
      "img id out: 8223\n",
      "img id in: 8224\n",
      "img id out: 8224\n",
      "img id in: 8225\n",
      "img id out: 8225\n",
      "img id in: 8226\n",
      "img id out: 8226\n",
      "img id in: 8227\n",
      "img id out: 8227\n",
      "img id in: 8228\n",
      "img id out: 8228\n",
      "img id in: 8229\n",
      "img id out: 8229\n",
      "img id in: 8230\n",
      "img id out: 8230\n",
      "img id in: 8231\n",
      "img id out: 8231\n",
      "img id in: 8232\n",
      "img id out: 8232\n",
      "img id in: 8233\n",
      "img id out: 8233\n",
      "img id in: 8234\n",
      "img id out: 8234\n",
      "img id in: 8235\n",
      "img id out: 8235\n",
      "img id in: 8236\n",
      "img id out: 8236\n",
      "img id in: 8237\n",
      "img id out: 8237\n",
      "img id in: 8238\n",
      "img id out: 8238\n",
      "img id in: 8239\n",
      "img id out: 8239\n",
      "img id in: 8240\n",
      "img id out: 8240\n",
      "img id in: 8241\n",
      "img id out: 8241\n",
      "img id in: 8242\n",
      "img id out: 8242\n",
      "img id in: 8243\n",
      "img id out: 8243\n",
      "img id in: 8244\n",
      "img id out: 8244\n",
      "img id in: 8245\n",
      "img id out: 8245\n",
      "img id in: 8246\n",
      "img id out: 8246\n",
      "img id in: 8247\n",
      "img id out: 8247\n",
      "img id in: 8248\n",
      "img id out: 8248\n",
      "img id in: 8249\n",
      "img id out: 8249\n",
      "img id in: 8250\n",
      "img id out: 8250\n",
      "img id in: 8251\n",
      "img id out: 8251\n",
      "img id in: 8252\n",
      "img id out: 8252\n",
      "img id in: 8253\n",
      "img id out: 8253\n",
      "img id in: 8254\n",
      "img id out: 8254\n",
      "img id in: 8255\n",
      "img id out: 8255\n",
      "img id in: 8256\n",
      "img id out: 8256\n",
      "img id in: 8257\n",
      "img id out: 8257\n",
      "img id in: 8258\n",
      "img id out: 8258\n",
      "img id in: 8259\n",
      "img id out: 8259\n",
      "img id in: 8260\n",
      "img id out: 8260\n",
      "img id in: 8261\n",
      "img id out: 8261\n",
      "img id in: 8262\n",
      "img id out: 8262\n",
      "img id in: 8263\n",
      "img id out: 8263\n",
      "img id in: 8264\n",
      "img id out: 8264\n",
      "img id in: 8265\n",
      "img id out: 8265\n",
      "img id in: 8266\n",
      "img id out: 8266\n",
      "img id in: 8267\n",
      "img id out: 8267\n",
      "img id in: 8268\n",
      "img id out: 8268\n",
      "img id in: 8269\n",
      "img id out: 8269\n",
      "img id in: 8270\n",
      "img id out: 8270\n",
      "img id in: 8271\n",
      "img id out: 8271\n",
      "img id in: 8272\n",
      "img id out: 8272\n",
      "img id in: 8273\n",
      "img id out: 8273\n",
      "img id in: 8274\n",
      "img id out: 8274\n",
      "img id in: 8275\n",
      "img id out: 8275\n",
      "img id in: 8276\n",
      "img id out: 8276\n",
      "img id in: 8277\n",
      "img id out: 8277\n",
      "img id in: 8278\n",
      "img id out: 8278\n",
      "img id in: 8279\n",
      "img id out: 8279\n",
      "img id in: 8280\n",
      "img id out: 8280\n",
      "img id in: 8281\n",
      "img id out: 8281\n",
      "img id in: 8282\n",
      "img id out: 8282\n",
      "img id in: 8283\n",
      "img id out: 8283\n",
      "img id in: 8284\n",
      "img id out: 8284\n",
      "img id in: 8285\n",
      "img id out: 8285\n",
      "img id in: 8286\n",
      "img id out: 8286\n",
      "img id in: 8287\n",
      "img id out: 8287\n",
      "img id in: 8288\n",
      "img id out: 8288\n",
      "img id in: 8289\n",
      "img id out: 8289\n",
      "img id in: 8290\n",
      "img id out: 8290\n",
      "img id in: 8291\n",
      "img id out: 8291\n",
      "img id in: 8292\n",
      "img id out: 8292\n",
      "img id in: 8293\n",
      "img id out: 8293\n",
      "img id in: 8294\n",
      "img id out: 8294\n",
      "img id in: 8295\n",
      "img id out: 8295\n",
      "img id in: 8296\n",
      "img id out: 8296\n",
      "img id in: 8297\n",
      "img id out: 8297\n",
      "img id in: 8298\n",
      "img id out: 8298\n",
      "img id in: 8299\n",
      "img id out: 8299\n",
      "img id in: 8300\n",
      "img id out: 8300\n",
      "img id in: 8301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 8301\n",
      "img id in: 8302\n",
      "img id out: 8302\n",
      "img id in: 8303\n",
      "img id out: 8303\n",
      "img id in: 8304\n",
      "img id out: 8304\n",
      "img id in: 8305\n",
      "img id out: 8305\n",
      "img id in: 8306\n",
      "img id out: 8306\n",
      "img id in: 8307\n",
      "img id out: 8307\n",
      "img id in: 8308\n",
      "img id out: 8308\n",
      "img id in: 8309\n",
      "img id out: 8309\n",
      "img id in: 8310\n",
      "img id out: 8310\n",
      "img id in: 8311\n",
      "img id out: 8311\n",
      "img id in: 8312\n",
      "img id out: 8312\n",
      "img id in: 8313\n",
      "img id out: 8313\n",
      "img id in: 8314\n",
      "img id out: 8314\n",
      "img id in: 8315\n",
      "img id out: 8315\n",
      "img id in: 8316\n",
      "img id out: 8316\n",
      "img id in: 8317\n",
      "img id out: 8317\n",
      "img id in: 8318\n",
      "img id out: 8318\n",
      "img id in: 8319\n",
      "img id out: 8319\n",
      "img id in: 8320\n",
      "img id out: 8320\n",
      "img id in: 8321\n",
      "img id out: 8321\n",
      "img id in: 8322\n",
      "img id out: 8322\n",
      "img id in: 8323\n",
      "img id out: 8323\n",
      "img id in: 8324\n",
      "img id out: 8324\n",
      "img id in: 8325\n",
      "img id out: 8325\n",
      "img id in: 8326\n",
      "img id out: 8326\n",
      "img id in: 8327\n",
      "img id out: 8327\n",
      "img id in: 8328\n",
      "img id out: 8328\n",
      "img id in: 8329\n",
      "img id out: 8329\n",
      "img id in: 8330\n",
      "img id out: 8330\n",
      "img id in: 8331\n",
      "img id out: 8331\n",
      "img id in: 8332\n",
      "img id out: 8332\n",
      "img id in: 8333\n",
      "img id out: 8333\n",
      "img id in: 8334\n",
      "img id out: 8334\n",
      "img id in: 8335\n",
      "img id out: 8335\n",
      "img id in: 8336\n",
      "img id out: 8336\n",
      "img id in: 8337\n",
      "img id out: 8337\n",
      "img id in: 8338\n",
      "img id out: 8338\n",
      "img id in: 8339\n",
      "img id out: 8339\n",
      "img id in: 8340\n",
      "img id out: 8340\n",
      "img id in: 8341\n",
      "img id out: 8341\n",
      "img id in: 8342\n",
      "img id out: 8342\n",
      "img id in: 8343\n",
      "img id out: 8343\n",
      "img id in: 8344\n",
      "img id out: 8344\n",
      "img id in: 8345\n",
      "img id out: 8345\n",
      "img id in: 8346\n",
      "img id out: 8346\n",
      "img id in: 8347\n",
      "img id out: 8347\n",
      "img id in: 8348\n",
      "img id out: 8348\n",
      "img id in: 8349\n",
      "img id out: 8349\n",
      "img id in: 8350\n",
      "img id out: 8350\n",
      "img id in: 8351\n",
      "img id out: 8351\n",
      "img id in: 8352\n",
      "img id out: 8352\n",
      "img id in: 8353\n",
      "img id out: 8353\n",
      "img id in: 8354\n",
      "img id out: 8354\n",
      "img id in: 8355\n",
      "img id out: 8355\n",
      "img id in: 8356\n",
      "img id out: 8356\n",
      "img id in: 8357\n",
      "img id out: 8357\n",
      "img id in: 8358\n",
      "img id out: 8358\n",
      "img id in: 8359\n",
      "img id out: 8359\n",
      "img id in: 8360\n",
      "img id out: 8360\n",
      "img id in: 8361\n",
      "img id out: 8361\n",
      "img id in: 8362\n",
      "img id out: 8362\n",
      "img id in: 8363\n",
      "img id out: 8363\n",
      "img id in: 8364\n",
      "img id out: 8364\n",
      "img id in: 8365\n",
      "img id out: 8365\n",
      "img id in: 8366\n",
      "img id out: 8366\n",
      "img id in: 8367\n",
      "img id out: 8367\n",
      "img id in: 8368\n",
      "img id out: 8368\n",
      "img id in: 8369\n",
      "img id out: 8369\n",
      "img id in: 8370\n",
      "img id out: 8370\n",
      "img id in: 8371\n",
      "img id out: 8371\n",
      "img id in: 8372\n",
      "img id out: 8372\n",
      "img id in: 8373\n",
      "img id out: 8373\n",
      "img id in: 8374\n",
      "img id out: 8374\n",
      "img id in: 8375\n",
      "img id out: 8375\n",
      "img id in: 8376\n",
      "img id out: 8376\n",
      "img id in: 8377\n",
      "img id out: 8377\n",
      "img id in: 8378\n",
      "img id out: 8378\n",
      "img id in: 8379\n",
      "img id out: 8379\n",
      "img id in: 8380\n",
      "img id out: 8380\n",
      "img id in: 8381\n",
      "img id out: 8381\n",
      "img id in: 8382\n",
      "img id out: 8382\n",
      "img id in: 8383\n",
      "img id out: 8383\n",
      "img id in: 8384\n",
      "img id out: 8384\n",
      "img id in: 8385\n",
      "img id out: 8385\n",
      "img id in: 8386\n",
      "img id out: 8386\n",
      "img id in: 8387\n",
      "img id out: 8387\n",
      "img id in: 8388\n",
      "img id out: 8388\n",
      "img id in: 8389\n",
      "img id out: 8389\n",
      "img id in: 8390\n",
      "img id out: 8390\n",
      "img id in: 8391\n",
      "img id out: 8391\n",
      "img id in: 8392\n",
      "img id out: 8392\n",
      "img id in: 8393\n",
      "img id out: 8393\n",
      "img id in: 8394\n",
      "img id out: 8394\n",
      "img id in: 8395\n",
      "img id out: 8395\n",
      "img id in: 8396\n",
      "img id out: 8396\n",
      "img id in: 8397\n",
      "img id out: 8397\n",
      "img id in: 8398\n",
      "img id out: 8398\n",
      "img id in: 8399\n",
      "img id out: 8399\n",
      "img id in: 8400\n",
      "img id out: 8400\n",
      "img id in: 8401\n",
      "img id out: 8401\n",
      "img id in: 8402\n",
      "img id out: 8402\n",
      "img id in: 8403\n",
      "img id out: 8403\n",
      "img id in: 8404\n",
      "img id out: 8404\n",
      "img id in: 8405\n",
      "img id out: 8405\n",
      "img id in: 8406\n",
      "img id out: 8406\n",
      "img id in: 8407\n",
      "img id out: 8407\n",
      "img id in: 8408\n",
      "img id out: 8408\n",
      "img id in: 8409\n",
      "img id out: 8409\n",
      "img id in: 8410\n",
      "img id out: 8410\n",
      "img id in: 8411\n",
      "img id out: 8411\n",
      "img id in: 8412\n",
      "img id out: 8412\n",
      "img id in: 8413\n",
      "img id out: 8413\n",
      "img id in: 8414\n",
      "img id out: 8414\n",
      "img id in: 8415\n",
      "img id out: 8415\n",
      "img id in: 8416\n",
      "img id out: 8416\n",
      "img id in: 8417\n",
      "img id out: 8417\n",
      "img id in: 8418\n",
      "img id out: 8418\n",
      "img id in: 8419\n",
      "img id out: 8419\n",
      "img id in: 8420\n",
      "img id out: 8420\n",
      "img id in: 8421\n",
      "img id out: 8421\n",
      "img id in: 8422\n",
      "img id out: 8422\n",
      "img id in: 8423\n",
      "img id out: 8423\n",
      "img id in: 8424\n",
      "img id out: 8424\n",
      "img id in: 8425\n",
      "img id out: 8425\n",
      "img id in: 8426\n",
      "img id out: 8426\n",
      "img id in: 8427\n",
      "img id out: 8427\n",
      "img id in: 8428\n",
      "img id out: 8428\n",
      "img id in: 8429\n",
      "img id out: 8429\n",
      "img id in: 8430\n",
      "img id out: 8430\n",
      "img id in: 8431\n",
      "img id out: 8431\n",
      "img id in: 8432\n",
      "img id out: 8432\n",
      "img id in: 8433\n",
      "img id out: 8433\n",
      "img id in: 8434\n",
      "img id out: 8434\n",
      "img id in: 8435\n",
      "img id out: 8435\n",
      "img id in: 8436\n",
      "img id out: 8436\n",
      "img id in: 8437\n",
      "img id out: 8437\n",
      "img id in: 8438\n",
      "img id out: 8438\n",
      "img id in: 8439\n",
      "img id out: 8439\n",
      "img id in: 8440\n",
      "img id out: 8440\n",
      "img id in: 8441\n",
      "img id out: 8441\n",
      "img id in: 8442\n",
      "img id out: 8442\n",
      "img id in: 8443\n",
      "img id out: 8443\n",
      "img id in: 8444\n",
      "img id out: 8444\n",
      "img id in: 8445\n",
      "img id out: 8445\n",
      "img id in: 8446\n",
      "img id out: 8446\n",
      "img id in: 8447\n",
      "img id out: 8447\n",
      "img id in: 8448\n",
      "img id out: 8448\n",
      "img id in: 8449\n",
      "img id out: 8449\n",
      "img id in: 8450\n",
      "img id out: 8450\n",
      "img id in: 8451\n",
      "img id out: 8451\n",
      "img id in: 8452\n",
      "img id out: 8452\n",
      "img id in: 8453\n",
      "img id out: 8453\n",
      "img id in: 8454\n",
      "img id out: 8454\n",
      "img id in: 8455\n",
      "img id out: 8455\n",
      "img id in: 8456\n",
      "img id out: 8456\n",
      "img id in: 8457\n",
      "img id out: 8457\n",
      "img id in: 8458\n",
      "img id out: 8458\n",
      "img id in: 8459\n",
      "img id out: 8459\n",
      "img id in: 8460\n",
      "img id out: 8460\n",
      "img id in: 8461\n",
      "img id out: 8461\n",
      "img id in: 8462\n",
      "img id out: 8462\n",
      "img id in: 8463\n",
      "img id out: 8463\n",
      "img id in: 8464\n",
      "img id out: 8464\n",
      "img id in: 8465\n",
      "img id out: 8465\n",
      "img id in: 8466\n",
      "img id out: 8466\n",
      "img id in: 8467\n",
      "img id out: 8467\n",
      "img id in: 8468\n",
      "img id out: 8468\n",
      "img id in: 8469\n",
      "img id out: 8469\n",
      "img id in: 8470\n",
      "img id out: 8470\n",
      "img id in: 8471\n",
      "img id out: 8471\n",
      "img id in: 8472\n",
      "img id out: 8472\n",
      "img id in: 8473\n",
      "img id out: 8473\n",
      "img id in: 8474\n",
      "img id out: 8474\n",
      "img id in: 8475\n",
      "img id out: 8475\n",
      "img id in: 8476\n",
      "img id out: 8476\n",
      "img id in: 8477\n",
      "img id out: 8477\n",
      "img id in: 8478\n",
      "img id out: 8478\n",
      "img id in: 8479\n",
      "img id out: 8479\n",
      "img id in: 8480\n",
      "img id out: 8480\n",
      "img id in: 8481\n",
      "img id out: 8481\n",
      "img id in: 8482\n",
      "img id out: 8482\n",
      "img id in: 8483\n",
      "img id out: 8483\n",
      "img id in: 8484\n",
      "img id out: 8484\n",
      "img id in: 8485\n",
      "img id out: 8485\n",
      "img id in: 8486\n",
      "img id out: 8486\n",
      "img id in: 8487\n",
      "img id out: 8487\n",
      "img id in: 8488\n",
      "img id out: 8488\n",
      "img id in: 8489\n",
      "img id out: 8489\n",
      "img id in: 8490\n",
      "img id out: 8490\n",
      "img id in: 8491\n",
      "img id out: 8491\n",
      "img id in: 8492\n",
      "img id out: 8492\n",
      "img id in: 8493\n",
      "img id out: 8493\n",
      "img id in: 8494\n",
      "img id out: 8494\n",
      "img id in: 8495\n",
      "img id out: 8495\n",
      "img id in: 8496\n",
      "img id out: 8496\n",
      "img id in: 8497\n",
      "img id out: 8497\n",
      "img id in: 8498\n",
      "img id out: 8498\n",
      "img id in: 8499\n",
      "img id out: 8499\n",
      "img id in: 8500\n",
      "img id out: 8500\n",
      "img id in: 8501\n",
      "img id out: 8501\n",
      "img id in: 8502\n",
      "img id out: 8502\n",
      "img id in: 8503\n",
      "img id out: 8503\n",
      "img id in: 8504\n",
      "img id out: 8504\n",
      "img id in: 8505\n",
      "img id out: 8505\n",
      "img id in: 8506\n",
      "img id out: 8506\n",
      "img id in: 8507\n",
      "img id out: 8507\n",
      "img id in: 8508\n",
      "img id out: 8508\n",
      "img id in: 8509\n",
      "img id out: 8509\n",
      "img id in: 8510\n",
      "img id out: 8510\n",
      "img id in: 8511\n",
      "img id out: 8511\n",
      "img id in: 8512\n",
      "img id out: 8512\n",
      "img id in: 8513\n",
      "img id out: 8513\n",
      "img id in: 8514\n",
      "img id out: 8514\n",
      "img id in: 8515\n",
      "img id out: 8515\n",
      "img id in: 8516\n",
      "img id out: 8516\n",
      "img id in: 8517\n",
      "img id out: 8517\n",
      "img id in: 8518\n",
      "img id out: 8518\n",
      "img id in: 8519\n",
      "img id out: 8519\n",
      "img id in: 8520\n",
      "img id out: 8520\n",
      "img id in: 8521\n",
      "img id out: 8521\n",
      "img id in: 8522\n",
      "img id out: 8522\n",
      "img id in: 8523\n",
      "img id out: 8523\n",
      "img id in: 8524\n",
      "img id out: 8524\n",
      "img id in: 8525\n",
      "img id out: 8525\n",
      "img id in: 8526\n",
      "img id out: 8526\n",
      "img id in: 8527\n",
      "img id out: 8527\n",
      "img id in: 8528\n",
      "img id out: 8528\n",
      "img id in: 8529\n",
      "img id out: 8529\n",
      "img id in: 8530\n",
      "img id out: 8530\n",
      "img id in: 8531\n",
      "img id out: 8531\n",
      "img id in: 8532\n",
      "img id out: 8532\n",
      "img id in: 8533\n",
      "img id out: 8533\n",
      "img id in: 8534\n",
      "img id out: 8534\n",
      "img id in: 8535\n",
      "img id out: 8535\n",
      "img id in: 8536\n",
      "img id out: 8536\n",
      "img id in: 8537\n",
      "img id out: 8537\n",
      "img id in: 8538\n",
      "img id out: 8538\n",
      "img id in: 8539\n",
      "img id out: 8539\n",
      "img id in: 8540\n",
      "img id out: 8540\n",
      "img id in: 8541\n",
      "img id out: 8541\n",
      "img id in: 8542\n",
      "img id out: 8542\n",
      "img id in: 8543\n",
      "img id out: 8543\n",
      "img id in: 8544\n",
      "img id out: 8544\n",
      "img id in: 8545\n",
      "img id out: 8545\n",
      "img id in: 8546\n",
      "img id out: 8546\n",
      "img id in: 8547\n",
      "img id out: 8547\n",
      "img id in: 8548\n",
      "img id out: 8548\n",
      "img id in: 8549\n",
      "img id out: 8549\n",
      "img id in: 8550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 8550\n",
      "img id in: 8551\n",
      "img id out: 8551\n",
      "img id in: 8552\n",
      "img id out: 8552\n",
      "img id in: 8553\n",
      "img id out: 8553\n",
      "img id in: 8554\n",
      "img id out: 8554\n",
      "img id in: 8555\n",
      "img id out: 8555\n",
      "img id in: 8556\n",
      "img id out: 8556\n",
      "img id in: 8557\n",
      "img id out: 8557\n",
      "img id in: 8558\n",
      "img id out: 8558\n",
      "img id in: 8559\n",
      "img id out: 8559\n",
      "img id in: 8560\n",
      "img id out: 8560\n",
      "img id in: 8561\n",
      "img id out: 8561\n",
      "img id in: 8562\n",
      "img id out: 8562\n",
      "img id in: 8563\n",
      "img id out: 8563\n",
      "img id in: 8564\n",
      "img id out: 8564\n",
      "img id in: 8565\n",
      "img id out: 8565\n",
      "img id in: 8566\n",
      "img id out: 8566\n",
      "img id in: 8567\n",
      "img id out: 8567\n",
      "img id in: 8568\n",
      "img id out: 8568\n",
      "img id in: 8569\n",
      "img id out: 8569\n",
      "img id in: 8570\n",
      "img id out: 8570\n",
      "img id in: 8571\n",
      "img id out: 8571\n",
      "img id in: 8572\n",
      "img id out: 8572\n",
      "img id in: 8573\n",
      "img id out: 8573\n",
      "img id in: 8574\n",
      "img id out: 8574\n",
      "img id in: 8575\n",
      "img id out: 8575\n",
      "img id in: 8576\n",
      "img id out: 8576\n",
      "img id in: 8577\n",
      "img id out: 8577\n",
      "img id in: 8578\n",
      "img id out: 8578\n",
      "img id in: 8579\n",
      "img id out: 8579\n",
      "img id in: 8580\n",
      "img id out: 8580\n",
      "img id in: 8581\n",
      "img id out: 8581\n",
      "img id in: 8582\n",
      "img id out: 8582\n",
      "img id in: 8583\n",
      "img id out: 8583\n",
      "img id in: 8584\n",
      "img id out: 8584\n",
      "img id in: 8585\n",
      "img id out: 8585\n",
      "img id in: 8586\n",
      "img id out: 8586\n",
      "img id in: 8587\n",
      "img id out: 8587\n",
      "img id in: 8588\n",
      "img id out: 8588\n",
      "img id in: 8589\n",
      "img id out: 8589\n",
      "img id in: 8590\n",
      "img id out: 8590\n",
      "img id in: 8591\n",
      "img id out: 8591\n",
      "img id in: 8592\n",
      "img id out: 8592\n",
      "img id in: 8593\n",
      "img id out: 8593\n",
      "img id in: 8594\n",
      "img id out: 8594\n",
      "img id in: 8595\n",
      "img id out: 8595\n",
      "img id in: 8596\n",
      "img id out: 8596\n",
      "img id in: 8597\n",
      "img id out: 8597\n",
      "img id in: 8598\n",
      "img id out: 8598\n",
      "img id in: 8599\n",
      "img id out: 8599\n",
      "img id in: 8600\n",
      "img id out: 8600\n",
      "img id in: 8601\n",
      "img id out: 8601\n",
      "img id in: 8602\n",
      "img id out: 8602\n",
      "img id in: 8603\n",
      "img id out: 8603\n",
      "img id in: 8604\n",
      "img id out: 8604\n",
      "img id in: 8605\n",
      "img id out: 8605\n",
      "img id in: 8606\n",
      "img id out: 8606\n",
      "img id in: 8607\n",
      "img id out: 8607\n",
      "img id in: 8608\n",
      "img id out: 8608\n",
      "img id in: 8609\n",
      "img id out: 8609\n",
      "img id in: 8610\n",
      "img id out: 8610\n",
      "img id in: 8611\n",
      "img id out: 8611\n",
      "img id in: 8612\n",
      "img id out: 8612\n",
      "img id in: 8613\n",
      "img id out: 8613\n",
      "img id in: 8614\n",
      "img id out: 8614\n",
      "img id in: 8615\n",
      "img id out: 8615\n",
      "img id in: 8616\n",
      "img id out: 8616\n",
      "img id in: 8617\n",
      "img id out: 8617\n",
      "img id in: 8618\n",
      "img id out: 8618\n",
      "img id in: 8619\n",
      "img id out: 8619\n",
      "img id in: 8620\n",
      "img id out: 8620\n",
      "img id in: 8621\n",
      "img id out: 8621\n",
      "img id in: 8622\n",
      "img id out: 8622\n",
      "img id in: 8623\n",
      "img id out: 8623\n",
      "img id in: 8624\n",
      "img id out: 8624\n",
      "img id in: 8625\n",
      "img id out: 8625\n",
      "img id in: 8626\n",
      "img id out: 8626\n",
      "img id in: 8627\n",
      "img id out: 8627\n",
      "img id in: 8628\n",
      "img id out: 8628\n",
      "img id in: 8629\n",
      "img id out: 8629\n",
      "img id in: 8630\n",
      "img id out: 8630\n",
      "img id in: 8631\n",
      "img id out: 8631\n",
      "img id in: 8632\n",
      "img id out: 8632\n",
      "img id in: 8633\n",
      "img id out: 8633\n",
      "img id in: 8634\n",
      "img id out: 8634\n",
      "img id in: 8635\n",
      "img id out: 8635\n",
      "img id in: 8636\n",
      "img id out: 8636\n",
      "img id in: 8637\n",
      "img id out: 8637\n",
      "img id in: 8638\n",
      "img id out: 8638\n",
      "img id in: 8639\n",
      "img id out: 8639\n",
      "img id in: 8640\n",
      "img id out: 8640\n",
      "img id in: 8641\n",
      "img id out: 8641\n",
      "img id in: 8642\n",
      "img id out: 8642\n",
      "img id in: 8643\n",
      "img id out: 8643\n",
      "img id in: 8644\n",
      "img id out: 8644\n",
      "img id in: 8645\n",
      "img id out: 8645\n",
      "img id in: 8646\n",
      "img id out: 8646\n",
      "img id in: 8647\n",
      "img id out: 8647\n",
      "img id in: 8648\n",
      "img id out: 8648\n",
      "img id in: 8649\n",
      "img id out: 8649\n",
      "img id in: 8650\n",
      "img id out: 8650\n",
      "img id in: 8651\n",
      "img id out: 8651\n",
      "img id in: 8652\n",
      "img id out: 8652\n",
      "img id in: 8653\n",
      "img id out: 8653\n",
      "img id in: 8654\n",
      "img id out: 8654\n",
      "img id in: 8655\n",
      "img id out: 8655\n",
      "img id in: 8656\n",
      "img id out: 8656\n",
      "img id in: 8657\n",
      "img id out: 8657\n",
      "img id in: 8658\n",
      "img id out: 8658\n",
      "img id in: 8659\n",
      "img id out: 8659\n",
      "img id in: 8660\n",
      "img id out: 8660\n",
      "img id in: 8661\n",
      "img id out: 8661\n",
      "img id in: 8662\n",
      "img id out: 8662\n",
      "img id in: 8663\n",
      "img id out: 8663\n",
      "img id in: 8664\n",
      "img id out: 8664\n",
      "img id in: 8665\n",
      "img id out: 8665\n",
      "img id in: 8666\n",
      "img id out: 8666\n",
      "img id in: 8667\n",
      "img id out: 8667\n",
      "img id in: 8668\n",
      "img id out: 8668\n",
      "img id in: 8669\n",
      "img id out: 8669\n",
      "img id in: 8670\n",
      "img id out: 8670\n",
      "img id in: 8671\n",
      "img id out: 8671\n",
      "img id in: 8672\n",
      "img id out: 8672\n",
      "img id in: 8673\n",
      "img id out: 8673\n",
      "img id in: 8674\n",
      "img id out: 8674\n",
      "img id in: 8675\n",
      "img id out: 8675\n",
      "img id in: 8676\n",
      "img id out: 8676\n",
      "img id in: 8677\n",
      "img id out: 8677\n",
      "img id in: 8678\n",
      "img id out: 8678\n",
      "img id in: 8679\n",
      "img id out: 8679\n",
      "img id in: 8680\n",
      "img id out: 8680\n",
      "img id in: 8681\n",
      "img id out: 8681\n",
      "img id in: 8682\n",
      "img id out: 8682\n",
      "img id in: 8683\n",
      "img id out: 8683\n",
      "img id in: 8684\n",
      "img id out: 8684\n",
      "img id in: 8685\n",
      "img id out: 8685\n",
      "img id in: 8686\n",
      "img id out: 8686\n",
      "img id in: 8687\n",
      "img id out: 8687\n",
      "img id in: 8688\n",
      "img id out: 8688\n",
      "img id in: 8689\n",
      "img id out: 8689\n",
      "img id in: 8690\n",
      "img id out: 8690\n",
      "img id in: 8691\n",
      "img id out: 8691\n",
      "img id in: 8692\n",
      "img id out: 8692\n",
      "img id in: 8693\n",
      "img id out: 8693\n",
      "img id in: 8694\n",
      "img id out: 8694\n",
      "img id in: 8695\n",
      "img id out: 8695\n",
      "img id in: 8696\n",
      "img id out: 8696\n",
      "img id in: 8697\n",
      "img id out: 8697\n",
      "img id in: 8698\n",
      "img id out: 8698\n",
      "img id in: 8699\n",
      "img id out: 8699\n",
      "img id in: 8700\n",
      "img id out: 8700\n",
      "img id in: 8701\n",
      "img id out: 8701\n",
      "img id in: 8702\n",
      "img id out: 8702\n",
      "img id in: 8703\n",
      "img id out: 8703\n",
      "img id in: 8704\n",
      "img id out: 8704\n",
      "img id in: 8705\n",
      "img id out: 8705\n",
      "img id in: 8706\n",
      "img id out: 8706\n",
      "img id in: 8707\n",
      "img id out: 8707\n",
      "img id in: 8708\n",
      "img id out: 8708\n",
      "img id in: 8709\n",
      "img id out: 8709\n",
      "img id in: 8710\n",
      "img id out: 8710\n",
      "img id in: 8711\n",
      "img id out: 8711\n",
      "img id in: 8712\n",
      "img id out: 8712\n",
      "img id in: 8713\n",
      "img id out: 8713\n",
      "img id in: 8714\n",
      "img id out: 8714\n",
      "img id in: 8715\n",
      "img id out: 8715\n",
      "img id in: 8716\n",
      "img id out: 8716\n",
      "img id in: 8717\n",
      "img id out: 8717\n",
      "img id in: 8718\n",
      "img id out: 8718\n",
      "img id in: 8719\n",
      "img id out: 8719\n",
      "img id in: 8720\n",
      "img id out: 8720\n",
      "img id in: 8721\n",
      "img id out: 8721\n",
      "img id in: 8722\n",
      "img id out: 8722\n",
      "img id in: 8723\n",
      "img id out: 8723\n",
      "img id in: 8724\n",
      "img id out: 8724\n",
      "img id in: 8725\n",
      "img id out: 8725\n",
      "img id in: 8726\n",
      "img id out: 8726\n",
      "img id in: 8727\n",
      "img id out: 8727\n",
      "img id in: 8728\n",
      "img id out: 8728\n",
      "img id in: 8729\n",
      "img id out: 8729\n",
      "img id in: 8730\n",
      "img id out: 8730\n",
      "img id in: 8731\n",
      "img id out: 8731\n",
      "img id in: 8732\n",
      "img id out: 8732\n",
      "img id in: 8733\n",
      "img id out: 8733\n",
      "img id in: 8734\n",
      "img id out: 8734\n",
      "img id in: 8735\n",
      "img id out: 8735\n",
      "img id in: 8736\n",
      "img id out: 8736\n",
      "img id in: 8737\n",
      "img id out: 8737\n",
      "img id in: 8738\n",
      "img id out: 8738\n",
      "img id in: 8739\n",
      "img id out: 8739\n",
      "img id in: 8740\n",
      "img id out: 8740\n",
      "img id in: 8741\n",
      "img id out: 8741\n",
      "img id in: 8742\n",
      "img id out: 8742\n",
      "img id in: 8743\n",
      "img id out: 8743\n",
      "img id in: 8744\n",
      "img id out: 8744\n",
      "img id in: 8745\n",
      "img id out: 8745\n",
      "img id in: 8746\n",
      "img id out: 8746\n",
      "img id in: 8747\n",
      "img id out: 8747\n",
      "img id in: 8748\n",
      "img id out: 8748\n",
      "img id in: 8749\n",
      "img id out: 8749\n",
      "img id in: 8750\n",
      "img id out: 8750\n",
      "img id in: 8751\n",
      "img id out: 8751\n",
      "img id in: 8752\n",
      "img id out: 8752\n",
      "img id in: 8753\n",
      "img id out: 8753\n",
      "img id in: 8754\n",
      "img id out: 8754\n",
      "img id in: 8755\n",
      "img id out: 8755\n",
      "img id in: 8756\n",
      "img id out: 8756\n",
      "img id in: 8757\n",
      "img id out: 8757\n",
      "img id in: 8758\n",
      "img id out: 8758\n",
      "img id in: 8759\n",
      "img id out: 8759\n",
      "img id in: 8760\n",
      "img id out: 8760\n",
      "img id in: 8761\n",
      "img id out: 8761\n",
      "img id in: 8762\n",
      "img id out: 8762\n",
      "img id in: 8763\n",
      "img id out: 8763\n",
      "img id in: 8764\n",
      "img id out: 8764\n",
      "img id in: 8765\n",
      "img id out: 8765\n",
      "img id in: 8766\n",
      "img id out: 8766\n",
      "img id in: 8767\n",
      "img id out: 8767\n",
      "img id in: 8768\n",
      "img id out: 8768\n",
      "img id in: 8769\n",
      "img id out: 8769\n",
      "img id in: 8770\n",
      "img id out: 8770\n",
      "img id in: 8771\n",
      "img id out: 8771\n",
      "img id in: 8772\n",
      "img id out: 8772\n",
      "img id in: 8773\n",
      "img id out: 8773\n",
      "img id in: 8774\n",
      "img id out: 8774\n",
      "img id in: 8775\n",
      "img id out: 8775\n",
      "img id in: 8776\n",
      "img id out: 8776\n",
      "img id in: 8777\n",
      "img id out: 8777\n",
      "img id in: 8778\n",
      "img id out: 8778\n",
      "img id in: 8779\n",
      "img id out: 8779\n",
      "img id in: 8780\n",
      "img id out: 8780\n",
      "img id in: 8781\n",
      "img id out: 8781\n",
      "img id in: 8782\n",
      "img id out: 8782\n",
      "img id in: 8783\n",
      "img id out: 8783\n",
      "img id in: 8784\n",
      "img id out: 8784\n",
      "img id in: 8785\n",
      "img id out: 8785\n",
      "img id in: 8786\n",
      "img id out: 8786\n",
      "img id in: 8787\n",
      "img id out: 8787\n",
      "img id in: 8788\n",
      "img id out: 8788\n",
      "img id in: 8789\n",
      "img id out: 8789\n",
      "img id in: 8790\n",
      "img id out: 8790\n",
      "img id in: 8791\n",
      "img id out: 8791\n",
      "img id in: 8792\n",
      "img id out: 8792\n",
      "img id in: 8793\n",
      "img id out: 8793\n",
      "img id in: 8794\n",
      "img id out: 8794\n",
      "img id in: 8795\n",
      "img id out: 8795\n",
      "img id in: 8796\n",
      "img id out: 8796\n",
      "img id in: 8797\n",
      "img id out: 8797\n",
      "img id in: 8798\n",
      "img id out: 8798\n",
      "img id in: 8799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 8799\n",
      "img id in: 8800\n",
      "img id out: 8800\n",
      "img id in: 8801\n",
      "img id out: 8801\n",
      "img id in: 8802\n",
      "img id out: 8802\n",
      "img id in: 8803\n",
      "img id out: 8803\n",
      "img id in: 8804\n",
      "img id out: 8804\n",
      "img id in: 8805\n",
      "img id out: 8805\n",
      "img id in: 8806\n",
      "img id out: 8806\n",
      "img id in: 8807\n",
      "img id out: 8807\n",
      "img id in: 8808\n",
      "img id out: 8808\n",
      "img id in: 8809\n",
      "img id out: 8809\n",
      "img id in: 8810\n",
      "img id out: 8810\n",
      "img id in: 8811\n",
      "img id out: 8811\n",
      "img id in: 8812\n",
      "img id out: 8812\n",
      "img id in: 8813\n",
      "img id out: 8813\n",
      "img id in: 8814\n",
      "img id out: 8814\n",
      "img id in: 8815\n",
      "img id out: 8815\n",
      "img id in: 8816\n",
      "img id out: 8816\n",
      "img id in: 8817\n",
      "img id out: 8817\n",
      "img id in: 8818\n",
      "img id out: 8818\n",
      "img id in: 8819\n",
      "img id out: 8819\n",
      "img id in: 8820\n",
      "img id out: 8820\n",
      "img id in: 8821\n",
      "img id out: 8821\n",
      "img id in: 8822\n",
      "img id out: 8822\n",
      "img id in: 8823\n",
      "img id out: 8823\n",
      "img id in: 8824\n",
      "img id out: 8824\n",
      "img id in: 8825\n",
      "img id out: 8825\n",
      "img id in: 8826\n",
      "img id out: 8826\n",
      "img id in: 8827\n",
      "img id out: 8827\n",
      "img id in: 8828\n",
      "img id out: 8828\n",
      "img id in: 8829\n",
      "img id out: 8829\n",
      "img id in: 8830\n",
      "img id out: 8830\n",
      "img id in: 8831\n",
      "img id out: 8831\n",
      "img id in: 8832\n",
      "img id out: 8832\n",
      "img id in: 8833\n",
      "img id out: 8833\n",
      "img id in: 8834\n",
      "img id out: 8834\n",
      "img id in: 8835\n",
      "img id out: 8835\n",
      "img id in: 8836\n",
      "img id out: 8836\n",
      "img id in: 8837\n",
      "img id out: 8837\n",
      "img id in: 8838\n",
      "img id out: 8838\n",
      "img id in: 8839\n",
      "img id out: 8839\n",
      "img id in: 8840\n",
      "img id out: 8840\n",
      "img id in: 8841\n",
      "img id out: 8841\n",
      "img id in: 8842\n",
      "img id out: 8842\n",
      "img id in: 8843\n",
      "img id out: 8843\n",
      "img id in: 8844\n",
      "img id out: 8844\n",
      "img id in: 8845\n",
      "img id out: 8845\n",
      "img id in: 8846\n",
      "img id out: 8846\n",
      "img id in: 8847\n",
      "img id out: 8847\n",
      "img id in: 8848\n",
      "img id out: 8848\n",
      "img id in: 8849\n",
      "img id out: 8849\n",
      "img id in: 8850\n",
      "img id out: 8850\n",
      "img id in: 8851\n",
      "img id out: 8851\n",
      "img id in: 8852\n",
      "img id out: 8852\n",
      "img id in: 8853\n",
      "img id out: 8853\n",
      "img id in: 8854\n",
      "img id out: 8854\n",
      "img id in: 8855\n",
      "img id out: 8855\n",
      "img id in: 8856\n",
      "img id out: 8856\n",
      "img id in: 8857\n",
      "img id out: 8857\n",
      "img id in: 8858\n",
      "img id out: 8858\n",
      "img id in: 8859\n",
      "img id out: 8859\n",
      "img id in: 8860\n",
      "img id out: 8860\n",
      "img id in: 8861\n",
      "img id out: 8861\n",
      "img id in: 8862\n",
      "img id out: 8862\n",
      "img id in: 8863\n",
      "img id out: 8863\n",
      "img id in: 8864\n",
      "img id out: 8864\n",
      "img id in: 8865\n",
      "img id out: 8865\n",
      "img id in: 8866\n",
      "img id out: 8866\n",
      "img id in: 8867\n",
      "img id out: 8867\n",
      "img id in: 8868\n",
      "img id out: 8868\n",
      "img id in: 8869\n",
      "img id out: 8869\n",
      "img id in: 8870\n",
      "img id out: 8870\n",
      "img id in: 8871\n",
      "img id out: 8871\n",
      "img id in: 8872\n",
      "img id out: 8872\n",
      "img id in: 8873\n",
      "img id out: 8873\n",
      "img id in: 8874\n",
      "img id out: 8874\n",
      "img id in: 8875\n",
      "img id out: 8875\n",
      "img id in: 8876\n",
      "img id out: 8876\n",
      "img id in: 8877\n",
      "img id out: 8877\n",
      "img id in: 8878\n",
      "img id out: 8878\n",
      "img id in: 8879\n",
      "img id out: 8879\n",
      "img id in: 8880\n",
      "img id out: 8880\n",
      "img id in: 8881\n",
      "img id out: 8881\n",
      "img id in: 8882\n",
      "img id out: 8882\n",
      "img id in: 8883\n",
      "img id out: 8883\n",
      "img id in: 8884\n",
      "img id out: 8884\n",
      "img id in: 8885\n",
      "img id out: 8885\n",
      "img id in: 8886\n",
      "img id out: 8886\n",
      "img id in: 8887\n",
      "img id out: 8887\n",
      "img id in: 8888\n",
      "img id out: 8888\n",
      "img id in: 8889\n",
      "img id out: 8889\n",
      "img id in: 8890\n",
      "img id out: 8890\n",
      "img id in: 8891\n",
      "img id out: 8891\n",
      "img id in: 8892\n",
      "img id out: 8892\n",
      "img id in: 8893\n",
      "img id out: 8893\n",
      "img id in: 8894\n",
      "img id out: 8894\n",
      "img id in: 8895\n",
      "img id out: 8895\n",
      "img id in: 8896\n",
      "img id out: 8896\n",
      "img id in: 8897\n",
      "img id out: 8897\n",
      "img id in: 8898\n",
      "img id out: 8898\n",
      "img id in: 8899\n",
      "img id out: 8899\n",
      "img id in: 8900\n",
      "img id out: 8900\n",
      "img id in: 8901\n",
      "img id out: 8901\n",
      "img id in: 8902\n",
      "img id out: 8902\n",
      "img id in: 8903\n",
      "img id out: 8903\n",
      "img id in: 8904\n",
      "img id out: 8904\n",
      "img id in: 8905\n",
      "img id out: 8905\n",
      "img id in: 8906\n",
      "img id out: 8906\n",
      "img id in: 8907\n",
      "img id out: 8907\n",
      "img id in: 8908\n",
      "img id out: 8908\n",
      "img id in: 8909\n",
      "img id out: 8909\n",
      "img id in: 8910\n",
      "img id out: 8910\n",
      "img id in: 8911\n",
      "img id out: 8911\n",
      "img id in: 8912\n",
      "img id out: 8912\n",
      "img id in: 8913\n",
      "img id out: 8913\n",
      "img id in: 8914\n",
      "img id out: 8914\n",
      "img id in: 8915\n",
      "img id out: 8915\n",
      "img id in: 8916\n",
      "img id out: 8916\n",
      "img id in: 8917\n",
      "img id out: 8917\n",
      "img id in: 8918\n",
      "img id out: 8918\n",
      "img id in: 8919\n",
      "img id out: 8919\n",
      "img id in: 8920\n",
      "img id out: 8920\n",
      "img id in: 8921\n",
      "img id out: 8921\n",
      "img id in: 8922\n",
      "img id out: 8922\n",
      "img id in: 8923\n",
      "img id out: 8923\n",
      "img id in: 8924\n",
      "img id out: 8924\n",
      "img id in: 8925\n",
      "img id out: 8925\n",
      "img id in: 8926\n",
      "img id out: 8926\n",
      "img id in: 8927\n",
      "img id out: 8927\n",
      "img id in: 8928\n",
      "img id out: 8928\n",
      "img id in: 8929\n",
      "img id out: 8929\n",
      "img id in: 8930\n",
      "img id out: 8930\n",
      "img id in: 8931\n",
      "img id out: 8931\n",
      "img id in: 8932\n",
      "img id out: 8932\n",
      "img id in: 8933\n",
      "img id out: 8933\n",
      "img id in: 8934\n",
      "img id out: 8934\n",
      "img id in: 8935\n",
      "img id out: 8935\n",
      "img id in: 8936\n",
      "img id out: 8936\n",
      "img id in: 8937\n",
      "img id out: 8937\n",
      "img id in: 8938\n",
      "img id out: 8938\n",
      "img id in: 8939\n",
      "img id out: 8939\n",
      "img id in: 8940\n",
      "img id out: 8940\n",
      "img id in: 8941\n",
      "img id out: 8941\n",
      "img id in: 8942\n",
      "img id out: 8942\n",
      "img id in: 8943\n",
      "img id out: 8943\n",
      "img id in: 8944\n",
      "img id out: 8944\n",
      "img id in: 8945\n",
      "img id out: 8945\n",
      "img id in: 8946\n",
      "img id out: 8946\n",
      "img id in: 8947\n",
      "img id out: 8947\n",
      "img id in: 8948\n",
      "img id out: 8948\n",
      "img id in: 8949\n",
      "img id out: 8949\n",
      "img id in: 8950\n",
      "img id out: 8950\n",
      "img id in: 8951\n",
      "img id out: 8951\n",
      "img id in: 8952\n",
      "img id out: 8952\n",
      "img id in: 8953\n",
      "img id out: 8953\n",
      "img id in: 8954\n",
      "img id out: 8954\n",
      "img id in: 8955\n",
      "img id out: 8955\n",
      "img id in: 8956\n",
      "img id out: 8956\n",
      "img id in: 8957\n",
      "img id out: 8957\n",
      "img id in: 8958\n",
      "img id out: 8958\n",
      "img id in: 8959\n",
      "img id out: 8959\n",
      "img id in: 8960\n",
      "img id out: 8960\n",
      "img id in: 8961\n",
      "img id out: 8961\n",
      "img id in: 8962\n",
      "img id out: 8962\n",
      "img id in: 8963\n",
      "img id out: 8963\n",
      "img id in: 8964\n",
      "img id out: 8964\n",
      "img id in: 8965\n",
      "img id out: 8965\n",
      "img id in: 8966\n",
      "img id out: 8966\n",
      "img id in: 8967\n",
      "img id out: 8967\n",
      "img id in: 8968\n",
      "img id out: 8968\n",
      "img id in: 8969\n",
      "img id out: 8969\n",
      "img id in: 8970\n",
      "img id out: 8970\n",
      "img id in: 8971\n",
      "img id out: 8971\n",
      "img id in: 8972\n",
      "img id out: 8972\n",
      "img id in: 8973\n",
      "img id out: 8973\n",
      "img id in: 8974\n",
      "img id out: 8974\n",
      "img id in: 8975\n",
      "img id out: 8975\n",
      "img id in: 8976\n",
      "img id out: 8976\n",
      "img id in: 8977\n",
      "img id out: 8977\n",
      "img id in: 8978\n",
      "img id out: 8978\n",
      "img id in: 8979\n",
      "img id out: 8979\n",
      "img id in: 8980\n",
      "img id out: 8980\n",
      "img id in: 8981\n",
      "img id out: 8981\n",
      "img id in: 8982\n",
      "img id out: 8982\n",
      "img id in: 8983\n",
      "img id out: 8983\n",
      "img id in: 8984\n",
      "img id out: 8984\n",
      "img id in: 8985\n",
      "img id out: 8985\n",
      "img id in: 8986\n",
      "img id out: 8986\n",
      "img id in: 8987\n",
      "img id out: 8987\n",
      "img id in: 8988\n",
      "img id out: 8988\n",
      "img id in: 8989\n",
      "img id out: 8989\n",
      "img id in: 8990\n",
      "img id out: 8990\n",
      "img id in: 8991\n",
      "img id out: 8991\n",
      "img id in: 8992\n",
      "img id out: 8992\n",
      "img id in: 8993\n",
      "img id out: 8993\n",
      "img id in: 8994\n",
      "img id out: 8994\n",
      "img id in: 8995\n",
      "img id out: 8995\n",
      "img id in: 8996\n",
      "img id out: 8996\n",
      "img id in: 8997\n",
      "img id out: 8997\n",
      "img id in: 8998\n",
      "img id out: 8998\n",
      "img id in: 8999\n",
      "img id out: 8999\n",
      "img id in: 9000\n",
      "img id out: 9000\n",
      "img id in: 9001\n",
      "img id out: 9001\n",
      "img id in: 9002\n",
      "img id out: 9002\n",
      "img id in: 9003\n",
      "img id out: 9003\n",
      "img id in: 9004\n",
      "img id out: 9004\n",
      "img id in: 9005\n",
      "img id out: 9005\n",
      "img id in: 9006\n",
      "img id out: 9006\n",
      "img id in: 9007\n",
      "img id out: 9007\n",
      "img id in: 9008\n",
      "img id out: 9008\n",
      "img id in: 9009\n",
      "img id out: 9009\n",
      "img id in: 9010\n",
      "img id out: 9010\n",
      "img id in: 9011\n",
      "img id out: 9011\n",
      "img id in: 9012\n",
      "img id out: 9012\n",
      "img id in: 9013\n",
      "img id out: 9013\n",
      "img id in: 9014\n",
      "img id out: 9014\n",
      "img id in: 9015\n",
      "img id out: 9015\n",
      "img id in: 9016\n",
      "img id out: 9016\n",
      "img id in: 9017\n",
      "img id out: 9017\n",
      "img id in: 9018\n",
      "img id out: 9018\n",
      "img id in: 9019\n",
      "img id out: 9019\n",
      "img id in: 9020\n",
      "img id out: 9020\n",
      "img id in: 9021\n",
      "img id out: 9021\n",
      "img id in: 9022\n",
      "img id out: 9022\n",
      "img id in: 9023\n",
      "img id out: 9023\n",
      "img id in: 9024\n",
      "img id out: 9024\n",
      "img id in: 9025\n",
      "img id out: 9025\n",
      "img id in: 9026\n",
      "img id out: 9026\n",
      "img id in: 9027\n",
      "img id out: 9027\n",
      "img id in: 9028\n",
      "img id out: 9028\n",
      "img id in: 9029\n",
      "img id out: 9029\n",
      "img id in: 9030\n",
      "img id out: 9030\n",
      "img id in: 9031\n",
      "img id out: 9031\n",
      "img id in: 9032\n",
      "img id out: 9032\n",
      "img id in: 9033\n",
      "img id out: 9033\n",
      "img id in: 9034\n",
      "img id out: 9034\n",
      "img id in: 9035\n",
      "img id out: 9035\n",
      "img id in: 9036\n",
      "img id out: 9036\n",
      "img id in: 9037\n",
      "img id out: 9037\n",
      "img id in: 9038\n",
      "img id out: 9038\n",
      "img id in: 9039\n",
      "img id out: 9039\n",
      "img id in: 9040\n",
      "img id out: 9040\n",
      "img id in: 9041\n",
      "img id out: 9041\n",
      "img id in: 9042\n",
      "img id out: 9042\n",
      "img id in: 9043\n",
      "img id out: 9043\n",
      "img id in: 9044\n",
      "img id out: 9044\n",
      "img id in: 9045\n",
      "img id out: 9045\n",
      "img id in: 9046\n",
      "img id out: 9046\n",
      "img id in: 9047\n",
      "img id out: 9047\n",
      "img id in: 9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 9048\n",
      "img id in: 9049\n",
      "img id out: 9049\n",
      "img id in: 9050\n",
      "img id out: 9050\n",
      "img id in: 9051\n",
      "img id out: 9051\n",
      "img id in: 9052\n",
      "img id out: 9052\n",
      "img id in: 9053\n",
      "img id out: 9053\n",
      "img id in: 9054\n",
      "img id out: 9054\n",
      "img id in: 9055\n",
      "img id out: 9055\n",
      "img id in: 9056\n",
      "img id out: 9056\n",
      "img id in: 9057\n",
      "img id out: 9057\n",
      "img id in: 9058\n",
      "img id out: 9058\n",
      "img id in: 9059\n",
      "img id out: 9059\n",
      "img id in: 9060\n",
      "img id out: 9060\n",
      "img id in: 9061\n",
      "img id out: 9061\n",
      "img id in: 9062\n",
      "img id out: 9062\n",
      "img id in: 9063\n",
      "img id out: 9063\n",
      "img id in: 9064\n",
      "img id out: 9064\n",
      "img id in: 9065\n",
      "img id out: 9065\n",
      "img id in: 9066\n",
      "img id out: 9066\n",
      "img id in: 9067\n",
      "img id out: 9067\n",
      "img id in: 9068\n",
      "img id out: 9068\n",
      "img id in: 9069\n",
      "img id out: 9069\n",
      "img id in: 9070\n",
      "img id out: 9070\n",
      "img id in: 9071\n",
      "img id out: 9071\n",
      "img id in: 9072\n",
      "img id out: 9072\n",
      "img id in: 9073\n",
      "img id out: 9073\n",
      "img id in: 9074\n",
      "img id out: 9074\n",
      "img id in: 9075\n",
      "img id out: 9075\n",
      "img id in: 9076\n",
      "img id out: 9076\n",
      "img id in: 9077\n",
      "img id out: 9077\n",
      "img id in: 9078\n",
      "img id out: 9078\n",
      "img id in: 9079\n",
      "img id out: 9079\n",
      "img id in: 9080\n",
      "img id out: 9080\n",
      "img id in: 9081\n",
      "img id out: 9081\n",
      "img id in: 9082\n",
      "img id out: 9082\n",
      "img id in: 9083\n",
      "img id out: 9083\n",
      "img id in: 9084\n",
      "img id out: 9084\n",
      "img id in: 9085\n",
      "img id out: 9085\n",
      "img id in: 9086\n",
      "img id out: 9086\n",
      "img id in: 9087\n",
      "img id out: 9087\n",
      "img id in: 9088\n",
      "img id out: 9088\n",
      "img id in: 9089\n",
      "img id out: 9089\n",
      "img id in: 9090\n",
      "img id out: 9090\n",
      "img id in: 9091\n",
      "img id out: 9091\n",
      "img id in: 9092\n",
      "img id out: 9092\n",
      "img id in: 9093\n",
      "img id out: 9093\n",
      "img id in: 9094\n",
      "img id out: 9094\n",
      "img id in: 9095\n",
      "img id out: 9095\n",
      "img id in: 9096\n",
      "img id out: 9096\n",
      "img id in: 9097\n",
      "img id out: 9097\n",
      "img id in: 9098\n",
      "img id out: 9098\n",
      "img id in: 9099\n",
      "img id out: 9099\n",
      "img id in: 9100\n",
      "img id out: 9100\n",
      "img id in: 9101\n",
      "img id out: 9101\n",
      "img id in: 9102\n",
      "img id out: 9102\n",
      "img id in: 9103\n",
      "img id out: 9103\n",
      "img id in: 9104\n",
      "img id out: 9104\n",
      "img id in: 9105\n",
      "img id out: 9105\n",
      "img id in: 9106\n",
      "img id out: 9106\n",
      "img id in: 9107\n",
      "img id out: 9107\n",
      "img id in: 9108\n",
      "img id out: 9108\n",
      "img id in: 9109\n",
      "img id out: 9109\n",
      "img id in: 9110\n",
      "img id out: 9110\n",
      "img id in: 9111\n",
      "img id out: 9111\n",
      "img id in: 9112\n",
      "img id out: 9112\n",
      "img id in: 9113\n",
      "img id out: 9113\n",
      "img id in: 9114\n",
      "img id out: 9114\n",
      "img id in: 9115\n",
      "img id out: 9115\n",
      "img id in: 9116\n",
      "img id out: 9116\n",
      "img id in: 9117\n",
      "img id out: 9117\n",
      "img id in: 9118\n",
      "img id out: 9118\n",
      "img id in: 9119\n",
      "img id out: 9119\n",
      "img id in: 9120\n",
      "img id out: 9120\n",
      "img id in: 9121\n",
      "img id out: 9121\n",
      "img id in: 9122\n",
      "img id out: 9122\n",
      "img id in: 9123\n",
      "img id out: 9123\n",
      "img id in: 9124\n",
      "img id out: 9124\n",
      "img id in: 9125\n",
      "img id out: 9125\n",
      "img id in: 9126\n",
      "img id out: 9126\n",
      "img id in: 9127\n",
      "img id out: 9127\n",
      "img id in: 9128\n",
      "img id out: 9128\n",
      "img id in: 9129\n",
      "img id out: 9129\n",
      "img id in: 9130\n",
      "img id out: 9130\n",
      "img id in: 9131\n",
      "img id out: 9131\n",
      "img id in: 9132\n",
      "img id out: 9132\n",
      "img id in: 9133\n",
      "img id out: 9133\n",
      "img id in: 9134\n",
      "img id out: 9134\n",
      "img id in: 9135\n",
      "img id out: 9135\n",
      "img id in: 9136\n",
      "img id out: 9136\n",
      "img id in: 9137\n",
      "img id out: 9137\n",
      "img id in: 9138\n",
      "img id out: 9138\n",
      "img id in: 9139\n",
      "img id out: 9139\n",
      "img id in: 9140\n",
      "img id out: 9140\n",
      "img id in: 9141\n",
      "img id out: 9141\n",
      "img id in: 9142\n",
      "img id out: 9142\n",
      "img id in: 9143\n",
      "img id out: 9143\n",
      "img id in: 9144\n",
      "img id out: 9144\n",
      "img id in: 9145\n",
      "img id out: 9145\n",
      "img id in: 9146\n",
      "img id out: 9146\n",
      "img id in: 9147\n",
      "img id out: 9147\n",
      "img id in: 9148\n",
      "img id out: 9148\n",
      "img id in: 9149\n",
      "img id out: 9149\n",
      "img id in: 9150\n",
      "img id out: 9150\n",
      "img id in: 9151\n",
      "img id out: 9151\n",
      "img id in: 9152\n",
      "img id out: 9152\n",
      "img id in: 9153\n",
      "img id out: 9153\n",
      "img id in: 9154\n",
      "img id out: 9154\n",
      "img id in: 9155\n",
      "img id out: 9155\n",
      "img id in: 9156\n",
      "img id out: 9156\n",
      "img id in: 9157\n",
      "img id out: 9157\n",
      "img id in: 9158\n",
      "img id out: 9158\n",
      "img id in: 9159\n",
      "img id out: 9159\n",
      "img id in: 9160\n",
      "img id out: 9160\n",
      "img id in: 9161\n",
      "img id out: 9161\n",
      "img id in: 9162\n",
      "img id out: 9162\n",
      "img id in: 9163\n",
      "img id out: 9163\n",
      "img id in: 9164\n",
      "img id out: 9164\n",
      "img id in: 9165\n",
      "img id out: 9165\n",
      "img id in: 9166\n",
      "img id out: 9166\n",
      "img id in: 9167\n",
      "img id out: 9167\n",
      "img id in: 9168\n",
      "img id out: 9168\n",
      "img id in: 9169\n",
      "img id out: 9169\n",
      "img id in: 9170\n",
      "img id out: 9170\n",
      "img id in: 9171\n",
      "img id out: 9171\n",
      "img id in: 9172\n",
      "img id out: 9172\n",
      "img id in: 9173\n",
      "img id out: 9173\n",
      "img id in: 9174\n",
      "img id out: 9174\n",
      "img id in: 9175\n",
      "img id out: 9175\n",
      "img id in: 9176\n",
      "img id out: 9176\n",
      "img id in: 9177\n",
      "img id out: 9177\n",
      "img id in: 9178\n",
      "img id out: 9178\n",
      "img id in: 9179\n",
      "img id out: 9179\n",
      "img id in: 9180\n",
      "img id out: 9180\n",
      "img id in: 9181\n",
      "img id out: 9181\n",
      "img id in: 9182\n",
      "img id out: 9182\n",
      "img id in: 9183\n",
      "img id out: 9183\n",
      "img id in: 9184\n",
      "img id out: 9184\n",
      "img id in: 9185\n",
      "img id out: 9185\n",
      "img id in: 9186\n",
      "img id out: 9186\n",
      "img id in: 9187\n",
      "img id out: 9187\n",
      "img id in: 9188\n",
      "img id out: 9188\n",
      "img id in: 9189\n",
      "img id out: 9189\n",
      "img id in: 9190\n",
      "img id out: 9190\n",
      "img id in: 9191\n",
      "img id out: 9191\n",
      "img id in: 9192\n",
      "img id out: 9192\n",
      "img id in: 9193\n",
      "img id out: 9193\n",
      "img id in: 9194\n",
      "img id out: 9194\n",
      "img id in: 9195\n",
      "img id out: 9195\n",
      "img id in: 9196\n",
      "img id out: 9196\n",
      "img id in: 9197\n",
      "img id out: 9197\n",
      "img id in: 9198\n",
      "img id out: 9198\n",
      "img id in: 9199\n",
      "img id out: 9199\n",
      "img id in: 9200\n",
      "img id out: 9200\n",
      "img id in: 9201\n",
      "img id out: 9201\n",
      "img id in: 9202\n",
      "img id out: 9202\n",
      "img id in: 9203\n",
      "img id out: 9203\n",
      "img id in: 9204\n",
      "img id out: 9204\n",
      "img id in: 9205\n",
      "img id out: 9205\n",
      "img id in: 9206\n",
      "img id out: 9206\n",
      "img id in: 9207\n",
      "img id out: 9207\n",
      "img id in: 9208\n",
      "img id out: 9208\n",
      "img id in: 9209\n",
      "img id out: 9209\n",
      "img id in: 9210\n",
      "img id out: 9210\n",
      "img id in: 9211\n",
      "img id out: 9211\n",
      "img id in: 9212\n",
      "img id out: 9212\n",
      "img id in: 9213\n",
      "img id out: 9213\n",
      "img id in: 9214\n",
      "img id out: 9214\n",
      "img id in: 9215\n",
      "img id out: 9215\n",
      "img id in: 9216\n",
      "img id out: 9216\n",
      "img id in: 9217\n",
      "img id out: 9217\n",
      "img id in: 9218\n",
      "img id out: 9218\n",
      "img id in: 9219\n",
      "img id out: 9219\n",
      "img id in: 9220\n",
      "img id out: 9220\n",
      "img id in: 9221\n",
      "img id out: 9221\n",
      "img id in: 9222\n",
      "img id out: 9222\n",
      "img id in: 9223\n",
      "img id out: 9223\n",
      "img id in: 9224\n",
      "img id out: 9224\n",
      "img id in: 9225\n",
      "img id out: 9225\n",
      "img id in: 9226\n",
      "img id out: 9226\n",
      "img id in: 9227\n",
      "img id out: 9227\n",
      "img id in: 9228\n",
      "img id out: 9228\n",
      "img id in: 9229\n",
      "img id out: 9229\n",
      "img id in: 9230\n",
      "img id out: 9230\n",
      "img id in: 9231\n",
      "img id out: 9231\n",
      "img id in: 9232\n",
      "img id out: 9232\n",
      "img id in: 9233\n",
      "img id out: 9233\n",
      "img id in: 9234\n",
      "img id out: 9234\n",
      "img id in: 9235\n",
      "img id out: 9235\n",
      "img id in: 9236\n",
      "img id out: 9236\n",
      "img id in: 9237\n",
      "img id out: 9237\n",
      "img id in: 9238\n",
      "img id out: 9238\n",
      "img id in: 9239\n",
      "img id out: 9239\n",
      "img id in: 9240\n",
      "img id out: 9240\n",
      "img id in: 9241\n",
      "img id out: 9241\n",
      "img id in: 9242\n",
      "img id out: 9242\n",
      "img id in: 9243\n",
      "img id out: 9243\n",
      "img id in: 9244\n",
      "img id out: 9244\n",
      "img id in: 9245\n",
      "img id out: 9245\n",
      "img id in: 9246\n",
      "img id out: 9246\n",
      "img id in: 9247\n",
      "img id out: 9247\n",
      "img id in: 9248\n",
      "img id out: 9248\n",
      "img id in: 9249\n",
      "img id out: 9249\n",
      "img id in: 9250\n",
      "img id out: 9250\n",
      "img id in: 9251\n",
      "img id out: 9251\n",
      "img id in: 9252\n",
      "img id out: 9252\n",
      "img id in: 9253\n",
      "img id out: 9253\n",
      "img id in: 9254\n",
      "img id out: 9254\n",
      "img id in: 9255\n",
      "img id out: 9255\n",
      "img id in: 9256\n",
      "img id out: 9256\n",
      "img id in: 9257\n",
      "img id out: 9257\n",
      "img id in: 9258\n",
      "img id out: 9258\n",
      "img id in: 9259\n",
      "img id out: 9259\n",
      "img id in: 9260\n",
      "img id out: 9260\n",
      "img id in: 9261\n",
      "img id out: 9261\n",
      "img id in: 9262\n",
      "img id out: 9262\n",
      "img id in: 9263\n",
      "img id out: 9263\n",
      "img id in: 9264\n",
      "img id out: 9264\n",
      "img id in: 9265\n",
      "img id out: 9265\n",
      "img id in: 9266\n",
      "img id out: 9266\n",
      "img id in: 9267\n",
      "img id out: 9267\n",
      "img id in: 9268\n",
      "img id out: 9268\n",
      "img id in: 9269\n",
      "img id out: 9269\n",
      "img id in: 9270\n",
      "img id out: 9270\n",
      "img id in: 9271\n",
      "img id out: 9271\n",
      "img id in: 9272\n",
      "img id out: 9272\n",
      "img id in: 9273\n",
      "img id out: 9273\n",
      "img id in: 9274\n",
      "img id out: 9274\n",
      "img id in: 9275\n",
      "img id out: 9275\n",
      "img id in: 9276\n",
      "img id out: 9276\n",
      "img id in: 9277\n",
      "img id out: 9277\n",
      "img id in: 9278\n",
      "img id out: 9278\n",
      "img id in: 9279\n",
      "img id out: 9279\n",
      "img id in: 9280\n",
      "img id out: 9280\n",
      "img id in: 9281\n",
      "img id out: 9281\n",
      "img id in: 9282\n",
      "img id out: 9282\n",
      "img id in: 9283\n",
      "img id out: 9283\n",
      "img id in: 9284\n",
      "img id out: 9284\n",
      "img id in: 9285\n",
      "img id out: 9285\n",
      "img id in: 9286\n",
      "img id out: 9286\n",
      "img id in: 9287\n",
      "img id out: 9287\n",
      "img id in: 9288\n",
      "img id out: 9288\n",
      "img id in: 9289\n",
      "img id out: 9289\n",
      "img id in: 9290\n",
      "img id out: 9290\n",
      "img id in: 9291\n",
      "img id out: 9291\n",
      "img id in: 9292\n",
      "img id out: 9292\n",
      "img id in: 9293\n",
      "img id out: 9293\n",
      "img id in: 9294\n",
      "img id out: 9294\n",
      "img id in: 9295\n",
      "img id out: 9295\n",
      "img id in: 9296\n",
      "img id out: 9296\n",
      "img id in: 9297\n",
      "img id out: 9297\n",
      "img id in: 9298\n",
      "img id out: 9298\n",
      "img id in: 9299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 9299\n",
      "img id in: 9300\n",
      "img id out: 9300\n",
      "img id in: 9301\n",
      "img id out: 9301\n",
      "img id in: 9302\n",
      "img id out: 9302\n",
      "img id in: 9303\n",
      "img id out: 9303\n",
      "img id in: 9304\n",
      "img id out: 9304\n",
      "img id in: 9305\n",
      "img id out: 9305\n",
      "img id in: 9306\n",
      "img id out: 9306\n",
      "img id in: 9307\n",
      "img id out: 9307\n",
      "img id in: 9308\n",
      "img id out: 9308\n",
      "img id in: 9309\n",
      "img id out: 9309\n",
      "img id in: 9310\n",
      "img id out: 9310\n",
      "img id in: 9311\n",
      "img id out: 9311\n",
      "img id in: 9312\n",
      "img id out: 9312\n",
      "img id in: 9313\n",
      "img id out: 9313\n",
      "img id in: 9314\n",
      "img id out: 9314\n",
      "img id in: 9315\n",
      "img id out: 9315\n",
      "img id in: 9316\n",
      "img id out: 9316\n",
      "img id in: 9317\n",
      "img id out: 9317\n",
      "img id in: 9318\n",
      "img id out: 9318\n",
      "img id in: 9319\n",
      "img id out: 9319\n",
      "img id in: 9320\n",
      "img id out: 9320\n",
      "img id in: 9321\n",
      "img id out: 9321\n",
      "img id in: 9322\n",
      "img id out: 9322\n",
      "img id in: 9323\n",
      "img id out: 9323\n",
      "img id in: 9324\n",
      "img id out: 9324\n",
      "img id in: 9325\n",
      "img id out: 9325\n",
      "img id in: 9326\n",
      "img id out: 9326\n",
      "img id in: 9327\n",
      "img id out: 9327\n",
      "img id in: 9328\n",
      "img id out: 9328\n",
      "img id in: 9329\n",
      "img id out: 9329\n",
      "img id in: 9330\n",
      "img id out: 9330\n",
      "img id in: 9331\n",
      "img id out: 9331\n",
      "img id in: 9332\n",
      "img id out: 9332\n",
      "img id in: 9333\n",
      "img id out: 9333\n",
      "img id in: 9334\n",
      "img id out: 9334\n",
      "img id in: 9335\n",
      "img id out: 9335\n",
      "img id in: 9336\n",
      "img id out: 9336\n",
      "img id in: 9337\n",
      "img id out: 9337\n",
      "img id in: 9338\n",
      "img id out: 9338\n",
      "img id in: 9339\n",
      "img id out: 9339\n",
      "img id in: 9340\n",
      "img id out: 9340\n",
      "img id in: 9341\n",
      "img id out: 9341\n",
      "img id in: 9342\n",
      "img id out: 9342\n",
      "img id in: 9343\n",
      "img id out: 9343\n",
      "img id in: 9344\n",
      "img id out: 9344\n",
      "img id in: 9345\n",
      "img id out: 9345\n",
      "img id in: 9346\n",
      "img id out: 9346\n",
      "img id in: 9347\n",
      "img id out: 9347\n",
      "img id in: 9348\n",
      "img id out: 9348\n",
      "img id in: 9349\n",
      "img id out: 9349\n",
      "img id in: 9350\n",
      "img id out: 9350\n",
      "img id in: 9351\n",
      "img id out: 9351\n",
      "img id in: 9352\n",
      "img id out: 9352\n",
      "img id in: 9353\n",
      "img id out: 9353\n",
      "img id in: 9354\n",
      "img id out: 9354\n",
      "img id in: 9355\n",
      "img id out: 9355\n",
      "img id in: 9356\n",
      "img id out: 9356\n",
      "img id in: 9357\n",
      "img id out: 9357\n",
      "img id in: 9358\n",
      "img id out: 9358\n",
      "img id in: 9359\n",
      "img id out: 9359\n",
      "img id in: 9360\n",
      "img id out: 9360\n",
      "img id in: 9361\n",
      "img id out: 9361\n",
      "img id in: 9362\n",
      "img id out: 9362\n",
      "img id in: 9363\n",
      "img id out: 9363\n",
      "img id in: 9364\n",
      "img id out: 9364\n",
      "img id in: 9365\n",
      "img id out: 9365\n",
      "img id in: 9366\n",
      "img id out: 9366\n",
      "img id in: 9367\n",
      "img id out: 9367\n",
      "img id in: 9368\n",
      "img id out: 9368\n",
      "img id in: 9369\n",
      "img id out: 9369\n",
      "img id in: 9370\n",
      "img id out: 9370\n",
      "img id in: 9371\n",
      "img id out: 9371\n",
      "img id in: 9372\n",
      "img id out: 9372\n",
      "img id in: 9373\n",
      "img id out: 9373\n",
      "img id in: 9374\n",
      "img id out: 9374\n",
      "img id in: 9375\n",
      "img id out: 9375\n",
      "img id in: 9376\n",
      "img id out: 9376\n",
      "img id in: 9377\n",
      "img id out: 9377\n",
      "img id in: 9378\n",
      "img id out: 9378\n",
      "img id in: 9379\n",
      "img id out: 9379\n",
      "img id in: 9380\n",
      "img id out: 9380\n",
      "img id in: 9381\n",
      "img id out: 9381\n",
      "img id in: 9382\n",
      "img id out: 9382\n",
      "img id in: 9383\n",
      "img id out: 9383\n",
      "img id in: 9384\n",
      "img id out: 9384\n",
      "img id in: 9385\n",
      "img id out: 9385\n",
      "img id in: 9386\n",
      "img id out: 9386\n",
      "img id in: 9387\n",
      "img id out: 9387\n",
      "img id in: 9388\n",
      "img id out: 9388\n",
      "img id in: 9389\n",
      "img id out: 9389\n",
      "img id in: 9390\n",
      "img id out: 9390\n",
      "img id in: 9391\n",
      "img id out: 9391\n",
      "img id in: 9392\n",
      "img id out: 9392\n",
      "img id in: 9393\n",
      "img id out: 9393\n",
      "img id in: 9394\n",
      "img id out: 9394\n",
      "img id in: 9395\n",
      "img id out: 9395\n",
      "img id in: 9396\n",
      "img id out: 9396\n",
      "img id in: 9397\n",
      "img id out: 9397\n",
      "img id in: 9398\n",
      "img id out: 9398\n",
      "img id in: 9399\n",
      "img id out: 9399\n",
      "img id in: 9400\n",
      "img id out: 9400\n",
      "img id in: 9401\n",
      "img id out: 9401\n",
      "img id in: 9402\n",
      "img id out: 9402\n",
      "img id in: 9403\n",
      "img id out: 9403\n",
      "img id in: 9404\n",
      "img id out: 9404\n",
      "img id in: 9405\n",
      "img id out: 9405\n",
      "img id in: 9406\n",
      "img id out: 9406\n",
      "img id in: 9407\n",
      "img id out: 9407\n",
      "img id in: 9408\n",
      "img id out: 9408\n",
      "img id in: 9409\n",
      "img id out: 9409\n",
      "img id in: 9410\n",
      "img id out: 9410\n",
      "img id in: 9411\n",
      "img id out: 9411\n",
      "img id in: 9412\n",
      "img id out: 9412\n",
      "img id in: 9413\n",
      "img id out: 9413\n",
      "img id in: 9414\n",
      "img id out: 9414\n",
      "img id in: 9415\n",
      "img id out: 9415\n",
      "img id in: 9416\n",
      "img id out: 9416\n",
      "img id in: 9417\n",
      "img id out: 9417\n",
      "img id in: 9418\n",
      "img id out: 9418\n",
      "img id in: 9419\n",
      "img id out: 9419\n",
      "img id in: 9420\n",
      "img id out: 9420\n",
      "img id in: 9421\n",
      "img id out: 9421\n",
      "img id in: 9422\n",
      "img id out: 9422\n",
      "img id in: 9423\n",
      "img id out: 9423\n",
      "img id in: 9424\n",
      "img id out: 9424\n",
      "img id in: 9425\n",
      "img id out: 9425\n",
      "img id in: 9426\n",
      "img id out: 9426\n",
      "img id in: 9427\n",
      "img id out: 9427\n",
      "img id in: 9428\n",
      "img id out: 9428\n",
      "img id in: 9429\n",
      "img id out: 9429\n",
      "img id in: 9430\n",
      "img id out: 9430\n",
      "img id in: 9431\n",
      "img id out: 9431\n",
      "img id in: 9432\n",
      "img id out: 9432\n",
      "img id in: 9433\n",
      "img id out: 9433\n",
      "img id in: 9434\n",
      "img id out: 9434\n",
      "img id in: 9435\n",
      "img id out: 9435\n",
      "img id in: 9436\n",
      "img id out: 9436\n",
      "img id in: 9437\n",
      "img id out: 9437\n",
      "img id in: 9438\n",
      "img id out: 9438\n",
      "img id in: 9439\n",
      "img id out: 9439\n",
      "img id in: 9440\n",
      "img id out: 9440\n",
      "img id in: 9441\n",
      "img id out: 9441\n",
      "img id in: 9442\n",
      "img id out: 9442\n",
      "img id in: 9443\n",
      "img id out: 9443\n",
      "img id in: 9444\n",
      "img id out: 9444\n",
      "img id in: 9445\n",
      "img id out: 9445\n",
      "img id in: 9446\n",
      "img id out: 9446\n",
      "img id in: 9447\n",
      "img id out: 9447\n",
      "img id in: 9448\n",
      "img id out: 9448\n",
      "img id in: 9449\n",
      "img id out: 9449\n",
      "img id in: 9450\n",
      "img id out: 9450\n",
      "img id in: 9451\n",
      "img id out: 9451\n",
      "img id in: 9452\n",
      "img id out: 9452\n",
      "img id in: 9453\n",
      "img id out: 9453\n",
      "img id in: 9454\n",
      "img id out: 9454\n",
      "img id in: 9455\n",
      "img id out: 9455\n",
      "img id in: 9456\n",
      "img id out: 9456\n",
      "img id in: 9457\n",
      "img id out: 9457\n",
      "img id in: 9458\n",
      "img id out: 9458\n",
      "img id in: 9459\n",
      "img id out: 9459\n",
      "img id in: 9460\n",
      "img id out: 9460\n",
      "img id in: 9461\n",
      "img id out: 9461\n",
      "img id in: 9462\n",
      "img id out: 9462\n",
      "img id in: 9463\n",
      "img id out: 9463\n",
      "img id in: 9464\n",
      "img id out: 9464\n",
      "img id in: 9465\n",
      "img id out: 9465\n",
      "img id in: 9466\n",
      "img id out: 9466\n",
      "img id in: 9467\n",
      "img id out: 9467\n",
      "img id in: 9468\n",
      "img id out: 9468\n",
      "img id in: 9469\n",
      "img id out: 9469\n",
      "img id in: 9470\n",
      "img id out: 9470\n",
      "img id in: 9471\n",
      "img id out: 9471\n",
      "img id in: 9472\n",
      "img id out: 9472\n",
      "img id in: 9473\n",
      "img id out: 9473\n",
      "img id in: 9474\n",
      "img id out: 9474\n",
      "img id in: 9475\n",
      "img id out: 9475\n",
      "img id in: 9476\n",
      "img id out: 9476\n",
      "img id in: 9477\n",
      "img id out: 9477\n",
      "img id in: 9478\n",
      "img id out: 9478\n",
      "img id in: 9479\n",
      "img id out: 9479\n",
      "img id in: 9480\n",
      "img id out: 9480\n",
      "img id in: 9481\n",
      "img id out: 9481\n",
      "img id in: 9482\n",
      "img id out: 9482\n",
      "img id in: 9483\n",
      "img id out: 9483\n",
      "img id in: 9484\n",
      "img id out: 9484\n",
      "img id in: 9485\n",
      "img id out: 9485\n",
      "img id in: 9486\n",
      "img id out: 9486\n",
      "img id in: 9487\n",
      "img id out: 9487\n",
      "img id in: 9488\n",
      "img id out: 9488\n",
      "img id in: 9489\n",
      "img id out: 9489\n",
      "img id in: 9490\n",
      "img id out: 9490\n",
      "img id in: 9491\n",
      "img id out: 9491\n",
      "img id in: 9492\n",
      "img id out: 9492\n",
      "img id in: 9493\n",
      "img id out: 9493\n",
      "img id in: 9494\n",
      "img id out: 9494\n",
      "img id in: 9495\n",
      "img id out: 9495\n",
      "img id in: 9496\n",
      "img id out: 9496\n",
      "img id in: 9497\n",
      "img id out: 9497\n",
      "img id in: 9498\n",
      "img id out: 9498\n",
      "img id in: 9499\n",
      "img id out: 9499\n",
      "img id in: 9500\n",
      "img id out: 9500\n",
      "img id in: 9501\n",
      "img id out: 9501\n",
      "img id in: 9502\n",
      "img id out: 9502\n",
      "img id in: 9503\n",
      "img id out: 9503\n",
      "img id in: 9504\n",
      "img id out: 9504\n",
      "img id in: 9505\n",
      "img id out: 9505\n",
      "img id in: 9506\n",
      "img id out: 9506\n",
      "img id in: 9507\n",
      "img id out: 9507\n",
      "img id in: 9508\n",
      "img id out: 9508\n",
      "img id in: 9509\n",
      "img id out: 9509\n",
      "img id in: 9510\n",
      "img id out: 9510\n",
      "img id in: 9511\n",
      "img id out: 9511\n",
      "img id in: 9512\n",
      "img id out: 9512\n",
      "img id in: 9513\n",
      "img id out: 9513\n",
      "img id in: 9514\n",
      "img id out: 9514\n",
      "img id in: 9515\n",
      "img id out: 9515\n",
      "img id in: 9516\n",
      "img id out: 9516\n",
      "img id in: 9517\n",
      "img id out: 9517\n",
      "img id in: 9518\n",
      "img id out: 9518\n",
      "img id in: 9519\n",
      "img id out: 9519\n",
      "img id in: 9520\n",
      "img id out: 9520\n",
      "img id in: 9521\n",
      "img id out: 9521\n",
      "img id in: 9522\n",
      "img id out: 9522\n",
      "img id in: 9523\n",
      "img id out: 9523\n",
      "img id in: 9524\n",
      "img id out: 9524\n",
      "img id in: 9525\n",
      "img id out: 9525\n",
      "img id in: 9526\n",
      "img id out: 9526\n",
      "img id in: 9527\n",
      "img id out: 9527\n",
      "img id in: 9528\n",
      "img id out: 9528\n",
      "img id in: 9529\n",
      "img id out: 9529\n",
      "img id in: 9530\n",
      "img id out: 9530\n",
      "img id in: 9531\n",
      "img id out: 9531\n",
      "img id in: 9532\n",
      "img id out: 9532\n",
      "img id in: 9533\n",
      "img id out: 9533\n",
      "img id in: 9534\n",
      "img id out: 9534\n",
      "img id in: 9535\n",
      "img id out: 9535\n",
      "img id in: 9536\n",
      "img id out: 9536\n",
      "img id in: 9537\n",
      "img id out: 9537\n",
      "img id in: 9538\n",
      "img id out: 9538\n",
      "img id in: 9539\n",
      "img id out: 9539\n",
      "img id in: 9540\n",
      "img id out: 9540\n",
      "img id in: 9541\n",
      "img id out: 9541\n",
      "img id in: 9542\n",
      "img id out: 9542\n",
      "img id in: 9543\n",
      "img id out: 9543\n",
      "img id in: 9544\n",
      "img id out: 9544\n",
      "img id in: 9545\n",
      "img id out: 9545\n",
      "img id in: 9546\n",
      "img id out: 9546\n",
      "img id in: 9547\n",
      "img id out: 9547\n",
      "img id in: 9548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 9548\n",
      "img id in: 9549\n",
      "img id out: 9549\n",
      "img id in: 9550\n",
      "img id out: 9550\n",
      "img id in: 9551\n",
      "img id out: 9551\n",
      "img id in: 9552\n",
      "img id out: 9552\n",
      "img id in: 9553\n",
      "img id out: 9553\n",
      "img id in: 9554\n",
      "img id out: 9554\n",
      "img id in: 9555\n",
      "img id out: 9555\n",
      "img id in: 9556\n",
      "img id out: 9556\n",
      "img id in: 9557\n",
      "img id out: 9557\n",
      "img id in: 9558\n",
      "img id out: 9558\n",
      "img id in: 9559\n",
      "img id out: 9559\n",
      "img id in: 9560\n",
      "img id out: 9560\n",
      "img id in: 9561\n",
      "img id out: 9561\n",
      "img id in: 9562\n",
      "img id out: 9562\n",
      "img id in: 9563\n",
      "img id out: 9563\n",
      "img id in: 9564\n",
      "img id out: 9564\n",
      "img id in: 9565\n",
      "img id out: 9565\n",
      "img id in: 9566\n",
      "img id out: 9566\n",
      "img id in: 9567\n",
      "img id out: 9567\n",
      "img id in: 9568\n",
      "img id out: 9568\n",
      "img id in: 9569\n",
      "img id out: 9569\n",
      "img id in: 9570\n",
      "img id out: 9570\n",
      "img id in: 9571\n",
      "img id out: 9571\n",
      "img id in: 9572\n",
      "img id out: 9572\n",
      "img id in: 9573\n",
      "img id out: 9573\n",
      "img id in: 9574\n",
      "img id out: 9574\n",
      "img id in: 9575\n",
      "img id out: 9575\n",
      "img id in: 9576\n",
      "img id out: 9576\n",
      "img id in: 9577\n",
      "img id out: 9577\n",
      "img id in: 9578\n",
      "img id out: 9578\n",
      "img id in: 9579\n",
      "img id out: 9579\n",
      "img id in: 9580\n",
      "img id out: 9580\n",
      "img id in: 9581\n",
      "img id out: 9581\n",
      "img id in: 9582\n",
      "img id out: 9582\n",
      "img id in: 9583\n",
      "img id out: 9583\n",
      "img id in: 9584\n",
      "img id out: 9584\n",
      "img id in: 9585\n",
      "img id out: 9585\n",
      "img id in: 9586\n",
      "img id out: 9586\n",
      "img id in: 9587\n",
      "img id out: 9587\n",
      "img id in: 9588\n",
      "img id out: 9588\n",
      "img id in: 9589\n",
      "img id out: 9589\n",
      "img id in: 9590\n",
      "img id out: 9590\n",
      "img id in: 9591\n",
      "img id out: 9591\n",
      "img id in: 9592\n",
      "img id out: 9592\n",
      "img id in: 9593\n",
      "img id out: 9593\n",
      "img id in: 9594\n",
      "img id out: 9594\n",
      "img id in: 9595\n",
      "img id out: 9595\n",
      "img id in: 9596\n",
      "img id out: 9596\n",
      "img id in: 9597\n",
      "img id out: 9597\n",
      "img id in: 9598\n",
      "img id out: 9598\n",
      "img id in: 9599\n",
      "img id out: 9599\n",
      "img id in: 9600\n",
      "img id out: 9600\n",
      "img id in: 9601\n",
      "img id out: 9601\n",
      "img id in: 9602\n",
      "img id out: 9602\n",
      "img id in: 9603\n",
      "img id out: 9603\n",
      "img id in: 9604\n",
      "img id out: 9604\n",
      "img id in: 9605\n",
      "img id out: 9605\n",
      "img id in: 9606\n",
      "img id out: 9606\n",
      "img id in: 9607\n",
      "img id out: 9607\n",
      "img id in: 9608\n",
      "img id out: 9608\n",
      "img id in: 9609\n",
      "img id out: 9609\n",
      "img id in: 9610\n",
      "img id out: 9610\n",
      "img id in: 9611\n",
      "img id out: 9611\n",
      "img id in: 9612\n",
      "img id out: 9612\n",
      "img id in: 9613\n",
      "img id out: 9613\n",
      "img id in: 9614\n",
      "img id out: 9614\n",
      "img id in: 9615\n",
      "img id out: 9615\n",
      "img id in: 9616\n",
      "img id out: 9616\n",
      "img id in: 9617\n",
      "img id out: 9617\n",
      "img id in: 9618\n",
      "img id out: 9618\n",
      "img id in: 9619\n",
      "img id out: 9619\n",
      "img id in: 9620\n",
      "img id out: 9620\n",
      "img id in: 9621\n",
      "img id out: 9621\n",
      "img id in: 9622\n",
      "img id out: 9622\n",
      "img id in: 9623\n",
      "img id out: 9623\n",
      "img id in: 9624\n",
      "img id out: 9624\n",
      "img id in: 9625\n",
      "img id out: 9625\n",
      "img id in: 9626\n",
      "img id out: 9626\n",
      "img id in: 9627\n",
      "img id out: 9627\n",
      "img id in: 9628\n",
      "img id out: 9628\n",
      "img id in: 9629\n",
      "img id out: 9629\n",
      "img id in: 9630\n",
      "img id out: 9630\n",
      "img id in: 9631\n",
      "img id out: 9631\n",
      "img id in: 9632\n",
      "img id out: 9632\n",
      "img id in: 9633\n",
      "img id out: 9633\n",
      "img id in: 9634\n",
      "img id out: 9634\n",
      "img id in: 9635\n",
      "img id out: 9635\n",
      "img id in: 9636\n",
      "img id out: 9636\n",
      "img id in: 9637\n",
      "img id out: 9637\n",
      "img id in: 9638\n",
      "img id out: 9638\n",
      "img id in: 9639\n",
      "img id out: 9639\n",
      "img id in: 9640\n",
      "img id out: 9640\n",
      "img id in: 9641\n",
      "img id out: 9641\n",
      "img id in: 9642\n",
      "img id out: 9642\n",
      "img id in: 9643\n",
      "img id out: 9643\n",
      "img id in: 9644\n",
      "img id out: 9644\n",
      "img id in: 9645\n",
      "img id out: 9645\n",
      "img id in: 9646\n",
      "img id out: 9646\n",
      "img id in: 9647\n",
      "img id out: 9647\n",
      "img id in: 9648\n",
      "img id out: 9648\n",
      "img id in: 9649\n",
      "img id out: 9649\n",
      "img id in: 9650\n",
      "img id out: 9650\n",
      "img id in: 9651\n",
      "img id out: 9651\n",
      "img id in: 9652\n",
      "img id out: 9652\n",
      "img id in: 9653\n",
      "img id out: 9653\n",
      "img id in: 9654\n",
      "img id out: 9654\n",
      "img id in: 9655\n",
      "img id out: 9655\n",
      "img id in: 9656\n",
      "img id out: 9656\n",
      "img id in: 9657\n",
      "img id out: 9657\n",
      "img id in: 9658\n",
      "img id out: 9658\n",
      "img id in: 9659\n",
      "img id out: 9659\n",
      "img id in: 9660\n",
      "img id out: 9660\n",
      "img id in: 9661\n",
      "img id out: 9661\n",
      "img id in: 9662\n",
      "img id out: 9662\n",
      "img id in: 9663\n",
      "img id out: 9663\n",
      "img id in: 9664\n",
      "img id out: 9664\n",
      "img id in: 9665\n",
      "img id out: 9665\n",
      "img id in: 9666\n",
      "img id out: 9666\n",
      "img id in: 9667\n",
      "img id out: 9667\n",
      "img id in: 9668\n",
      "img id out: 9668\n",
      "img id in: 9669\n",
      "img id out: 9669\n",
      "img id in: 9670\n",
      "img id out: 9670\n",
      "img id in: 9671\n",
      "img id out: 9671\n",
      "img id in: 9672\n",
      "img id out: 9672\n",
      "img id in: 9673\n",
      "img id out: 9673\n",
      "img id in: 9674\n",
      "img id out: 9674\n",
      "img id in: 9675\n",
      "img id out: 9675\n",
      "img id in: 9676\n",
      "img id out: 9676\n",
      "img id in: 9677\n",
      "img id out: 9677\n",
      "img id in: 9678\n",
      "img id out: 9678\n",
      "img id in: 9679\n",
      "img id out: 9679\n",
      "img id in: 9680\n",
      "img id out: 9680\n",
      "img id in: 9681\n",
      "img id out: 9681\n",
      "img id in: 9682\n",
      "img id out: 9682\n",
      "img id in: 9683\n",
      "img id out: 9683\n",
      "img id in: 9684\n",
      "img id out: 9684\n",
      "img id in: 9685\n",
      "img id out: 9685\n",
      "img id in: 9686\n",
      "img id out: 9686\n",
      "img id in: 9687\n",
      "img id out: 9687\n",
      "img id in: 9688\n",
      "img id out: 9688\n",
      "img id in: 9689\n",
      "img id out: 9689\n",
      "img id in: 9690\n",
      "img id out: 9690\n",
      "img id in: 9691\n",
      "img id out: 9691\n",
      "img id in: 9692\n",
      "img id out: 9692\n",
      "img id in: 9693\n",
      "img id out: 9693\n",
      "img id in: 9694\n",
      "img id out: 9694\n",
      "img id in: 9695\n",
      "img id out: 9695\n",
      "img id in: 9696\n",
      "img id out: 9696\n",
      "img id in: 9697\n",
      "img id out: 9697\n",
      "img id in: 9698\n",
      "img id out: 9698\n",
      "img id in: 9699\n",
      "img id out: 9699\n",
      "img id in: 9700\n",
      "img id out: 9700\n",
      "img id in: 9701\n",
      "img id out: 9701\n",
      "img id in: 9702\n",
      "img id out: 9702\n",
      "img id in: 9703\n",
      "img id out: 9703\n",
      "img id in: 9704\n",
      "img id out: 9704\n",
      "img id in: 9705\n",
      "img id out: 9705\n",
      "img id in: 9706\n",
      "img id out: 9706\n",
      "img id in: 9707\n",
      "img id out: 9707\n",
      "img id in: 9708\n",
      "img id out: 9708\n",
      "img id in: 9709\n",
      "img id out: 9709\n",
      "img id in: 9710\n",
      "img id out: 9710\n",
      "img id in: 9711\n",
      "img id out: 9711\n",
      "img id in: 9712\n",
      "img id out: 9712\n",
      "img id in: 9713\n",
      "img id out: 9713\n",
      "img id in: 9714\n",
      "img id out: 9714\n",
      "img id in: 9715\n",
      "img id out: 9715\n",
      "img id in: 9716\n",
      "img id out: 9716\n",
      "img id in: 9717\n",
      "img id out: 9717\n",
      "img id in: 9718\n",
      "img id out: 9718\n",
      "img id in: 9719\n",
      "img id out: 9719\n",
      "img id in: 9720\n",
      "img id out: 9720\n",
      "img id in: 9721\n",
      "img id out: 9721\n",
      "img id in: 9722\n",
      "img id out: 9722\n",
      "img id in: 9723\n",
      "img id out: 9723\n",
      "img id in: 9724\n",
      "img id out: 9724\n",
      "img id in: 9725\n",
      "img id out: 9725\n",
      "img id in: 9726\n",
      "img id out: 9726\n",
      "img id in: 9727\n",
      "img id out: 9727\n",
      "img id in: 9728\n",
      "img id out: 9728\n",
      "img id in: 9729\n",
      "img id out: 9729\n",
      "img id in: 9730\n",
      "img id out: 9730\n",
      "img id in: 9731\n",
      "img id out: 9731\n",
      "img id in: 9732\n",
      "img id out: 9732\n",
      "img id in: 9733\n",
      "img id out: 9733\n",
      "img id in: 9734\n",
      "img id out: 9734\n",
      "img id in: 9735\n",
      "img id out: 9735\n",
      "img id in: 9736\n",
      "img id out: 9736\n",
      "img id in: 9737\n",
      "img id out: 9737\n",
      "img id in: 9738\n",
      "img id out: 9738\n",
      "img id in: 9739\n",
      "img id out: 9739\n",
      "img id in: 9740\n",
      "img id out: 9740\n",
      "img id in: 9741\n",
      "img id out: 9741\n",
      "img id in: 9742\n",
      "img id out: 9742\n",
      "img id in: 9743\n",
      "img id out: 9743\n",
      "img id in: 9744\n",
      "img id out: 9744\n",
      "img id in: 9745\n",
      "img id out: 9745\n",
      "img id in: 9746\n",
      "img id out: 9746\n",
      "img id in: 9747\n",
      "img id out: 9747\n",
      "img id in: 9748\n",
      "img id out: 9748\n",
      "img id in: 9749\n",
      "img id out: 9749\n",
      "img id in: 9750\n",
      "img id out: 9750\n",
      "img id in: 9751\n",
      "img id out: 9751\n",
      "img id in: 9752\n",
      "img id out: 9752\n",
      "img id in: 9753\n",
      "img id out: 9753\n",
      "img id in: 9754\n",
      "img id out: 9754\n",
      "img id in: 9755\n",
      "img id out: 9755\n",
      "img id in: 9756\n",
      "img id out: 9756\n",
      "img id in: 9757\n",
      "img id out: 9757\n",
      "img id in: 9758\n",
      "img id out: 9758\n",
      "img id in: 9759\n",
      "img id out: 9759\n",
      "img id in: 9760\n",
      "img id out: 9760\n",
      "img id in: 9761\n",
      "img id out: 9761\n",
      "img id in: 9762\n",
      "img id out: 9762\n",
      "img id in: 9763\n",
      "img id out: 9763\n",
      "img id in: 9764\n",
      "img id out: 9764\n",
      "img id in: 9765\n",
      "img id out: 9765\n",
      "img id in: 9766\n",
      "img id out: 9766\n",
      "img id in: 9767\n",
      "img id out: 9767\n",
      "img id in: 9768\n",
      "img id out: 9768\n",
      "img id in: 9769\n",
      "img id out: 9769\n",
      "img id in: 9770\n",
      "img id out: 9770\n",
      "img id in: 9771\n",
      "img id out: 9771\n",
      "img id in: 9772\n",
      "img id out: 9772\n",
      "img id in: 9773\n",
      "img id out: 9773\n",
      "img id in: 9774\n",
      "img id out: 9774\n",
      "img id in: 9775\n",
      "img id out: 9775\n",
      "img id in: 9776\n",
      "img id out: 9776\n",
      "img id in: 9777\n",
      "img id out: 9777\n",
      "img id in: 9778\n",
      "img id out: 9778\n",
      "img id in: 9779\n",
      "img id out: 9779\n",
      "img id in: 9780\n",
      "img id out: 9780\n",
      "img id in: 9781\n",
      "img id out: 9781\n",
      "img id in: 9782\n",
      "img id out: 9782\n",
      "img id in: 9783\n",
      "img id out: 9783\n",
      "img id in: 9784\n",
      "img id out: 9784\n",
      "img id in: 9785\n",
      "img id out: 9785\n",
      "img id in: 9786\n",
      "img id out: 9786\n",
      "img id in: 9787\n",
      "img id out: 9787\n",
      "img id in: 9788\n",
      "img id out: 9788\n",
      "img id in: 9789\n",
      "img id out: 9789\n",
      "img id in: 9790\n",
      "img id out: 9790\n",
      "img id in: 9791\n",
      "img id out: 9791\n",
      "img id in: 9792\n",
      "img id out: 9792\n",
      "img id in: 9793\n",
      "img id out: 9793\n",
      "img id in: 9794\n",
      "img id out: 9794\n",
      "img id in: 9795\n",
      "img id out: 9795\n",
      "img id in: 9796\n",
      "img id out: 9796\n",
      "img id in: 9797\n",
      "img id out: 9797\n",
      "img id in: 9798\n",
      "img id out: 9798\n",
      "img id in: 9799\n",
      "img id out: 9799\n",
      "img id in: 9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 9800\n",
      "img id in: 9801\n",
      "img id out: 9801\n",
      "img id in: 9802\n",
      "img id out: 9802\n",
      "img id in: 9803\n",
      "img id out: 9803\n",
      "img id in: 9804\n",
      "img id out: 9804\n",
      "img id in: 9805\n",
      "img id out: 9805\n",
      "img id in: 9806\n",
      "img id out: 9806\n",
      "img id in: 9807\n",
      "img id out: 9807\n",
      "img id in: 9808\n",
      "img id out: 9808\n",
      "img id in: 9809\n",
      "img id out: 9809\n",
      "img id in: 9810\n",
      "img id out: 9810\n",
      "img id in: 9811\n",
      "img id out: 9811\n",
      "img id in: 9812\n",
      "img id out: 9812\n",
      "img id in: 9813\n",
      "img id out: 9813\n",
      "img id in: 9814\n",
      "img id out: 9814\n",
      "img id in: 9815\n",
      "img id out: 9815\n",
      "img id in: 9816\n",
      "img id out: 9816\n",
      "img id in: 9817\n",
      "img id out: 9817\n",
      "img id in: 9818\n",
      "img id out: 9818\n",
      "img id in: 9819\n",
      "img id out: 9819\n",
      "img id in: 9820\n",
      "img id out: 9820\n",
      "img id in: 9821\n",
      "img id out: 9821\n",
      "img id in: 9822\n",
      "img id out: 9822\n",
      "img id in: 9823\n",
      "img id out: 9823\n",
      "img id in: 9824\n",
      "img id out: 9824\n",
      "img id in: 9825\n",
      "img id out: 9825\n",
      "img id in: 9826\n",
      "img id out: 9826\n",
      "img id in: 9827\n",
      "img id out: 9827\n",
      "img id in: 9828\n",
      "img id out: 9828\n",
      "img id in: 9829\n",
      "img id out: 9829\n",
      "img id in: 9830\n",
      "img id out: 9830\n",
      "img id in: 9831\n",
      "img id out: 9831\n",
      "img id in: 9832\n",
      "img id out: 9832\n",
      "img id in: 9833\n",
      "img id out: 9833\n",
      "img id in: 9834\n",
      "img id out: 9834\n",
      "img id in: 9835\n",
      "img id out: 9835\n",
      "img id in: 9836\n",
      "img id out: 9836\n",
      "img id in: 9837\n",
      "img id out: 9837\n",
      "img id in: 9838\n",
      "img id out: 9838\n",
      "img id in: 9839\n",
      "img id out: 9839\n",
      "img id in: 9840\n",
      "img id out: 9840\n",
      "img id in: 9841\n",
      "img id out: 9841\n",
      "img id in: 9842\n",
      "img id out: 9842\n",
      "img id in: 9843\n",
      "img id out: 9843\n",
      "img id in: 9844\n",
      "img id out: 9844\n",
      "img id in: 9845\n",
      "img id out: 9845\n",
      "img id in: 9846\n",
      "img id out: 9846\n",
      "img id in: 9847\n",
      "img id out: 9847\n",
      "img id in: 9848\n",
      "img id out: 9848\n",
      "img id in: 9849\n",
      "img id out: 9849\n",
      "img id in: 9850\n",
      "img id out: 9850\n",
      "img id in: 9851\n",
      "img id out: 9851\n",
      "img id in: 9852\n",
      "img id out: 9852\n",
      "img id in: 9853\n",
      "img id out: 9853\n",
      "img id in: 9854\n",
      "img id out: 9854\n",
      "img id in: 9855\n",
      "img id out: 9855\n",
      "img id in: 9856\n",
      "img id out: 9856\n",
      "img id in: 9857\n",
      "img id out: 9857\n",
      "img id in: 9858\n",
      "img id out: 9858\n",
      "img id in: 9859\n",
      "img id out: 9859\n",
      "img id in: 9860\n",
      "img id out: 9860\n",
      "img id in: 9861\n",
      "img id out: 9861\n",
      "img id in: 9862\n",
      "img id out: 9862\n",
      "img id in: 9863\n",
      "img id out: 9863\n",
      "img id in: 9864\n",
      "img id out: 9864\n",
      "img id in: 9865\n",
      "img id out: 9865\n",
      "img id in: 9866\n",
      "img id out: 9866\n",
      "img id in: 9867\n",
      "img id out: 9867\n",
      "img id in: 9868\n",
      "img id out: 9868\n",
      "img id in: 9869\n",
      "img id out: 9869\n",
      "img id in: 9870\n",
      "img id out: 9870\n",
      "img id in: 9871\n",
      "img id out: 9871\n",
      "img id in: 9872\n",
      "img id out: 9872\n",
      "img id in: 9873\n",
      "img id out: 9873\n",
      "img id in: 9874\n",
      "img id out: 9874\n",
      "img id in: 9875\n",
      "img id out: 9875\n",
      "img id in: 9876\n",
      "img id out: 9876\n",
      "img id in: 9877\n",
      "img id out: 9877\n",
      "img id in: 9878\n",
      "img id out: 9878\n",
      "img id in: 9879\n",
      "img id out: 9879\n",
      "img id in: 9880\n",
      "img id out: 9880\n",
      "img id in: 9881\n",
      "img id out: 9881\n",
      "img id in: 9882\n",
      "img id out: 9882\n",
      "img id in: 9883\n",
      "img id out: 9883\n",
      "img id in: 9884\n",
      "img id out: 9884\n",
      "img id in: 9885\n",
      "img id out: 9885\n",
      "img id in: 9886\n",
      "img id out: 9886\n",
      "img id in: 9887\n",
      "img id out: 9887\n",
      "img id in: 9888\n",
      "img id out: 9888\n",
      "img id in: 9889\n",
      "img id out: 9889\n",
      "img id in: 9890\n",
      "img id out: 9890\n",
      "img id in: 9891\n",
      "img id out: 9891\n",
      "img id in: 9892\n",
      "img id out: 9892\n",
      "img id in: 9893\n",
      "img id out: 9893\n",
      "img id in: 9894\n",
      "img id out: 9894\n",
      "img id in: 9895\n",
      "img id out: 9895\n",
      "img id in: 9896\n",
      "img id out: 9896\n",
      "img id in: 9897\n",
      "img id out: 9897\n",
      "img id in: 9898\n",
      "img id out: 9898\n",
      "img id in: 9899\n",
      "img id out: 9899\n",
      "img id in: 9900\n",
      "img id out: 9900\n",
      "img id in: 9901\n",
      "img id out: 9901\n",
      "img id in: 9902\n",
      "img id out: 9902\n",
      "img id in: 9903\n",
      "img id out: 9903\n",
      "img id in: 9904\n",
      "img id out: 9904\n",
      "img id in: 9905\n",
      "img id out: 9905\n",
      "img id in: 9906\n",
      "img id out: 9906\n",
      "img id in: 9907\n",
      "img id out: 9907\n",
      "img id in: 9908\n",
      "img id out: 9908\n",
      "img id in: 9909\n",
      "img id out: 9909\n",
      "img id in: 9910\n",
      "img id out: 9910\n",
      "img id in: 9911\n",
      "img id out: 9911\n",
      "img id in: 9912\n",
      "img id out: 9912\n",
      "img id in: 9913\n",
      "img id out: 9913\n",
      "img id in: 9914\n",
      "img id out: 9914\n",
      "img id in: 9915\n",
      "img id out: 9915\n",
      "img id in: 9916\n",
      "img id out: 9916\n",
      "img id in: 9917\n",
      "img id out: 9917\n",
      "img id in: 9918\n",
      "img id out: 9918\n",
      "img id in: 9919\n",
      "img id out: 9919\n",
      "img id in: 9920\n",
      "img id out: 9920\n",
      "img id in: 9921\n",
      "img id out: 9921\n",
      "img id in: 9922\n",
      "img id out: 9922\n",
      "img id in: 9923\n",
      "img id out: 9923\n",
      "img id in: 9924\n",
      "img id out: 9924\n",
      "img id in: 9925\n",
      "img id out: 9925\n",
      "img id in: 9926\n",
      "img id out: 9926\n",
      "img id in: 9927\n",
      "img id out: 9927\n",
      "img id in: 9928\n",
      "img id out: 9928\n",
      "img id in: 9929\n",
      "img id out: 9929\n",
      "img id in: 9930\n",
      "img id out: 9930\n",
      "img id in: 9931\n",
      "img id out: 9931\n",
      "img id in: 9932\n",
      "img id out: 9932\n",
      "img id in: 9933\n",
      "img id out: 9933\n",
      "img id in: 9934\n",
      "img id out: 9934\n",
      "img id in: 9935\n",
      "img id out: 9935\n",
      "img id in: 9936\n",
      "img id out: 9936\n",
      "img id in: 9937\n",
      "img id out: 9937\n",
      "img id in: 9938\n",
      "img id out: 9938\n",
      "img id in: 9939\n",
      "img id out: 9939\n",
      "img id in: 9940\n",
      "img id out: 9940\n",
      "img id in: 9941\n",
      "img id out: 9941\n",
      "img id in: 9942\n",
      "img id out: 9942\n",
      "img id in: 9943\n",
      "img id out: 9943\n",
      "img id in: 9944\n",
      "img id out: 9944\n",
      "img id in: 9945\n",
      "img id out: 9945\n",
      "img id in: 9946\n",
      "img id out: 9946\n",
      "img id in: 9947\n",
      "img id out: 9947\n",
      "img id in: 9948\n",
      "img id out: 9948\n",
      "img id in: 9949\n",
      "img id out: 9949\n",
      "img id in: 9950\n",
      "img id out: 9950\n",
      "img id in: 9951\n",
      "img id out: 9951\n",
      "img id in: 9952\n",
      "img id out: 9952\n",
      "img id in: 9953\n",
      "img id out: 9953\n",
      "img id in: 9954\n",
      "img id out: 9954\n",
      "img id in: 9955\n",
      "img id out: 9955\n",
      "img id in: 9956\n",
      "img id out: 9956\n",
      "img id in: 9957\n",
      "img id out: 9957\n",
      "img id in: 9958\n",
      "img id out: 9958\n",
      "img id in: 9959\n",
      "img id out: 9959\n",
      "img id in: 9960\n",
      "img id out: 9960\n",
      "img id in: 9961\n",
      "img id out: 9961\n",
      "img id in: 9962\n",
      "img id out: 9962\n",
      "img id in: 9963\n",
      "img id out: 9963\n",
      "img id in: 9964\n",
      "img id out: 9964\n",
      "img id in: 9965\n",
      "img id out: 9965\n",
      "img id in: 9966\n",
      "img id out: 9966\n",
      "img id in: 9967\n",
      "img id out: 9967\n",
      "img id in: 9968\n",
      "img id out: 9968\n",
      "img id in: 9969\n",
      "img id out: 9969\n",
      "img id in: 9970\n",
      "img id out: 9970\n",
      "img id in: 9971\n",
      "img id out: 9971\n",
      "img id in: 9972\n",
      "img id out: 9972\n",
      "img id in: 9973\n",
      "img id out: 9973\n",
      "img id in: 9974\n",
      "img id out: 9974\n",
      "img id in: 9975\n",
      "img id out: 9975\n",
      "img id in: 9976\n",
      "img id out: 9976\n",
      "img id in: 9977\n",
      "img id out: 9977\n",
      "img id in: 9978\n",
      "img id out: 9978\n",
      "img id in: 9979\n",
      "img id out: 9979\n",
      "img id in: 9980\n",
      "img id out: 9980\n",
      "img id in: 9981\n",
      "img id out: 9981\n",
      "img id in: 9982\n",
      "img id out: 9982\n",
      "img id in: 9983\n",
      "img id out: 9983\n",
      "img id in: 9984\n",
      "img id out: 9984\n",
      "img id in: 9985\n",
      "img id out: 9985\n",
      "img id in: 9986\n",
      "img id out: 9986\n",
      "img id in: 9987\n",
      "img id out: 9987\n",
      "img id in: 9988\n",
      "img id out: 9988\n",
      "img id in: 9989\n",
      "img id out: 9989\n",
      "img id in: 9990\n",
      "img id out: 9990\n",
      "img id in: 9991\n",
      "img id out: 9991\n",
      "img id in: 9992\n",
      "img id out: 9992\n",
      "img id in: 9993\n",
      "img id out: 9993\n",
      "img id in: 9994\n",
      "img id out: 9994\n",
      "img id in: 9995\n",
      "img id out: 9995\n",
      "img id in: 9996\n",
      "img id out: 9996\n",
      "img id in: 9997\n",
      "img id out: 9997\n",
      "img id in: 9998\n",
      "img id out: 9998\n",
      "img id in: 9999\n",
      "img id out: 9999\n",
      "img id in: 10000\n",
      "img id out: 10000\n",
      "img id in: 10001\n",
      "img id out: 10001\n",
      "img id in: 10002\n",
      "img id out: 10002\n",
      "img id in: 10003\n",
      "img id out: 10003\n",
      "img id in: 10004\n",
      "img id out: 10004\n",
      "img id in: 10005\n",
      "img id out: 10005\n",
      "img id in: 10006\n",
      "img id out: 10006\n",
      "img id in: 10007\n",
      "img id out: 10007\n",
      "img id in: 10008\n",
      "img id out: 10008\n",
      "img id in: 10009\n",
      "img id out: 10009\n",
      "img id in: 10010\n",
      "img id out: 10010\n",
      "img id in: 10011\n",
      "img id out: 10011\n",
      "img id in: 10012\n",
      "img id out: 10012\n",
      "img id in: 10013\n",
      "img id out: 10013\n",
      "img id in: 10014\n",
      "img id out: 10014\n",
      "img id in: 10015\n",
      "img id out: 10015\n",
      "img id in: 10016\n",
      "img id out: 10016\n",
      "img id in: 10017\n",
      "img id out: 10017\n",
      "img id in: 10018\n",
      "img id out: 10018\n",
      "img id in: 10019\n",
      "img id out: 10019\n",
      "img id in: 10020\n",
      "img id out: 10020\n",
      "img id in: 10021\n",
      "img id out: 10021\n",
      "img id in: 10022\n",
      "img id out: 10022\n",
      "img id in: 10023\n",
      "img id out: 10023\n",
      "img id in: 10024\n",
      "img id out: 10024\n",
      "img id in: 10025\n",
      "img id out: 10025\n",
      "img id in: 10026\n",
      "img id out: 10026\n",
      "img id in: 10027\n",
      "img id out: 10027\n",
      "img id in: 10028\n",
      "img id out: 10028\n",
      "img id in: 10029\n",
      "img id out: 10029\n",
      "img id in: 10030\n",
      "img id out: 10030\n",
      "img id in: 10031\n",
      "img id out: 10031\n",
      "img id in: 10032\n",
      "img id out: 10032\n",
      "img id in: 10033\n",
      "img id out: 10033\n",
      "img id in: 10034\n",
      "img id out: 10034\n",
      "img id in: 10035\n",
      "img id out: 10035\n",
      "img id in: 10036\n",
      "img id out: 10036\n",
      "img id in: 10037\n",
      "img id out: 10037\n",
      "img id in: 10038\n",
      "img id out: 10038\n",
      "img id in: 10039\n",
      "img id out: 10039\n",
      "img id in: 10040\n",
      "img id out: 10040\n",
      "img id in: 10041\n",
      "img id out: 10041\n",
      "img id in: 10042\n",
      "img id out: 10042\n",
      "img id in: 10043\n",
      "img id out: 10043\n",
      "img id in: 10044\n",
      "img id out: 10044\n",
      "img id in: 10045\n",
      "img id out: 10045\n",
      "img id in: 10046\n",
      "img id out: 10046\n",
      "img id in: 10047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 10047\n",
      "img id in: 10048\n",
      "img id out: 10048\n",
      "img id in: 10049\n",
      "img id out: 10049\n",
      "img id in: 10050\n",
      "img id out: 10050\n",
      "img id in: 10051\n",
      "img id out: 10051\n",
      "img id in: 10052\n",
      "img id out: 10052\n",
      "img id in: 10053\n",
      "img id out: 10053\n",
      "img id in: 10054\n",
      "img id out: 10054\n",
      "img id in: 10055\n",
      "img id out: 10055\n",
      "img id in: 10056\n",
      "img id out: 10056\n",
      "img id in: 10057\n",
      "img id out: 10057\n",
      "img id in: 10058\n",
      "img id out: 10058\n",
      "img id in: 10059\n",
      "img id out: 10059\n",
      "img id in: 10060\n",
      "img id out: 10060\n",
      "img id in: 10061\n",
      "img id out: 10061\n",
      "img id in: 10062\n",
      "img id out: 10062\n",
      "img id in: 10063\n",
      "img id out: 10063\n",
      "img id in: 10064\n",
      "img id out: 10064\n",
      "img id in: 10065\n",
      "img id out: 10065\n",
      "img id in: 10066\n",
      "img id out: 10066\n",
      "img id in: 10067\n",
      "img id out: 10067\n",
      "img id in: 10068\n",
      "img id out: 10068\n",
      "img id in: 10069\n",
      "img id out: 10069\n",
      "img id in: 10070\n",
      "img id out: 10070\n",
      "img id in: 10071\n",
      "img id out: 10071\n",
      "img id in: 10072\n",
      "img id out: 10072\n",
      "img id in: 10073\n",
      "img id out: 10073\n",
      "img id in: 10074\n",
      "img id out: 10074\n",
      "img id in: 10075\n",
      "img id out: 10075\n",
      "img id in: 10076\n",
      "img id out: 10076\n",
      "img id in: 10077\n",
      "img id out: 10077\n",
      "img id in: 10078\n",
      "img id out: 10078\n",
      "img id in: 10079\n",
      "img id out: 10079\n",
      "img id in: 10080\n",
      "img id out: 10080\n",
      "img id in: 10081\n",
      "img id out: 10081\n",
      "img id in: 10082\n",
      "img id out: 10082\n",
      "img id in: 10083\n",
      "img id out: 10083\n",
      "img id in: 10084\n",
      "img id out: 10084\n",
      "img id in: 10085\n",
      "img id out: 10085\n",
      "img id in: 10086\n",
      "img id out: 10086\n",
      "img id in: 10087\n",
      "img id out: 10087\n",
      "img id in: 10088\n",
      "img id out: 10088\n",
      "img id in: 10089\n",
      "img id out: 10089\n",
      "img id in: 10090\n",
      "img id out: 10090\n",
      "img id in: 10091\n",
      "img id out: 10091\n",
      "img id in: 10092\n",
      "img id out: 10092\n",
      "img id in: 10093\n",
      "img id out: 10093\n",
      "img id in: 10094\n",
      "img id out: 10094\n",
      "img id in: 10095\n",
      "img id out: 10095\n",
      "img id in: 10096\n",
      "img id out: 10096\n",
      "img id in: 10097\n",
      "img id out: 10097\n",
      "img id in: 10098\n",
      "img id out: 10098\n",
      "img id in: 10099\n",
      "img id out: 10099\n",
      "img id in: 10100\n",
      "img id out: 10100\n",
      "img id in: 10101\n",
      "img id out: 10101\n",
      "img id in: 10102\n",
      "img id out: 10102\n",
      "img id in: 10103\n",
      "img id out: 10103\n",
      "img id in: 10104\n",
      "img id out: 10104\n",
      "img id in: 10105\n",
      "img id out: 10105\n",
      "img id in: 10106\n",
      "img id out: 10106\n",
      "img id in: 10107\n",
      "img id out: 10107\n",
      "img id in: 10108\n",
      "img id out: 10108\n",
      "img id in: 10109\n",
      "img id out: 10109\n",
      "img id in: 10110\n",
      "img id out: 10110\n",
      "img id in: 10111\n",
      "img id out: 10111\n",
      "img id in: 10112\n",
      "img id out: 10112\n",
      "img id in: 10113\n",
      "img id out: 10113\n",
      "img id in: 10114\n",
      "img id out: 10114\n",
      "img id in: 10115\n",
      "img id out: 10115\n",
      "img id in: 10116\n",
      "img id out: 10116\n",
      "img id in: 10117\n",
      "img id out: 10117\n",
      "img id in: 10118\n",
      "img id out: 10118\n",
      "img id in: 10119\n",
      "img id out: 10119\n",
      "img id in: 10120\n",
      "img id out: 10120\n",
      "img id in: 10121\n",
      "img id out: 10121\n",
      "img id in: 10122\n",
      "img id out: 10122\n",
      "img id in: 10123\n",
      "img id out: 10123\n",
      "img id in: 10124\n",
      "img id out: 10124\n",
      "img id in: 10125\n",
      "img id out: 10125\n",
      "img id in: 10126\n",
      "img id out: 10126\n",
      "img id in: 10127\n",
      "img id out: 10127\n",
      "img id in: 10128\n",
      "img id out: 10128\n",
      "img id in: 10129\n",
      "img id out: 10129\n",
      "img id in: 10130\n",
      "img id out: 10130\n",
      "img id in: 10131\n",
      "img id out: 10131\n",
      "img id in: 10132\n",
      "img id out: 10132\n",
      "img id in: 10133\n",
      "img id out: 10133\n",
      "img id in: 10134\n",
      "img id out: 10134\n",
      "img id in: 10135\n",
      "img id out: 10135\n",
      "img id in: 10136\n",
      "img id out: 10136\n",
      "img id in: 10137\n",
      "img id out: 10137\n",
      "img id in: 10138\n",
      "img id out: 10138\n",
      "img id in: 10139\n",
      "img id out: 10139\n",
      "img id in: 10140\n",
      "img id out: 10140\n",
      "img id in: 10141\n",
      "img id out: 10141\n",
      "img id in: 10142\n",
      "img id out: 10142\n",
      "img id in: 10143\n",
      "img id out: 10143\n",
      "img id in: 10144\n",
      "img id out: 10144\n",
      "img id in: 10145\n",
      "img id out: 10145\n",
      "img id in: 10146\n",
      "img id out: 10146\n",
      "img id in: 10147\n",
      "img id out: 10147\n",
      "img id in: 10148\n",
      "img id out: 10148\n",
      "img id in: 10149\n",
      "img id out: 10149\n",
      "img id in: 10150\n",
      "img id out: 10150\n",
      "img id in: 10151\n",
      "img id out: 10151\n",
      "img id in: 10152\n",
      "img id out: 10152\n",
      "img id in: 10153\n",
      "img id out: 10153\n",
      "img id in: 10154\n",
      "img id out: 10154\n",
      "img id in: 10155\n",
      "img id out: 10155\n",
      "img id in: 10156\n",
      "img id out: 10156\n",
      "img id in: 10157\n",
      "img id out: 10157\n",
      "img id in: 10158\n",
      "img id out: 10158\n",
      "img id in: 10159\n",
      "img id out: 10159\n",
      "img id in: 10160\n",
      "img id out: 10160\n",
      "img id in: 10161\n",
      "img id out: 10161\n",
      "img id in: 10162\n",
      "img id out: 10162\n",
      "img id in: 10163\n",
      "img id out: 10163\n",
      "img id in: 10164\n",
      "img id out: 10164\n",
      "img id in: 10165\n",
      "img id out: 10165\n",
      "img id in: 10166\n",
      "img id out: 10166\n",
      "img id in: 10167\n",
      "img id out: 10167\n",
      "img id in: 10168\n",
      "img id out: 10168\n",
      "img id in: 10169\n",
      "img id out: 10169\n",
      "img id in: 10170\n",
      "img id out: 10170\n",
      "img id in: 10171\n",
      "img id out: 10171\n",
      "img id in: 10172\n",
      "img id out: 10172\n",
      "img id in: 10173\n",
      "img id out: 10173\n",
      "img id in: 10174\n",
      "img id out: 10174\n",
      "img id in: 10175\n",
      "img id out: 10175\n",
      "img id in: 10176\n",
      "img id out: 10176\n",
      "img id in: 10177\n",
      "img id out: 10177\n",
      "img id in: 10178\n",
      "img id out: 10178\n",
      "img id in: 10179\n",
      "img id out: 10179\n",
      "img id in: 10180\n",
      "img id out: 10180\n",
      "img id in: 10181\n",
      "img id out: 10181\n",
      "img id in: 10182\n",
      "img id out: 10182\n",
      "img id in: 10183\n",
      "img id out: 10183\n",
      "img id in: 10184\n",
      "img id out: 10184\n",
      "img id in: 10185\n",
      "img id out: 10185\n",
      "img id in: 10186\n",
      "img id out: 10186\n",
      "img id in: 10187\n",
      "img id out: 10187\n",
      "img id in: 10188\n",
      "img id out: 10188\n",
      "img id in: 10189\n",
      "img id out: 10189\n",
      "img id in: 10190\n",
      "img id out: 10190\n",
      "img id in: 10191\n",
      "img id out: 10191\n",
      "img id in: 10192\n",
      "img id out: 10192\n",
      "img id in: 10193\n",
      "img id out: 10193\n",
      "img id in: 10194\n",
      "img id out: 10194\n",
      "img id in: 10195\n",
      "img id out: 10195\n",
      "img id in: 10196\n",
      "img id out: 10196\n",
      "img id in: 10197\n",
      "img id out: 10197\n",
      "img id in: 10198\n",
      "img id out: 10198\n",
      "img id in: 10199\n",
      "img id out: 10199\n",
      "img id in: 10200\n",
      "img id out: 10200\n",
      "img id in: 10201\n",
      "img id out: 10201\n",
      "img id in: 10202\n",
      "img id out: 10202\n",
      "img id in: 10203\n",
      "img id out: 10203\n",
      "img id in: 10204\n",
      "img id out: 10204\n",
      "img id in: 10205\n",
      "img id out: 10205\n",
      "img id in: 10206\n",
      "img id out: 10206\n",
      "img id in: 10207\n",
      "img id out: 10207\n",
      "img id in: 10208\n",
      "img id out: 10208\n",
      "img id in: 10209\n",
      "img id out: 10209\n",
      "img id in: 10210\n",
      "img id out: 10210\n",
      "img id in: 10211\n",
      "img id out: 10211\n",
      "img id in: 10212\n",
      "img id out: 10212\n",
      "img id in: 10213\n",
      "img id out: 10213\n",
      "img id in: 10214\n",
      "img id out: 10214\n",
      "img id in: 10215\n",
      "img id out: 10215\n",
      "img id in: 10216\n",
      "img id out: 10216\n",
      "img id in: 10217\n",
      "img id out: 10217\n",
      "img id in: 10218\n",
      "img id out: 10218\n",
      "img id in: 10219\n",
      "img id out: 10219\n",
      "img id in: 10220\n",
      "img id out: 10220\n",
      "img id in: 10221\n",
      "img id out: 10221\n",
      "img id in: 10222\n",
      "img id out: 10222\n",
      "img id in: 10223\n",
      "img id out: 10223\n",
      "img id in: 10224\n",
      "img id out: 10224\n",
      "img id in: 10225\n",
      "img id out: 10225\n",
      "img id in: 10226\n",
      "img id out: 10226\n",
      "img id in: 10227\n",
      "img id out: 10227\n",
      "img id in: 10228\n",
      "img id out: 10228\n",
      "img id in: 10229\n",
      "img id out: 10229\n",
      "img id in: 10230\n",
      "img id out: 10230\n",
      "img id in: 10231\n",
      "img id out: 10231\n",
      "img id in: 10232\n",
      "img id out: 10232\n",
      "img id in: 10233\n",
      "img id out: 10233\n",
      "img id in: 10234\n",
      "img id out: 10234\n",
      "img id in: 10235\n",
      "img id out: 10235\n",
      "img id in: 10236\n",
      "img id out: 10236\n",
      "img id in: 10237\n",
      "img id out: 10237\n",
      "img id in: 10238\n",
      "img id out: 10238\n",
      "img id in: 10239\n",
      "img id out: 10239\n",
      "img id in: 10240\n",
      "img id out: 10240\n",
      "img id in: 10241\n",
      "img id out: 10241\n",
      "img id in: 10242\n",
      "img id out: 10242\n",
      "img id in: 10243\n",
      "img id out: 10243\n",
      "img id in: 10244\n",
      "img id out: 10244\n",
      "img id in: 10245\n",
      "img id out: 10245\n",
      "img id in: 10246\n",
      "img id out: 10246\n",
      "img id in: 10247\n",
      "img id out: 10247\n",
      "img id in: 10248\n",
      "img id out: 10248\n",
      "img id in: 10249\n",
      "img id out: 10249\n",
      "img id in: 10250\n",
      "img id out: 10250\n",
      "img id in: 10251\n",
      "img id out: 10251\n",
      "img id in: 10252\n",
      "img id out: 10252\n",
      "img id in: 10253\n",
      "img id out: 10253\n",
      "img id in: 10254\n",
      "img id out: 10254\n",
      "img id in: 10255\n",
      "img id out: 10255\n",
      "img id in: 10256\n",
      "img id out: 10256\n",
      "img id in: 10257\n",
      "img id out: 10257\n",
      "img id in: 10258\n",
      "img id out: 10258\n",
      "img id in: 10259\n",
      "img id out: 10259\n",
      "img id in: 10260\n",
      "img id out: 10260\n",
      "img id in: 10261\n",
      "img id out: 10261\n",
      "img id in: 10262\n",
      "img id out: 10262\n",
      "img id in: 10263\n",
      "img id out: 10263\n",
      "img id in: 10264\n",
      "img id out: 10264\n",
      "img id in: 10265\n",
      "img id out: 10265\n",
      "img id in: 10266\n",
      "img id out: 10266\n",
      "img id in: 10267\n",
      "img id out: 10267\n",
      "img id in: 10268\n",
      "img id out: 10268\n",
      "img id in: 10269\n",
      "img id out: 10269\n",
      "img id in: 10270\n",
      "img id out: 10270\n",
      "img id in: 10271\n",
      "img id out: 10271\n",
      "img id in: 10272\n",
      "img id out: 10272\n",
      "img id in: 10273\n",
      "img id out: 10273\n",
      "img id in: 10274\n",
      "img id out: 10274\n",
      "img id in: 10275\n",
      "img id out: 10275\n",
      "img id in: 10276\n",
      "img id out: 10276\n",
      "img id in: 10277\n",
      "img id out: 10277\n",
      "img id in: 10278\n",
      "img id out: 10278\n",
      "img id in: 10279\n",
      "img id out: 10279\n",
      "img id in: 10280\n",
      "img id out: 10280\n",
      "img id in: 10281\n",
      "img id out: 10281\n",
      "img id in: 10282\n",
      "img id out: 10282\n",
      "img id in: 10283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 10283\n",
      "img id in: 10284\n",
      "img id out: 10284\n",
      "img id in: 10285\n",
      "img id out: 10285\n",
      "img id in: 10286\n",
      "img id out: 10286\n",
      "img id in: 10287\n",
      "img id out: 10287\n",
      "img id in: 10288\n",
      "img id out: 10288\n",
      "img id in: 10289\n",
      "img id out: 10289\n",
      "img id in: 10290\n",
      "img id out: 10290\n",
      "img id in: 10291\n",
      "img id out: 10291\n",
      "img id in: 10292\n",
      "img id out: 10292\n",
      "img id in: 10293\n",
      "img id out: 10293\n",
      "img id in: 10294\n",
      "img id out: 10294\n",
      "img id in: 10295\n",
      "img id out: 10295\n",
      "img id in: 10296\n",
      "img id out: 10296\n",
      "img id in: 10297\n",
      "img id out: 10297\n",
      "img id in: 10298\n",
      "img id out: 10298\n",
      "img id in: 10299\n",
      "img id out: 10299\n",
      "img id in: 10300\n",
      "img id out: 10300\n",
      "img id in: 10301\n",
      "img id out: 10301\n",
      "img id in: 10302\n",
      "img id out: 10302\n",
      "img id in: 10303\n",
      "img id out: 10303\n",
      "img id in: 10304\n",
      "img id out: 10304\n",
      "img id in: 10305\n",
      "img id out: 10305\n",
      "img id in: 10306\n",
      "img id out: 10306\n",
      "img id in: 10307\n",
      "img id out: 10307\n",
      "img id in: 10308\n",
      "img id out: 10308\n",
      "img id in: 10309\n",
      "img id out: 10309\n",
      "img id in: 10310\n",
      "img id out: 10310\n",
      "img id in: 10311\n",
      "img id out: 10311\n",
      "img id in: 10312\n",
      "img id out: 10312\n",
      "img id in: 10313\n",
      "img id out: 10313\n",
      "img id in: 10314\n",
      "img id out: 10314\n",
      "img id in: 10315\n",
      "img id out: 10315\n",
      "img id in: 10316\n",
      "img id out: 10316\n",
      "img id in: 10317\n",
      "img id out: 10317\n",
      "img id in: 10318\n",
      "img id out: 10318\n",
      "img id in: 10319\n",
      "img id out: 10319\n",
      "img id in: 10320\n",
      "img id out: 10320\n",
      "img id in: 10321\n",
      "img id out: 10321\n",
      "img id in: 10322\n",
      "img id out: 10322\n",
      "img id in: 10323\n",
      "img id out: 10323\n",
      "img id in: 10324\n",
      "img id out: 10324\n",
      "img id in: 10325\n",
      "img id out: 10325\n",
      "img id in: 10326\n",
      "img id out: 10326\n",
      "img id in: 10327\n",
      "img id out: 10327\n",
      "img id in: 10328\n",
      "img id out: 10328\n",
      "img id in: 10329\n",
      "img id out: 10329\n",
      "img id in: 10330\n",
      "img id out: 10330\n",
      "img id in: 10331\n",
      "img id out: 10331\n",
      "img id in: 10332\n",
      "img id out: 10332\n",
      "img id in: 10333\n",
      "img id out: 10333\n",
      "img id in: 10334\n",
      "img id out: 10334\n",
      "img id in: 10335\n",
      "img id out: 10335\n",
      "img id in: 10336\n",
      "img id out: 10336\n",
      "img id in: 10337\n",
      "img id out: 10337\n",
      "img id in: 10338\n",
      "img id out: 10338\n",
      "img id in: 10339\n",
      "img id out: 10339\n",
      "img id in: 10340\n",
      "img id out: 10340\n",
      "img id in: 10341\n",
      "img id out: 10341\n",
      "img id in: 10342\n",
      "img id out: 10342\n",
      "img id in: 10343\n",
      "img id out: 10343\n",
      "img id in: 10344\n",
      "img id out: 10344\n",
      "img id in: 10345\n",
      "img id out: 10345\n",
      "img id in: 10346\n",
      "img id out: 10346\n",
      "img id in: 10347\n",
      "img id out: 10347\n",
      "img id in: 10348\n",
      "img id out: 10348\n",
      "img id in: 10349\n",
      "img id out: 10349\n",
      "img id in: 10350\n",
      "img id out: 10350\n",
      "img id in: 10351\n",
      "img id out: 10351\n",
      "img id in: 10352\n",
      "img id out: 10352\n",
      "img id in: 10353\n",
      "img id out: 10353\n",
      "img id in: 10354\n",
      "img id out: 10354\n",
      "img id in: 10355\n",
      "img id out: 10355\n",
      "img id in: 10356\n",
      "img id out: 10356\n",
      "img id in: 10357\n",
      "img id out: 10357\n",
      "img id in: 10358\n",
      "img id out: 10358\n",
      "img id in: 10359\n",
      "img id out: 10359\n",
      "img id in: 10360\n",
      "img id out: 10360\n",
      "img id in: 10361\n",
      "img id out: 10361\n",
      "img id in: 10362\n",
      "img id out: 10362\n",
      "img id in: 10363\n",
      "img id out: 10363\n",
      "img id in: 10364\n",
      "img id out: 10364\n",
      "img id in: 10365\n",
      "img id out: 10365\n",
      "img id in: 10366\n",
      "img id out: 10366\n",
      "img id in: 10367\n",
      "img id out: 10367\n",
      "img id in: 10368\n",
      "img id out: 10368\n",
      "img id in: 10369\n",
      "img id out: 10369\n",
      "img id in: 10370\n",
      "img id out: 10370\n",
      "img id in: 10371\n",
      "img id out: 10371\n",
      "img id in: 10372\n",
      "img id out: 10372\n",
      "img id in: 10373\n",
      "img id out: 10373\n",
      "img id in: 10374\n",
      "img id out: 10374\n",
      "img id in: 10375\n",
      "img id out: 10375\n",
      "img id in: 10376\n",
      "img id out: 10376\n",
      "img id in: 10377\n",
      "img id out: 10377\n",
      "img id in: 10378\n",
      "img id out: 10378\n",
      "img id in: 10379\n",
      "img id out: 10379\n",
      "img id in: 10380\n",
      "img id out: 10380\n",
      "img id in: 10381\n",
      "img id out: 10381\n",
      "img id in: 10382\n",
      "img id out: 10382\n",
      "img id in: 10383\n",
      "img id out: 10383\n",
      "img id in: 10384\n",
      "img id out: 10384\n",
      "img id in: 10385\n",
      "img id out: 10385\n",
      "img id in: 10386\n",
      "img id out: 10386\n",
      "img id in: 10387\n",
      "img id out: 10387\n",
      "img id in: 10388\n",
      "img id out: 10388\n",
      "img id in: 10389\n",
      "img id out: 10389\n",
      "img id in: 10390\n",
      "img id out: 10390\n",
      "img id in: 10391\n",
      "img id out: 10391\n",
      "img id in: 10392\n",
      "img id out: 10392\n",
      "img id in: 10393\n",
      "img id out: 10393\n",
      "img id in: 10394\n",
      "img id out: 10394\n",
      "img id in: 10395\n",
      "img id out: 10395\n",
      "img id in: 10396\n",
      "img id out: 10396\n",
      "img id in: 10397\n",
      "img id out: 10397\n",
      "img id in: 10398\n",
      "img id out: 10398\n",
      "img id in: 10399\n",
      "img id out: 10399\n",
      "img id in: 10400\n",
      "img id out: 10400\n",
      "img id in: 10401\n",
      "img id out: 10401\n",
      "img id in: 10402\n",
      "img id out: 10402\n",
      "img id in: 10403\n",
      "img id out: 10403\n",
      "img id in: 10404\n",
      "img id out: 10404\n",
      "img id in: 10405\n",
      "img id out: 10405\n",
      "img id in: 10406\n",
      "img id out: 10406\n",
      "img id in: 10407\n",
      "img id out: 10407\n",
      "img id in: 10408\n",
      "img id out: 10408\n",
      "img id in: 10409\n",
      "img id out: 10409\n",
      "img id in: 10410\n",
      "img id out: 10410\n",
      "img id in: 10411\n",
      "img id out: 10411\n",
      "img id in: 10412\n",
      "img id out: 10412\n",
      "img id in: 10413\n",
      "img id out: 10413\n",
      "img id in: 10414\n",
      "img id out: 10414\n",
      "img id in: 10415\n",
      "img id out: 10415\n",
      "img id in: 10416\n",
      "img id out: 10416\n",
      "img id in: 10417\n",
      "img id out: 10417\n",
      "img id in: 10418\n",
      "img id out: 10418\n",
      "img id in: 10419\n",
      "img id out: 10419\n",
      "img id in: 10420\n",
      "img id out: 10420\n",
      "img id in: 10421\n",
      "img id out: 10421\n",
      "img id in: 10422\n",
      "img id out: 10422\n",
      "img id in: 10423\n",
      "img id out: 10423\n",
      "img id in: 10424\n",
      "img id out: 10424\n",
      "img id in: 10425\n",
      "img id out: 10425\n",
      "img id in: 10426\n",
      "img id out: 10426\n",
      "img id in: 10427\n",
      "img id out: 10427\n",
      "img id in: 10428\n",
      "img id out: 10428\n",
      "img id in: 10429\n",
      "img id out: 10429\n",
      "img id in: 10430\n",
      "img id out: 10430\n",
      "img id in: 10431\n",
      "img id out: 10431\n",
      "img id in: 10432\n",
      "img id out: 10432\n",
      "img id in: 10433\n",
      "img id out: 10433\n",
      "img id in: 10434\n",
      "img id out: 10434\n",
      "img id in: 10435\n",
      "img id out: 10435\n",
      "img id in: 10436\n",
      "img id out: 10436\n",
      "img id in: 10437\n",
      "img id out: 10437\n",
      "img id in: 10438\n",
      "img id out: 10438\n",
      "img id in: 10439\n",
      "img id out: 10439\n",
      "img id in: 10440\n",
      "img id out: 10440\n",
      "img id in: 10441\n",
      "img id out: 10441\n",
      "img id in: 10442\n",
      "img id out: 10442\n",
      "img id in: 10443\n",
      "img id out: 10443\n",
      "img id in: 10444\n",
      "img id out: 10444\n",
      "img id in: 10445\n",
      "img id out: 10445\n",
      "img id in: 10446\n",
      "img id out: 10446\n",
      "img id in: 10447\n",
      "img id out: 10447\n",
      "img id in: 10448\n",
      "img id out: 10448\n",
      "img id in: 10449\n",
      "img id out: 10449\n",
      "img id in: 10450\n",
      "img id out: 10450\n",
      "img id in: 10451\n",
      "img id out: 10451\n",
      "img id in: 10452\n",
      "img id out: 10452\n",
      "img id in: 10453\n",
      "img id out: 10453\n",
      "img id in: 10454\n",
      "img id out: 10454\n",
      "img id in: 10455\n",
      "img id out: 10455\n",
      "img id in: 10456\n",
      "img id out: 10456\n",
      "img id in: 10457\n",
      "img id out: 10457\n",
      "img id in: 10458\n",
      "img id out: 10458\n",
      "img id in: 10459\n",
      "img id out: 10459\n",
      "img id in: 10460\n",
      "img id out: 10460\n",
      "img id in: 10461\n",
      "img id out: 10461\n",
      "img id in: 10462\n",
      "img id out: 10462\n",
      "img id in: 10463\n",
      "img id out: 10463\n",
      "img id in: 10464\n",
      "img id out: 10464\n",
      "img id in: 10465\n",
      "img id out: 10465\n",
      "img id in: 10466\n",
      "img id out: 10466\n",
      "img id in: 10467\n",
      "img id out: 10467\n",
      "img id in: 10468\n",
      "img id out: 10468\n",
      "img id in: 10469\n",
      "img id out: 10469\n",
      "img id in: 10470\n",
      "img id out: 10470\n",
      "img id in: 10471\n",
      "img id out: 10471\n",
      "img id in: 10472\n",
      "img id out: 10472\n",
      "img id in: 10473\n",
      "img id out: 10473\n",
      "img id in: 10474\n",
      "img id out: 10474\n",
      "img id in: 10475\n",
      "img id out: 10475\n",
      "img id in: 10476\n",
      "img id out: 10476\n",
      "img id in: 10477\n",
      "img id out: 10477\n",
      "img id in: 10478\n",
      "img id out: 10478\n",
      "img id in: 10479\n",
      "img id out: 10479\n",
      "img id in: 10480\n",
      "img id out: 10480\n",
      "img id in: 10481\n",
      "img id out: 10481\n",
      "img id in: 10482\n",
      "img id out: 10482\n",
      "img id in: 10483\n",
      "img id out: 10483\n",
      "img id in: 10484\n",
      "img id out: 10484\n",
      "img id in: 10485\n",
      "img id out: 10485\n",
      "img id in: 10486\n",
      "img id out: 10486\n",
      "img id in: 10487\n",
      "img id out: 10487\n",
      "img id in: 10488\n",
      "img id out: 10488\n",
      "img id in: 10489\n",
      "img id out: 10489\n",
      "img id in: 10490\n",
      "img id out: 10490\n",
      "img id in: 10491\n",
      "img id out: 10491\n",
      "img id in: 10492\n",
      "img id out: 10492\n",
      "img id in: 10493\n",
      "img id out: 10493\n",
      "img id in: 10494\n",
      "img id out: 10494\n",
      "img id in: 10495\n",
      "img id out: 10495\n",
      "img id in: 10496\n",
      "img id out: 10496\n",
      "img id in: 10497\n",
      "img id out: 10497\n",
      "img id in: 10498\n",
      "img id out: 10498\n",
      "img id in: 10499\n",
      "img id out: 10499\n",
      "img id in: 10500\n",
      "img id out: 10500\n",
      "img id in: 10501\n",
      "img id out: 10501\n",
      "img id in: 10502\n",
      "img id out: 10502\n",
      "img id in: 10503\n",
      "img id out: 10503\n",
      "img id in: 10504\n",
      "img id out: 10504\n",
      "img id in: 10505\n",
      "img id out: 10505\n",
      "img id in: 10506\n",
      "img id out: 10506\n",
      "img id in: 10507\n",
      "img id out: 10507\n",
      "img id in: 10508\n",
      "img id out: 10508\n",
      "img id in: 10509\n",
      "img id out: 10509\n",
      "img id in: 10510\n",
      "img id out: 10510\n",
      "img id in: 10511\n",
      "img id out: 10511\n",
      "img id in: 10512\n",
      "img id out: 10512\n",
      "img id in: 10513\n",
      "img id out: 10513\n",
      "img id in: 10514\n",
      "img id out: 10514\n",
      "img id in: 10515\n",
      "img id out: 10515\n",
      "img id in: 10516\n",
      "img id out: 10516\n",
      "img id in: 10517\n",
      "img id out: 10517\n",
      "img id in: 10518\n",
      "img id out: 10518\n",
      "img id in: 10519\n",
      "img id out: 10519\n",
      "img id in: 10520\n",
      "img id out: 10520\n",
      "img id in: 10521\n",
      "img id out: 10521\n",
      "img id in: 10522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 10522\n",
      "img id in: 10523\n",
      "img id out: 10523\n",
      "img id in: 10524\n",
      "img id out: 10524\n",
      "img id in: 10525\n",
      "img id out: 10525\n",
      "img id in: 10526\n",
      "img id out: 10526\n",
      "img id in: 10527\n",
      "img id out: 10527\n",
      "img id in: 10528\n",
      "img id out: 10528\n",
      "img id in: 10529\n",
      "img id out: 10529\n",
      "img id in: 10530\n",
      "img id out: 10530\n",
      "img id in: 10531\n",
      "img id out: 10531\n",
      "img id in: 10532\n",
      "img id out: 10532\n",
      "img id in: 10533\n",
      "img id out: 10533\n",
      "img id in: 10534\n",
      "img id out: 10534\n",
      "img id in: 10535\n",
      "img id out: 10535\n",
      "img id in: 10536\n",
      "img id out: 10536\n",
      "img id in: 10537\n",
      "img id out: 10537\n",
      "img id in: 10538\n",
      "img id out: 10538\n",
      "img id in: 10539\n",
      "img id out: 10539\n",
      "img id in: 10540\n",
      "img id out: 10540\n",
      "img id in: 10541\n",
      "img id out: 10541\n",
      "img id in: 10542\n",
      "img id out: 10542\n",
      "img id in: 10543\n",
      "img id out: 10543\n",
      "img id in: 10544\n",
      "img id out: 10544\n",
      "img id in: 10545\n",
      "img id out: 10545\n",
      "img id in: 10546\n",
      "img id out: 10546\n",
      "img id in: 10547\n",
      "img id out: 10547\n",
      "img id in: 10548\n",
      "img id out: 10548\n",
      "img id in: 10549\n",
      "img id out: 10549\n",
      "img id in: 10550\n",
      "img id out: 10550\n",
      "img id in: 10551\n",
      "img id out: 10551\n",
      "img id in: 10552\n",
      "img id out: 10552\n",
      "img id in: 10553\n",
      "img id out: 10553\n",
      "img id in: 10554\n",
      "img id out: 10554\n",
      "img id in: 10555\n",
      "img id out: 10555\n",
      "img id in: 10556\n",
      "img id out: 10556\n",
      "img id in: 10557\n",
      "img id out: 10557\n",
      "img id in: 10558\n",
      "img id out: 10558\n",
      "img id in: 10559\n",
      "img id out: 10559\n",
      "img id in: 10560\n",
      "img id out: 10560\n",
      "img id in: 10561\n",
      "img id out: 10561\n",
      "img id in: 10562\n",
      "img id out: 10562\n",
      "img id in: 10563\n",
      "img id out: 10563\n",
      "img id in: 10564\n",
      "img id out: 10564\n",
      "img id in: 10565\n",
      "img id out: 10565\n",
      "img id in: 10566\n",
      "img id out: 10566\n",
      "img id in: 10567\n",
      "img id out: 10567\n",
      "img id in: 10568\n",
      "img id out: 10568\n",
      "img id in: 10569\n",
      "img id out: 10569\n",
      "img id in: 10570\n",
      "img id out: 10570\n",
      "img id in: 10571\n",
      "img id out: 10571\n",
      "img id in: 10572\n",
      "img id out: 10572\n",
      "img id in: 10573\n",
      "img id out: 10573\n",
      "img id in: 10574\n",
      "img id out: 10574\n",
      "img id in: 10575\n",
      "img id out: 10575\n",
      "img id in: 10576\n",
      "img id out: 10576\n",
      "img id in: 10577\n",
      "img id out: 10577\n",
      "img id in: 10578\n",
      "img id out: 10578\n",
      "img id in: 10579\n",
      "img id out: 10579\n",
      "img id in: 10580\n",
      "img id out: 10580\n",
      "img id in: 10581\n",
      "img id out: 10581\n",
      "img id in: 10582\n",
      "img id out: 10582\n",
      "img id in: 10583\n",
      "img id out: 10583\n",
      "img id in: 10584\n",
      "img id out: 10584\n",
      "img id in: 10585\n",
      "img id out: 10585\n",
      "img id in: 10586\n",
      "img id out: 10586\n",
      "img id in: 10587\n",
      "img id out: 10587\n",
      "img id in: 10588\n",
      "img id out: 10588\n",
      "img id in: 10589\n",
      "img id out: 10589\n",
      "img id in: 10590\n",
      "img id out: 10590\n",
      "img id in: 10591\n",
      "img id out: 10591\n",
      "img id in: 10592\n",
      "img id out: 10592\n",
      "img id in: 10593\n",
      "img id out: 10593\n",
      "img id in: 10594\n",
      "img id out: 10594\n",
      "img id in: 10595\n",
      "img id out: 10595\n",
      "img id in: 10596\n",
      "img id out: 10596\n",
      "img id in: 10597\n",
      "img id out: 10597\n",
      "img id in: 10598\n",
      "img id out: 10598\n",
      "img id in: 10599\n",
      "img id out: 10599\n",
      "img id in: 10600\n",
      "img id out: 10600\n",
      "img id in: 10601\n",
      "img id out: 10601\n",
      "img id in: 10602\n",
      "img id out: 10602\n",
      "img id in: 10603\n",
      "img id out: 10603\n",
      "img id in: 10604\n",
      "img id out: 10604\n",
      "img id in: 10605\n",
      "img id out: 10605\n",
      "img id in: 10606\n",
      "img id out: 10606\n",
      "img id in: 10607\n",
      "img id out: 10607\n",
      "img id in: 10608\n",
      "img id out: 10608\n",
      "img id in: 10609\n",
      "img id out: 10609\n",
      "img id in: 10610\n",
      "img id out: 10610\n",
      "img id in: 10611\n",
      "img id out: 10611\n",
      "img id in: 10612\n",
      "img id out: 10612\n",
      "img id in: 10613\n",
      "img id out: 10613\n",
      "img id in: 10614\n",
      "img id out: 10614\n",
      "img id in: 10615\n",
      "img id out: 10615\n",
      "img id in: 10616\n",
      "img id out: 10616\n",
      "img id in: 10617\n",
      "img id out: 10617\n",
      "img id in: 10618\n",
      "img id out: 10618\n",
      "img id in: 10619\n",
      "img id out: 10619\n",
      "img id in: 10620\n",
      "img id out: 10620\n",
      "img id in: 10621\n",
      "img id out: 10621\n",
      "img id in: 10622\n",
      "img id out: 10622\n",
      "img id in: 10623\n",
      "img id out: 10623\n",
      "img id in: 10624\n",
      "img id out: 10624\n",
      "img id in: 10625\n",
      "img id out: 10625\n",
      "img id in: 10626\n",
      "img id out: 10626\n",
      "img id in: 10627\n",
      "img id out: 10627\n",
      "img id in: 10628\n",
      "img id out: 10628\n",
      "img id in: 10629\n",
      "img id out: 10629\n",
      "img id in: 10630\n",
      "img id out: 10630\n",
      "img id in: 10631\n",
      "img id out: 10631\n",
      "img id in: 10632\n",
      "img id out: 10632\n",
      "img id in: 10633\n",
      "img id out: 10633\n",
      "img id in: 10634\n",
      "img id out: 10634\n",
      "img id in: 10635\n",
      "img id out: 10635\n",
      "img id in: 10636\n",
      "img id out: 10636\n",
      "img id in: 10637\n",
      "img id out: 10637\n",
      "img id in: 10638\n",
      "img id out: 10638\n",
      "img id in: 10639\n",
      "img id out: 10639\n",
      "img id in: 10640\n",
      "img id out: 10640\n",
      "img id in: 10641\n",
      "img id out: 10641\n",
      "img id in: 10642\n",
      "img id out: 10642\n",
      "img id in: 10643\n",
      "img id out: 10643\n",
      "img id in: 10644\n",
      "img id out: 10644\n",
      "img id in: 10645\n",
      "img id out: 10645\n",
      "img id in: 10646\n",
      "img id out: 10646\n",
      "img id in: 10647\n",
      "img id out: 10647\n",
      "img id in: 10648\n",
      "img id out: 10648\n",
      "img id in: 10649\n",
      "img id out: 10649\n",
      "img id in: 10650\n",
      "img id out: 10650\n",
      "img id in: 10651\n",
      "img id out: 10651\n",
      "img id in: 10652\n",
      "img id out: 10652\n",
      "img id in: 10653\n",
      "img id out: 10653\n",
      "img id in: 10654\n",
      "img id out: 10654\n",
      "img id in: 10655\n",
      "img id out: 10655\n",
      "img id in: 10656\n",
      "img id out: 10656\n",
      "img id in: 10657\n",
      "img id out: 10657\n",
      "img id in: 10658\n",
      "img id out: 10658\n",
      "img id in: 10659\n",
      "img id out: 10659\n",
      "img id in: 10660\n",
      "img id out: 10660\n",
      "img id in: 10661\n",
      "img id out: 10661\n",
      "img id in: 10662\n",
      "img id out: 10662\n",
      "img id in: 10663\n",
      "img id out: 10663\n",
      "img id in: 10664\n",
      "img id out: 10664\n",
      "img id in: 10665\n",
      "img id out: 10665\n",
      "img id in: 10666\n",
      "img id out: 10666\n",
      "img id in: 10667\n",
      "img id out: 10667\n",
      "img id in: 10668\n",
      "img id out: 10668\n",
      "img id in: 10669\n",
      "img id out: 10669\n",
      "img id in: 10670\n",
      "img id out: 10670\n",
      "img id in: 10671\n",
      "img id out: 10671\n",
      "img id in: 10672\n",
      "img id out: 10672\n",
      "img id in: 10673\n",
      "img id out: 10673\n",
      "img id in: 10674\n",
      "img id out: 10674\n",
      "img id in: 10675\n",
      "img id out: 10675\n",
      "img id in: 10676\n",
      "img id out: 10676\n",
      "img id in: 10677\n",
      "img id out: 10677\n",
      "img id in: 10678\n",
      "img id out: 10678\n",
      "img id in: 10679\n",
      "img id out: 10679\n",
      "img id in: 10680\n",
      "img id out: 10680\n",
      "img id in: 10681\n",
      "img id out: 10681\n",
      "img id in: 10682\n",
      "img id out: 10682\n",
      "img id in: 10683\n",
      "img id out: 10683\n",
      "img id in: 10684\n",
      "img id out: 10684\n",
      "img id in: 10685\n",
      "img id out: 10685\n",
      "img id in: 10686\n",
      "img id out: 10686\n",
      "img id in: 10687\n",
      "img id out: 10687\n",
      "img id in: 10688\n",
      "img id out: 10688\n",
      "img id in: 10689\n",
      "img id out: 10689\n",
      "img id in: 10690\n",
      "img id out: 10690\n",
      "img id in: 10691\n",
      "img id out: 10691\n",
      "img id in: 10692\n",
      "img id out: 10692\n",
      "img id in: 10693\n",
      "img id out: 10693\n",
      "img id in: 10694\n",
      "img id out: 10694\n",
      "img id in: 10695\n",
      "img id out: 10695\n",
      "img id in: 10696\n",
      "img id out: 10696\n",
      "img id in: 10697\n",
      "img id out: 10697\n",
      "img id in: 10698\n",
      "img id out: 10698\n",
      "img id in: 10699\n",
      "img id out: 10699\n",
      "img id in: 10700\n",
      "img id out: 10700\n",
      "img id in: 10701\n",
      "img id out: 10701\n",
      "img id in: 10702\n",
      "img id out: 10702\n",
      "img id in: 10703\n",
      "img id out: 10703\n",
      "img id in: 10704\n",
      "img id out: 10704\n",
      "img id in: 10705\n",
      "img id out: 10705\n",
      "img id in: 10706\n",
      "img id out: 10706\n",
      "img id in: 10707\n",
      "img id out: 10707\n",
      "img id in: 10708\n",
      "img id out: 10708\n",
      "img id in: 10709\n",
      "img id out: 10709\n",
      "img id in: 10710\n",
      "img id out: 10710\n",
      "img id in: 10711\n",
      "img id out: 10711\n",
      "img id in: 10712\n",
      "img id out: 10712\n",
      "img id in: 10713\n",
      "img id out: 10713\n",
      "img id in: 10714\n",
      "img id out: 10714\n",
      "img id in: 10715\n",
      "img id out: 10715\n",
      "img id in: 10716\n",
      "img id out: 10716\n",
      "img id in: 10717\n",
      "img id out: 10717\n",
      "img id in: 10718\n",
      "img id out: 10718\n",
      "img id in: 10719\n",
      "img id out: 10719\n",
      "img id in: 10720\n",
      "img id out: 10720\n",
      "img id in: 10721\n",
      "img id out: 10721\n",
      "img id in: 10722\n",
      "img id out: 10722\n",
      "img id in: 10723\n",
      "img id out: 10723\n",
      "img id in: 10724\n",
      "img id out: 10724\n",
      "img id in: 10725\n",
      "img id out: 10725\n",
      "img id in: 10726\n",
      "img id out: 10726\n",
      "img id in: 10727\n",
      "img id out: 10727\n",
      "img id in: 10728\n",
      "img id out: 10728\n",
      "img id in: 10729\n",
      "img id out: 10729\n",
      "img id in: 10730\n",
      "img id out: 10730\n",
      "img id in: 10731\n",
      "img id out: 10731\n",
      "img id in: 10732\n",
      "img id out: 10732\n",
      "img id in: 10733\n",
      "img id out: 10733\n",
      "img id in: 10734\n",
      "img id out: 10734\n",
      "img id in: 10735\n",
      "img id out: 10735\n",
      "img id in: 10736\n",
      "img id out: 10736\n",
      "img id in: 10737\n",
      "img id out: 10737\n",
      "img id in: 10738\n",
      "img id out: 10738\n",
      "img id in: 10739\n",
      "img id out: 10739\n",
      "img id in: 10740\n",
      "img id out: 10740\n",
      "img id in: 10741\n",
      "img id out: 10741\n",
      "img id in: 10742\n",
      "img id out: 10742\n",
      "img id in: 10743\n",
      "img id out: 10743\n",
      "img id in: 10744\n",
      "img id out: 10744\n",
      "img id in: 10745\n",
      "img id out: 10745\n",
      "img id in: 10746\n",
      "img id out: 10746\n",
      "img id in: 10747\n",
      "img id out: 10747\n",
      "img id in: 10748\n",
      "img id out: 10748\n",
      "img id in: 10749\n",
      "img id out: 10749\n",
      "img id in: 10750\n",
      "img id out: 10750\n",
      "img id in: 10751\n",
      "img id out: 10751\n",
      "img id in: 10752\n",
      "img id out: 10752\n",
      "img id in: 10753\n",
      "img id out: 10753\n",
      "img id in: 10754\n",
      "img id out: 10754\n",
      "img id in: 10755\n",
      "img id out: 10755\n",
      "img id in: 10756\n",
      "img id out: 10756\n",
      "img id in: 10757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 10757\n",
      "img id in: 10758\n",
      "img id out: 10758\n",
      "img id in: 10759\n",
      "img id out: 10759\n",
      "img id in: 10760\n",
      "img id out: 10760\n",
      "img id in: 10761\n",
      "img id out: 10761\n",
      "img id in: 10762\n",
      "img id out: 10762\n",
      "img id in: 10763\n",
      "img id out: 10763\n",
      "img id in: 10764\n",
      "img id out: 10764\n",
      "img id in: 10765\n",
      "img id out: 10765\n",
      "img id in: 10766\n",
      "img id out: 10766\n",
      "img id in: 10767\n",
      "img id out: 10767\n",
      "img id in: 10768\n",
      "img id out: 10768\n",
      "img id in: 10769\n",
      "img id out: 10769\n",
      "img id in: 10770\n",
      "img id out: 10770\n",
      "img id in: 10771\n",
      "img id out: 10771\n",
      "img id in: 10772\n",
      "img id out: 10772\n",
      "img id in: 10773\n",
      "img id out: 10773\n",
      "img id in: 10774\n",
      "img id out: 10774\n",
      "img id in: 10775\n",
      "img id out: 10775\n",
      "img id in: 10776\n",
      "img id out: 10776\n",
      "img id in: 10777\n",
      "img id out: 10777\n",
      "img id in: 10778\n",
      "img id out: 10778\n",
      "img id in: 10779\n",
      "img id out: 10779\n",
      "img id in: 10780\n",
      "img id out: 10780\n",
      "img id in: 10781\n",
      "img id out: 10781\n",
      "img id in: 10782\n",
      "img id out: 10782\n",
      "img id in: 10783\n",
      "img id out: 10783\n",
      "img id in: 10784\n",
      "img id out: 10784\n",
      "img id in: 10785\n",
      "img id out: 10785\n",
      "img id in: 10786\n",
      "img id out: 10786\n",
      "img id in: 10787\n",
      "img id out: 10787\n",
      "img id in: 10788\n",
      "img id out: 10788\n",
      "img id in: 10789\n",
      "img id out: 10789\n",
      "img id in: 10790\n",
      "img id out: 10790\n",
      "img id in: 10791\n",
      "img id out: 10791\n",
      "img id in: 10792\n",
      "img id out: 10792\n",
      "img id in: 10793\n",
      "img id out: 10793\n",
      "img id in: 10794\n",
      "img id out: 10794\n",
      "img id in: 10795\n",
      "img id out: 10795\n",
      "img id in: 10796\n",
      "img id out: 10796\n",
      "img id in: 10797\n",
      "img id out: 10797\n",
      "img id in: 10798\n",
      "img id out: 10798\n",
      "img id in: 10799\n",
      "img id out: 10799\n",
      "img id in: 10800\n",
      "img id out: 10800\n",
      "img id in: 10801\n",
      "img id out: 10801\n",
      "img id in: 10802\n",
      "img id out: 10802\n",
      "img id in: 10803\n",
      "img id out: 10803\n",
      "img id in: 10804\n",
      "img id out: 10804\n",
      "img id in: 10805\n",
      "img id out: 10805\n",
      "img id in: 10806\n",
      "img id out: 10806\n",
      "img id in: 10807\n",
      "img id out: 10807\n",
      "img id in: 10808\n",
      "img id out: 10808\n",
      "img id in: 10809\n",
      "img id out: 10809\n",
      "img id in: 10810\n",
      "img id out: 10810\n",
      "img id in: 10811\n",
      "img id out: 10811\n",
      "img id in: 10812\n",
      "img id out: 10812\n",
      "img id in: 10813\n",
      "img id out: 10813\n",
      "img id in: 10814\n",
      "img id out: 10814\n",
      "img id in: 10815\n",
      "img id out: 10815\n",
      "img id in: 10816\n",
      "img id out: 10816\n",
      "img id in: 10817\n",
      "img id out: 10817\n",
      "img id in: 10818\n",
      "img id out: 10818\n",
      "img id in: 10819\n",
      "img id out: 10819\n",
      "img id in: 10820\n",
      "img id out: 10820\n",
      "img id in: 10821\n",
      "img id out: 10821\n",
      "img id in: 10822\n",
      "img id out: 10822\n",
      "img id in: 10823\n",
      "img id out: 10823\n",
      "img id in: 10824\n",
      "img id out: 10824\n",
      "img id in: 10825\n",
      "img id out: 10825\n",
      "img id in: 10826\n",
      "img id out: 10826\n",
      "img id in: 10827\n",
      "img id out: 10827\n",
      "img id in: 10828\n",
      "img id out: 10828\n",
      "img id in: 10829\n",
      "img id out: 10829\n",
      "img id in: 10830\n",
      "img id out: 10830\n",
      "img id in: 10831\n",
      "img id out: 10831\n",
      "img id in: 10832\n",
      "img id out: 10832\n",
      "img id in: 10833\n",
      "img id out: 10833\n",
      "img id in: 10834\n",
      "img id out: 10834\n",
      "img id in: 10835\n",
      "img id out: 10835\n",
      "img id in: 10836\n",
      "img id out: 10836\n",
      "img id in: 10837\n",
      "img id out: 10837\n",
      "img id in: 10838\n",
      "img id out: 10838\n",
      "img id in: 10839\n",
      "img id out: 10839\n",
      "img id in: 10840\n",
      "img id out: 10840\n",
      "img id in: 10841\n",
      "img id out: 10841\n",
      "img id in: 10842\n",
      "img id out: 10842\n",
      "img id in: 10843\n",
      "img id out: 10843\n",
      "img id in: 10844\n",
      "img id out: 10844\n",
      "img id in: 10845\n",
      "img id out: 10845\n",
      "img id in: 10846\n",
      "img id out: 10846\n",
      "img id in: 10847\n",
      "img id out: 10847\n",
      "img id in: 10848\n",
      "img id out: 10848\n",
      "img id in: 10849\n",
      "img id out: 10849\n",
      "img id in: 10850\n",
      "img id out: 10850\n",
      "img id in: 10851\n",
      "img id out: 10851\n",
      "img id in: 10852\n",
      "img id out: 10852\n",
      "img id in: 10853\n",
      "img id out: 10853\n",
      "img id in: 10854\n",
      "img id out: 10854\n",
      "img id in: 10855\n",
      "img id out: 10855\n",
      "img id in: 10856\n",
      "img id out: 10856\n",
      "img id in: 10857\n",
      "img id out: 10857\n",
      "img id in: 10858\n",
      "img id out: 10858\n",
      "img id in: 10859\n",
      "img id out: 10859\n",
      "img id in: 10860\n",
      "img id out: 10860\n",
      "img id in: 10861\n",
      "img id out: 10861\n",
      "img id in: 10862\n",
      "img id out: 10862\n",
      "img id in: 10863\n",
      "img id out: 10863\n",
      "img id in: 10864\n",
      "img id out: 10864\n",
      "img id in: 10865\n",
      "img id out: 10865\n",
      "img id in: 10866\n",
      "img id out: 10866\n",
      "img id in: 10867\n",
      "img id out: 10867\n",
      "img id in: 10868\n",
      "img id out: 10868\n",
      "img id in: 10869\n",
      "img id out: 10869\n",
      "img id in: 10870\n",
      "img id out: 10870\n",
      "img id in: 10871\n",
      "img id out: 10871\n",
      "img id in: 10872\n",
      "img id out: 10872\n",
      "img id in: 10873\n",
      "img id out: 10873\n",
      "img id in: 10874\n",
      "img id out: 10874\n",
      "img id in: 10875\n",
      "img id out: 10875\n",
      "img id in: 10876\n",
      "img id out: 10876\n",
      "img id in: 10877\n",
      "img id out: 10877\n",
      "img id in: 10878\n",
      "img id out: 10878\n",
      "img id in: 10879\n",
      "img id out: 10879\n",
      "img id in: 10880\n",
      "img id out: 10880\n",
      "img id in: 10881\n",
      "img id out: 10881\n",
      "img id in: 10882\n",
      "img id out: 10882\n",
      "img id in: 10883\n",
      "img id out: 10883\n",
      "img id in: 10884\n",
      "img id out: 10884\n",
      "img id in: 10885\n",
      "img id out: 10885\n",
      "img id in: 10886\n",
      "img id out: 10886\n",
      "img id in: 10887\n",
      "img id out: 10887\n",
      "img id in: 10888\n",
      "img id out: 10888\n",
      "img id in: 10889\n",
      "img id out: 10889\n",
      "img id in: 10890\n",
      "img id out: 10890\n",
      "img id in: 10891\n",
      "img id out: 10891\n",
      "img id in: 10892\n",
      "img id out: 10892\n",
      "img id in: 10893\n",
      "img id out: 10893\n",
      "img id in: 10894\n",
      "img id out: 10894\n",
      "img id in: 10895\n",
      "img id out: 10895\n",
      "img id in: 10896\n",
      "img id out: 10896\n",
      "img id in: 10897\n",
      "img id out: 10897\n",
      "img id in: 10898\n",
      "img id out: 10898\n",
      "img id in: 10899\n",
      "img id out: 10899\n",
      "img id in: 10900\n",
      "img id out: 10900\n",
      "img id in: 10901\n",
      "img id out: 10901\n",
      "img id in: 10902\n",
      "img id out: 10902\n",
      "img id in: 10903\n",
      "img id out: 10903\n",
      "img id in: 10904\n",
      "img id out: 10904\n",
      "img id in: 10905\n",
      "img id out: 10905\n",
      "img id in: 10906\n",
      "img id out: 10906\n",
      "img id in: 10907\n",
      "img id out: 10907\n",
      "img id in: 10908\n",
      "img id out: 10908\n",
      "img id in: 10909\n",
      "img id out: 10909\n",
      "img id in: 10910\n",
      "img id out: 10910\n",
      "img id in: 10911\n",
      "img id out: 10911\n",
      "img id in: 10912\n",
      "img id out: 10912\n",
      "img id in: 10913\n",
      "img id out: 10913\n",
      "img id in: 10914\n",
      "img id out: 10914\n",
      "img id in: 10915\n",
      "img id out: 10915\n",
      "img id in: 10916\n",
      "img id out: 10916\n",
      "img id in: 10917\n",
      "img id out: 10917\n",
      "img id in: 10918\n",
      "img id out: 10918\n",
      "img id in: 10919\n",
      "img id out: 10919\n",
      "img id in: 10920\n",
      "img id out: 10920\n",
      "img id in: 10921\n",
      "img id out: 10921\n",
      "img id in: 10922\n",
      "img id out: 10922\n",
      "img id in: 10923\n",
      "img id out: 10923\n",
      "img id in: 10924\n",
      "img id out: 10924\n",
      "img id in: 10925\n",
      "img id out: 10925\n",
      "img id in: 10926\n",
      "img id out: 10926\n",
      "img id in: 10927\n",
      "img id out: 10927\n",
      "img id in: 10928\n",
      "img id out: 10928\n",
      "img id in: 10929\n",
      "img id out: 10929\n",
      "img id in: 10930\n",
      "img id out: 10930\n",
      "img id in: 10931\n",
      "img id out: 10931\n",
      "img id in: 10932\n",
      "img id out: 10932\n",
      "img id in: 10933\n",
      "img id out: 10933\n",
      "img id in: 10934\n",
      "img id out: 10934\n",
      "img id in: 10935\n",
      "img id out: 10935\n",
      "img id in: 10936\n",
      "img id out: 10936\n",
      "img id in: 10937\n",
      "img id out: 10937\n",
      "img id in: 10938\n",
      "img id out: 10938\n",
      "img id in: 10939\n",
      "img id out: 10939\n",
      "img id in: 10940\n",
      "img id out: 10940\n",
      "img id in: 10941\n",
      "img id out: 10941\n",
      "img id in: 10942\n",
      "img id out: 10942\n",
      "img id in: 10943\n",
      "img id out: 10943\n",
      "img id in: 10944\n",
      "img id out: 10944\n",
      "img id in: 10945\n",
      "img id out: 10945\n",
      "img id in: 10946\n",
      "img id out: 10946\n",
      "img id in: 10947\n",
      "img id out: 10947\n",
      "img id in: 10948\n",
      "img id out: 10948\n",
      "img id in: 10949\n",
      "img id out: 10949\n",
      "img id in: 10950\n",
      "img id out: 10950\n",
      "img id in: 10951\n",
      "img id out: 10951\n",
      "img id in: 10952\n",
      "img id out: 10952\n",
      "img id in: 10953\n",
      "img id out: 10953\n",
      "img id in: 10954\n",
      "img id out: 10954\n",
      "img id in: 10955\n",
      "img id out: 10955\n",
      "img id in: 10956\n",
      "img id out: 10956\n",
      "img id in: 10957\n",
      "img id out: 10957\n",
      "img id in: 10958\n",
      "img id out: 10958\n",
      "img id in: 10959\n",
      "img id out: 10959\n",
      "img id in: 10960\n",
      "img id out: 10960\n",
      "img id in: 10961\n",
      "img id out: 10961\n",
      "img id in: 10962\n",
      "img id out: 10962\n",
      "img id in: 10963\n",
      "img id out: 10963\n",
      "img id in: 10964\n",
      "img id out: 10964\n",
      "img id in: 10965\n",
      "img id out: 10965\n",
      "img id in: 10966\n",
      "img id out: 10966\n",
      "img id in: 10967\n",
      "img id out: 10967\n",
      "img id in: 10968\n",
      "img id out: 10968\n",
      "img id in: 10969\n",
      "img id out: 10969\n",
      "img id in: 10970\n",
      "img id out: 10970\n",
      "img id in: 10971\n",
      "img id out: 10971\n",
      "img id in: 10972\n",
      "img id out: 10972\n",
      "img id in: 10973\n",
      "img id out: 10973\n",
      "img id in: 10974\n",
      "img id out: 10974\n",
      "img id in: 10975\n",
      "img id out: 10975\n",
      "img id in: 10976\n",
      "img id out: 10976\n",
      "img id in: 10977\n",
      "img id out: 10977\n",
      "img id in: 10978\n",
      "img id out: 10978\n",
      "img id in: 10979\n",
      "img id out: 10979\n",
      "img id in: 10980\n",
      "img id out: 10980\n",
      "img id in: 10981\n",
      "img id out: 10981\n",
      "img id in: 10982\n",
      "img id out: 10982\n",
      "img id in: 10983\n",
      "img id out: 10983\n",
      "img id in: 10984\n",
      "img id out: 10984\n",
      "img id in: 10985\n",
      "img id out: 10985\n",
      "img id in: 10986\n",
      "img id out: 10986\n",
      "img id in: 10987\n",
      "img id out: 10987\n",
      "img id in: 10988\n",
      "img id out: 10988\n",
      "img id in: 10989\n",
      "img id out: 10989\n",
      "img id in: 10990\n",
      "img id out: 10990\n",
      "img id in: 10991\n",
      "img id out: 10991\n",
      "img id in: 10992\n",
      "img id out: 10992\n",
      "img id in: 10993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 10993\n",
      "img id in: 10994\n",
      "img id out: 10994\n",
      "img id in: 10995\n",
      "img id out: 10995\n",
      "img id in: 10996\n",
      "img id out: 10996\n",
      "img id in: 10997\n",
      "img id out: 10997\n",
      "img id in: 10998\n",
      "img id out: 10998\n",
      "img id in: 10999\n",
      "img id out: 10999\n",
      "img id in: 11000\n",
      "img id out: 11000\n",
      "img id in: 11001\n",
      "img id out: 11001\n",
      "img id in: 11002\n",
      "img id out: 11002\n",
      "img id in: 11003\n",
      "img id out: 11003\n",
      "img id in: 11004\n",
      "img id out: 11004\n",
      "img id in: 11005\n",
      "img id out: 11005\n",
      "img id in: 11006\n",
      "img id out: 11006\n",
      "img id in: 11007\n",
      "img id out: 11007\n",
      "img id in: 11008\n",
      "img id out: 11008\n",
      "img id in: 11009\n",
      "img id out: 11009\n",
      "img id in: 11010\n",
      "img id out: 11010\n",
      "img id in: 11011\n",
      "img id out: 11011\n",
      "img id in: 11012\n",
      "img id out: 11012\n",
      "img id in: 11013\n",
      "img id out: 11013\n",
      "img id in: 11014\n",
      "img id out: 11014\n",
      "img id in: 11015\n",
      "img id out: 11015\n",
      "img id in: 11016\n",
      "img id out: 11016\n",
      "img id in: 11017\n",
      "img id out: 11017\n",
      "img id in: 11018\n",
      "img id out: 11018\n",
      "img id in: 11019\n",
      "img id out: 11019\n",
      "img id in: 11020\n",
      "img id out: 11020\n",
      "img id in: 11021\n",
      "img id out: 11021\n",
      "img id in: 11022\n",
      "img id out: 11022\n",
      "img id in: 11023\n",
      "img id out: 11023\n",
      "img id in: 11024\n",
      "img id out: 11024\n",
      "img id in: 11025\n",
      "img id out: 11025\n",
      "img id in: 11026\n",
      "img id out: 11026\n",
      "img id in: 11027\n",
      "img id out: 11027\n",
      "img id in: 11028\n",
      "img id out: 11028\n",
      "img id in: 11029\n",
      "img id out: 11029\n",
      "img id in: 11030\n",
      "img id out: 11030\n",
      "img id in: 11031\n",
      "img id out: 11031\n",
      "img id in: 11032\n",
      "img id out: 11032\n",
      "img id in: 11033\n",
      "img id out: 11033\n",
      "img id in: 11034\n",
      "img id out: 11034\n",
      "img id in: 11035\n",
      "img id out: 11035\n",
      "img id in: 11036\n",
      "img id out: 11036\n",
      "img id in: 11037\n",
      "img id out: 11037\n",
      "img id in: 11038\n",
      "img id out: 11038\n",
      "img id in: 11039\n",
      "img id out: 11039\n",
      "img id in: 11040\n",
      "img id out: 11040\n",
      "img id in: 11041\n",
      "img id out: 11041\n",
      "img id in: 11042\n",
      "img id out: 11042\n",
      "img id in: 11043\n",
      "img id out: 11043\n",
      "img id in: 11044\n",
      "img id out: 11044\n",
      "img id in: 11045\n",
      "img id out: 11045\n",
      "img id in: 11046\n",
      "img id out: 11046\n",
      "img id in: 11047\n",
      "img id out: 11047\n",
      "img id in: 11048\n",
      "img id out: 11048\n",
      "img id in: 11049\n",
      "img id out: 11049\n",
      "img id in: 11050\n",
      "img id out: 11050\n",
      "img id in: 11051\n",
      "img id out: 11051\n",
      "img id in: 11052\n",
      "img id out: 11052\n",
      "img id in: 11053\n",
      "img id out: 11053\n",
      "img id in: 11054\n",
      "img id out: 11054\n",
      "img id in: 11055\n",
      "img id out: 11055\n",
      "img id in: 11056\n",
      "img id out: 11056\n",
      "img id in: 11057\n",
      "img id out: 11057\n",
      "img id in: 11058\n",
      "img id out: 11058\n",
      "img id in: 11059\n",
      "img id out: 11059\n",
      "img id in: 11060\n",
      "img id out: 11060\n",
      "img id in: 11061\n",
      "img id out: 11061\n",
      "img id in: 11062\n",
      "img id out: 11062\n",
      "img id in: 11063\n",
      "img id out: 11063\n",
      "img id in: 11064\n",
      "img id out: 11064\n",
      "img id in: 11065\n",
      "img id out: 11065\n",
      "img id in: 11066\n",
      "img id out: 11066\n",
      "img id in: 11067\n",
      "img id out: 11067\n",
      "img id in: 11068\n",
      "img id out: 11068\n",
      "img id in: 11069\n",
      "img id out: 11069\n",
      "img id in: 11070\n",
      "img id out: 11070\n",
      "img id in: 11071\n",
      "img id out: 11071\n",
      "img id in: 11072\n",
      "img id out: 11072\n",
      "img id in: 11073\n",
      "img id out: 11073\n",
      "img id in: 11074\n",
      "img id out: 11074\n",
      "img id in: 11075\n",
      "img id out: 11075\n",
      "img id in: 11076\n",
      "img id out: 11076\n",
      "img id in: 11077\n",
      "img id out: 11077\n",
      "img id in: 11078\n",
      "img id out: 11078\n",
      "img id in: 11079\n",
      "img id out: 11079\n",
      "img id in: 11080\n",
      "img id out: 11080\n",
      "img id in: 11081\n",
      "img id out: 11081\n",
      "img id in: 11082\n",
      "img id out: 11082\n",
      "img id in: 11083\n",
      "img id out: 11083\n",
      "img id in: 11084\n",
      "img id out: 11084\n",
      "img id in: 11085\n",
      "img id out: 11085\n",
      "img id in: 11086\n",
      "img id out: 11086\n",
      "img id in: 11087\n",
      "img id out: 11087\n",
      "img id in: 11088\n",
      "img id out: 11088\n",
      "img id in: 11089\n",
      "img id out: 11089\n",
      "img id in: 11090\n",
      "img id out: 11090\n",
      "img id in: 11091\n",
      "img id out: 11091\n",
      "img id in: 11092\n",
      "img id out: 11092\n",
      "img id in: 11093\n",
      "img id out: 11093\n",
      "img id in: 11094\n",
      "img id out: 11094\n",
      "img id in: 11095\n",
      "img id out: 11095\n",
      "img id in: 11096\n",
      "img id out: 11096\n",
      "img id in: 11097\n",
      "img id out: 11097\n",
      "img id in: 11098\n",
      "img id out: 11098\n",
      "img id in: 11099\n",
      "img id out: 11099\n",
      "img id in: 11100\n",
      "img id out: 11100\n",
      "img id in: 11101\n",
      "img id out: 11101\n",
      "img id in: 11102\n",
      "img id out: 11102\n",
      "img id in: 11103\n",
      "img id out: 11103\n",
      "img id in: 11104\n",
      "img id out: 11104\n",
      "img id in: 11105\n",
      "img id out: 11105\n",
      "img id in: 11106\n",
      "img id out: 11106\n",
      "img id in: 11107\n",
      "img id out: 11107\n",
      "img id in: 11108\n",
      "img id out: 11108\n",
      "img id in: 11109\n",
      "img id out: 11109\n",
      "img id in: 11110\n",
      "img id out: 11110\n",
      "img id in: 11111\n",
      "img id out: 11111\n",
      "img id in: 11112\n",
      "img id out: 11112\n",
      "img id in: 11113\n",
      "img id out: 11113\n",
      "img id in: 11114\n",
      "img id out: 11114\n",
      "img id in: 11115\n",
      "img id out: 11115\n",
      "img id in: 11116\n",
      "img id out: 11116\n",
      "img id in: 11117\n",
      "img id out: 11117\n",
      "img id in: 11118\n",
      "img id out: 11118\n",
      "img id in: 11119\n",
      "img id out: 11119\n",
      "img id in: 11120\n",
      "img id out: 11120\n",
      "img id in: 11121\n",
      "img id out: 11121\n",
      "img id in: 11122\n",
      "img id out: 11122\n",
      "img id in: 11123\n",
      "img id out: 11123\n",
      "img id in: 11124\n",
      "img id out: 11124\n",
      "img id in: 11125\n",
      "img id out: 11125\n",
      "img id in: 11126\n",
      "img id out: 11126\n",
      "img id in: 11127\n",
      "img id out: 11127\n",
      "img id in: 11128\n",
      "img id out: 11128\n",
      "img id in: 11129\n",
      "img id out: 11129\n",
      "img id in: 11130\n",
      "img id out: 11130\n",
      "img id in: 11131\n",
      "img id out: 11131\n",
      "img id in: 11132\n",
      "img id out: 11132\n",
      "img id in: 11133\n",
      "img id out: 11133\n",
      "img id in: 11134\n",
      "img id out: 11134\n",
      "img id in: 11135\n",
      "img id out: 11135\n",
      "img id in: 11136\n",
      "img id out: 11136\n",
      "img id in: 11137\n",
      "img id out: 11137\n",
      "img id in: 11138\n",
      "img id out: 11138\n",
      "img id in: 11139\n",
      "img id out: 11139\n",
      "img id in: 11140\n",
      "img id out: 11140\n",
      "img id in: 11141\n",
      "img id out: 11141\n",
      "img id in: 11142\n",
      "img id out: 11142\n",
      "img id in: 11143\n",
      "img id out: 11143\n",
      "img id in: 11144\n",
      "img id out: 11144\n",
      "img id in: 11145\n",
      "img id out: 11145\n",
      "img id in: 11146\n",
      "img id out: 11146\n",
      "img id in: 11147\n",
      "img id out: 11147\n",
      "img id in: 11148\n",
      "img id out: 11148\n",
      "img id in: 11149\n",
      "img id out: 11149\n",
      "img id in: 11150\n",
      "img id out: 11150\n",
      "img id in: 11151\n",
      "img id out: 11151\n",
      "img id in: 11152\n",
      "img id out: 11152\n",
      "img id in: 11153\n",
      "img id out: 11153\n",
      "img id in: 11154\n",
      "img id out: 11154\n",
      "img id in: 11155\n",
      "img id out: 11155\n",
      "img id in: 11156\n",
      "img id out: 11156\n",
      "img id in: 11157\n",
      "img id out: 11157\n",
      "img id in: 11158\n",
      "img id out: 11158\n",
      "img id in: 11159\n",
      "img id out: 11159\n",
      "img id in: 11160\n",
      "img id out: 11160\n",
      "img id in: 11161\n",
      "img id out: 11161\n",
      "img id in: 11162\n",
      "img id out: 11162\n",
      "img id in: 11163\n",
      "img id out: 11163\n",
      "img id in: 11164\n",
      "img id out: 11164\n",
      "img id in: 11165\n",
      "img id out: 11165\n",
      "img id in: 11166\n",
      "img id out: 11166\n",
      "img id in: 11167\n",
      "img id out: 11167\n",
      "img id in: 11168\n",
      "img id out: 11168\n",
      "img id in: 11169\n",
      "img id out: 11169\n",
      "img id in: 11170\n",
      "img id out: 11170\n",
      "img id in: 11171\n",
      "img id out: 11171\n",
      "img id in: 11172\n",
      "img id out: 11172\n",
      "img id in: 11173\n",
      "img id out: 11173\n",
      "img id in: 11174\n",
      "img id out: 11174\n",
      "img id in: 11175\n",
      "img id out: 11175\n",
      "img id in: 11176\n",
      "img id out: 11176\n",
      "img id in: 11177\n",
      "img id out: 11177\n",
      "img id in: 11178\n",
      "img id out: 11178\n",
      "img id in: 11179\n",
      "img id out: 11179\n",
      "img id in: 11180\n",
      "img id out: 11180\n",
      "img id in: 11181\n",
      "img id out: 11181\n",
      "img id in: 11182\n",
      "img id out: 11182\n",
      "img id in: 11183\n",
      "img id out: 11183\n",
      "img id in: 11184\n",
      "img id out: 11184\n",
      "img id in: 11185\n",
      "img id out: 11185\n",
      "img id in: 11186\n",
      "img id out: 11186\n",
      "img id in: 11187\n",
      "img id out: 11187\n",
      "img id in: 11188\n",
      "img id out: 11188\n",
      "img id in: 11189\n",
      "img id out: 11189\n",
      "img id in: 11190\n",
      "img id out: 11190\n",
      "img id in: 11191\n",
      "img id out: 11191\n",
      "img id in: 11192\n",
      "img id out: 11192\n",
      "img id in: 11193\n",
      "img id out: 11193\n",
      "img id in: 11194\n",
      "img id out: 11194\n",
      "img id in: 11195\n",
      "img id out: 11195\n",
      "img id in: 11196\n",
      "img id out: 11196\n",
      "img id in: 11197\n",
      "img id out: 11197\n",
      "img id in: 11198\n",
      "img id out: 11198\n",
      "img id in: 11199\n",
      "img id out: 11199\n",
      "img id in: 11200\n",
      "img id out: 11200\n",
      "img id in: 11201\n",
      "img id out: 11201\n",
      "img id in: 11202\n",
      "img id out: 11202\n",
      "img id in: 11203\n",
      "img id out: 11203\n",
      "img id in: 11204\n",
      "img id out: 11204\n",
      "img id in: 11205\n",
      "img id out: 11205\n",
      "img id in: 11206\n",
      "img id out: 11206\n",
      "img id in: 11207\n",
      "img id out: 11207\n",
      "img id in: 11208\n",
      "img id out: 11208\n",
      "img id in: 11209\n",
      "img id out: 11209\n",
      "img id in: 11210\n",
      "img id out: 11210\n",
      "img id in: 11211\n",
      "img id out: 11211\n",
      "img id in: 11212\n",
      "img id out: 11212\n",
      "img id in: 11213\n",
      "img id out: 11213\n",
      "img id in: 11214\n",
      "img id out: 11214\n",
      "img id in: 11215\n",
      "img id out: 11215\n",
      "img id in: 11216\n",
      "img id out: 11216\n",
      "img id in: 11217\n",
      "img id out: 11217\n",
      "img id in: 11218\n",
      "img id out: 11218\n",
      "img id in: 11219\n",
      "img id out: 11219\n",
      "img id in: 11220\n",
      "img id out: 11220\n",
      "img id in: 11221\n",
      "img id out: 11221\n",
      "img id in: 11222\n",
      "img id out: 11222\n",
      "img id in: 11223\n",
      "img id out: 11223\n",
      "img id in: 11224\n",
      "img id out: 11224\n",
      "img id in: 11225\n",
      "img id out: 11225\n",
      "img id in: 11226\n",
      "img id out: 11226\n",
      "img id in: 11227\n",
      "img id out: 11227\n",
      "img id in: 11228\n",
      "img id out: 11228\n",
      "img id in: 11229\n",
      "img id out: 11229\n",
      "img id in: 11230\n",
      "img id out: 11230\n",
      "img id in: 11231\n",
      "img id out: 11231\n",
      "img id in: 11232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 11232\n",
      "img id in: 11233\n",
      "img id out: 11233\n",
      "img id in: 11234\n",
      "img id out: 11234\n",
      "img id in: 11235\n",
      "img id out: 11235\n",
      "img id in: 11236\n",
      "img id out: 11236\n",
      "img id in: 11237\n",
      "img id out: 11237\n",
      "img id in: 11238\n",
      "img id out: 11238\n",
      "img id in: 11239\n",
      "img id out: 11239\n",
      "img id in: 11240\n",
      "img id out: 11240\n",
      "img id in: 11241\n",
      "img id out: 11241\n",
      "img id in: 11242\n",
      "img id out: 11242\n",
      "img id in: 11243\n",
      "img id out: 11243\n",
      "img id in: 11244\n",
      "img id out: 11244\n",
      "img id in: 11245\n",
      "img id out: 11245\n",
      "img id in: 11246\n",
      "img id out: 11246\n",
      "img id in: 11247\n",
      "img id out: 11247\n",
      "img id in: 11248\n",
      "img id out: 11248\n",
      "img id in: 11249\n",
      "img id out: 11249\n",
      "img id in: 11250\n",
      "img id out: 11250\n",
      "img id in: 11251\n",
      "img id out: 11251\n",
      "img id in: 11252\n",
      "img id out: 11252\n",
      "img id in: 11253\n",
      "img id out: 11253\n",
      "img id in: 11254\n",
      "img id out: 11254\n",
      "img id in: 11255\n",
      "img id out: 11255\n",
      "img id in: 11256\n",
      "img id out: 11256\n",
      "img id in: 11257\n",
      "img id out: 11257\n",
      "img id in: 11258\n",
      "img id out: 11258\n",
      "img id in: 11259\n",
      "img id out: 11259\n",
      "img id in: 11260\n",
      "img id out: 11260\n",
      "img id in: 11261\n",
      "img id out: 11261\n",
      "img id in: 11262\n",
      "img id out: 11262\n",
      "img id in: 11263\n",
      "img id out: 11263\n",
      "img id in: 11264\n",
      "img id out: 11264\n",
      "img id in: 11265\n",
      "img id out: 11265\n",
      "img id in: 11266\n",
      "img id out: 11266\n",
      "img id in: 11267\n",
      "img id out: 11267\n",
      "img id in: 11268\n",
      "img id out: 11268\n",
      "img id in: 11269\n",
      "img id out: 11269\n",
      "img id in: 11270\n",
      "img id out: 11270\n",
      "img id in: 11271\n",
      "img id out: 11271\n",
      "img id in: 11272\n",
      "img id out: 11272\n",
      "img id in: 11273\n",
      "img id out: 11273\n",
      "img id in: 11274\n",
      "img id out: 11274\n",
      "img id in: 11275\n",
      "img id out: 11275\n",
      "img id in: 11276\n",
      "img id out: 11276\n",
      "img id in: 11277\n",
      "img id out: 11277\n",
      "img id in: 11278\n",
      "img id out: 11278\n",
      "img id in: 11279\n",
      "img id out: 11279\n",
      "img id in: 11280\n",
      "img id out: 11280\n",
      "img id in: 11281\n",
      "img id out: 11281\n",
      "img id in: 11282\n",
      "img id out: 11282\n",
      "img id in: 11283\n",
      "img id out: 11283\n",
      "img id in: 11284\n",
      "img id out: 11284\n",
      "img id in: 11285\n",
      "img id out: 11285\n",
      "img id in: 11286\n",
      "img id out: 11286\n",
      "img id in: 11287\n",
      "img id out: 11287\n",
      "img id in: 11288\n",
      "img id out: 11288\n",
      "img id in: 11289\n",
      "img id out: 11289\n",
      "img id in: 11290\n",
      "img id out: 11290\n",
      "img id in: 11291\n",
      "img id out: 11291\n",
      "img id in: 11292\n",
      "img id out: 11292\n",
      "img id in: 11293\n",
      "img id out: 11293\n",
      "img id in: 11294\n",
      "img id out: 11294\n",
      "img id in: 11295\n",
      "img id out: 11295\n",
      "img id in: 11296\n",
      "img id out: 11296\n",
      "img id in: 11297\n",
      "img id out: 11297\n",
      "img id in: 11298\n",
      "img id out: 11298\n",
      "img id in: 11299\n",
      "img id out: 11299\n",
      "img id in: 11300\n",
      "img id out: 11300\n",
      "img id in: 11301\n",
      "img id out: 11301\n",
      "img id in: 11302\n",
      "img id out: 11302\n",
      "img id in: 11303\n",
      "img id out: 11303\n",
      "img id in: 11304\n",
      "img id out: 11304\n",
      "img id in: 11305\n",
      "img id out: 11305\n",
      "img id in: 11306\n",
      "img id out: 11306\n",
      "img id in: 11307\n",
      "img id out: 11307\n",
      "img id in: 11308\n",
      "img id out: 11308\n",
      "img id in: 11309\n",
      "img id out: 11309\n",
      "img id in: 11310\n",
      "img id out: 11310\n",
      "img id in: 11311\n",
      "img id out: 11311\n",
      "img id in: 11312\n",
      "img id out: 11312\n",
      "img id in: 11313\n",
      "img id out: 11313\n",
      "img id in: 11314\n",
      "img id out: 11314\n",
      "img id in: 11315\n",
      "img id out: 11315\n",
      "img id in: 11316\n",
      "img id out: 11316\n",
      "img id in: 11317\n",
      "img id out: 11317\n",
      "img id in: 11318\n",
      "img id out: 11318\n",
      "img id in: 11319\n",
      "img id out: 11319\n",
      "img id in: 11320\n",
      "img id out: 11320\n",
      "img id in: 11321\n",
      "img id out: 11321\n",
      "img id in: 11322\n",
      "img id out: 11322\n",
      "img id in: 11323\n",
      "img id out: 11323\n",
      "img id in: 11324\n",
      "img id out: 11324\n",
      "img id in: 11325\n",
      "img id out: 11325\n",
      "img id in: 11326\n",
      "img id out: 11326\n",
      "img id in: 11327\n",
      "img id out: 11327\n",
      "img id in: 11328\n",
      "img id out: 11328\n",
      "img id in: 11329\n",
      "img id out: 11329\n",
      "img id in: 11330\n",
      "img id out: 11330\n",
      "img id in: 11331\n",
      "img id out: 11331\n",
      "img id in: 11332\n",
      "img id out: 11332\n",
      "img id in: 11333\n",
      "img id out: 11333\n",
      "img id in: 11334\n",
      "img id out: 11334\n",
      "img id in: 11335\n",
      "img id out: 11335\n",
      "img id in: 11336\n",
      "img id out: 11336\n",
      "img id in: 11337\n",
      "img id out: 11337\n",
      "img id in: 11338\n",
      "img id out: 11338\n",
      "img id in: 11339\n",
      "img id out: 11339\n",
      "img id in: 11340\n",
      "img id out: 11340\n",
      "img id in: 11341\n",
      "img id out: 11341\n",
      "img id in: 11342\n",
      "img id out: 11342\n",
      "img id in: 11343\n",
      "img id out: 11343\n",
      "img id in: 11344\n",
      "img id out: 11344\n",
      "img id in: 11345\n",
      "img id out: 11345\n",
      "img id in: 11346\n",
      "img id out: 11346\n",
      "img id in: 11347\n",
      "img id out: 11347\n",
      "img id in: 11348\n",
      "img id out: 11348\n",
      "img id in: 11349\n",
      "img id out: 11349\n",
      "img id in: 11350\n",
      "img id out: 11350\n",
      "img id in: 11351\n",
      "img id out: 11351\n",
      "img id in: 11352\n",
      "img id out: 11352\n",
      "img id in: 11353\n",
      "img id out: 11353\n",
      "img id in: 11354\n",
      "img id out: 11354\n",
      "img id in: 11355\n",
      "img id out: 11355\n",
      "img id in: 11356\n",
      "img id out: 11356\n",
      "img id in: 11357\n",
      "img id out: 11357\n",
      "img id in: 11358\n",
      "img id out: 11358\n",
      "img id in: 11359\n",
      "img id out: 11359\n",
      "img id in: 11360\n",
      "img id out: 11360\n",
      "img id in: 11361\n",
      "img id out: 11361\n",
      "img id in: 11362\n",
      "img id out: 11362\n",
      "img id in: 11363\n",
      "img id out: 11363\n",
      "img id in: 11364\n",
      "img id out: 11364\n",
      "img id in: 11365\n",
      "img id out: 11365\n",
      "img id in: 11366\n",
      "img id out: 11366\n",
      "img id in: 11367\n",
      "img id out: 11367\n",
      "img id in: 11368\n",
      "img id out: 11368\n",
      "img id in: 11369\n",
      "img id out: 11369\n",
      "img id in: 11370\n",
      "img id out: 11370\n",
      "img id in: 11371\n",
      "img id out: 11371\n",
      "img id in: 11372\n",
      "img id out: 11372\n",
      "img id in: 11373\n",
      "img id out: 11373\n",
      "img id in: 11374\n",
      "img id out: 11374\n",
      "img id in: 11375\n",
      "img id out: 11375\n",
      "img id in: 11376\n",
      "img id out: 11376\n",
      "img id in: 11377\n",
      "img id out: 11377\n",
      "img id in: 11378\n",
      "img id out: 11378\n",
      "img id in: 11379\n",
      "img id out: 11379\n",
      "img id in: 11380\n",
      "img id out: 11380\n",
      "img id in: 11381\n",
      "img id out: 11381\n",
      "img id in: 11382\n",
      "img id out: 11382\n",
      "img id in: 11383\n",
      "img id out: 11383\n",
      "img id in: 11384\n",
      "img id out: 11384\n",
      "img id in: 11385\n",
      "img id out: 11385\n",
      "img id in: 11386\n",
      "img id out: 11386\n",
      "img id in: 11387\n",
      "img id out: 11387\n",
      "img id in: 11388\n",
      "img id out: 11388\n",
      "img id in: 11389\n",
      "img id out: 11389\n",
      "img id in: 11390\n",
      "img id out: 11390\n",
      "img id in: 11391\n",
      "img id out: 11391\n",
      "img id in: 11392\n",
      "img id out: 11392\n",
      "img id in: 11393\n",
      "img id out: 11393\n",
      "img id in: 11394\n",
      "img id out: 11394\n",
      "img id in: 11395\n",
      "img id out: 11395\n",
      "img id in: 11396\n",
      "img id out: 11396\n",
      "img id in: 11397\n",
      "img id out: 11397\n",
      "img id in: 11398\n",
      "img id out: 11398\n",
      "img id in: 11399\n",
      "img id out: 11399\n",
      "img id in: 11400\n",
      "img id out: 11400\n",
      "img id in: 11401\n",
      "img id out: 11401\n",
      "img id in: 11402\n",
      "img id out: 11402\n",
      "img id in: 11403\n",
      "img id out: 11403\n",
      "img id in: 11404\n",
      "img id out: 11404\n",
      "img id in: 11405\n",
      "img id out: 11405\n",
      "img id in: 11406\n",
      "img id out: 11406\n",
      "img id in: 11407\n",
      "img id out: 11407\n",
      "img id in: 11408\n",
      "img id out: 11408\n",
      "img id in: 11409\n",
      "img id out: 11409\n",
      "img id in: 11410\n",
      "img id out: 11410\n",
      "img id in: 11411\n",
      "img id out: 11411\n",
      "img id in: 11412\n",
      "img id out: 11412\n",
      "img id in: 11413\n",
      "img id out: 11413\n",
      "img id in: 11414\n",
      "img id out: 11414\n",
      "img id in: 11415\n",
      "img id out: 11415\n",
      "img id in: 11416\n",
      "img id out: 11416\n",
      "img id in: 11417\n",
      "img id out: 11417\n",
      "img id in: 11418\n",
      "img id out: 11418\n",
      "img id in: 11419\n",
      "img id out: 11419\n",
      "img id in: 11420\n",
      "img id out: 11420\n",
      "img id in: 11421\n",
      "img id out: 11421\n",
      "img id in: 11422\n",
      "img id out: 11422\n",
      "img id in: 11423\n",
      "img id out: 11423\n",
      "img id in: 11424\n",
      "img id out: 11424\n",
      "img id in: 11425\n",
      "img id out: 11425\n",
      "img id in: 11426\n",
      "img id out: 11426\n",
      "img id in: 11427\n",
      "img id out: 11427\n",
      "img id in: 11428\n",
      "img id out: 11428\n",
      "img id in: 11429\n",
      "img id out: 11429\n",
      "img id in: 11430\n",
      "img id out: 11430\n",
      "img id in: 11431\n",
      "img id out: 11431\n",
      "img id in: 11432\n",
      "img id out: 11432\n",
      "img id in: 11433\n",
      "img id out: 11433\n",
      "img id in: 11434\n",
      "img id out: 11434\n",
      "img id in: 11435\n",
      "img id out: 11435\n",
      "img id in: 11436\n",
      "img id out: 11436\n",
      "img id in: 11437\n",
      "img id out: 11437\n",
      "img id in: 11438\n",
      "img id out: 11438\n",
      "img id in: 11439\n",
      "img id out: 11439\n",
      "img id in: 11440\n",
      "img id out: 11440\n",
      "img id in: 11441\n",
      "img id out: 11441\n",
      "img id in: 11442\n",
      "img id out: 11442\n",
      "img id in: 11443\n",
      "img id out: 11443\n",
      "img id in: 11444\n",
      "img id out: 11444\n",
      "img id in: 11445\n",
      "img id out: 11445\n",
      "img id in: 11446\n",
      "img id out: 11446\n",
      "img id in: 11447\n",
      "img id out: 11447\n",
      "img id in: 11448\n",
      "img id out: 11448\n",
      "img id in: 11449\n",
      "img id out: 11449\n",
      "img id in: 11450\n",
      "img id out: 11450\n",
      "img id in: 11451\n",
      "img id out: 11451\n",
      "img id in: 11452\n",
      "img id out: 11452\n",
      "img id in: 11453\n",
      "img id out: 11453\n",
      "img id in: 11454\n",
      "img id out: 11454\n",
      "img id in: 11455\n",
      "img id out: 11455\n",
      "img id in: 11456\n",
      "img id out: 11456\n",
      "img id in: 11457\n",
      "img id out: 11457\n",
      "img id in: 11458\n",
      "img id out: 11458\n",
      "img id in: 11459\n",
      "img id out: 11459\n",
      "img id in: 11460\n",
      "img id out: 11460\n",
      "img id in: 11461\n",
      "img id out: 11461\n",
      "img id in: 11462\n",
      "img id out: 11462\n",
      "img id in: 11463\n",
      "img id out: 11463\n",
      "img id in: 11464\n",
      "img id out: 11464\n",
      "img id in: 11465\n",
      "img id out: 11465\n",
      "img id in: 11466\n",
      "img id out: 11466\n",
      "img id in: 11467\n",
      "img id out: 11467\n",
      "img id in: 11468\n",
      "img id out: 11468\n",
      "img id in: 11469\n",
      "img id out: 11469\n",
      "img id in: 11470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 11470\n",
      "img id in: 11471\n",
      "img id out: 11471\n",
      "img id in: 11472\n",
      "img id out: 11472\n",
      "img id in: 11473\n",
      "img id out: 11473\n",
      "img id in: 11474\n",
      "img id out: 11474\n",
      "img id in: 11475\n",
      "img id out: 11475\n",
      "img id in: 11476\n",
      "img id out: 11476\n",
      "img id in: 11477\n",
      "img id out: 11477\n",
      "img id in: 11478\n",
      "img id out: 11478\n",
      "img id in: 11479\n",
      "img id out: 11479\n",
      "img id in: 11480\n",
      "img id out: 11480\n",
      "img id in: 11481\n",
      "img id out: 11481\n",
      "img id in: 11482\n",
      "img id out: 11482\n",
      "img id in: 11483\n",
      "img id out: 11483\n",
      "img id in: 11484\n",
      "img id out: 11484\n",
      "img id in: 11485\n",
      "img id out: 11485\n",
      "img id in: 11486\n",
      "img id out: 11486\n",
      "img id in: 11487\n",
      "img id out: 11487\n",
      "img id in: 11488\n",
      "img id out: 11488\n",
      "img id in: 11489\n",
      "img id out: 11489\n",
      "img id in: 11490\n",
      "img id out: 11490\n",
      "img id in: 11491\n",
      "img id out: 11491\n",
      "img id in: 11492\n",
      "img id out: 11492\n",
      "img id in: 11493\n",
      "img id out: 11493\n",
      "img id in: 11494\n",
      "img id out: 11494\n",
      "img id in: 11495\n",
      "img id out: 11495\n",
      "img id in: 11496\n",
      "img id out: 11496\n",
      "img id in: 11497\n",
      "img id out: 11497\n",
      "img id in: 11498\n",
      "img id out: 11498\n",
      "img id in: 11499\n",
      "img id out: 11499\n",
      "img id in: 11500\n",
      "img id out: 11500\n",
      "img id in: 11501\n",
      "img id out: 11501\n",
      "img id in: 11502\n",
      "img id out: 11502\n",
      "img id in: 11503\n",
      "img id out: 11503\n",
      "img id in: 11504\n",
      "img id out: 11504\n",
      "img id in: 11505\n",
      "img id out: 11505\n",
      "img id in: 11506\n",
      "img id out: 11506\n",
      "img id in: 11507\n",
      "img id out: 11507\n",
      "img id in: 11508\n",
      "img id out: 11508\n",
      "img id in: 11509\n",
      "img id out: 11509\n",
      "img id in: 11510\n",
      "img id out: 11510\n",
      "img id in: 11511\n",
      "img id out: 11511\n",
      "img id in: 11512\n",
      "img id out: 11512\n",
      "img id in: 11513\n",
      "img id out: 11513\n",
      "img id in: 11514\n",
      "img id out: 11514\n",
      "img id in: 11515\n",
      "img id out: 11515\n",
      "img id in: 11516\n",
      "img id out: 11516\n",
      "img id in: 11517\n",
      "img id out: 11517\n",
      "img id in: 11518\n",
      "img id out: 11518\n",
      "img id in: 11519\n",
      "img id out: 11519\n",
      "img id in: 11520\n",
      "img id out: 11520\n",
      "img id in: 11521\n",
      "img id out: 11521\n",
      "img id in: 11522\n",
      "img id out: 11522\n",
      "img id in: 11523\n",
      "img id out: 11523\n",
      "img id in: 11524\n",
      "img id out: 11524\n",
      "img id in: 11525\n",
      "img id out: 11525\n",
      "img id in: 11526\n",
      "img id out: 11526\n",
      "img id in: 11527\n",
      "img id out: 11527\n",
      "img id in: 11528\n",
      "img id out: 11528\n",
      "img id in: 11529\n",
      "img id out: 11529\n",
      "img id in: 11530\n",
      "img id out: 11530\n",
      "img id in: 11531\n",
      "img id out: 11531\n",
      "img id in: 11532\n",
      "img id out: 11532\n",
      "img id in: 11533\n",
      "img id out: 11533\n",
      "img id in: 11534\n",
      "img id out: 11534\n",
      "img id in: 11535\n",
      "img id out: 11535\n",
      "img id in: 11536\n",
      "img id out: 11536\n",
      "img id in: 11537\n",
      "img id out: 11537\n",
      "img id in: 11538\n",
      "img id out: 11538\n",
      "img id in: 11539\n",
      "img id out: 11539\n",
      "img id in: 11540\n",
      "img id out: 11540\n",
      "img id in: 11541\n",
      "img id out: 11541\n",
      "img id in: 11542\n",
      "img id out: 11542\n",
      "img id in: 11543\n",
      "img id out: 11543\n",
      "img id in: 11544\n",
      "img id out: 11544\n",
      "img id in: 11545\n",
      "img id out: 11545\n",
      "img id in: 11546\n",
      "img id out: 11546\n",
      "img id in: 11547\n",
      "img id out: 11547\n",
      "img id in: 11548\n",
      "img id out: 11548\n",
      "img id in: 11549\n",
      "img id out: 11549\n",
      "img id in: 11550\n",
      "img id out: 11550\n",
      "img id in: 11551\n",
      "img id out: 11551\n",
      "img id in: 11552\n",
      "img id out: 11552\n",
      "img id in: 11553\n",
      "img id out: 11553\n",
      "img id in: 11554\n",
      "img id out: 11554\n",
      "img id in: 11555\n",
      "img id out: 11555\n",
      "img id in: 11556\n",
      "img id out: 11556\n",
      "img id in: 11557\n",
      "img id out: 11557\n",
      "img id in: 11558\n",
      "img id out: 11558\n",
      "img id in: 11559\n",
      "img id out: 11559\n",
      "img id in: 11560\n",
      "img id out: 11560\n",
      "img id in: 11561\n",
      "img id out: 11561\n",
      "img id in: 11562\n",
      "img id out: 11562\n",
      "img id in: 11563\n",
      "img id out: 11563\n",
      "img id in: 11564\n",
      "img id out: 11564\n",
      "img id in: 11565\n",
      "img id out: 11565\n",
      "img id in: 11566\n",
      "img id out: 11566\n",
      "img id in: 11567\n",
      "img id out: 11567\n",
      "img id in: 11568\n",
      "img id out: 11568\n",
      "img id in: 11569\n",
      "img id out: 11569\n",
      "img id in: 11570\n",
      "img id out: 11570\n",
      "img id in: 11571\n",
      "img id out: 11571\n",
      "img id in: 11572\n",
      "img id out: 11572\n",
      "img id in: 11573\n",
      "img id out: 11573\n",
      "img id in: 11574\n",
      "img id out: 11574\n",
      "img id in: 11575\n",
      "img id out: 11575\n",
      "img id in: 11576\n",
      "img id out: 11576\n",
      "img id in: 11577\n",
      "img id out: 11577\n",
      "img id in: 11578\n",
      "img id out: 11578\n",
      "img id in: 11579\n",
      "img id out: 11579\n",
      "img id in: 11580\n",
      "img id out: 11580\n",
      "img id in: 11581\n",
      "img id out: 11581\n",
      "img id in: 11582\n",
      "img id out: 11582\n",
      "img id in: 11583\n",
      "img id out: 11583\n",
      "img id in: 11584\n",
      "img id out: 11584\n",
      "img id in: 11585\n",
      "img id out: 11585\n",
      "img id in: 11586\n",
      "img id out: 11586\n",
      "img id in: 11587\n",
      "img id out: 11587\n",
      "img id in: 11588\n",
      "img id out: 11588\n",
      "img id in: 11589\n",
      "img id out: 11589\n",
      "img id in: 11590\n",
      "img id out: 11590\n",
      "img id in: 11591\n",
      "img id out: 11591\n",
      "img id in: 11592\n",
      "img id out: 11592\n",
      "img id in: 11593\n",
      "img id out: 11593\n",
      "img id in: 11594\n",
      "img id out: 11594\n",
      "img id in: 11595\n",
      "img id out: 11595\n",
      "img id in: 11596\n",
      "img id out: 11596\n",
      "img id in: 11597\n",
      "img id out: 11597\n",
      "img id in: 11598\n",
      "img id out: 11598\n",
      "img id in: 11599\n",
      "img id out: 11599\n",
      "img id in: 11600\n",
      "img id out: 11600\n",
      "img id in: 11601\n",
      "img id out: 11601\n",
      "img id in: 11602\n",
      "img id out: 11602\n",
      "img id in: 11603\n",
      "img id out: 11603\n",
      "img id in: 11604\n",
      "img id out: 11604\n",
      "img id in: 11605\n",
      "img id out: 11605\n",
      "img id in: 11606\n",
      "img id out: 11606\n",
      "img id in: 11607\n",
      "img id out: 11607\n",
      "img id in: 11608\n",
      "img id out: 11608\n",
      "img id in: 11609\n",
      "img id out: 11609\n",
      "img id in: 11610\n",
      "img id out: 11610\n",
      "img id in: 11611\n",
      "img id out: 11611\n",
      "img id in: 11612\n",
      "img id out: 11612\n",
      "img id in: 11613\n",
      "img id out: 11613\n",
      "img id in: 11614\n",
      "img id out: 11614\n",
      "img id in: 11615\n",
      "img id out: 11615\n",
      "img id in: 11616\n",
      "img id out: 11616\n",
      "img id in: 11617\n",
      "img id out: 11617\n",
      "img id in: 11618\n",
      "img id out: 11618\n",
      "img id in: 11619\n",
      "img id out: 11619\n",
      "img id in: 11620\n",
      "img id out: 11620\n",
      "img id in: 11621\n",
      "img id out: 11621\n",
      "img id in: 11622\n",
      "img id out: 11622\n",
      "img id in: 11623\n",
      "img id out: 11623\n",
      "img id in: 11624\n",
      "img id out: 11624\n",
      "img id in: 11625\n",
      "img id out: 11625\n",
      "img id in: 11626\n",
      "img id out: 11626\n",
      "img id in: 11627\n",
      "img id out: 11627\n",
      "img id in: 11628\n",
      "img id out: 11628\n",
      "img id in: 11629\n",
      "img id out: 11629\n",
      "img id in: 11630\n",
      "img id out: 11630\n",
      "img id in: 11631\n",
      "img id out: 11631\n",
      "img id in: 11632\n",
      "img id out: 11632\n",
      "img id in: 11633\n",
      "img id out: 11633\n",
      "img id in: 11634\n",
      "img id out: 11634\n",
      "img id in: 11635\n",
      "img id out: 11635\n",
      "img id in: 11636\n",
      "img id out: 11636\n",
      "img id in: 11637\n",
      "img id out: 11637\n",
      "img id in: 11638\n",
      "img id out: 11638\n",
      "img id in: 11639\n",
      "img id out: 11639\n",
      "img id in: 11640\n",
      "img id out: 11640\n",
      "img id in: 11641\n",
      "img id out: 11641\n",
      "img id in: 11642\n",
      "img id out: 11642\n",
      "img id in: 11643\n",
      "img id out: 11643\n",
      "img id in: 11644\n",
      "img id out: 11644\n",
      "img id in: 11645\n",
      "img id out: 11645\n",
      "img id in: 11646\n",
      "img id out: 11646\n",
      "img id in: 11647\n",
      "img id out: 11647\n",
      "img id in: 11648\n",
      "img id out: 11648\n",
      "img id in: 11649\n",
      "img id out: 11649\n",
      "img id in: 11650\n",
      "img id out: 11650\n",
      "img id in: 11651\n",
      "img id out: 11651\n",
      "img id in: 11652\n",
      "img id out: 11652\n",
      "img id in: 11653\n",
      "img id out: 11653\n",
      "img id in: 11654\n",
      "img id out: 11654\n",
      "img id in: 11655\n",
      "img id out: 11655\n",
      "img id in: 11656\n",
      "img id out: 11656\n",
      "img id in: 11657\n",
      "img id out: 11657\n",
      "img id in: 11658\n",
      "img id out: 11658\n",
      "img id in: 11659\n",
      "img id out: 11659\n",
      "img id in: 11660\n",
      "img id out: 11660\n",
      "img id in: 11661\n",
      "img id out: 11661\n",
      "img id in: 11662\n",
      "img id out: 11662\n",
      "img id in: 11663\n",
      "img id out: 11663\n",
      "img id in: 11664\n",
      "img id out: 11664\n",
      "img id in: 11665\n",
      "img id out: 11665\n",
      "img id in: 11666\n",
      "img id out: 11666\n",
      "img id in: 11667\n",
      "img id out: 11667\n",
      "img id in: 11668\n",
      "img id out: 11668\n",
      "img id in: 11669\n",
      "img id out: 11669\n",
      "img id in: 11670\n",
      "img id out: 11670\n",
      "img id in: 11671\n",
      "img id out: 11671\n",
      "img id in: 11672\n",
      "img id out: 11672\n",
      "img id in: 11673\n",
      "img id out: 11673\n",
      "img id in: 11674\n",
      "img id out: 11674\n",
      "img id in: 11675\n",
      "img id out: 11675\n",
      "img id in: 11676\n",
      "img id out: 11676\n",
      "img id in: 11677\n",
      "img id out: 11677\n",
      "img id in: 11678\n",
      "img id out: 11678\n",
      "img id in: 11679\n",
      "img id out: 11679\n",
      "img id in: 11680\n",
      "img id out: 11680\n",
      "img id in: 11681\n",
      "img id out: 11681\n",
      "img id in: 11682\n",
      "img id out: 11682\n",
      "img id in: 11683\n",
      "img id out: 11683\n",
      "img id in: 11684\n",
      "img id out: 11684\n",
      "img id in: 11685\n",
      "img id out: 11685\n",
      "img id in: 11686\n",
      "img id out: 11686\n",
      "img id in: 11687\n",
      "img id out: 11687\n",
      "img id in: 11688\n",
      "img id out: 11688\n",
      "img id in: 11689\n",
      "img id out: 11689\n",
      "img id in: 11690\n",
      "img id out: 11690\n",
      "img id in: 11691\n",
      "img id out: 11691\n",
      "img id in: 11692\n",
      "img id out: 11692\n",
      "img id in: 11693\n",
      "img id out: 11693\n",
      "img id in: 11694\n",
      "img id out: 11694\n",
      "img id in: 11695\n",
      "img id out: 11695\n",
      "img id in: 11696\n",
      "img id out: 11696\n",
      "img id in: 11697\n",
      "img id out: 11697\n",
      "img id in: 11698\n",
      "img id out: 11698\n",
      "img id in: 11699\n",
      "img id out: 11699\n",
      "img id in: 11700\n",
      "img id out: 11700\n",
      "img id in: 11701\n",
      "img id out: 11701\n",
      "img id in: 11702\n",
      "img id out: 11702\n",
      "img id in: 11703\n",
      "img id out: 11703\n",
      "img id in: 11704\n",
      "img id out: 11704\n",
      "img id in: 11705\n",
      "img id out: 11705\n",
      "img id in: 11706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 11706\n",
      "img id in: 11707\n",
      "img id out: 11707\n",
      "img id in: 11708\n",
      "img id out: 11708\n",
      "img id in: 11709\n",
      "img id out: 11709\n",
      "img id in: 11710\n",
      "img id out: 11710\n",
      "img id in: 11711\n",
      "img id out: 11711\n",
      "img id in: 11712\n",
      "img id out: 11712\n",
      "img id in: 11713\n",
      "img id out: 11713\n",
      "img id in: 11714\n",
      "img id out: 11714\n",
      "img id in: 11715\n",
      "img id out: 11715\n",
      "img id in: 11716\n",
      "img id out: 11716\n",
      "img id in: 11717\n",
      "img id out: 11717\n",
      "img id in: 11718\n",
      "img id out: 11718\n",
      "img id in: 11719\n",
      "img id out: 11719\n",
      "img id in: 11720\n",
      "img id out: 11720\n",
      "img id in: 11721\n",
      "img id out: 11721\n",
      "img id in: 11722\n",
      "img id out: 11722\n",
      "img id in: 11723\n",
      "img id out: 11723\n",
      "img id in: 11724\n",
      "img id out: 11724\n",
      "img id in: 11725\n",
      "img id out: 11725\n",
      "img id in: 11726\n",
      "img id out: 11726\n",
      "img id in: 11727\n",
      "img id out: 11727\n",
      "img id in: 11728\n",
      "img id out: 11728\n",
      "img id in: 11729\n",
      "img id out: 11729\n",
      "img id in: 11730\n",
      "img id out: 11730\n",
      "img id in: 11731\n",
      "img id out: 11731\n",
      "img id in: 11732\n",
      "img id out: 11732\n",
      "img id in: 11733\n",
      "img id out: 11733\n",
      "img id in: 11734\n",
      "img id out: 11734\n",
      "img id in: 11735\n",
      "img id out: 11735\n",
      "img id in: 11736\n",
      "img id out: 11736\n",
      "img id in: 11737\n",
      "img id out: 11737\n",
      "img id in: 11738\n",
      "img id out: 11738\n",
      "img id in: 11739\n",
      "img id out: 11739\n",
      "img id in: 11740\n",
      "img id out: 11740\n",
      "img id in: 11741\n",
      "img id out: 11741\n",
      "img id in: 11742\n",
      "img id out: 11742\n",
      "img id in: 11743\n",
      "img id out: 11743\n",
      "img id in: 11744\n",
      "img id out: 11744\n",
      "img id in: 11745\n",
      "img id out: 11745\n",
      "img id in: 11746\n",
      "img id out: 11746\n",
      "img id in: 11747\n",
      "img id out: 11747\n",
      "img id in: 11748\n",
      "img id out: 11748\n",
      "img id in: 11749\n",
      "img id out: 11749\n",
      "img id in: 11750\n",
      "img id out: 11750\n",
      "img id in: 11751\n",
      "img id out: 11751\n",
      "img id in: 11752\n",
      "img id out: 11752\n",
      "img id in: 11753\n",
      "img id out: 11753\n",
      "img id in: 11754\n",
      "img id out: 11754\n",
      "img id in: 11755\n",
      "img id out: 11755\n",
      "img id in: 11756\n",
      "img id out: 11756\n",
      "img id in: 11757\n",
      "img id out: 11757\n",
      "img id in: 11758\n",
      "img id out: 11758\n",
      "img id in: 11759\n",
      "img id out: 11759\n",
      "img id in: 11760\n",
      "img id out: 11760\n",
      "img id in: 11761\n",
      "img id out: 11761\n",
      "img id in: 11762\n",
      "img id out: 11762\n",
      "img id in: 11763\n",
      "img id out: 11763\n",
      "img id in: 11764\n",
      "img id out: 11764\n",
      "img id in: 11765\n",
      "img id out: 11765\n",
      "img id in: 11766\n",
      "img id out: 11766\n",
      "img id in: 11767\n",
      "img id out: 11767\n",
      "img id in: 11768\n",
      "img id out: 11768\n",
      "img id in: 11769\n",
      "img id out: 11769\n",
      "img id in: 11770\n",
      "img id out: 11770\n",
      "img id in: 11771\n",
      "img id out: 11771\n",
      "img id in: 11772\n",
      "img id out: 11772\n",
      "img id in: 11773\n",
      "img id out: 11773\n",
      "img id in: 11774\n",
      "img id out: 11774\n",
      "img id in: 11775\n",
      "img id out: 11775\n",
      "img id in: 11776\n",
      "img id out: 11776\n",
      "img id in: 11777\n",
      "img id out: 11777\n",
      "img id in: 11778\n",
      "img id out: 11778\n",
      "img id in: 11779\n",
      "img id out: 11779\n",
      "img id in: 11780\n",
      "img id out: 11780\n",
      "img id in: 11781\n",
      "img id out: 11781\n",
      "img id in: 11782\n",
      "img id out: 11782\n",
      "img id in: 11783\n",
      "img id out: 11783\n",
      "img id in: 11784\n",
      "img id out: 11784\n",
      "img id in: 11785\n",
      "img id out: 11785\n",
      "img id in: 11786\n",
      "img id out: 11786\n",
      "img id in: 11787\n",
      "img id out: 11787\n",
      "img id in: 11788\n",
      "img id out: 11788\n",
      "img id in: 11789\n",
      "img id out: 11789\n",
      "img id in: 11790\n",
      "img id out: 11790\n",
      "img id in: 11791\n",
      "img id out: 11791\n",
      "img id in: 11792\n",
      "img id out: 11792\n",
      "img id in: 11793\n",
      "img id out: 11793\n",
      "img id in: 11794\n",
      "img id out: 11794\n",
      "img id in: 11795\n",
      "img id out: 11795\n",
      "img id in: 11796\n",
      "img id out: 11796\n",
      "img id in: 11797\n",
      "img id out: 11797\n",
      "img id in: 11798\n",
      "img id out: 11798\n",
      "img id in: 11799\n",
      "img id out: 11799\n",
      "img id in: 11800\n",
      "img id out: 11800\n",
      "img id in: 11801\n",
      "img id out: 11801\n",
      "img id in: 11802\n",
      "img id out: 11802\n",
      "img id in: 11803\n",
      "img id out: 11803\n",
      "img id in: 11804\n",
      "img id out: 11804\n",
      "img id in: 11805\n",
      "img id out: 11805\n",
      "img id in: 11806\n",
      "img id out: 11806\n",
      "img id in: 11807\n",
      "img id out: 11807\n",
      "img id in: 11808\n",
      "img id out: 11808\n",
      "img id in: 11809\n",
      "img id out: 11809\n",
      "img id in: 11810\n",
      "img id out: 11810\n",
      "img id in: 11811\n",
      "img id out: 11811\n",
      "img id in: 11812\n",
      "img id out: 11812\n",
      "img id in: 11813\n",
      "img id out: 11813\n",
      "img id in: 11814\n",
      "img id out: 11814\n",
      "img id in: 11815\n",
      "img id out: 11815\n",
      "img id in: 11816\n",
      "img id out: 11816\n",
      "img id in: 11817\n",
      "img id out: 11817\n",
      "img id in: 11818\n",
      "img id out: 11818\n",
      "img id in: 11819\n",
      "img id out: 11819\n",
      "img id in: 11820\n",
      "img id out: 11820\n",
      "img id in: 11821\n",
      "img id out: 11821\n",
      "img id in: 11822\n",
      "img id out: 11822\n",
      "img id in: 11823\n",
      "img id out: 11823\n",
      "img id in: 11824\n",
      "img id out: 11824\n",
      "img id in: 11825\n",
      "img id out: 11825\n",
      "img id in: 11826\n",
      "img id out: 11826\n",
      "img id in: 11827\n",
      "img id out: 11827\n",
      "img id in: 11828\n",
      "img id out: 11828\n",
      "img id in: 11829\n",
      "img id out: 11829\n",
      "img id in: 11830\n",
      "img id out: 11830\n",
      "img id in: 11831\n",
      "img id out: 11831\n",
      "img id in: 11832\n",
      "img id out: 11832\n",
      "img id in: 11833\n",
      "img id out: 11833\n",
      "img id in: 11834\n",
      "img id out: 11834\n",
      "img id in: 11835\n",
      "img id out: 11835\n",
      "img id in: 11836\n",
      "img id out: 11836\n",
      "img id in: 11837\n",
      "img id out: 11837\n",
      "img id in: 11838\n",
      "img id out: 11838\n",
      "img id in: 11839\n",
      "img id out: 11839\n",
      "img id in: 11840\n",
      "img id out: 11840\n",
      "img id in: 11841\n",
      "img id out: 11841\n",
      "img id in: 11842\n",
      "img id out: 11842\n",
      "img id in: 11843\n",
      "img id out: 11843\n",
      "img id in: 11844\n",
      "img id out: 11844\n",
      "img id in: 11845\n",
      "img id out: 11845\n",
      "img id in: 11846\n",
      "img id out: 11846\n",
      "img id in: 11847\n",
      "img id out: 11847\n",
      "img id in: 11848\n",
      "img id out: 11848\n",
      "img id in: 11849\n",
      "img id out: 11849\n",
      "img id in: 11850\n",
      "img id out: 11850\n",
      "img id in: 11851\n",
      "img id out: 11851\n",
      "img id in: 11852\n",
      "img id out: 11852\n",
      "img id in: 11853\n",
      "img id out: 11853\n",
      "img id in: 11854\n",
      "img id out: 11854\n",
      "img id in: 11855\n",
      "img id out: 11855\n",
      "img id in: 11856\n",
      "img id out: 11856\n",
      "img id in: 11857\n",
      "img id out: 11857\n",
      "img id in: 11858\n",
      "img id out: 11858\n",
      "img id in: 11859\n",
      "img id out: 11859\n",
      "img id in: 11860\n",
      "img id out: 11860\n",
      "img id in: 11861\n",
      "img id out: 11861\n",
      "img id in: 11862\n",
      "img id out: 11862\n",
      "img id in: 11863\n",
      "img id out: 11863\n",
      "img id in: 11864\n",
      "img id out: 11864\n",
      "img id in: 11865\n",
      "img id out: 11865\n",
      "img id in: 11866\n",
      "img id out: 11866\n",
      "img id in: 11867\n",
      "img id out: 11867\n",
      "img id in: 11868\n",
      "img id out: 11868\n",
      "img id in: 11869\n",
      "img id out: 11869\n",
      "img id in: 11870\n",
      "img id out: 11870\n",
      "img id in: 11871\n",
      "img id out: 11871\n",
      "img id in: 11872\n",
      "img id out: 11872\n",
      "img id in: 11873\n",
      "img id out: 11873\n",
      "img id in: 11874\n",
      "img id out: 11874\n",
      "img id in: 11875\n",
      "img id out: 11875\n",
      "img id in: 11876\n",
      "img id out: 11876\n",
      "img id in: 11877\n",
      "img id out: 11877\n",
      "img id in: 11878\n",
      "img id out: 11878\n",
      "img id in: 11879\n",
      "img id out: 11879\n",
      "img id in: 11880\n",
      "img id out: 11880\n",
      "img id in: 11881\n",
      "img id out: 11881\n",
      "img id in: 11882\n",
      "img id out: 11882\n",
      "img id in: 11883\n",
      "img id out: 11883\n",
      "img id in: 11884\n",
      "img id out: 11884\n",
      "img id in: 11885\n",
      "img id out: 11885\n",
      "img id in: 11886\n",
      "img id out: 11886\n",
      "img id in: 11887\n",
      "img id out: 11887\n",
      "img id in: 11888\n",
      "img id out: 11888\n",
      "img id in: 11889\n",
      "img id out: 11889\n",
      "img id in: 11890\n",
      "img id out: 11890\n",
      "img id in: 11891\n",
      "img id out: 11891\n",
      "img id in: 11892\n",
      "img id out: 11892\n",
      "img id in: 11893\n",
      "img id out: 11893\n",
      "img id in: 11894\n",
      "img id out: 11894\n",
      "img id in: 11895\n",
      "img id out: 11895\n",
      "img id in: 11896\n",
      "img id out: 11896\n",
      "img id in: 11897\n",
      "img id out: 11897\n",
      "img id in: 11898\n",
      "img id out: 11898\n",
      "img id in: 11899\n",
      "img id out: 11899\n",
      "img id in: 11900\n",
      "img id out: 11900\n",
      "img id in: 11901\n",
      "img id out: 11901\n",
      "img id in: 11902\n",
      "img id out: 11902\n",
      "img id in: 11903\n",
      "img id out: 11903\n",
      "img id in: 11904\n",
      "img id out: 11904\n",
      "img id in: 11905\n",
      "img id out: 11905\n",
      "img id in: 11906\n",
      "img id out: 11906\n",
      "img id in: 11907\n",
      "img id out: 11907\n",
      "img id in: 11908\n",
      "img id out: 11908\n",
      "img id in: 11909\n",
      "img id out: 11909\n",
      "img id in: 11910\n",
      "img id out: 11910\n",
      "img id in: 11911\n",
      "img id out: 11911\n",
      "img id in: 11912\n",
      "img id out: 11912\n",
      "img id in: 11913\n",
      "img id out: 11913\n",
      "img id in: 11914\n",
      "img id out: 11914\n",
      "img id in: 11915\n",
      "img id out: 11915\n",
      "img id in: 11916\n",
      "img id out: 11916\n",
      "img id in: 11917\n",
      "img id out: 11917\n",
      "img id in: 11918\n",
      "img id out: 11918\n",
      "img id in: 11919\n",
      "img id out: 11919\n",
      "img id in: 11920\n",
      "img id out: 11920\n",
      "img id in: 11921\n",
      "img id out: 11921\n",
      "img id in: 11922\n",
      "img id out: 11922\n",
      "img id in: 11923\n",
      "img id out: 11923\n",
      "img id in: 11924\n",
      "img id out: 11924\n",
      "img id in: 11925\n",
      "img id out: 11925\n",
      "img id in: 11926\n",
      "img id out: 11926\n",
      "img id in: 11927\n",
      "img id out: 11927\n",
      "img id in: 11928\n",
      "img id out: 11928\n",
      "img id in: 11929\n",
      "img id out: 11929\n",
      "img id in: 11930\n",
      "img id out: 11930\n",
      "img id in: 11931\n",
      "img id out: 11931\n",
      "img id in: 11932\n",
      "img id out: 11932\n",
      "img id in: 11933\n",
      "img id out: 11933\n",
      "img id in: 11934\n",
      "img id out: 11934\n",
      "img id in: 11935\n",
      "img id out: 11935\n",
      "img id in: 11936\n",
      "img id out: 11936\n",
      "img id in: 11937\n",
      "img id out: 11937\n",
      "img id in: 11938\n",
      "img id out: 11938\n",
      "img id in: 11939\n",
      "img id out: 11939\n",
      "img id in: 11940\n",
      "img id out: 11940\n",
      "img id in: 11941\n",
      "img id out: 11941\n",
      "img id in: 11942\n",
      "img id out: 11942\n",
      "img id in: 11943\n",
      "img id out: 11943\n",
      "img id in: 11944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 11944\n",
      "img id in: 11945\n",
      "img id out: 11945\n",
      "img id in: 11946\n",
      "img id out: 11946\n",
      "img id in: 11947\n",
      "img id out: 11947\n",
      "img id in: 11948\n",
      "img id out: 11948\n",
      "img id in: 11949\n",
      "img id out: 11949\n",
      "img id in: 11950\n",
      "img id out: 11950\n",
      "img id in: 11951\n",
      "img id out: 11951\n",
      "img id in: 11952\n",
      "img id out: 11952\n",
      "img id in: 11953\n",
      "img id out: 11953\n",
      "img id in: 11954\n",
      "img id out: 11954\n",
      "img id in: 11955\n",
      "img id out: 11955\n",
      "img id in: 11956\n",
      "img id out: 11956\n",
      "img id in: 11957\n",
      "img id out: 11957\n",
      "img id in: 11958\n",
      "img id out: 11958\n",
      "img id in: 11959\n",
      "img id out: 11959\n",
      "img id in: 11960\n",
      "img id out: 11960\n",
      "img id in: 11961\n",
      "img id out: 11961\n",
      "img id in: 11962\n",
      "img id out: 11962\n",
      "img id in: 11963\n",
      "img id out: 11963\n",
      "img id in: 11964\n",
      "img id out: 11964\n",
      "img id in: 11965\n",
      "img id out: 11965\n",
      "img id in: 11966\n",
      "img id out: 11966\n",
      "img id in: 11967\n",
      "img id out: 11967\n",
      "img id in: 11968\n",
      "img id out: 11968\n",
      "img id in: 11969\n",
      "img id out: 11969\n",
      "img id in: 11970\n",
      "img id out: 11970\n",
      "img id in: 11971\n",
      "img id out: 11971\n",
      "img id in: 11972\n",
      "img id out: 11972\n",
      "img id in: 11973\n",
      "img id out: 11973\n",
      "img id in: 11974\n",
      "img id out: 11974\n",
      "img id in: 11975\n",
      "img id out: 11975\n",
      "img id in: 11976\n",
      "img id out: 11976\n",
      "img id in: 11977\n",
      "img id out: 11977\n",
      "img id in: 11978\n",
      "img id out: 11978\n",
      "img id in: 11979\n",
      "img id out: 11979\n",
      "img id in: 11980\n",
      "img id out: 11980\n",
      "img id in: 11981\n",
      "img id out: 11981\n",
      "img id in: 11982\n",
      "img id out: 11982\n",
      "img id in: 11983\n",
      "img id out: 11983\n",
      "img id in: 11984\n",
      "img id out: 11984\n",
      "img id in: 11985\n",
      "img id out: 11985\n",
      "img id in: 11986\n",
      "img id out: 11986\n",
      "img id in: 11987\n",
      "img id out: 11987\n",
      "img id in: 11988\n",
      "img id out: 11988\n",
      "img id in: 11989\n",
      "img id out: 11989\n",
      "img id in: 11990\n",
      "img id out: 11990\n",
      "img id in: 11991\n",
      "img id out: 11991\n",
      "img id in: 11992\n",
      "img id out: 11992\n",
      "img id in: 11993\n",
      "img id out: 11993\n",
      "img id in: 11994\n",
      "img id out: 11994\n",
      "img id in: 11995\n",
      "img id out: 11995\n",
      "img id in: 11996\n",
      "img id out: 11996\n",
      "img id in: 11997\n",
      "img id out: 11997\n",
      "img id in: 11998\n",
      "img id out: 11998\n",
      "img id in: 11999\n",
      "img id out: 11999\n",
      "img id in: 12000\n",
      "img id out: 12000\n",
      "img id in: 12001\n",
      "img id out: 12001\n",
      "img id in: 12002\n",
      "img id out: 12002\n",
      "img id in: 12003\n",
      "img id out: 12003\n",
      "img id in: 12004\n",
      "img id out: 12004\n",
      "img id in: 12005\n",
      "img id out: 12005\n",
      "img id in: 12006\n",
      "img id out: 12006\n",
      "img id in: 12007\n",
      "img id out: 12007\n",
      "img id in: 12008\n",
      "img id out: 12008\n",
      "img id in: 12009\n",
      "img id out: 12009\n",
      "img id in: 12010\n",
      "img id out: 12010\n",
      "img id in: 12011\n",
      "img id out: 12011\n",
      "img id in: 12012\n",
      "img id out: 12012\n",
      "img id in: 12013\n",
      "img id out: 12013\n",
      "img id in: 12014\n",
      "img id out: 12014\n",
      "img id in: 12015\n",
      "img id out: 12015\n",
      "img id in: 12016\n",
      "img id out: 12016\n",
      "img id in: 12017\n",
      "img id out: 12017\n",
      "img id in: 12018\n",
      "img id out: 12018\n",
      "img id in: 12019\n",
      "img id out: 12019\n",
      "img id in: 12020\n",
      "img id out: 12020\n",
      "img id in: 12021\n",
      "img id out: 12021\n",
      "img id in: 12022\n",
      "img id out: 12022\n",
      "img id in: 12023\n",
      "img id out: 12023\n",
      "img id in: 12024\n",
      "img id out: 12024\n",
      "img id in: 12025\n",
      "img id out: 12025\n",
      "img id in: 12026\n",
      "img id out: 12026\n",
      "img id in: 12027\n",
      "img id out: 12027\n",
      "img id in: 12028\n",
      "img id out: 12028\n",
      "img id in: 12029\n",
      "img id out: 12029\n",
      "img id in: 12030\n",
      "img id out: 12030\n",
      "img id in: 12031\n",
      "img id out: 12031\n",
      "img id in: 12032\n",
      "img id out: 12032\n",
      "img id in: 12033\n",
      "img id out: 12033\n",
      "img id in: 12034\n",
      "img id out: 12034\n",
      "img id in: 12035\n",
      "img id out: 12035\n",
      "img id in: 12036\n",
      "img id out: 12036\n",
      "img id in: 12037\n",
      "img id out: 12037\n",
      "img id in: 12038\n",
      "img id out: 12038\n",
      "img id in: 12039\n",
      "img id out: 12039\n",
      "img id in: 12040\n",
      "img id out: 12040\n",
      "img id in: 12041\n",
      "img id out: 12041\n",
      "img id in: 12042\n",
      "img id out: 12042\n",
      "img id in: 12043\n",
      "img id out: 12043\n",
      "img id in: 12044\n",
      "img id out: 12044\n",
      "img id in: 12045\n",
      "img id out: 12045\n",
      "img id in: 12046\n",
      "img id out: 12046\n",
      "img id in: 12047\n",
      "img id out: 12047\n",
      "img id in: 12048\n",
      "img id out: 12048\n",
      "img id in: 12049\n",
      "img id out: 12049\n",
      "img id in: 12050\n",
      "img id out: 12050\n",
      "img id in: 12051\n",
      "img id out: 12051\n",
      "img id in: 12052\n",
      "img id out: 12052\n",
      "img id in: 12053\n",
      "img id out: 12053\n",
      "img id in: 12054\n",
      "img id out: 12054\n",
      "img id in: 12055\n",
      "img id out: 12055\n",
      "img id in: 12056\n",
      "img id out: 12056\n",
      "img id in: 12057\n",
      "img id out: 12057\n",
      "img id in: 12058\n",
      "img id out: 12058\n",
      "img id in: 12059\n",
      "img id out: 12059\n",
      "img id in: 12060\n",
      "img id out: 12060\n",
      "img id in: 12061\n",
      "img id out: 12061\n",
      "img id in: 12062\n",
      "img id out: 12062\n",
      "img id in: 12063\n",
      "img id out: 12063\n",
      "img id in: 12064\n",
      "img id out: 12064\n",
      "img id in: 12065\n",
      "img id out: 12065\n",
      "img id in: 12066\n",
      "img id out: 12066\n",
      "img id in: 12067\n",
      "img id out: 12067\n",
      "img id in: 12068\n",
      "img id out: 12068\n",
      "img id in: 12069\n",
      "img id out: 12069\n",
      "img id in: 12070\n",
      "img id out: 12070\n",
      "img id in: 12071\n",
      "img id out: 12071\n",
      "img id in: 12072\n",
      "img id out: 12072\n",
      "img id in: 12073\n",
      "img id out: 12073\n",
      "img id in: 12074\n",
      "img id out: 12074\n",
      "img id in: 12075\n",
      "img id out: 12075\n",
      "img id in: 12076\n",
      "img id out: 12076\n",
      "img id in: 12077\n",
      "img id out: 12077\n",
      "img id in: 12078\n",
      "img id out: 12078\n",
      "img id in: 12079\n",
      "img id out: 12079\n",
      "img id in: 12080\n",
      "img id out: 12080\n",
      "img id in: 12081\n",
      "img id out: 12081\n",
      "img id in: 12082\n",
      "img id out: 12082\n",
      "img id in: 12083\n",
      "img id out: 12083\n",
      "img id in: 12084\n",
      "img id out: 12084\n",
      "img id in: 12085\n",
      "img id out: 12085\n",
      "img id in: 12086\n",
      "img id out: 12086\n",
      "img id in: 12087\n",
      "img id out: 12087\n",
      "img id in: 12088\n",
      "img id out: 12088\n",
      "img id in: 12089\n",
      "img id out: 12089\n",
      "img id in: 12090\n",
      "img id out: 12090\n",
      "img id in: 12091\n",
      "img id out: 12091\n",
      "img id in: 12092\n",
      "img id out: 12092\n",
      "img id in: 12093\n",
      "img id out: 12093\n",
      "img id in: 12094\n",
      "img id out: 12094\n",
      "img id in: 12095\n",
      "img id out: 12095\n",
      "img id in: 12096\n",
      "img id out: 12096\n",
      "img id in: 12097\n",
      "img id out: 12097\n",
      "img id in: 12098\n",
      "img id out: 12098\n",
      "img id in: 12099\n",
      "img id out: 12099\n",
      "img id in: 12100\n",
      "img id out: 12100\n",
      "img id in: 12101\n",
      "img id out: 12101\n",
      "img id in: 12102\n",
      "img id out: 12102\n",
      "img id in: 12103\n",
      "img id out: 12103\n",
      "img id in: 12104\n",
      "img id out: 12104\n",
      "img id in: 12105\n",
      "img id out: 12105\n",
      "img id in: 12106\n",
      "img id out: 12106\n",
      "img id in: 12107\n",
      "img id out: 12107\n",
      "img id in: 12108\n",
      "img id out: 12108\n",
      "img id in: 12109\n",
      "img id out: 12109\n",
      "img id in: 12110\n",
      "img id out: 12110\n",
      "img id in: 12111\n",
      "img id out: 12111\n",
      "img id in: 12112\n",
      "img id out: 12112\n",
      "img id in: 12113\n",
      "img id out: 12113\n",
      "img id in: 12114\n",
      "img id out: 12114\n",
      "img id in: 12115\n",
      "img id out: 12115\n",
      "img id in: 12116\n",
      "img id out: 12116\n",
      "img id in: 12117\n",
      "img id out: 12117\n",
      "img id in: 12118\n",
      "img id out: 12118\n",
      "img id in: 12119\n",
      "img id out: 12119\n",
      "img id in: 12120\n",
      "img id out: 12120\n",
      "img id in: 12121\n",
      "img id out: 12121\n",
      "img id in: 12122\n",
      "img id out: 12122\n",
      "img id in: 12123\n",
      "img id out: 12123\n",
      "img id in: 12124\n",
      "img id out: 12124\n",
      "img id in: 12125\n",
      "img id out: 12125\n",
      "img id in: 12126\n",
      "img id out: 12126\n",
      "img id in: 12127\n",
      "img id out: 12127\n",
      "img id in: 12128\n",
      "img id out: 12128\n",
      "img id in: 12129\n",
      "img id out: 12129\n",
      "img id in: 12130\n",
      "img id out: 12130\n",
      "img id in: 12131\n",
      "img id out: 12131\n",
      "img id in: 12132\n",
      "img id out: 12132\n",
      "img id in: 12133\n",
      "img id out: 12133\n",
      "img id in: 12134\n",
      "img id out: 12134\n",
      "img id in: 12135\n",
      "img id out: 12135\n",
      "img id in: 12136\n",
      "img id out: 12136\n",
      "img id in: 12137\n",
      "img id out: 12137\n",
      "img id in: 12138\n",
      "img id out: 12138\n",
      "img id in: 12139\n",
      "img id out: 12139\n",
      "img id in: 12140\n",
      "img id out: 12140\n",
      "img id in: 12141\n",
      "img id out: 12141\n",
      "img id in: 12142\n",
      "img id out: 12142\n",
      "img id in: 12143\n",
      "img id out: 12143\n",
      "img id in: 12144\n",
      "img id out: 12144\n",
      "img id in: 12145\n",
      "img id out: 12145\n",
      "img id in: 12146\n",
      "img id out: 12146\n",
      "img id in: 12147\n",
      "img id out: 12147\n",
      "img id in: 12148\n",
      "img id out: 12148\n",
      "img id in: 12149\n",
      "img id out: 12149\n",
      "img id in: 12150\n",
      "img id out: 12150\n",
      "img id in: 12151\n",
      "img id out: 12151\n",
      "img id in: 12152\n",
      "img id out: 12152\n",
      "img id in: 12153\n",
      "img id out: 12153\n",
      "img id in: 12154\n",
      "img id out: 12154\n",
      "img id in: 12155\n",
      "img id out: 12155\n",
      "img id in: 12156\n",
      "img id out: 12156\n",
      "img id in: 12157\n",
      "img id out: 12157\n",
      "img id in: 12158\n",
      "img id out: 12158\n",
      "img id in: 12159\n",
      "img id out: 12159\n",
      "img id in: 12160\n",
      "img id out: 12160\n",
      "img id in: 12161\n",
      "img id out: 12161\n",
      "img id in: 12162\n",
      "img id out: 12162\n",
      "img id in: 12163\n",
      "img id out: 12163\n",
      "img id in: 12164\n",
      "img id out: 12164\n",
      "img id in: 12165\n",
      "img id out: 12165\n",
      "img id in: 12166\n",
      "img id out: 12166\n",
      "img id in: 12167\n",
      "img id out: 12167\n",
      "img id in: 12168\n",
      "img id out: 12168\n",
      "img id in: 12169\n",
      "img id out: 12169\n",
      "img id in: 12170\n",
      "img id out: 12170\n",
      "img id in: 12171\n",
      "img id out: 12171\n",
      "img id in: 12172\n",
      "img id out: 12172\n",
      "img id in: 12173\n",
      "img id out: 12173\n",
      "img id in: 12174\n",
      "img id out: 12174\n",
      "img id in: 12175\n",
      "img id out: 12175\n",
      "img id in: 12176\n",
      "img id out: 12176\n",
      "img id in: 12177\n",
      "img id out: 12177\n",
      "img id in: 12178\n",
      "img id out: 12178\n",
      "img id in: 12179\n",
      "img id out: 12179\n",
      "img id in: 12180\n",
      "img id out: 12180\n",
      "img id in: 12181\n",
      "img id out: 12181\n",
      "img id in: 12182\n",
      "img id out: 12182\n",
      "img id in: 12183\n",
      "img id out: 12183\n",
      "img id in: 12184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 12184\n",
      "img id in: 12185\n",
      "img id out: 12185\n",
      "img id in: 12186\n",
      "img id out: 12186\n",
      "img id in: 12187\n",
      "img id out: 12187\n",
      "img id in: 12188\n",
      "img id out: 12188\n",
      "img id in: 12189\n",
      "img id out: 12189\n",
      "img id in: 12190\n",
      "img id out: 12190\n",
      "img id in: 12191\n",
      "img id out: 12191\n",
      "img id in: 12192\n",
      "img id out: 12192\n",
      "img id in: 12193\n",
      "img id out: 12193\n",
      "img id in: 12194\n",
      "img id out: 12194\n",
      "img id in: 12195\n",
      "img id out: 12195\n",
      "img id in: 12196\n",
      "img id out: 12196\n",
      "img id in: 12197\n",
      "img id out: 12197\n",
      "img id in: 12198\n",
      "img id out: 12198\n",
      "img id in: 12199\n",
      "img id out: 12199\n",
      "img id in: 12200\n",
      "img id out: 12200\n",
      "img id in: 12201\n",
      "img id out: 12201\n",
      "img id in: 12202\n",
      "img id out: 12202\n",
      "img id in: 12203\n",
      "img id out: 12203\n",
      "img id in: 12204\n",
      "img id out: 12204\n",
      "img id in: 12205\n",
      "img id out: 12205\n",
      "img id in: 12206\n",
      "img id out: 12206\n",
      "img id in: 12207\n",
      "img id out: 12207\n",
      "img id in: 12208\n",
      "img id out: 12208\n",
      "img id in: 12209\n",
      "img id out: 12209\n",
      "img id in: 12210\n",
      "img id out: 12210\n",
      "img id in: 12211\n",
      "img id out: 12211\n",
      "img id in: 12212\n",
      "img id out: 12212\n",
      "img id in: 12213\n",
      "img id out: 12213\n",
      "img id in: 12214\n",
      "img id out: 12214\n",
      "img id in: 12215\n",
      "img id out: 12215\n",
      "img id in: 12216\n",
      "img id out: 12216\n",
      "img id in: 12217\n",
      "img id out: 12217\n",
      "img id in: 12218\n",
      "img id out: 12218\n",
      "img id in: 12219\n",
      "img id out: 12219\n",
      "img id in: 12220\n",
      "img id out: 12220\n",
      "img id in: 12221\n",
      "img id out: 12221\n",
      "img id in: 12222\n",
      "img id out: 12222\n",
      "img id in: 12223\n",
      "img id out: 12223\n",
      "img id in: 12224\n",
      "img id out: 12224\n",
      "img id in: 12225\n",
      "img id out: 12225\n",
      "img id in: 12226\n",
      "img id out: 12226\n",
      "img id in: 12227\n",
      "img id out: 12227\n",
      "img id in: 12228\n",
      "img id out: 12228\n",
      "img id in: 12229\n",
      "img id out: 12229\n",
      "img id in: 12230\n",
      "img id out: 12230\n",
      "img id in: 12231\n",
      "img id out: 12231\n",
      "img id in: 12232\n",
      "img id out: 12232\n",
      "img id in: 12233\n",
      "img id out: 12233\n",
      "img id in: 12234\n",
      "img id out: 12234\n",
      "img id in: 12235\n",
      "img id out: 12235\n",
      "img id in: 12236\n",
      "img id out: 12236\n",
      "img id in: 12237\n",
      "img id out: 12237\n",
      "img id in: 12238\n",
      "img id out: 12238\n",
      "img id in: 12239\n",
      "img id out: 12239\n",
      "img id in: 12240\n",
      "img id out: 12240\n",
      "img id in: 12241\n",
      "img id out: 12241\n",
      "img id in: 12242\n",
      "img id out: 12242\n",
      "img id in: 12243\n",
      "img id out: 12243\n",
      "img id in: 12244\n",
      "img id out: 12244\n",
      "img id in: 12245\n",
      "img id out: 12245\n",
      "img id in: 12246\n",
      "img id out: 12246\n",
      "img id in: 12247\n",
      "img id out: 12247\n",
      "img id in: 12248\n",
      "img id out: 12248\n",
      "img id in: 12249\n",
      "img id out: 12249\n",
      "img id in: 12250\n",
      "img id out: 12250\n",
      "img id in: 12251\n",
      "img id out: 12251\n",
      "img id in: 12252\n",
      "img id out: 12252\n",
      "img id in: 12253\n",
      "img id out: 12253\n",
      "img id in: 12254\n",
      "img id out: 12254\n",
      "img id in: 12255\n",
      "img id out: 12255\n",
      "img id in: 12256\n",
      "img id out: 12256\n",
      "img id in: 12257\n",
      "img id out: 12257\n",
      "img id in: 12258\n",
      "img id out: 12258\n",
      "img id in: 12259\n",
      "img id out: 12259\n",
      "img id in: 12260\n",
      "img id out: 12260\n",
      "img id in: 12261\n",
      "img id out: 12261\n",
      "img id in: 12262\n",
      "img id out: 12262\n",
      "img id in: 12263\n",
      "img id out: 12263\n",
      "img id in: 12264\n",
      "img id out: 12264\n",
      "img id in: 12265\n",
      "img id out: 12265\n",
      "img id in: 12266\n",
      "img id out: 12266\n",
      "img id in: 12267\n",
      "img id out: 12267\n",
      "img id in: 12268\n",
      "img id out: 12268\n",
      "img id in: 12269\n",
      "img id out: 12269\n",
      "img id in: 12270\n",
      "img id out: 12270\n",
      "img id in: 12271\n",
      "img id out: 12271\n",
      "img id in: 12272\n",
      "img id out: 12272\n",
      "img id in: 12273\n",
      "img id out: 12273\n",
      "img id in: 12274\n",
      "img id out: 12274\n",
      "img id in: 12275\n",
      "img id out: 12275\n",
      "img id in: 12276\n",
      "img id out: 12276\n",
      "img id in: 12277\n",
      "img id out: 12277\n",
      "img id in: 12278\n",
      "img id out: 12278\n",
      "img id in: 12279\n",
      "img id out: 12279\n",
      "img id in: 12280\n",
      "img id out: 12280\n",
      "img id in: 12281\n",
      "img id out: 12281\n",
      "img id in: 12282\n",
      "img id out: 12282\n",
      "img id in: 12283\n",
      "img id out: 12283\n",
      "img id in: 12284\n",
      "img id out: 12284\n",
      "img id in: 12285\n",
      "img id out: 12285\n",
      "img id in: 12286\n",
      "img id out: 12286\n",
      "img id in: 12287\n",
      "img id out: 12287\n",
      "img id in: 12288\n",
      "img id out: 12288\n",
      "img id in: 12289\n",
      "img id out: 12289\n",
      "img id in: 12290\n",
      "img id out: 12290\n",
      "img id in: 12291\n",
      "img id out: 12291\n",
      "img id in: 12292\n",
      "img id out: 12292\n",
      "img id in: 12293\n",
      "img id out: 12293\n",
      "img id in: 12294\n",
      "img id out: 12294\n",
      "img id in: 12295\n",
      "img id out: 12295\n",
      "img id in: 12296\n",
      "img id out: 12296\n",
      "img id in: 12297\n",
      "img id out: 12297\n",
      "img id in: 12298\n",
      "img id out: 12298\n",
      "img id in: 12299\n",
      "img id out: 12299\n",
      "img id in: 12300\n",
      "img id out: 12300\n",
      "img id in: 12301\n",
      "img id out: 12301\n",
      "img id in: 12302\n",
      "img id out: 12302\n",
      "img id in: 12303\n",
      "img id out: 12303\n",
      "img id in: 12304\n",
      "img id out: 12304\n",
      "img id in: 12305\n",
      "img id out: 12305\n",
      "img id in: 12306\n",
      "img id out: 12306\n",
      "img id in: 12307\n",
      "img id out: 12307\n",
      "img id in: 12308\n",
      "img id out: 12308\n",
      "img id in: 12309\n",
      "img id out: 12309\n",
      "img id in: 12310\n",
      "img id out: 12310\n",
      "img id in: 12311\n",
      "img id out: 12311\n",
      "img id in: 12312\n",
      "img id out: 12312\n",
      "img id in: 12313\n",
      "img id out: 12313\n",
      "img id in: 12314\n",
      "img id out: 12314\n",
      "img id in: 12315\n",
      "img id out: 12315\n",
      "img id in: 12316\n",
      "img id out: 12316\n",
      "img id in: 12317\n",
      "img id out: 12317\n",
      "img id in: 12318\n",
      "img id out: 12318\n",
      "img id in: 12319\n",
      "img id out: 12319\n",
      "img id in: 12320\n",
      "img id out: 12320\n",
      "img id in: 12321\n",
      "img id out: 12321\n",
      "img id in: 12322\n",
      "img id out: 12322\n",
      "img id in: 12323\n",
      "img id out: 12323\n",
      "img id in: 12324\n",
      "img id out: 12324\n",
      "img id in: 12325\n",
      "img id out: 12325\n",
      "img id in: 12326\n",
      "img id out: 12326\n",
      "img id in: 12327\n",
      "img id out: 12327\n",
      "img id in: 12328\n",
      "img id out: 12328\n",
      "img id in: 12329\n",
      "img id out: 12329\n",
      "img id in: 12330\n",
      "img id out: 12330\n",
      "img id in: 12331\n",
      "img id out: 12331\n",
      "img id in: 12332\n",
      "img id out: 12332\n",
      "img id in: 12333\n",
      "img id out: 12333\n",
      "img id in: 12334\n",
      "img id out: 12334\n",
      "img id in: 12335\n",
      "img id out: 12335\n",
      "img id in: 12336\n",
      "img id out: 12336\n",
      "img id in: 12337\n",
      "img id out: 12337\n",
      "img id in: 12338\n",
      "img id out: 12338\n",
      "img id in: 12339\n",
      "img id out: 12339\n",
      "img id in: 12340\n",
      "img id out: 12340\n",
      "img id in: 12341\n",
      "img id out: 12341\n",
      "img id in: 12342\n",
      "img id out: 12342\n",
      "img id in: 12343\n",
      "img id out: 12343\n",
      "img id in: 12344\n",
      "img id out: 12344\n",
      "img id in: 12345\n",
      "img id out: 12345\n",
      "img id in: 12346\n",
      "img id out: 12346\n",
      "img id in: 12347\n",
      "img id out: 12347\n",
      "img id in: 12348\n",
      "img id out: 12348\n",
      "img id in: 12349\n",
      "img id out: 12349\n",
      "img id in: 12350\n",
      "img id out: 12350\n",
      "img id in: 12351\n",
      "img id out: 12351\n",
      "img id in: 12352\n",
      "img id out: 12352\n",
      "img id in: 12353\n",
      "img id out: 12353\n",
      "img id in: 12354\n",
      "img id out: 12354\n",
      "img id in: 12355\n",
      "img id out: 12355\n",
      "img id in: 12356\n",
      "img id out: 12356\n",
      "img id in: 12357\n",
      "img id out: 12357\n",
      "img id in: 12358\n",
      "img id out: 12358\n",
      "img id in: 12359\n",
      "img id out: 12359\n",
      "img id in: 12360\n",
      "img id out: 12360\n",
      "img id in: 12361\n",
      "img id out: 12361\n",
      "img id in: 12362\n",
      "img id out: 12362\n",
      "img id in: 12363\n",
      "img id out: 12363\n",
      "img id in: 12364\n",
      "img id out: 12364\n",
      "img id in: 12365\n",
      "img id out: 12365\n",
      "img id in: 12366\n",
      "img id out: 12366\n",
      "img id in: 12367\n",
      "img id out: 12367\n",
      "img id in: 12368\n",
      "img id out: 12368\n",
      "img id in: 12369\n",
      "img id out: 12369\n",
      "img id in: 12370\n",
      "img id out: 12370\n",
      "img id in: 12371\n",
      "img id out: 12371\n",
      "img id in: 12372\n",
      "img id out: 12372\n",
      "img id in: 12373\n",
      "img id out: 12373\n",
      "img id in: 12374\n",
      "img id out: 12374\n",
      "img id in: 12375\n",
      "img id out: 12375\n",
      "img id in: 12376\n",
      "img id out: 12376\n",
      "img id in: 12377\n",
      "img id out: 12377\n",
      "img id in: 12378\n",
      "img id out: 12378\n",
      "img id in: 12379\n",
      "img id out: 12379\n",
      "img id in: 12380\n",
      "img id out: 12380\n",
      "img id in: 12381\n",
      "img id out: 12381\n",
      "img id in: 12382\n",
      "img id out: 12382\n",
      "img id in: 12383\n",
      "img id out: 12383\n",
      "img id in: 12384\n",
      "img id out: 12384\n",
      "img id in: 12385\n",
      "img id out: 12385\n",
      "img id in: 12386\n",
      "img id out: 12386\n",
      "img id in: 12387\n",
      "img id out: 12387\n",
      "img id in: 12388\n",
      "img id out: 12388\n",
      "img id in: 12389\n",
      "img id out: 12389\n",
      "img id in: 12390\n",
      "img id out: 12390\n",
      "img id in: 12391\n",
      "img id out: 12391\n",
      "img id in: 12392\n",
      "img id out: 12392\n",
      "img id in: 12393\n",
      "img id out: 12393\n",
      "img id in: 12394\n",
      "img id out: 12394\n",
      "img id in: 12395\n",
      "img id out: 12395\n",
      "img id in: 12396\n",
      "img id out: 12396\n",
      "img id in: 12397\n",
      "img id out: 12397\n",
      "img id in: 12398\n",
      "img id out: 12398\n",
      "img id in: 12399\n",
      "img id out: 12399\n",
      "img id in: 12400\n",
      "img id out: 12400\n",
      "img id in: 12401\n",
      "img id out: 12401\n",
      "img id in: 12402\n",
      "img id out: 12402\n",
      "img id in: 12403\n",
      "img id out: 12403\n",
      "img id in: 12404\n",
      "img id out: 12404\n",
      "img id in: 12405\n",
      "img id out: 12405\n",
      "img id in: 12406\n",
      "img id out: 12406\n",
      "img id in: 12407\n",
      "img id out: 12407\n",
      "img id in: 12408\n",
      "img id out: 12408\n",
      "img id in: 12409\n",
      "img id out: 12409\n",
      "img id in: 12410\n",
      "img id out: 12410\n",
      "img id in: 12411\n",
      "img id out: 12411\n",
      "img id in: 12412\n",
      "img id out: 12412\n",
      "img id in: 12413\n",
      "img id out: 12413\n",
      "img id in: 12414\n",
      "img id out: 12414\n",
      "img id in: 12415\n",
      "img id out: 12415\n",
      "img id in: 12416\n",
      "img id out: 12416\n",
      "img id in: 12417\n",
      "img id out: 12417\n",
      "img id in: 12418\n",
      "img id out: 12418\n",
      "img id in: 12419\n",
      "img id out: 12419\n",
      "img id in: 12420\n",
      "img id out: 12420\n",
      "img id in: 12421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 12421\n",
      "img id in: 12422\n",
      "img id out: 12422\n",
      "img id in: 12423\n",
      "img id out: 12423\n",
      "img id in: 12424\n",
      "img id out: 12424\n",
      "img id in: 12425\n",
      "img id out: 12425\n",
      "img id in: 12426\n",
      "img id out: 12426\n",
      "img id in: 12427\n",
      "img id out: 12427\n",
      "img id in: 12428\n",
      "img id out: 12428\n",
      "img id in: 12429\n",
      "img id out: 12429\n",
      "img id in: 12430\n",
      "img id out: 12430\n",
      "img id in: 12431\n",
      "img id out: 12431\n",
      "img id in: 12432\n",
      "img id out: 12432\n",
      "img id in: 12433\n",
      "img id out: 12433\n",
      "img id in: 12434\n",
      "img id out: 12434\n",
      "img id in: 12435\n",
      "img id out: 12435\n",
      "img id in: 12436\n",
      "img id out: 12436\n",
      "img id in: 12437\n",
      "img id out: 12437\n",
      "img id in: 12438\n",
      "img id out: 12438\n",
      "img id in: 12439\n",
      "img id out: 12439\n",
      "img id in: 12440\n",
      "img id out: 12440\n",
      "img id in: 12441\n",
      "img id out: 12441\n",
      "img id in: 12442\n",
      "img id out: 12442\n",
      "img id in: 12443\n",
      "img id out: 12443\n",
      "img id in: 12444\n",
      "img id out: 12444\n",
      "img id in: 12445\n",
      "img id out: 12445\n",
      "img id in: 12446\n",
      "img id out: 12446\n",
      "img id in: 12447\n",
      "img id out: 12447\n",
      "img id in: 12448\n",
      "img id out: 12448\n",
      "img id in: 12449\n",
      "img id out: 12449\n",
      "img id in: 12450\n",
      "img id out: 12450\n",
      "img id in: 12451\n",
      "img id out: 12451\n",
      "img id in: 12452\n",
      "img id out: 12452\n",
      "img id in: 12453\n",
      "img id out: 12453\n",
      "img id in: 12454\n",
      "img id out: 12454\n",
      "img id in: 12455\n",
      "img id out: 12455\n",
      "img id in: 12456\n",
      "img id out: 12456\n",
      "img id in: 12457\n",
      "img id out: 12457\n",
      "img id in: 12458\n",
      "img id out: 12458\n",
      "img id in: 12459\n",
      "img id out: 12459\n",
      "img id in: 12460\n",
      "img id out: 12460\n",
      "img id in: 12461\n",
      "img id out: 12461\n",
      "img id in: 12462\n",
      "img id out: 12462\n",
      "img id in: 12463\n",
      "img id out: 12463\n",
      "img id in: 12464\n",
      "img id out: 12464\n",
      "img id in: 12465\n",
      "img id out: 12465\n",
      "img id in: 12466\n",
      "img id out: 12466\n",
      "img id in: 12467\n",
      "img id out: 12467\n",
      "img id in: 12468\n",
      "img id out: 12468\n",
      "img id in: 12469\n",
      "img id out: 12469\n",
      "img id in: 12470\n",
      "img id out: 12470\n",
      "img id in: 12471\n",
      "img id out: 12471\n",
      "img id in: 12472\n",
      "img id out: 12472\n",
      "img id in: 12473\n",
      "img id out: 12473\n",
      "img id in: 12474\n",
      "img id out: 12474\n",
      "img id in: 12475\n",
      "img id out: 12475\n",
      "img id in: 12476\n",
      "img id out: 12476\n",
      "img id in: 12477\n",
      "img id out: 12477\n",
      "img id in: 12478\n",
      "img id out: 12478\n",
      "img id in: 12479\n",
      "img id out: 12479\n",
      "img id in: 12480\n",
      "img id out: 12480\n",
      "img id in: 12481\n",
      "img id out: 12481\n",
      "img id in: 12482\n",
      "img id out: 12482\n",
      "img id in: 12483\n",
      "img id out: 12483\n",
      "img id in: 12484\n",
      "img id out: 12484\n",
      "img id in: 12485\n",
      "img id out: 12485\n",
      "img id in: 12486\n",
      "img id out: 12486\n",
      "img id in: 12487\n",
      "img id out: 12487\n",
      "img id in: 12488\n",
      "img id out: 12488\n",
      "img id in: 12489\n",
      "img id out: 12489\n",
      "img id in: 12490\n",
      "img id out: 12490\n",
      "img id in: 12491\n",
      "img id out: 12491\n",
      "img id in: 12492\n",
      "img id out: 12492\n",
      "img id in: 12493\n",
      "img id out: 12493\n",
      "img id in: 12494\n",
      "img id out: 12494\n",
      "img id in: 12495\n",
      "img id out: 12495\n",
      "img id in: 12496\n",
      "img id out: 12496\n",
      "img id in: 12497\n",
      "img id out: 12497\n",
      "img id in: 12498\n",
      "img id out: 12498\n",
      "img id in: 12499\n",
      "img id out: 12499\n",
      "img id in: 12500\n",
      "img id out: 12500\n",
      "img id in: 12501\n",
      "img id out: 12501\n",
      "img id in: 12502\n",
      "img id out: 12502\n",
      "img id in: 12503\n",
      "img id out: 12503\n",
      "img id in: 12504\n",
      "img id out: 12504\n",
      "img id in: 12505\n",
      "img id out: 12505\n",
      "img id in: 12506\n",
      "img id out: 12506\n",
      "img id in: 12507\n",
      "img id out: 12507\n",
      "img id in: 12508\n",
      "img id out: 12508\n",
      "img id in: 12509\n",
      "img id out: 12509\n",
      "img id in: 12510\n",
      "img id out: 12510\n",
      "img id in: 12511\n",
      "img id out: 12511\n",
      "img id in: 12512\n",
      "img id out: 12512\n",
      "img id in: 12513\n",
      "img id out: 12513\n",
      "img id in: 12514\n",
      "img id out: 12514\n",
      "img id in: 12515\n",
      "img id out: 12515\n",
      "img id in: 12516\n",
      "img id out: 12516\n",
      "img id in: 12517\n",
      "img id out: 12517\n",
      "img id in: 12518\n",
      "img id out: 12518\n",
      "img id in: 12519\n",
      "img id out: 12519\n",
      "img id in: 12520\n",
      "img id out: 12520\n",
      "img id in: 12521\n",
      "img id out: 12521\n",
      "img id in: 12522\n",
      "img id out: 12522\n",
      "img id in: 12523\n",
      "img id out: 12523\n",
      "img id in: 12524\n",
      "img id out: 12524\n",
      "img id in: 12525\n",
      "img id out: 12525\n",
      "img id in: 12526\n",
      "img id out: 12526\n",
      "img id in: 12527\n",
      "img id out: 12527\n",
      "img id in: 12528\n",
      "img id out: 12528\n",
      "img id in: 12529\n",
      "img id out: 12529\n",
      "img id in: 12530\n",
      "img id out: 12530\n",
      "img id in: 12531\n",
      "img id out: 12531\n",
      "img id in: 12532\n",
      "img id out: 12532\n",
      "img id in: 12533\n",
      "img id out: 12533\n",
      "img id in: 12534\n",
      "img id out: 12534\n",
      "img id in: 12535\n",
      "img id out: 12535\n",
      "img id in: 12536\n",
      "img id out: 12536\n",
      "img id in: 12537\n",
      "img id out: 12537\n",
      "img id in: 12538\n",
      "img id out: 12538\n",
      "img id in: 12539\n",
      "img id out: 12539\n",
      "img id in: 12540\n",
      "img id out: 12540\n",
      "img id in: 12541\n",
      "img id out: 12541\n",
      "img id in: 12542\n",
      "img id out: 12542\n",
      "img id in: 12543\n",
      "img id out: 12543\n",
      "img id in: 12544\n",
      "img id out: 12544\n",
      "img id in: 12545\n",
      "img id out: 12545\n",
      "img id in: 12546\n",
      "img id out: 12546\n",
      "img id in: 12547\n",
      "img id out: 12547\n",
      "img id in: 12548\n",
      "img id out: 12548\n",
      "img id in: 12549\n",
      "img id out: 12549\n",
      "img id in: 12550\n",
      "img id out: 12550\n",
      "img id in: 12551\n",
      "img id out: 12551\n",
      "img id in: 12552\n",
      "img id out: 12552\n",
      "img id in: 12553\n",
      "img id out: 12553\n",
      "img id in: 12554\n",
      "img id out: 12554\n",
      "img id in: 12555\n",
      "img id out: 12555\n",
      "img id in: 12556\n",
      "img id out: 12556\n",
      "img id in: 12557\n",
      "img id out: 12557\n",
      "img id in: 12558\n",
      "img id out: 12558\n",
      "img id in: 12559\n",
      "img id out: 12559\n",
      "img id in: 12560\n",
      "img id out: 12560\n",
      "img id in: 12561\n",
      "img id out: 12561\n",
      "img id in: 12562\n",
      "img id out: 12562\n",
      "img id in: 12563\n",
      "img id out: 12563\n",
      "img id in: 12564\n",
      "img id out: 12564\n",
      "img id in: 12565\n",
      "img id out: 12565\n",
      "img id in: 12566\n",
      "img id out: 12566\n",
      "img id in: 12567\n",
      "img id out: 12567\n",
      "img id in: 12568\n",
      "img id out: 12568\n",
      "img id in: 12569\n",
      "img id out: 12569\n",
      "img id in: 12570\n",
      "img id out: 12570\n",
      "img id in: 12571\n",
      "img id out: 12571\n",
      "img id in: 12572\n",
      "img id out: 12572\n",
      "img id in: 12573\n",
      "img id out: 12573\n",
      "img id in: 12574\n",
      "img id out: 12574\n",
      "img id in: 12575\n",
      "img id out: 12575\n",
      "img id in: 12576\n",
      "img id out: 12576\n",
      "img id in: 12577\n",
      "img id out: 12577\n",
      "img id in: 12578\n",
      "img id out: 12578\n",
      "img id in: 12579\n",
      "img id out: 12579\n",
      "img id in: 12580\n",
      "img id out: 12580\n",
      "img id in: 12581\n",
      "img id out: 12581\n",
      "img id in: 12582\n",
      "img id out: 12582\n",
      "img id in: 12583\n",
      "img id out: 12583\n",
      "img id in: 12584\n",
      "img id out: 12584\n",
      "img id in: 12585\n",
      "img id out: 12585\n",
      "img id in: 12586\n",
      "img id out: 12586\n",
      "img id in: 12587\n",
      "img id out: 12587\n",
      "img id in: 12588\n",
      "img id out: 12588\n",
      "img id in: 12589\n",
      "img id out: 12589\n",
      "img id in: 12590\n",
      "img id out: 12590\n",
      "img id in: 12591\n",
      "img id out: 12591\n",
      "img id in: 12592\n",
      "img id out: 12592\n",
      "img id in: 12593\n",
      "img id out: 12593\n",
      "img id in: 12594\n",
      "img id out: 12594\n",
      "img id in: 12595\n",
      "img id out: 12595\n",
      "img id in: 12596\n",
      "img id out: 12596\n",
      "img id in: 12597\n",
      "img id out: 12597\n",
      "img id in: 12598\n",
      "img id out: 12598\n",
      "img id in: 12599\n",
      "img id out: 12599\n",
      "img id in: 12600\n",
      "img id out: 12600\n",
      "img id in: 12601\n",
      "img id out: 12601\n",
      "img id in: 12602\n",
      "img id out: 12602\n",
      "img id in: 12603\n",
      "img id out: 12603\n",
      "img id in: 12604\n",
      "img id out: 12604\n",
      "img id in: 12605\n",
      "img id out: 12605\n",
      "img id in: 12606\n",
      "img id out: 12606\n",
      "img id in: 12607\n",
      "img id out: 12607\n",
      "img id in: 12608\n",
      "img id out: 12608\n",
      "img id in: 12609\n",
      "img id out: 12609\n",
      "img id in: 12610\n",
      "img id out: 12610\n",
      "img id in: 12611\n",
      "img id out: 12611\n",
      "img id in: 12612\n",
      "img id out: 12612\n",
      "img id in: 12613\n",
      "img id out: 12613\n",
      "img id in: 12614\n",
      "img id out: 12614\n",
      "img id in: 12615\n",
      "img id out: 12615\n",
      "img id in: 12616\n",
      "img id out: 12616\n",
      "img id in: 12617\n",
      "img id out: 12617\n",
      "img id in: 12618\n",
      "img id out: 12618\n",
      "img id in: 12619\n",
      "img id out: 12619\n",
      "img id in: 12620\n",
      "img id out: 12620\n",
      "img id in: 12621\n",
      "img id out: 12621\n",
      "img id in: 12622\n",
      "img id out: 12622\n",
      "img id in: 12623\n",
      "img id out: 12623\n",
      "img id in: 12624\n",
      "img id out: 12624\n",
      "img id in: 12625\n",
      "img id out: 12625\n",
      "img id in: 12626\n",
      "img id out: 12626\n",
      "img id in: 12627\n",
      "img id out: 12627\n",
      "img id in: 12628\n",
      "img id out: 12628\n",
      "img id in: 12629\n",
      "img id out: 12629\n",
      "img id in: 12630\n",
      "img id out: 12630\n",
      "img id in: 12631\n",
      "img id out: 12631\n",
      "img id in: 12632\n",
      "img id out: 12632\n",
      "img id in: 12633\n",
      "img id out: 12633\n",
      "img id in: 12634\n",
      "img id out: 12634\n",
      "img id in: 12635\n",
      "img id out: 12635\n",
      "img id in: 12636\n",
      "img id out: 12636\n",
      "img id in: 12637\n",
      "img id out: 12637\n",
      "img id in: 12638\n",
      "img id out: 12638\n",
      "img id in: 12639\n",
      "img id out: 12639\n",
      "img id in: 12640\n",
      "img id out: 12640\n",
      "img id in: 12641\n",
      "img id out: 12641\n",
      "img id in: 12642\n",
      "img id out: 12642\n",
      "img id in: 12643\n",
      "img id out: 12643\n",
      "img id in: 12644\n",
      "img id out: 12644\n",
      "img id in: 12645\n",
      "img id out: 12645\n",
      "img id in: 12646\n",
      "img id out: 12646\n",
      "img id in: 12647\n",
      "img id out: 12647\n",
      "img id in: 12648\n",
      "img id out: 12648\n",
      "img id in: 12649\n",
      "img id out: 12649\n",
      "img id in: 12650\n",
      "img id out: 12650\n",
      "img id in: 12651\n",
      "img id out: 12651\n",
      "img id in: 12652\n",
      "img id out: 12652\n",
      "img id in: 12653\n",
      "img id out: 12653\n",
      "img id in: 12654\n",
      "img id out: 12654\n",
      "img id in: 12655\n",
      "img id out: 12655\n",
      "img id in: 12656\n",
      "img id out: 12656\n",
      "img id in: 12657\n",
      "img id out: 12657\n",
      "img id in: 12658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 12658\n",
      "img id in: 12659\n",
      "img id out: 12659\n",
      "img id in: 12660\n",
      "img id out: 12660\n",
      "img id in: 12661\n",
      "img id out: 12661\n",
      "img id in: 12662\n",
      "img id out: 12662\n",
      "img id in: 12663\n",
      "img id out: 12663\n",
      "img id in: 12664\n",
      "img id out: 12664\n",
      "img id in: 12665\n",
      "img id out: 12665\n",
      "img id in: 12666\n",
      "img id out: 12666\n",
      "img id in: 12667\n",
      "img id out: 12667\n",
      "img id in: 12668\n",
      "img id out: 12668\n",
      "img id in: 12669\n",
      "img id out: 12669\n",
      "img id in: 12670\n",
      "img id out: 12670\n",
      "img id in: 12671\n",
      "img id out: 12671\n",
      "img id in: 12672\n",
      "img id out: 12672\n",
      "img id in: 12673\n",
      "img id out: 12673\n",
      "img id in: 12674\n",
      "img id out: 12674\n",
      "img id in: 12675\n",
      "img id out: 12675\n",
      "img id in: 12676\n",
      "img id out: 12676\n",
      "img id in: 12677\n",
      "img id out: 12677\n",
      "img id in: 12678\n",
      "img id out: 12678\n",
      "img id in: 12679\n",
      "img id out: 12679\n",
      "img id in: 12680\n",
      "img id out: 12680\n",
      "img id in: 12681\n",
      "img id out: 12681\n",
      "img id in: 12682\n",
      "img id out: 12682\n",
      "img id in: 12683\n",
      "img id out: 12683\n",
      "img id in: 12684\n",
      "img id out: 12684\n",
      "img id in: 12685\n",
      "img id out: 12685\n",
      "img id in: 12686\n",
      "img id out: 12686\n",
      "img id in: 12687\n",
      "img id out: 12687\n",
      "img id in: 12688\n",
      "img id out: 12688\n",
      "img id in: 12689\n",
      "img id out: 12689\n",
      "img id in: 12690\n",
      "img id out: 12690\n",
      "img id in: 12691\n",
      "img id out: 12691\n",
      "img id in: 12692\n",
      "img id out: 12692\n",
      "img id in: 12693\n",
      "img id out: 12693\n",
      "img id in: 12694\n",
      "img id out: 12694\n",
      "img id in: 12695\n",
      "img id out: 12695\n",
      "img id in: 12696\n",
      "img id out: 12696\n",
      "img id in: 12697\n",
      "img id out: 12697\n",
      "img id in: 12698\n",
      "img id out: 12698\n",
      "img id in: 12699\n",
      "img id out: 12699\n",
      "img id in: 12700\n",
      "img id out: 12700\n",
      "img id in: 12701\n",
      "img id out: 12701\n",
      "img id in: 12702\n",
      "img id out: 12702\n",
      "img id in: 12703\n",
      "img id out: 12703\n",
      "img id in: 12704\n",
      "img id out: 12704\n",
      "img id in: 12705\n",
      "img id out: 12705\n",
      "img id in: 12706\n",
      "img id out: 12706\n",
      "img id in: 12707\n",
      "img id out: 12707\n",
      "img id in: 12708\n",
      "img id out: 12708\n",
      "img id in: 12709\n",
      "img id out: 12709\n",
      "img id in: 12710\n",
      "img id out: 12710\n",
      "img id in: 12711\n",
      "img id out: 12711\n",
      "img id in: 12712\n",
      "img id out: 12712\n",
      "img id in: 12713\n",
      "img id out: 12713\n",
      "img id in: 12714\n",
      "img id out: 12714\n",
      "img id in: 12715\n",
      "img id out: 12715\n",
      "img id in: 12716\n",
      "img id out: 12716\n",
      "img id in: 12717\n",
      "img id out: 12717\n",
      "img id in: 12718\n",
      "img id out: 12718\n",
      "img id in: 12719\n",
      "img id out: 12719\n",
      "img id in: 12720\n",
      "img id out: 12720\n",
      "img id in: 12721\n",
      "img id out: 12721\n",
      "img id in: 12722\n",
      "img id out: 12722\n",
      "img id in: 12723\n",
      "img id out: 12723\n",
      "img id in: 12724\n",
      "img id out: 12724\n",
      "img id in: 12725\n",
      "img id out: 12725\n",
      "img id in: 12726\n",
      "img id out: 12726\n",
      "img id in: 12727\n",
      "img id out: 12727\n",
      "img id in: 12728\n",
      "img id out: 12728\n",
      "img id in: 12729\n",
      "img id out: 12729\n",
      "img id in: 12730\n",
      "img id out: 12730\n",
      "img id in: 12731\n",
      "img id out: 12731\n",
      "img id in: 12732\n",
      "img id out: 12732\n",
      "img id in: 12733\n",
      "img id out: 12733\n",
      "img id in: 12734\n",
      "img id out: 12734\n",
      "img id in: 12735\n",
      "img id out: 12735\n",
      "img id in: 12736\n",
      "img id out: 12736\n",
      "img id in: 12737\n",
      "img id out: 12737\n",
      "img id in: 12738\n",
      "img id out: 12738\n",
      "img id in: 12739\n",
      "img id out: 12739\n",
      "img id in: 12740\n",
      "img id out: 12740\n",
      "img id in: 12741\n",
      "img id out: 12741\n",
      "img id in: 12742\n",
      "img id out: 12742\n",
      "img id in: 12743\n",
      "img id out: 12743\n",
      "img id in: 12744\n",
      "img id out: 12744\n",
      "img id in: 12745\n",
      "img id out: 12745\n",
      "img id in: 12746\n",
      "img id out: 12746\n",
      "img id in: 12747\n",
      "img id out: 12747\n",
      "img id in: 12748\n",
      "img id out: 12748\n",
      "img id in: 12749\n",
      "img id out: 12749\n",
      "img id in: 12750\n",
      "img id out: 12750\n",
      "img id in: 12751\n",
      "img id out: 12751\n",
      "img id in: 12752\n",
      "img id out: 12752\n",
      "img id in: 12753\n",
      "img id out: 12753\n",
      "img id in: 12754\n",
      "img id out: 12754\n",
      "img id in: 12755\n",
      "img id out: 12755\n",
      "img id in: 12756\n",
      "img id out: 12756\n",
      "img id in: 12757\n",
      "img id out: 12757\n",
      "img id in: 12758\n",
      "img id out: 12758\n",
      "img id in: 12759\n",
      "img id out: 12759\n",
      "img id in: 12760\n",
      "img id out: 12760\n",
      "img id in: 12761\n",
      "img id out: 12761\n",
      "img id in: 12762\n",
      "img id out: 12762\n",
      "img id in: 12763\n",
      "img id out: 12763\n",
      "img id in: 12764\n",
      "img id out: 12764\n",
      "img id in: 12765\n",
      "img id out: 12765\n",
      "img id in: 12766\n",
      "img id out: 12766\n",
      "img id in: 12767\n",
      "img id out: 12767\n",
      "img id in: 12768\n",
      "img id out: 12768\n",
      "img id in: 12769\n",
      "img id out: 12769\n",
      "img id in: 12770\n",
      "img id out: 12770\n",
      "img id in: 12771\n",
      "img id out: 12771\n",
      "img id in: 12772\n",
      "img id out: 12772\n",
      "img id in: 12773\n",
      "img id out: 12773\n",
      "img id in: 12774\n",
      "img id out: 12774\n",
      "img id in: 12775\n",
      "img id out: 12775\n",
      "img id in: 12776\n",
      "img id out: 12776\n",
      "img id in: 12777\n",
      "img id out: 12777\n",
      "img id in: 12778\n",
      "img id out: 12778\n",
      "img id in: 12779\n",
      "img id out: 12779\n",
      "img id in: 12780\n",
      "img id out: 12780\n",
      "img id in: 12781\n",
      "img id out: 12781\n",
      "img id in: 12782\n",
      "img id out: 12782\n",
      "img id in: 12783\n",
      "img id out: 12783\n",
      "img id in: 12784\n",
      "img id out: 12784\n",
      "img id in: 12785\n",
      "img id out: 12785\n",
      "img id in: 12786\n",
      "img id out: 12786\n",
      "img id in: 12787\n",
      "img id out: 12787\n",
      "img id in: 12788\n",
      "img id out: 12788\n",
      "img id in: 12789\n",
      "img id out: 12789\n",
      "img id in: 12790\n",
      "img id out: 12790\n",
      "img id in: 12791\n",
      "img id out: 12791\n",
      "img id in: 12792\n",
      "img id out: 12792\n",
      "img id in: 12793\n",
      "img id out: 12793\n",
      "img id in: 12794\n",
      "img id out: 12794\n",
      "img id in: 12795\n",
      "img id out: 12795\n",
      "img id in: 12796\n",
      "img id out: 12796\n",
      "img id in: 12797\n",
      "img id out: 12797\n",
      "img id in: 12798\n",
      "img id out: 12798\n",
      "img id in: 12799\n",
      "img id out: 12799\n",
      "img id in: 12800\n",
      "img id out: 12800\n",
      "img id in: 12801\n",
      "img id out: 12801\n",
      "img id in: 12802\n",
      "img id out: 12802\n",
      "img id in: 12803\n",
      "img id out: 12803\n",
      "img id in: 12804\n",
      "img id out: 12804\n",
      "img id in: 12805\n",
      "img id out: 12805\n",
      "img id in: 12806\n",
      "img id out: 12806\n",
      "img id in: 12807\n",
      "img id out: 12807\n",
      "img id in: 12808\n",
      "img id out: 12808\n",
      "img id in: 12809\n",
      "img id out: 12809\n",
      "img id in: 12810\n",
      "img id out: 12810\n",
      "img id in: 12811\n",
      "img id out: 12811\n",
      "img id in: 12812\n",
      "img id out: 12812\n",
      "img id in: 12813\n",
      "img id out: 12813\n",
      "img id in: 12814\n",
      "img id out: 12814\n",
      "img id in: 12815\n",
      "img id out: 12815\n",
      "img id in: 12816\n",
      "img id out: 12816\n",
      "img id in: 12817\n",
      "img id out: 12817\n",
      "img id in: 12818\n",
      "img id out: 12818\n",
      "img id in: 12819\n",
      "img id out: 12819\n",
      "img id in: 12820\n",
      "img id out: 12820\n",
      "img id in: 12821\n",
      "img id out: 12821\n",
      "img id in: 12822\n",
      "img id out: 12822\n",
      "img id in: 12823\n",
      "img id out: 12823\n",
      "img id in: 12824\n",
      "img id out: 12824\n",
      "img id in: 12825\n",
      "img id out: 12825\n",
      "img id in: 12826\n",
      "img id out: 12826\n",
      "img id in: 12827\n",
      "img id out: 12827\n",
      "img id in: 12828\n",
      "img id out: 12828\n",
      "img id in: 12829\n",
      "img id out: 12829\n",
      "img id in: 12830\n",
      "img id out: 12830\n",
      "img id in: 12831\n",
      "img id out: 12831\n",
      "img id in: 12832\n",
      "img id out: 12832\n",
      "img id in: 12833\n",
      "img id out: 12833\n",
      "img id in: 12834\n",
      "img id out: 12834\n",
      "img id in: 12835\n",
      "img id out: 12835\n",
      "img id in: 12836\n",
      "img id out: 12836\n",
      "img id in: 12837\n",
      "img id out: 12837\n",
      "img id in: 12838\n",
      "img id out: 12838\n",
      "img id in: 12839\n",
      "img id out: 12839\n",
      "img id in: 12840\n",
      "img id out: 12840\n",
      "img id in: 12841\n",
      "img id out: 12841\n",
      "img id in: 12842\n",
      "img id out: 12842\n",
      "img id in: 12843\n",
      "img id out: 12843\n",
      "img id in: 12844\n",
      "img id out: 12844\n",
      "img id in: 12845\n",
      "img id out: 12845\n",
      "img id in: 12846\n",
      "img id out: 12846\n",
      "img id in: 12847\n",
      "img id out: 12847\n",
      "img id in: 12848\n",
      "img id out: 12848\n",
      "img id in: 12849\n",
      "img id out: 12849\n",
      "img id in: 12850\n",
      "img id out: 12850\n",
      "img id in: 12851\n",
      "img id out: 12851\n",
      "img id in: 12852\n",
      "img id out: 12852\n",
      "img id in: 12853\n",
      "img id out: 12853\n",
      "img id in: 12854\n",
      "img id out: 12854\n",
      "img id in: 12855\n",
      "img id out: 12855\n",
      "img id in: 12856\n",
      "img id out: 12856\n",
      "img id in: 12857\n",
      "img id out: 12857\n",
      "img id in: 12858\n",
      "img id out: 12858\n",
      "img id in: 12859\n",
      "img id out: 12859\n",
      "img id in: 12860\n",
      "img id out: 12860\n",
      "img id in: 12861\n",
      "img id out: 12861\n",
      "img id in: 12862\n",
      "img id out: 12862\n",
      "img id in: 12863\n",
      "img id out: 12863\n",
      "img id in: 12864\n",
      "img id out: 12864\n",
      "img id in: 12865\n",
      "img id out: 12865\n",
      "img id in: 12866\n",
      "img id out: 12866\n",
      "img id in: 12867\n",
      "img id out: 12867\n",
      "img id in: 12868\n",
      "img id out: 12868\n",
      "img id in: 12869\n",
      "img id out: 12869\n",
      "img id in: 12870\n",
      "img id out: 12870\n",
      "img id in: 12871\n",
      "img id out: 12871\n",
      "img id in: 12872\n",
      "img id out: 12872\n",
      "img id in: 12873\n",
      "img id out: 12873\n",
      "img id in: 12874\n",
      "img id out: 12874\n",
      "img id in: 12875\n",
      "img id out: 12875\n",
      "img id in: 12876\n",
      "img id out: 12876\n",
      "img id in: 12877\n",
      "img id out: 12877\n",
      "img id in: 12878\n",
      "img id out: 12878\n",
      "img id in: 12879\n",
      "img id out: 12879\n",
      "img id in: 12880\n",
      "img id out: 12880\n",
      "img id in: 12881\n",
      "img id out: 12881\n",
      "img id in: 12882\n",
      "img id out: 12882\n",
      "img id in: 12883\n",
      "img id out: 12883\n",
      "img id in: 12884\n",
      "img id out: 12884\n",
      "img id in: 12885\n",
      "img id out: 12885\n",
      "img id in: 12886\n",
      "img id out: 12886\n",
      "img id in: 12887\n",
      "img id out: 12887\n",
      "img id in: 12888\n",
      "img id out: 12888\n",
      "img id in: 12889\n",
      "img id out: 12889\n",
      "img id in: 12890\n",
      "img id out: 12890\n",
      "img id in: 12891\n",
      "img id out: 12891\n",
      "img id in: 12892\n",
      "img id out: 12892\n",
      "img id in: 12893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 12893\n",
      "img id in: 12894\n",
      "img id out: 12894\n",
      "img id in: 12895\n",
      "img id out: 12895\n",
      "img id in: 12896\n",
      "img id out: 12896\n",
      "img id in: 12897\n",
      "img id out: 12897\n",
      "img id in: 12898\n",
      "img id out: 12898\n",
      "img id in: 12899\n",
      "img id out: 12899\n",
      "img id in: 12900\n",
      "img id out: 12900\n",
      "img id in: 12901\n",
      "img id out: 12901\n",
      "img id in: 12902\n",
      "img id out: 12902\n",
      "img id in: 12903\n",
      "img id out: 12903\n",
      "img id in: 12904\n",
      "img id out: 12904\n",
      "img id in: 12905\n",
      "img id out: 12905\n",
      "img id in: 12906\n",
      "img id out: 12906\n",
      "img id in: 12907\n",
      "img id out: 12907\n",
      "img id in: 12908\n",
      "img id out: 12908\n",
      "img id in: 12909\n",
      "img id out: 12909\n",
      "img id in: 12910\n",
      "img id out: 12910\n",
      "img id in: 12911\n",
      "img id out: 12911\n",
      "img id in: 12912\n",
      "img id out: 12912\n",
      "img id in: 12913\n",
      "img id out: 12913\n",
      "img id in: 12914\n",
      "img id out: 12914\n",
      "img id in: 12915\n",
      "img id out: 12915\n",
      "img id in: 12916\n",
      "img id out: 12916\n",
      "img id in: 12917\n",
      "img id out: 12917\n",
      "img id in: 12918\n",
      "img id out: 12918\n",
      "img id in: 12919\n",
      "img id out: 12919\n",
      "img id in: 12920\n",
      "img id out: 12920\n",
      "img id in: 12921\n",
      "img id out: 12921\n",
      "img id in: 12922\n",
      "img id out: 12922\n",
      "img id in: 12923\n",
      "img id out: 12923\n",
      "img id in: 12924\n",
      "img id out: 12924\n",
      "img id in: 12925\n",
      "img id out: 12925\n",
      "img id in: 12926\n",
      "img id out: 12926\n",
      "img id in: 12927\n",
      "img id out: 12927\n",
      "img id in: 12928\n",
      "img id out: 12928\n",
      "img id in: 12929\n",
      "img id out: 12929\n",
      "img id in: 12930\n",
      "img id out: 12930\n",
      "img id in: 12931\n",
      "img id out: 12931\n",
      "img id in: 12932\n",
      "img id out: 12932\n",
      "img id in: 12933\n",
      "img id out: 12933\n",
      "img id in: 12934\n",
      "img id out: 12934\n",
      "img id in: 12935\n",
      "img id out: 12935\n",
      "img id in: 12936\n",
      "img id out: 12936\n",
      "img id in: 12937\n",
      "img id out: 12937\n",
      "img id in: 12938\n",
      "img id out: 12938\n",
      "img id in: 12939\n",
      "img id out: 12939\n",
      "img id in: 12940\n",
      "img id out: 12940\n",
      "img id in: 12941\n",
      "img id out: 12941\n",
      "img id in: 12942\n",
      "img id out: 12942\n",
      "img id in: 12943\n",
      "img id out: 12943\n",
      "img id in: 12944\n",
      "img id out: 12944\n",
      "img id in: 12945\n",
      "img id out: 12945\n",
      "img id in: 12946\n",
      "img id out: 12946\n",
      "img id in: 12947\n",
      "img id out: 12947\n",
      "img id in: 12948\n",
      "img id out: 12948\n",
      "img id in: 12949\n",
      "img id out: 12949\n",
      "img id in: 12950\n",
      "img id out: 12950\n",
      "img id in: 12951\n",
      "img id out: 12951\n",
      "img id in: 12952\n",
      "img id out: 12952\n",
      "img id in: 12953\n",
      "img id out: 12953\n",
      "img id in: 12954\n",
      "img id out: 12954\n",
      "img id in: 12955\n",
      "img id out: 12955\n",
      "img id in: 12956\n",
      "img id out: 12956\n",
      "img id in: 12957\n",
      "img id out: 12957\n",
      "img id in: 12958\n",
      "img id out: 12958\n",
      "img id in: 12959\n",
      "img id out: 12959\n",
      "img id in: 12960\n",
      "img id out: 12960\n",
      "img id in: 12961\n",
      "img id out: 12961\n",
      "img id in: 12962\n",
      "img id out: 12962\n",
      "img id in: 12963\n",
      "img id out: 12963\n",
      "img id in: 12964\n",
      "img id out: 12964\n",
      "img id in: 12965\n",
      "img id out: 12965\n",
      "img id in: 12966\n",
      "img id out: 12966\n",
      "img id in: 12967\n",
      "img id out: 12967\n",
      "img id in: 12968\n",
      "img id out: 12968\n",
      "img id in: 12969\n",
      "img id out: 12969\n",
      "img id in: 12970\n",
      "img id out: 12970\n",
      "img id in: 12971\n",
      "img id out: 12971\n",
      "img id in: 12972\n",
      "img id out: 12972\n",
      "img id in: 12973\n",
      "img id out: 12973\n",
      "img id in: 12974\n",
      "img id out: 12974\n",
      "img id in: 12975\n",
      "img id out: 12975\n",
      "img id in: 12976\n",
      "img id out: 12976\n",
      "img id in: 12977\n",
      "img id out: 12977\n",
      "img id in: 12978\n",
      "img id out: 12978\n",
      "img id in: 12979\n",
      "img id out: 12979\n",
      "img id in: 12980\n",
      "img id out: 12980\n",
      "img id in: 12981\n",
      "img id out: 12981\n",
      "img id in: 12982\n",
      "img id out: 12982\n",
      "img id in: 12983\n",
      "img id out: 12983\n",
      "img id in: 12984\n",
      "img id out: 12984\n",
      "img id in: 12985\n",
      "img id out: 12985\n",
      "img id in: 12986\n",
      "img id out: 12986\n",
      "img id in: 12987\n",
      "img id out: 12987\n",
      "img id in: 12988\n",
      "img id out: 12988\n",
      "img id in: 12989\n",
      "img id out: 12989\n",
      "img id in: 12990\n",
      "img id out: 12990\n",
      "img id in: 12991\n",
      "img id out: 12991\n",
      "img id in: 12992\n",
      "img id out: 12992\n",
      "img id in: 12993\n",
      "img id out: 12993\n",
      "img id in: 12994\n",
      "img id out: 12994\n",
      "img id in: 12995\n",
      "img id out: 12995\n",
      "img id in: 12996\n",
      "img id out: 12996\n",
      "img id in: 12997\n",
      "img id out: 12997\n",
      "img id in: 12998\n",
      "img id out: 12998\n",
      "img id in: 12999\n",
      "img id out: 12999\n",
      "img id in: 13000\n",
      "img id out: 13000\n",
      "img id in: 13001\n",
      "img id out: 13001\n",
      "img id in: 13002\n",
      "img id out: 13002\n",
      "img id in: 13003\n",
      "img id out: 13003\n",
      "img id in: 13004\n",
      "img id out: 13004\n",
      "img id in: 13005\n",
      "img id out: 13005\n",
      "img id in: 13006\n",
      "img id out: 13006\n",
      "img id in: 13007\n",
      "img id out: 13007\n",
      "img id in: 13008\n",
      "img id out: 13008\n",
      "img id in: 13009\n",
      "img id out: 13009\n",
      "img id in: 13010\n",
      "img id out: 13010\n",
      "img id in: 13011\n",
      "img id out: 13011\n",
      "img id in: 13012\n",
      "img id out: 13012\n",
      "img id in: 13013\n",
      "img id out: 13013\n",
      "img id in: 13014\n",
      "img id out: 13014\n",
      "img id in: 13015\n",
      "img id out: 13015\n",
      "img id in: 13016\n",
      "img id out: 13016\n",
      "img id in: 13017\n",
      "img id out: 13017\n",
      "img id in: 13018\n",
      "img id out: 13018\n",
      "img id in: 13019\n",
      "img id out: 13019\n",
      "img id in: 13020\n",
      "img id out: 13020\n",
      "img id in: 13021\n",
      "img id out: 13021\n",
      "img id in: 13022\n",
      "img id out: 13022\n",
      "img id in: 13023\n",
      "img id out: 13023\n",
      "img id in: 13024\n",
      "img id out: 13024\n",
      "img id in: 13025\n",
      "img id out: 13025\n",
      "img id in: 13026\n",
      "img id out: 13026\n",
      "img id in: 13027\n",
      "img id out: 13027\n",
      "img id in: 13028\n",
      "img id out: 13028\n",
      "img id in: 13029\n",
      "img id out: 13029\n",
      "img id in: 13030\n",
      "img id out: 13030\n",
      "img id in: 13031\n",
      "img id out: 13031\n",
      "img id in: 13032\n",
      "img id out: 13032\n",
      "img id in: 13033\n",
      "img id out: 13033\n",
      "img id in: 13034\n",
      "img id out: 13034\n",
      "img id in: 13035\n",
      "img id out: 13035\n",
      "img id in: 13036\n",
      "img id out: 13036\n",
      "img id in: 13037\n",
      "img id out: 13037\n",
      "img id in: 13038\n",
      "img id out: 13038\n",
      "img id in: 13039\n",
      "img id out: 13039\n",
      "img id in: 13040\n",
      "img id out: 13040\n",
      "img id in: 13041\n",
      "img id out: 13041\n",
      "img id in: 13042\n",
      "img id out: 13042\n",
      "img id in: 13043\n",
      "img id out: 13043\n",
      "img id in: 13044\n",
      "img id out: 13044\n",
      "img id in: 13045\n",
      "img id out: 13045\n",
      "img id in: 13046\n",
      "img id out: 13046\n",
      "img id in: 13047\n",
      "img id out: 13047\n",
      "img id in: 13048\n",
      "img id out: 13048\n",
      "img id in: 13049\n",
      "img id out: 13049\n",
      "img id in: 13050\n",
      "img id out: 13050\n",
      "img id in: 13051\n",
      "img id out: 13051\n",
      "img id in: 13052\n",
      "img id out: 13052\n",
      "img id in: 13053\n",
      "img id out: 13053\n",
      "img id in: 13054\n",
      "img id out: 13054\n",
      "img id in: 13055\n",
      "img id out: 13055\n",
      "img id in: 13056\n",
      "img id out: 13056\n",
      "img id in: 13057\n",
      "img id out: 13057\n",
      "img id in: 13058\n",
      "img id out: 13058\n",
      "img id in: 13059\n",
      "img id out: 13059\n",
      "img id in: 13060\n",
      "img id out: 13060\n",
      "img id in: 13061\n",
      "img id out: 13061\n",
      "img id in: 13062\n",
      "img id out: 13062\n",
      "img id in: 13063\n",
      "img id out: 13063\n",
      "img id in: 13064\n",
      "img id out: 13064\n",
      "img id in: 13065\n",
      "img id out: 13065\n",
      "img id in: 13066\n",
      "img id out: 13066\n",
      "img id in: 13067\n",
      "img id out: 13067\n",
      "img id in: 13068\n",
      "img id out: 13068\n",
      "img id in: 13069\n",
      "img id out: 13069\n",
      "img id in: 13070\n",
      "img id out: 13070\n",
      "img id in: 13071\n",
      "img id out: 13071\n",
      "img id in: 13072\n",
      "img id out: 13072\n",
      "img id in: 13073\n",
      "img id out: 13073\n",
      "img id in: 13074\n",
      "img id out: 13074\n",
      "img id in: 13075\n",
      "img id out: 13075\n",
      "img id in: 13076\n",
      "img id out: 13076\n",
      "img id in: 13077\n",
      "img id out: 13077\n",
      "img id in: 13078\n",
      "img id out: 13078\n",
      "img id in: 13079\n",
      "img id out: 13079\n",
      "img id in: 13080\n",
      "img id out: 13080\n",
      "img id in: 13081\n",
      "img id out: 13081\n",
      "img id in: 13082\n",
      "img id out: 13082\n",
      "img id in: 13083\n",
      "img id out: 13083\n",
      "img id in: 13084\n",
      "img id out: 13084\n",
      "img id in: 13085\n",
      "img id out: 13085\n",
      "img id in: 13086\n",
      "img id out: 13086\n",
      "img id in: 13087\n",
      "img id out: 13087\n",
      "img id in: 13088\n",
      "img id out: 13088\n",
      "img id in: 13089\n",
      "img id out: 13089\n",
      "img id in: 13090\n",
      "img id out: 13090\n",
      "img id in: 13091\n",
      "img id out: 13091\n",
      "img id in: 13092\n",
      "img id out: 13092\n",
      "img id in: 13093\n",
      "img id out: 13093\n",
      "img id in: 13094\n",
      "img id out: 13094\n",
      "img id in: 13095\n",
      "img id out: 13095\n",
      "img id in: 13096\n",
      "img id out: 13096\n",
      "img id in: 13097\n",
      "img id out: 13097\n",
      "img id in: 13098\n",
      "img id out: 13098\n",
      "img id in: 13099\n",
      "img id out: 13099\n",
      "img id in: 13100\n",
      "img id out: 13100\n",
      "img id in: 13101\n",
      "img id out: 13101\n",
      "img id in: 13102\n",
      "img id out: 13102\n",
      "img id in: 13103\n",
      "img id out: 13103\n",
      "img id in: 13104\n",
      "img id out: 13104\n",
      "img id in: 13105\n",
      "img id out: 13105\n",
      "img id in: 13106\n",
      "img id out: 13106\n",
      "img id in: 13107\n",
      "img id out: 13107\n",
      "img id in: 13108\n",
      "img id out: 13108\n",
      "img id in: 13109\n",
      "img id out: 13109\n",
      "img id in: 13110\n",
      "img id out: 13110\n",
      "img id in: 13111\n",
      "img id out: 13111\n",
      "img id in: 13112\n",
      "img id out: 13112\n",
      "img id in: 13113\n",
      "img id out: 13113\n",
      "img id in: 13114\n",
      "img id out: 13114\n",
      "img id in: 13115\n",
      "img id out: 13115\n",
      "img id in: 13116\n",
      "img id out: 13116\n",
      "img id in: 13117\n",
      "img id out: 13117\n",
      "img id in: 13118\n",
      "img id out: 13118\n",
      "img id in: 13119\n",
      "img id out: 13119\n",
      "img id in: 13120\n",
      "img id out: 13120\n",
      "img id in: 13121\n",
      "img id out: 13121\n",
      "img id in: 13122\n",
      "img id out: 13122\n",
      "img id in: 13123\n",
      "img id out: 13123\n",
      "img id in: 13124\n",
      "img id out: 13124\n",
      "img id in: 13125\n",
      "img id out: 13125\n",
      "img id in: 13126\n",
      "img id out: 13126\n",
      "img id in: 13127\n",
      "img id out: 13127\n",
      "img id in: 13128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 13128\n",
      "img id in: 13129\n",
      "img id out: 13129\n",
      "img id in: 13130\n",
      "img id out: 13130\n",
      "img id in: 13131\n",
      "img id out: 13131\n",
      "img id in: 13132\n",
      "img id out: 13132\n",
      "img id in: 13133\n",
      "img id out: 13133\n",
      "img id in: 13134\n",
      "img id out: 13134\n",
      "img id in: 13135\n",
      "img id out: 13135\n",
      "img id in: 13136\n",
      "img id out: 13136\n",
      "img id in: 13137\n",
      "img id out: 13137\n",
      "img id in: 13138\n",
      "img id out: 13138\n",
      "img id in: 13139\n",
      "img id out: 13139\n",
      "img id in: 13140\n",
      "img id out: 13140\n",
      "img id in: 13141\n",
      "img id out: 13141\n",
      "img id in: 13142\n",
      "img id out: 13142\n",
      "img id in: 13143\n",
      "img id out: 13143\n",
      "img id in: 13144\n",
      "img id out: 13144\n",
      "img id in: 13145\n",
      "img id out: 13145\n",
      "img id in: 13146\n",
      "img id out: 13146\n",
      "img id in: 13147\n",
      "img id out: 13147\n",
      "img id in: 13148\n",
      "img id out: 13148\n",
      "img id in: 13149\n",
      "img id out: 13149\n",
      "img id in: 13150\n",
      "img id out: 13150\n",
      "img id in: 13151\n",
      "img id out: 13151\n",
      "img id in: 13152\n",
      "img id out: 13152\n",
      "img id in: 13153\n",
      "img id out: 13153\n",
      "img id in: 13154\n",
      "img id out: 13154\n",
      "img id in: 13155\n",
      "img id out: 13155\n",
      "img id in: 13156\n",
      "img id out: 13156\n",
      "img id in: 13157\n",
      "img id out: 13157\n",
      "img id in: 13158\n",
      "img id out: 13158\n",
      "img id in: 13159\n",
      "img id out: 13159\n",
      "img id in: 13160\n",
      "img id out: 13160\n",
      "img id in: 13161\n",
      "img id out: 13161\n",
      "img id in: 13162\n",
      "img id out: 13162\n",
      "img id in: 13163\n",
      "img id out: 13163\n",
      "img id in: 13164\n",
      "img id out: 13164\n",
      "img id in: 13165\n",
      "img id out: 13165\n",
      "img id in: 13166\n",
      "img id out: 13166\n",
      "img id in: 13167\n",
      "img id out: 13167\n",
      "img id in: 13168\n",
      "img id out: 13168\n",
      "img id in: 13169\n",
      "img id out: 13169\n",
      "img id in: 13170\n",
      "img id out: 13170\n",
      "img id in: 13171\n",
      "img id out: 13171\n",
      "img id in: 13172\n",
      "img id out: 13172\n",
      "img id in: 13173\n",
      "img id out: 13173\n",
      "img id in: 13174\n",
      "img id out: 13174\n",
      "img id in: 13175\n",
      "img id out: 13175\n",
      "img id in: 13176\n",
      "img id out: 13176\n",
      "img id in: 13177\n",
      "img id out: 13177\n",
      "img id in: 13178\n",
      "img id out: 13178\n",
      "img id in: 13179\n",
      "img id out: 13179\n",
      "img id in: 13180\n",
      "img id out: 13180\n",
      "img id in: 13181\n",
      "img id out: 13181\n",
      "img id in: 13182\n",
      "img id out: 13182\n",
      "img id in: 13183\n",
      "img id out: 13183\n",
      "img id in: 13184\n",
      "img id out: 13184\n",
      "img id in: 13185\n",
      "img id out: 13185\n",
      "img id in: 13186\n",
      "img id out: 13186\n",
      "img id in: 13187\n",
      "img id out: 13187\n",
      "img id in: 13188\n",
      "img id out: 13188\n",
      "img id in: 13189\n",
      "img id out: 13189\n",
      "img id in: 13190\n",
      "img id out: 13190\n",
      "img id in: 13191\n",
      "img id out: 13191\n",
      "img id in: 13192\n",
      "img id out: 13192\n",
      "img id in: 13193\n",
      "img id out: 13193\n",
      "img id in: 13194\n",
      "img id out: 13194\n",
      "img id in: 13195\n",
      "img id out: 13195\n",
      "img id in: 13196\n",
      "img id out: 13196\n",
      "img id in: 13197\n",
      "img id out: 13197\n",
      "img id in: 13198\n",
      "img id out: 13198\n",
      "img id in: 13199\n",
      "img id out: 13199\n",
      "img id in: 13200\n",
      "img id out: 13200\n",
      "img id in: 13201\n",
      "img id out: 13201\n",
      "img id in: 13202\n",
      "img id out: 13202\n",
      "img id in: 13203\n",
      "img id out: 13203\n",
      "img id in: 13204\n",
      "img id out: 13204\n",
      "img id in: 13205\n",
      "img id out: 13205\n",
      "img id in: 13206\n",
      "img id out: 13206\n",
      "img id in: 13207\n",
      "img id out: 13207\n",
      "img id in: 13208\n",
      "img id out: 13208\n",
      "img id in: 13209\n",
      "img id out: 13209\n",
      "img id in: 13210\n",
      "img id out: 13210\n",
      "img id in: 13211\n",
      "img id out: 13211\n",
      "img id in: 13212\n",
      "img id out: 13212\n",
      "img id in: 13213\n",
      "img id out: 13213\n",
      "img id in: 13214\n",
      "img id out: 13214\n",
      "img id in: 13215\n",
      "img id out: 13215\n",
      "img id in: 13216\n",
      "img id out: 13216\n",
      "img id in: 13217\n",
      "img id out: 13217\n",
      "img id in: 13218\n",
      "img id out: 13218\n",
      "img id in: 13219\n",
      "img id out: 13219\n",
      "img id in: 13220\n",
      "img id out: 13220\n",
      "img id in: 13221\n",
      "img id out: 13221\n",
      "img id in: 13222\n",
      "img id out: 13222\n",
      "img id in: 13223\n",
      "img id out: 13223\n",
      "img id in: 13224\n",
      "img id out: 13224\n",
      "img id in: 13225\n",
      "img id out: 13225\n",
      "img id in: 13226\n",
      "img id out: 13226\n",
      "img id in: 13227\n",
      "img id out: 13227\n",
      "img id in: 13228\n",
      "img id out: 13228\n",
      "img id in: 13229\n",
      "img id out: 13229\n",
      "img id in: 13230\n",
      "img id out: 13230\n",
      "img id in: 13231\n",
      "img id out: 13231\n",
      "img id in: 13232\n",
      "img id out: 13232\n",
      "img id in: 13233\n",
      "img id out: 13233\n",
      "img id in: 13234\n",
      "img id out: 13234\n",
      "img id in: 13235\n",
      "img id out: 13235\n",
      "img id in: 13236\n",
      "img id out: 13236\n",
      "img id in: 13237\n",
      "img id out: 13237\n",
      "img id in: 13238\n",
      "img id out: 13238\n",
      "img id in: 13239\n",
      "img id out: 13239\n",
      "img id in: 13240\n",
      "img id out: 13240\n",
      "img id in: 13241\n",
      "img id out: 13241\n",
      "img id in: 13242\n",
      "img id out: 13242\n",
      "img id in: 13243\n",
      "img id out: 13243\n",
      "img id in: 13244\n",
      "img id out: 13244\n",
      "img id in: 13245\n",
      "img id out: 13245\n",
      "img id in: 13246\n",
      "img id out: 13246\n",
      "img id in: 13247\n",
      "img id out: 13247\n",
      "img id in: 13248\n",
      "img id out: 13248\n",
      "img id in: 13249\n",
      "img id out: 13249\n",
      "img id in: 13250\n",
      "img id out: 13250\n",
      "img id in: 13251\n",
      "img id out: 13251\n",
      "img id in: 13252\n",
      "img id out: 13252\n",
      "img id in: 13253\n",
      "img id out: 13253\n",
      "img id in: 13254\n",
      "img id out: 13254\n",
      "img id in: 13255\n",
      "img id out: 13255\n",
      "img id in: 13256\n",
      "img id out: 13256\n",
      "img id in: 13257\n",
      "img id out: 13257\n",
      "img id in: 13258\n",
      "img id out: 13258\n",
      "img id in: 13259\n",
      "img id out: 13259\n",
      "img id in: 13260\n",
      "img id out: 13260\n",
      "img id in: 13261\n",
      "img id out: 13261\n",
      "img id in: 13262\n",
      "img id out: 13262\n",
      "img id in: 13263\n",
      "img id out: 13263\n",
      "img id in: 13264\n",
      "img id out: 13264\n",
      "img id in: 13265\n",
      "img id out: 13265\n",
      "img id in: 13266\n",
      "img id out: 13266\n",
      "img id in: 13267\n",
      "img id out: 13267\n",
      "img id in: 13268\n",
      "img id out: 13268\n",
      "img id in: 13269\n",
      "img id out: 13269\n",
      "img id in: 13270\n",
      "img id out: 13270\n",
      "img id in: 13271\n",
      "img id out: 13271\n",
      "img id in: 13272\n",
      "img id out: 13272\n",
      "img id in: 13273\n",
      "img id out: 13273\n",
      "img id in: 13274\n",
      "img id out: 13274\n",
      "img id in: 13275\n",
      "img id out: 13275\n",
      "img id in: 13276\n",
      "img id out: 13276\n",
      "img id in: 13277\n",
      "img id out: 13277\n",
      "img id in: 13278\n",
      "img id out: 13278\n",
      "img id in: 13279\n",
      "img id out: 13279\n",
      "img id in: 13280\n",
      "img id out: 13280\n",
      "img id in: 13281\n",
      "img id out: 13281\n",
      "img id in: 13282\n",
      "img id out: 13282\n",
      "img id in: 13283\n",
      "img id out: 13283\n",
      "img id in: 13284\n",
      "img id out: 13284\n",
      "img id in: 13285\n",
      "img id out: 13285\n",
      "img id in: 13286\n",
      "img id out: 13286\n",
      "img id in: 13287\n",
      "img id out: 13287\n",
      "img id in: 13288\n",
      "img id out: 13288\n",
      "img id in: 13289\n",
      "img id out: 13289\n",
      "img id in: 13290\n",
      "img id out: 13290\n",
      "img id in: 13291\n",
      "img id out: 13291\n",
      "img id in: 13292\n",
      "img id out: 13292\n",
      "img id in: 13293\n",
      "img id out: 13293\n",
      "img id in: 13294\n",
      "img id out: 13294\n",
      "img id in: 13295\n",
      "img id out: 13295\n",
      "img id in: 13296\n",
      "img id out: 13296\n",
      "img id in: 13297\n",
      "img id out: 13297\n",
      "img id in: 13298\n",
      "img id out: 13298\n",
      "img id in: 13299\n",
      "img id out: 13299\n",
      "img id in: 13300\n",
      "img id out: 13300\n",
      "img id in: 13301\n",
      "img id out: 13301\n",
      "img id in: 13302\n",
      "img id out: 13302\n",
      "img id in: 13303\n",
      "img id out: 13303\n",
      "img id in: 13304\n",
      "img id out: 13304\n",
      "img id in: 13305\n",
      "img id out: 13305\n",
      "img id in: 13306\n",
      "img id out: 13306\n",
      "img id in: 13307\n",
      "img id out: 13307\n",
      "img id in: 13308\n",
      "img id out: 13308\n",
      "img id in: 13309\n",
      "img id out: 13309\n",
      "img id in: 13310\n",
      "img id out: 13310\n",
      "img id in: 13311\n",
      "img id out: 13311\n",
      "img id in: 13312\n",
      "img id out: 13312\n",
      "img id in: 13313\n",
      "img id out: 13313\n",
      "img id in: 13314\n",
      "img id out: 13314\n",
      "img id in: 13315\n",
      "img id out: 13315\n",
      "img id in: 13316\n",
      "img id out: 13316\n",
      "img id in: 13317\n",
      "img id out: 13317\n",
      "img id in: 13318\n",
      "img id out: 13318\n",
      "img id in: 13319\n",
      "img id out: 13319\n",
      "img id in: 13320\n",
      "img id out: 13320\n",
      "img id in: 13321\n",
      "img id out: 13321\n",
      "img id in: 13322\n",
      "img id out: 13322\n",
      "img id in: 13323\n",
      "img id out: 13323\n",
      "img id in: 13324\n",
      "img id out: 13324\n",
      "img id in: 13325\n",
      "img id out: 13325\n",
      "img id in: 13326\n",
      "img id out: 13326\n",
      "img id in: 13327\n",
      "img id out: 13327\n",
      "img id in: 13328\n",
      "img id out: 13328\n",
      "img id in: 13329\n",
      "img id out: 13329\n",
      "img id in: 13330\n",
      "img id out: 13330\n",
      "img id in: 13331\n",
      "img id out: 13331\n",
      "img id in: 13332\n",
      "img id out: 13332\n",
      "img id in: 13333\n",
      "img id out: 13333\n",
      "img id in: 13334\n",
      "img id out: 13334\n",
      "img id in: 13335\n",
      "img id out: 13335\n",
      "img id in: 13336\n",
      "img id out: 13336\n",
      "img id in: 13337\n",
      "img id out: 13337\n",
      "img id in: 13338\n",
      "img id out: 13338\n",
      "img id in: 13339\n",
      "img id out: 13339\n",
      "img id in: 13340\n",
      "img id out: 13340\n",
      "img id in: 13341\n",
      "img id out: 13341\n",
      "img id in: 13342\n",
      "img id out: 13342\n",
      "img id in: 13343\n",
      "img id out: 13343\n",
      "img id in: 13344\n",
      "img id out: 13344\n",
      "img id in: 13345\n",
      "img id out: 13345\n",
      "img id in: 13346\n",
      "img id out: 13346\n",
      "img id in: 13347\n",
      "img id out: 13347\n",
      "img id in: 13348\n",
      "img id out: 13348\n",
      "img id in: 13349\n",
      "img id out: 13349\n",
      "img id in: 13350\n",
      "img id out: 13350\n",
      "img id in: 13351\n",
      "img id out: 13351\n",
      "img id in: 13352\n",
      "img id out: 13352\n",
      "img id in: 13353\n",
      "img id out: 13353\n",
      "img id in: 13354\n",
      "img id out: 13354\n",
      "img id in: 13355\n",
      "img id out: 13355\n",
      "img id in: 13356\n",
      "img id out: 13356\n",
      "img id in: 13357\n",
      "img id out: 13357\n",
      "img id in: 13358\n",
      "img id out: 13358\n",
      "img id in: 13359\n",
      "img id out: 13359\n",
      "img id in: 13360\n",
      "img id out: 13360\n",
      "img id in: 13361\n",
      "img id out: 13361\n",
      "img id in: 13362\n",
      "img id out: 13362\n",
      "img id in: 13363\n",
      "img id out: 13363\n",
      "img id in: 13364\n",
      "img id out: 13364\n",
      "img id in: 13365\n",
      "img id out: 13365\n",
      "img id in: 13366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 13366\n",
      "img id in: 13367\n",
      "img id out: 13367\n",
      "img id in: 13368\n",
      "img id out: 13368\n",
      "img id in: 13369\n",
      "img id out: 13369\n",
      "img id in: 13370\n",
      "img id out: 13370\n",
      "img id in: 13371\n",
      "img id out: 13371\n",
      "img id in: 13372\n",
      "img id out: 13372\n",
      "img id in: 13373\n",
      "img id out: 13373\n",
      "img id in: 13374\n",
      "img id out: 13374\n",
      "img id in: 13375\n",
      "img id out: 13375\n",
      "img id in: 13376\n",
      "img id out: 13376\n",
      "img id in: 13377\n",
      "img id out: 13377\n",
      "img id in: 13378\n",
      "img id out: 13378\n",
      "img id in: 13379\n",
      "img id out: 13379\n",
      "img id in: 13380\n",
      "img id out: 13380\n",
      "img id in: 13381\n",
      "img id out: 13381\n",
      "img id in: 13382\n",
      "img id out: 13382\n",
      "img id in: 13383\n",
      "img id out: 13383\n",
      "img id in: 13384\n",
      "img id out: 13384\n",
      "img id in: 13385\n",
      "img id out: 13385\n",
      "img id in: 13386\n",
      "img id out: 13386\n",
      "img id in: 13387\n",
      "img id out: 13387\n",
      "img id in: 13388\n",
      "img id out: 13388\n",
      "img id in: 13389\n",
      "img id out: 13389\n",
      "img id in: 13390\n",
      "img id out: 13390\n",
      "img id in: 13391\n",
      "img id out: 13391\n",
      "img id in: 13392\n",
      "img id out: 13392\n",
      "img id in: 13393\n",
      "img id out: 13393\n",
      "img id in: 13394\n",
      "img id out: 13394\n",
      "img id in: 13395\n",
      "img id out: 13395\n",
      "img id in: 13396\n",
      "img id out: 13396\n",
      "img id in: 13397\n",
      "img id out: 13397\n",
      "img id in: 13398\n",
      "img id out: 13398\n",
      "img id in: 13399\n",
      "img id out: 13399\n",
      "img id in: 13400\n",
      "img id out: 13400\n",
      "img id in: 13401\n",
      "img id out: 13401\n",
      "img id in: 13402\n",
      "img id out: 13402\n",
      "img id in: 13403\n",
      "img id out: 13403\n",
      "img id in: 13404\n",
      "img id out: 13404\n",
      "img id in: 13405\n",
      "img id out: 13405\n",
      "img id in: 13406\n",
      "img id out: 13406\n",
      "img id in: 13407\n",
      "img id out: 13407\n",
      "img id in: 13408\n",
      "img id out: 13408\n",
      "img id in: 13409\n",
      "img id out: 13409\n",
      "img id in: 13410\n",
      "img id out: 13410\n",
      "img id in: 13411\n",
      "img id out: 13411\n",
      "img id in: 13412\n",
      "img id out: 13412\n",
      "img id in: 13413\n",
      "img id out: 13413\n",
      "img id in: 13414\n",
      "img id out: 13414\n",
      "img id in: 13415\n",
      "img id out: 13415\n",
      "img id in: 13416\n",
      "img id out: 13416\n",
      "img id in: 13417\n",
      "img id out: 13417\n",
      "img id in: 13418\n",
      "img id out: 13418\n",
      "img id in: 13419\n",
      "img id out: 13419\n",
      "img id in: 13420\n",
      "img id out: 13420\n",
      "img id in: 13421\n",
      "img id out: 13421\n",
      "img id in: 13422\n",
      "img id out: 13422\n",
      "img id in: 13423\n",
      "img id out: 13423\n",
      "img id in: 13424\n",
      "img id out: 13424\n",
      "img id in: 13425\n",
      "img id out: 13425\n",
      "img id in: 13426\n",
      "img id out: 13426\n",
      "img id in: 13427\n",
      "img id out: 13427\n",
      "img id in: 13428\n",
      "img id out: 13428\n",
      "img id in: 13429\n",
      "img id out: 13429\n",
      "img id in: 13430\n",
      "img id out: 13430\n",
      "img id in: 13431\n",
      "img id out: 13431\n",
      "img id in: 13432\n",
      "img id out: 13432\n",
      "img id in: 13433\n",
      "img id out: 13433\n",
      "img id in: 13434\n",
      "img id out: 13434\n",
      "img id in: 13435\n",
      "img id out: 13435\n",
      "img id in: 13436\n",
      "img id out: 13436\n",
      "img id in: 13437\n",
      "img id out: 13437\n",
      "img id in: 13438\n",
      "img id out: 13438\n",
      "img id in: 13439\n",
      "img id out: 13439\n",
      "img id in: 13440\n",
      "img id out: 13440\n",
      "img id in: 13441\n",
      "img id out: 13441\n",
      "img id in: 13442\n",
      "img id out: 13442\n",
      "img id in: 13443\n",
      "img id out: 13443\n",
      "img id in: 13444\n",
      "img id out: 13444\n",
      "img id in: 13445\n",
      "img id out: 13445\n",
      "img id in: 13446\n",
      "img id out: 13446\n",
      "img id in: 13447\n",
      "img id out: 13447\n",
      "img id in: 13448\n",
      "img id out: 13448\n",
      "img id in: 13449\n",
      "img id out: 13449\n",
      "img id in: 13450\n",
      "img id out: 13450\n",
      "img id in: 13451\n",
      "img id out: 13451\n",
      "img id in: 13452\n",
      "img id out: 13452\n",
      "img id in: 13453\n",
      "img id out: 13453\n",
      "img id in: 13454\n",
      "img id out: 13454\n",
      "img id in: 13455\n",
      "img id out: 13455\n",
      "img id in: 13456\n",
      "img id out: 13456\n",
      "img id in: 13457\n",
      "img id out: 13457\n",
      "img id in: 13458\n",
      "img id out: 13458\n",
      "img id in: 13459\n",
      "img id out: 13459\n",
      "img id in: 13460\n",
      "img id out: 13460\n",
      "img id in: 13461\n",
      "img id out: 13461\n",
      "img id in: 13462\n",
      "img id out: 13462\n",
      "img id in: 13463\n",
      "img id out: 13463\n",
      "img id in: 13464\n",
      "img id out: 13464\n",
      "img id in: 13465\n",
      "img id out: 13465\n",
      "img id in: 13466\n",
      "img id out: 13466\n",
      "img id in: 13467\n",
      "img id out: 13467\n",
      "img id in: 13468\n",
      "img id out: 13468\n",
      "img id in: 13469\n",
      "img id out: 13469\n",
      "img id in: 13470\n",
      "img id out: 13470\n",
      "img id in: 13471\n",
      "img id out: 13471\n",
      "img id in: 13472\n",
      "img id out: 13472\n",
      "img id in: 13473\n",
      "img id out: 13473\n",
      "img id in: 13474\n",
      "img id out: 13474\n",
      "img id in: 13475\n",
      "img id out: 13475\n",
      "img id in: 13476\n",
      "img id out: 13476\n",
      "img id in: 13477\n",
      "img id out: 13477\n",
      "img id in: 13478\n",
      "img id out: 13478\n",
      "img id in: 13479\n",
      "img id out: 13479\n",
      "img id in: 13480\n",
      "img id out: 13480\n",
      "img id in: 13481\n",
      "img id out: 13481\n",
      "img id in: 13482\n",
      "img id out: 13482\n",
      "img id in: 13483\n",
      "img id out: 13483\n",
      "img id in: 13484\n",
      "img id out: 13484\n",
      "img id in: 13485\n",
      "img id out: 13485\n",
      "img id in: 13486\n",
      "img id out: 13486\n",
      "img id in: 13487\n",
      "img id out: 13487\n",
      "img id in: 13488\n",
      "img id out: 13488\n",
      "img id in: 13489\n",
      "img id out: 13489\n",
      "img id in: 13490\n",
      "img id out: 13490\n",
      "img id in: 13491\n",
      "img id out: 13491\n",
      "img id in: 13492\n",
      "img id out: 13492\n",
      "img id in: 13493\n",
      "img id out: 13493\n",
      "img id in: 13494\n",
      "img id out: 13494\n",
      "img id in: 13495\n",
      "img id out: 13495\n",
      "img id in: 13496\n",
      "img id out: 13496\n",
      "img id in: 13497\n",
      "img id out: 13497\n",
      "img id in: 13498\n",
      "img id out: 13498\n",
      "img id in: 13499\n",
      "img id out: 13499\n",
      "img id in: 13500\n",
      "img id out: 13500\n",
      "img id in: 13501\n",
      "img id out: 13501\n",
      "img id in: 13502\n",
      "img id out: 13502\n",
      "img id in: 13503\n",
      "img id out: 13503\n",
      "img id in: 13504\n",
      "img id out: 13504\n",
      "img id in: 13505\n",
      "img id out: 13505\n",
      "img id in: 13506\n",
      "img id out: 13506\n",
      "img id in: 13507\n",
      "img id out: 13507\n",
      "img id in: 13508\n",
      "img id out: 13508\n",
      "img id in: 13509\n",
      "img id out: 13509\n",
      "img id in: 13510\n",
      "img id out: 13510\n",
      "img id in: 13511\n",
      "img id out: 13511\n",
      "img id in: 13512\n",
      "img id out: 13512\n",
      "img id in: 13513\n",
      "img id out: 13513\n",
      "img id in: 13514\n",
      "img id out: 13514\n",
      "img id in: 13515\n",
      "img id out: 13515\n",
      "img id in: 13516\n",
      "img id out: 13516\n",
      "img id in: 13517\n",
      "img id out: 13517\n",
      "img id in: 13518\n",
      "img id out: 13518\n",
      "img id in: 13519\n",
      "img id out: 13519\n",
      "img id in: 13520\n",
      "img id out: 13520\n",
      "img id in: 13521\n",
      "img id out: 13521\n",
      "img id in: 13522\n",
      "img id out: 13522\n",
      "img id in: 13523\n",
      "img id out: 13523\n",
      "img id in: 13524\n",
      "img id out: 13524\n",
      "img id in: 13525\n",
      "img id out: 13525\n",
      "img id in: 13526\n",
      "img id out: 13526\n",
      "img id in: 13527\n",
      "img id out: 13527\n",
      "img id in: 13528\n",
      "img id out: 13528\n",
      "img id in: 13529\n",
      "img id out: 13529\n",
      "img id in: 13530\n",
      "img id out: 13530\n",
      "img id in: 13531\n",
      "img id out: 13531\n",
      "img id in: 13532\n",
      "img id out: 13532\n",
      "img id in: 13533\n",
      "img id out: 13533\n",
      "img id in: 13534\n",
      "img id out: 13534\n",
      "img id in: 13535\n",
      "img id out: 13535\n",
      "img id in: 13536\n",
      "img id out: 13536\n",
      "img id in: 13537\n",
      "img id out: 13537\n",
      "img id in: 13538\n",
      "img id out: 13538\n",
      "img id in: 13539\n",
      "img id out: 13539\n",
      "img id in: 13540\n",
      "img id out: 13540\n",
      "img id in: 13541\n",
      "img id out: 13541\n",
      "img id in: 13542\n",
      "img id out: 13542\n",
      "img id in: 13543\n",
      "img id out: 13543\n",
      "img id in: 13544\n",
      "img id out: 13544\n",
      "img id in: 13545\n",
      "img id out: 13545\n",
      "img id in: 13546\n",
      "img id out: 13546\n",
      "img id in: 13547\n",
      "img id out: 13547\n",
      "img id in: 13548\n",
      "img id out: 13548\n",
      "img id in: 13549\n",
      "img id out: 13549\n",
      "img id in: 13550\n",
      "img id out: 13550\n",
      "img id in: 13551\n",
      "img id out: 13551\n",
      "img id in: 13552\n",
      "img id out: 13552\n",
      "img id in: 13553\n",
      "img id out: 13553\n",
      "img id in: 13554\n",
      "img id out: 13554\n",
      "img id in: 13555\n",
      "img id out: 13555\n",
      "img id in: 13556\n",
      "img id out: 13556\n",
      "img id in: 13557\n",
      "img id out: 13557\n",
      "img id in: 13558\n",
      "img id out: 13558\n",
      "img id in: 13559\n",
      "img id out: 13559\n",
      "img id in: 13560\n",
      "img id out: 13560\n",
      "img id in: 13561\n",
      "img id out: 13561\n",
      "img id in: 13562\n",
      "img id out: 13562\n",
      "img id in: 13563\n",
      "img id out: 13563\n",
      "img id in: 13564\n",
      "img id out: 13564\n",
      "img id in: 13565\n",
      "img id out: 13565\n",
      "img id in: 13566\n",
      "img id out: 13566\n",
      "img id in: 13567\n",
      "img id out: 13567\n",
      "img id in: 13568\n",
      "img id out: 13568\n",
      "img id in: 13569\n",
      "img id out: 13569\n",
      "img id in: 13570\n",
      "img id out: 13570\n",
      "img id in: 13571\n",
      "img id out: 13571\n",
      "img id in: 13572\n",
      "img id out: 13572\n",
      "img id in: 13573\n",
      "img id out: 13573\n",
      "img id in: 13574\n",
      "img id out: 13574\n",
      "img id in: 13575\n",
      "img id out: 13575\n",
      "img id in: 13576\n",
      "img id out: 13576\n",
      "img id in: 13577\n",
      "img id out: 13577\n",
      "img id in: 13578\n",
      "img id out: 13578\n",
      "img id in: 13579\n",
      "img id out: 13579\n",
      "img id in: 13580\n",
      "img id out: 13580\n",
      "img id in: 13581\n",
      "img id out: 13581\n",
      "img id in: 13582\n",
      "img id out: 13582\n",
      "img id in: 13583\n",
      "img id out: 13583\n",
      "img id in: 13584\n",
      "img id out: 13584\n",
      "img id in: 13585\n",
      "img id out: 13585\n",
      "img id in: 13586\n",
      "img id out: 13586\n",
      "img id in: 13587\n",
      "img id out: 13587\n",
      "img id in: 13588\n",
      "img id out: 13588\n",
      "img id in: 13589\n",
      "img id out: 13589\n",
      "img id in: 13590\n",
      "img id out: 13590\n",
      "img id in: 13591\n",
      "img id out: 13591\n",
      "img id in: 13592\n",
      "img id out: 13592\n",
      "img id in: 13593\n",
      "img id out: 13593\n",
      "img id in: 13594\n",
      "img id out: 13594\n",
      "img id in: 13595\n",
      "img id out: 13595\n",
      "img id in: 13596\n",
      "img id out: 13596\n",
      "img id in: 13597\n",
      "img id out: 13597\n",
      "img id in: 13598\n",
      "img id out: 13598\n",
      "img id in: 13599\n",
      "img id out: 13599\n",
      "img id in: 13600\n",
      "img id out: 13600\n",
      "img id in: 13601\n",
      "img id out: 13601\n",
      "img id in: 13602\n",
      "img id out: 13602\n",
      "img id in: 13603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 13603\n",
      "img id in: 13604\n",
      "img id out: 13604\n",
      "img id in: 13605\n",
      "img id out: 13605\n",
      "img id in: 13606\n",
      "img id out: 13606\n",
      "img id in: 13607\n",
      "img id out: 13607\n",
      "img id in: 13608\n",
      "img id out: 13608\n",
      "img id in: 13609\n",
      "img id out: 13609\n",
      "img id in: 13610\n",
      "img id out: 13610\n",
      "img id in: 13611\n",
      "img id out: 13611\n",
      "img id in: 13612\n",
      "img id out: 13612\n",
      "img id in: 13613\n",
      "img id out: 13613\n",
      "img id in: 13614\n",
      "img id out: 13614\n",
      "img id in: 13615\n",
      "img id out: 13615\n",
      "img id in: 13616\n",
      "img id out: 13616\n",
      "img id in: 13617\n",
      "img id out: 13617\n",
      "img id in: 13618\n",
      "img id out: 13618\n",
      "img id in: 13619\n",
      "img id out: 13619\n",
      "img id in: 13620\n",
      "img id out: 13620\n",
      "img id in: 13621\n",
      "img id out: 13621\n",
      "img id in: 13622\n",
      "img id out: 13622\n",
      "img id in: 13623\n",
      "img id out: 13623\n",
      "img id in: 13624\n",
      "img id out: 13624\n",
      "img id in: 13625\n",
      "img id out: 13625\n",
      "img id in: 13626\n",
      "img id out: 13626\n",
      "img id in: 13627\n",
      "img id out: 13627\n",
      "img id in: 13628\n",
      "img id out: 13628\n",
      "img id in: 13629\n",
      "img id out: 13629\n",
      "img id in: 13630\n",
      "img id out: 13630\n",
      "img id in: 13631\n",
      "img id out: 13631\n",
      "img id in: 13632\n",
      "img id out: 13632\n",
      "img id in: 13633\n",
      "img id out: 13633\n",
      "img id in: 13634\n",
      "img id out: 13634\n",
      "img id in: 13635\n",
      "img id out: 13635\n",
      "img id in: 13636\n",
      "img id out: 13636\n",
      "img id in: 13637\n",
      "img id out: 13637\n",
      "img id in: 13638\n",
      "img id out: 13638\n",
      "img id in: 13639\n",
      "img id out: 13639\n",
      "img id in: 13640\n",
      "img id out: 13640\n",
      "img id in: 13641\n",
      "img id out: 13641\n",
      "img id in: 13642\n",
      "img id out: 13642\n",
      "img id in: 13643\n",
      "img id out: 13643\n",
      "img id in: 13644\n",
      "img id out: 13644\n",
      "img id in: 13645\n",
      "img id out: 13645\n",
      "img id in: 13646\n",
      "img id out: 13646\n",
      "img id in: 13647\n",
      "img id out: 13647\n",
      "img id in: 13648\n",
      "img id out: 13648\n",
      "img id in: 13649\n",
      "img id out: 13649\n",
      "img id in: 13650\n",
      "img id out: 13650\n",
      "img id in: 13651\n",
      "img id out: 13651\n",
      "img id in: 13652\n",
      "img id out: 13652\n",
      "img id in: 13653\n",
      "img id out: 13653\n",
      "img id in: 13654\n",
      "img id out: 13654\n",
      "img id in: 13655\n",
      "img id out: 13655\n",
      "img id in: 13656\n",
      "img id out: 13656\n",
      "img id in: 13657\n",
      "img id out: 13657\n",
      "img id in: 13658\n",
      "img id out: 13658\n",
      "img id in: 13659\n",
      "img id out: 13659\n",
      "img id in: 13660\n",
      "img id out: 13660\n",
      "img id in: 13661\n",
      "img id out: 13661\n",
      "img id in: 13662\n",
      "img id out: 13662\n",
      "img id in: 13663\n",
      "img id out: 13663\n",
      "img id in: 13664\n",
      "img id out: 13664\n",
      "img id in: 13665\n",
      "img id out: 13665\n",
      "img id in: 13666\n",
      "img id out: 13666\n",
      "img id in: 13667\n",
      "img id out: 13667\n",
      "img id in: 13668\n",
      "img id out: 13668\n",
      "img id in: 13669\n",
      "img id out: 13669\n",
      "img id in: 13670\n",
      "img id out: 13670\n",
      "img id in: 13671\n",
      "img id out: 13671\n",
      "img id in: 13672\n",
      "img id out: 13672\n",
      "img id in: 13673\n",
      "img id out: 13673\n",
      "img id in: 13674\n",
      "img id out: 13674\n",
      "img id in: 13675\n",
      "img id out: 13675\n",
      "img id in: 13676\n",
      "img id out: 13676\n",
      "img id in: 13677\n",
      "img id out: 13677\n",
      "img id in: 13678\n",
      "img id out: 13678\n",
      "img id in: 13679\n",
      "img id out: 13679\n",
      "img id in: 13680\n",
      "img id out: 13680\n",
      "img id in: 13681\n",
      "img id out: 13681\n",
      "img id in: 13682\n",
      "img id out: 13682\n",
      "img id in: 13683\n",
      "img id out: 13683\n",
      "img id in: 13684\n",
      "img id out: 13684\n",
      "img id in: 13685\n",
      "img id out: 13685\n",
      "img id in: 13686\n",
      "img id out: 13686\n",
      "img id in: 13687\n",
      "img id out: 13687\n",
      "img id in: 13688\n",
      "img id out: 13688\n",
      "img id in: 13689\n",
      "img id out: 13689\n",
      "img id in: 13690\n",
      "img id out: 13690\n",
      "img id in: 13691\n",
      "img id out: 13691\n",
      "img id in: 13692\n",
      "img id out: 13692\n",
      "img id in: 13693\n",
      "img id out: 13693\n",
      "img id in: 13694\n",
      "img id out: 13694\n",
      "img id in: 13695\n",
      "img id out: 13695\n",
      "img id in: 13696\n",
      "img id out: 13696\n",
      "img id in: 13697\n",
      "img id out: 13697\n",
      "img id in: 13698\n",
      "img id out: 13698\n",
      "img id in: 13699\n",
      "img id out: 13699\n",
      "img id in: 13700\n",
      "img id out: 13700\n",
      "img id in: 13701\n",
      "img id out: 13701\n",
      "img id in: 13702\n",
      "img id out: 13702\n",
      "img id in: 13703\n",
      "img id out: 13703\n",
      "img id in: 13704\n",
      "img id out: 13704\n",
      "img id in: 13705\n",
      "img id out: 13705\n",
      "img id in: 13706\n",
      "img id out: 13706\n",
      "img id in: 13707\n",
      "img id out: 13707\n",
      "img id in: 13708\n",
      "img id out: 13708\n",
      "img id in: 13709\n",
      "img id out: 13709\n",
      "img id in: 13710\n",
      "img id out: 13710\n",
      "img id in: 13711\n",
      "img id out: 13711\n",
      "img id in: 13712\n",
      "img id out: 13712\n",
      "img id in: 13713\n",
      "img id out: 13713\n",
      "img id in: 13714\n",
      "img id out: 13714\n",
      "img id in: 13715\n",
      "img id out: 13715\n",
      "img id in: 13716\n",
      "img id out: 13716\n",
      "img id in: 13717\n",
      "img id out: 13717\n",
      "img id in: 13718\n",
      "img id out: 13718\n",
      "img id in: 13719\n",
      "img id out: 13719\n",
      "img id in: 13720\n",
      "img id out: 13720\n",
      "img id in: 13721\n",
      "img id out: 13721\n",
      "img id in: 13722\n",
      "img id out: 13722\n",
      "img id in: 13723\n",
      "img id out: 13723\n",
      "img id in: 13724\n",
      "img id out: 13724\n",
      "img id in: 13725\n",
      "img id out: 13725\n",
      "img id in: 13726\n",
      "img id out: 13726\n",
      "img id in: 13727\n",
      "img id out: 13727\n",
      "img id in: 13728\n",
      "img id out: 13728\n",
      "img id in: 13729\n",
      "img id out: 13729\n",
      "img id in: 13730\n",
      "img id out: 13730\n",
      "img id in: 13731\n",
      "img id out: 13731\n",
      "img id in: 13732\n",
      "img id out: 13732\n",
      "img id in: 13733\n",
      "img id out: 13733\n",
      "img id in: 13734\n",
      "img id out: 13734\n",
      "img id in: 13735\n",
      "img id out: 13735\n",
      "img id in: 13736\n",
      "img id out: 13736\n",
      "img id in: 13737\n",
      "img id out: 13737\n",
      "img id in: 13738\n",
      "img id out: 13738\n",
      "img id in: 13739\n",
      "img id out: 13739\n",
      "img id in: 13740\n",
      "img id out: 13740\n",
      "img id in: 13741\n",
      "img id out: 13741\n",
      "img id in: 13742\n",
      "img id out: 13742\n",
      "img id in: 13743\n",
      "img id out: 13743\n",
      "img id in: 13744\n",
      "img id out: 13744\n",
      "img id in: 13745\n",
      "img id out: 13745\n",
      "img id in: 13746\n",
      "img id out: 13746\n",
      "img id in: 13747\n",
      "img id out: 13747\n",
      "img id in: 13748\n",
      "img id out: 13748\n",
      "img id in: 13749\n",
      "img id out: 13749\n",
      "img id in: 13750\n",
      "img id out: 13750\n",
      "img id in: 13751\n",
      "img id out: 13751\n",
      "img id in: 13752\n",
      "img id out: 13752\n",
      "img id in: 13753\n",
      "img id out: 13753\n",
      "img id in: 13754\n",
      "img id out: 13754\n",
      "img id in: 13755\n",
      "img id out: 13755\n",
      "img id in: 13756\n",
      "img id out: 13756\n",
      "img id in: 13757\n",
      "img id out: 13757\n",
      "img id in: 13758\n",
      "img id out: 13758\n",
      "img id in: 13759\n",
      "img id out: 13759\n",
      "img id in: 13760\n",
      "img id out: 13760\n",
      "img id in: 13761\n",
      "img id out: 13761\n",
      "img id in: 13762\n",
      "img id out: 13762\n",
      "img id in: 13763\n",
      "img id out: 13763\n",
      "img id in: 13764\n",
      "img id out: 13764\n",
      "img id in: 13765\n",
      "img id out: 13765\n",
      "img id in: 13766\n",
      "img id out: 13766\n",
      "img id in: 13767\n",
      "img id out: 13767\n",
      "img id in: 13768\n",
      "img id out: 13768\n",
      "img id in: 13769\n",
      "img id out: 13769\n",
      "img id in: 13770\n",
      "img id out: 13770\n",
      "img id in: 13771\n",
      "img id out: 13771\n",
      "img id in: 13772\n",
      "img id out: 13772\n",
      "img id in: 13773\n",
      "img id out: 13773\n",
      "img id in: 13774\n",
      "img id out: 13774\n",
      "img id in: 13775\n",
      "img id out: 13775\n",
      "img id in: 13776\n",
      "img id out: 13776\n",
      "img id in: 13777\n",
      "img id out: 13777\n",
      "img id in: 13778\n",
      "img id out: 13778\n",
      "img id in: 13779\n",
      "img id out: 13779\n",
      "img id in: 13780\n",
      "img id out: 13780\n",
      "img id in: 13781\n",
      "img id out: 13781\n",
      "img id in: 13782\n",
      "img id out: 13782\n",
      "img id in: 13783\n",
      "img id out: 13783\n",
      "img id in: 13784\n",
      "img id out: 13784\n",
      "img id in: 13785\n",
      "img id out: 13785\n",
      "img id in: 13786\n",
      "img id out: 13786\n",
      "img id in: 13787\n",
      "img id out: 13787\n",
      "img id in: 13788\n",
      "img id out: 13788\n",
      "img id in: 13789\n",
      "img id out: 13789\n",
      "img id in: 13790\n",
      "img id out: 13790\n",
      "img id in: 13791\n",
      "img id out: 13791\n",
      "img id in: 13792\n",
      "img id out: 13792\n",
      "img id in: 13793\n",
      "img id out: 13793\n",
      "img id in: 13794\n",
      "img id out: 13794\n",
      "img id in: 13795\n",
      "img id out: 13795\n",
      "img id in: 13796\n",
      "img id out: 13796\n",
      "img id in: 13797\n",
      "img id out: 13797\n",
      "img id in: 13798\n",
      "img id out: 13798\n",
      "img id in: 13799\n",
      "img id out: 13799\n",
      "img id in: 13800\n",
      "img id out: 13800\n",
      "img id in: 13801\n",
      "img id out: 13801\n",
      "img id in: 13802\n",
      "img id out: 13802\n",
      "img id in: 13803\n",
      "img id out: 13803\n",
      "img id in: 13804\n",
      "img id out: 13804\n",
      "img id in: 13805\n",
      "img id out: 13805\n",
      "img id in: 13806\n",
      "img id out: 13806\n",
      "img id in: 13807\n",
      "img id out: 13807\n",
      "img id in: 13808\n",
      "img id out: 13808\n",
      "img id in: 13809\n",
      "img id out: 13809\n",
      "img id in: 13810\n",
      "img id out: 13810\n",
      "img id in: 13811\n",
      "img id out: 13811\n",
      "img id in: 13812\n",
      "img id out: 13812\n",
      "img id in: 13813\n",
      "img id out: 13813\n",
      "img id in: 13814\n",
      "img id out: 13814\n",
      "img id in: 13815\n",
      "img id out: 13815\n",
      "img id in: 13816\n",
      "img id out: 13816\n",
      "img id in: 13817\n",
      "img id out: 13817\n",
      "img id in: 13818\n",
      "img id out: 13818\n",
      "img id in: 13819\n",
      "img id out: 13819\n",
      "img id in: 13820\n",
      "img id out: 13820\n",
      "img id in: 13821\n",
      "img id out: 13821\n",
      "img id in: 13822\n",
      "img id out: 13822\n",
      "img id in: 13823\n",
      "img id out: 13823\n",
      "img id in: 13824\n",
      "img id out: 13824\n",
      "img id in: 13825\n",
      "img id out: 13825\n",
      "img id in: 13826\n",
      "img id out: 13826\n",
      "img id in: 13827\n",
      "img id out: 13827\n",
      "img id in: 13828\n",
      "img id out: 13828\n",
      "img id in: 13829\n",
      "img id out: 13829\n",
      "img id in: 13830\n",
      "img id out: 13830\n",
      "img id in: 13831\n",
      "img id out: 13831\n",
      "img id in: 13832\n",
      "img id out: 13832\n",
      "img id in: 13833\n",
      "img id out: 13833\n",
      "img id in: 13834\n",
      "img id out: 13834\n",
      "img id in: 13835\n",
      "img id out: 13835\n",
      "img id in: 13836\n",
      "img id out: 13836\n",
      "img id in: 13837\n",
      "img id out: 13837\n",
      "img id in: 13838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 13838\n",
      "img id in: 13839\n",
      "img id out: 13839\n",
      "img id in: 13840\n",
      "img id out: 13840\n",
      "img id in: 13841\n",
      "img id out: 13841\n",
      "img id in: 13842\n",
      "img id out: 13842\n",
      "img id in: 13843\n",
      "img id out: 13843\n",
      "img id in: 13844\n",
      "img id out: 13844\n",
      "img id in: 13845\n",
      "img id out: 13845\n",
      "img id in: 13846\n",
      "img id out: 13846\n",
      "img id in: 13847\n",
      "img id out: 13847\n",
      "img id in: 13848\n",
      "img id out: 13848\n",
      "img id in: 13849\n",
      "img id out: 13849\n",
      "img id in: 13850\n",
      "img id out: 13850\n",
      "img id in: 13851\n",
      "img id out: 13851\n",
      "img id in: 13852\n",
      "img id out: 13852\n",
      "img id in: 13853\n",
      "img id out: 13853\n",
      "img id in: 13854\n",
      "img id out: 13854\n",
      "img id in: 13855\n",
      "img id out: 13855\n",
      "img id in: 13856\n",
      "img id out: 13856\n",
      "img id in: 13857\n",
      "img id out: 13857\n",
      "img id in: 13858\n",
      "img id out: 13858\n",
      "img id in: 13859\n",
      "img id out: 13859\n",
      "img id in: 13860\n",
      "img id out: 13860\n",
      "img id in: 13861\n",
      "img id out: 13861\n",
      "img id in: 13862\n",
      "img id out: 13862\n",
      "img id in: 13863\n",
      "img id out: 13863\n",
      "img id in: 13864\n",
      "img id out: 13864\n",
      "img id in: 13865\n",
      "img id out: 13865\n",
      "img id in: 13866\n",
      "img id out: 13866\n",
      "img id in: 13867\n",
      "img id out: 13867\n",
      "img id in: 13868\n",
      "img id out: 13868\n",
      "img id in: 13869\n",
      "img id out: 13869\n",
      "img id in: 13870\n",
      "img id out: 13870\n",
      "img id in: 13871\n",
      "img id out: 13871\n",
      "img id in: 13872\n",
      "img id out: 13872\n",
      "img id in: 13873\n",
      "img id out: 13873\n",
      "img id in: 13874\n",
      "img id out: 13874\n",
      "img id in: 13875\n",
      "img id out: 13875\n",
      "img id in: 13876\n",
      "img id out: 13876\n",
      "img id in: 13877\n",
      "img id out: 13877\n",
      "img id in: 13878\n",
      "img id out: 13878\n",
      "img id in: 13879\n",
      "img id out: 13879\n",
      "img id in: 13880\n",
      "img id out: 13880\n",
      "img id in: 13881\n",
      "img id out: 13881\n",
      "img id in: 13882\n",
      "img id out: 13882\n",
      "img id in: 13883\n",
      "img id out: 13883\n",
      "img id in: 13884\n",
      "img id out: 13884\n",
      "img id in: 13885\n",
      "img id out: 13885\n",
      "img id in: 13886\n",
      "img id out: 13886\n",
      "img id in: 13887\n",
      "img id out: 13887\n",
      "img id in: 13888\n",
      "img id out: 13888\n",
      "img id in: 13889\n",
      "img id out: 13889\n",
      "img id in: 13890\n",
      "img id out: 13890\n",
      "img id in: 13891\n",
      "img id out: 13891\n",
      "img id in: 13892\n",
      "img id out: 13892\n",
      "img id in: 13893\n",
      "img id out: 13893\n",
      "img id in: 13894\n",
      "img id out: 13894\n",
      "img id in: 13895\n",
      "img id out: 13895\n",
      "img id in: 13896\n",
      "img id out: 13896\n",
      "img id in: 13897\n",
      "img id out: 13897\n",
      "img id in: 13898\n",
      "img id out: 13898\n",
      "img id in: 13899\n",
      "img id out: 13899\n",
      "img id in: 13900\n",
      "img id out: 13900\n",
      "img id in: 13901\n",
      "img id out: 13901\n",
      "img id in: 13902\n",
      "img id out: 13902\n",
      "img id in: 13903\n",
      "img id out: 13903\n",
      "img id in: 13904\n",
      "img id out: 13904\n",
      "img id in: 13905\n",
      "img id out: 13905\n",
      "img id in: 13906\n",
      "img id out: 13906\n",
      "img id in: 13907\n",
      "img id out: 13907\n",
      "img id in: 13908\n",
      "img id out: 13908\n",
      "img id in: 13909\n",
      "img id out: 13909\n",
      "img id in: 13910\n",
      "img id out: 13910\n",
      "img id in: 13911\n",
      "img id out: 13911\n",
      "img id in: 13912\n",
      "img id out: 13912\n",
      "img id in: 13913\n",
      "img id out: 13913\n",
      "img id in: 13914\n",
      "img id out: 13914\n",
      "img id in: 13915\n",
      "img id out: 13915\n",
      "img id in: 13916\n",
      "img id out: 13916\n",
      "img id in: 13917\n",
      "img id out: 13917\n",
      "img id in: 13918\n",
      "img id out: 13918\n",
      "img id in: 13919\n",
      "img id out: 13919\n",
      "img id in: 13920\n",
      "img id out: 13920\n",
      "img id in: 13921\n",
      "img id out: 13921\n",
      "img id in: 13922\n",
      "img id out: 13922\n",
      "img id in: 13923\n",
      "img id out: 13923\n",
      "img id in: 13924\n",
      "img id out: 13924\n",
      "img id in: 13925\n",
      "img id out: 13925\n",
      "img id in: 13926\n",
      "img id out: 13926\n",
      "img id in: 13927\n",
      "img id out: 13927\n",
      "img id in: 13928\n",
      "img id out: 13928\n",
      "img id in: 13929\n",
      "img id out: 13929\n",
      "img id in: 13930\n",
      "img id out: 13930\n",
      "img id in: 13931\n",
      "img id out: 13931\n",
      "img id in: 13932\n",
      "img id out: 13932\n",
      "img id in: 13933\n",
      "img id out: 13933\n",
      "img id in: 13934\n",
      "img id out: 13934\n",
      "img id in: 13935\n",
      "img id out: 13935\n",
      "img id in: 13936\n",
      "img id out: 13936\n",
      "img id in: 13937\n",
      "img id out: 13937\n",
      "img id in: 13938\n",
      "img id out: 13938\n",
      "img id in: 13939\n",
      "img id out: 13939\n",
      "img id in: 13940\n",
      "img id out: 13940\n",
      "img id in: 13941\n",
      "img id out: 13941\n",
      "img id in: 13942\n",
      "img id out: 13942\n",
      "img id in: 13943\n",
      "img id out: 13943\n",
      "img id in: 13944\n",
      "img id out: 13944\n",
      "img id in: 13945\n",
      "img id out: 13945\n",
      "img id in: 13946\n",
      "img id out: 13946\n",
      "img id in: 13947\n",
      "img id out: 13947\n",
      "img id in: 13948\n",
      "img id out: 13948\n",
      "img id in: 13949\n",
      "img id out: 13949\n",
      "img id in: 13950\n",
      "img id out: 13950\n",
      "img id in: 13951\n",
      "img id out: 13951\n",
      "img id in: 13952\n",
      "img id out: 13952\n",
      "img id in: 13953\n",
      "img id out: 13953\n",
      "img id in: 13954\n",
      "img id out: 13954\n",
      "img id in: 13955\n",
      "img id out: 13955\n",
      "img id in: 13956\n",
      "img id out: 13956\n",
      "img id in: 13957\n",
      "img id out: 13957\n",
      "img id in: 13958\n",
      "img id out: 13958\n",
      "img id in: 13959\n",
      "img id out: 13959\n",
      "img id in: 13960\n",
      "img id out: 13960\n",
      "img id in: 13961\n",
      "img id out: 13961\n",
      "img id in: 13962\n",
      "img id out: 13962\n",
      "img id in: 13963\n",
      "img id out: 13963\n",
      "img id in: 13964\n",
      "img id out: 13964\n",
      "img id in: 13965\n",
      "img id out: 13965\n",
      "img id in: 13966\n",
      "img id out: 13966\n",
      "img id in: 13967\n",
      "img id out: 13967\n",
      "img id in: 13968\n",
      "img id out: 13968\n",
      "img id in: 13969\n",
      "img id out: 13969\n",
      "img id in: 13970\n",
      "img id out: 13970\n",
      "img id in: 13971\n",
      "img id out: 13971\n",
      "img id in: 13972\n",
      "img id out: 13972\n",
      "img id in: 13973\n",
      "img id out: 13973\n",
      "img id in: 13974\n",
      "img id out: 13974\n",
      "img id in: 13975\n",
      "img id out: 13975\n",
      "img id in: 13976\n",
      "img id out: 13976\n",
      "img id in: 13977\n",
      "img id out: 13977\n",
      "img id in: 13978\n",
      "img id out: 13978\n",
      "img id in: 13979\n",
      "img id out: 13979\n",
      "img id in: 13980\n",
      "img id out: 13980\n",
      "img id in: 13981\n",
      "img id out: 13981\n",
      "img id in: 13982\n",
      "img id out: 13982\n",
      "img id in: 13983\n",
      "img id out: 13983\n",
      "img id in: 13984\n",
      "img id out: 13984\n",
      "img id in: 13985\n",
      "img id out: 13985\n",
      "img id in: 13986\n",
      "img id out: 13986\n",
      "img id in: 13987\n",
      "img id out: 13987\n",
      "img id in: 13988\n",
      "img id out: 13988\n",
      "img id in: 13989\n",
      "img id out: 13989\n",
      "img id in: 13990\n",
      "img id out: 13990\n",
      "img id in: 13991\n",
      "img id out: 13991\n",
      "img id in: 13992\n",
      "img id out: 13992\n",
      "img id in: 13993\n",
      "img id out: 13993\n",
      "img id in: 13994\n",
      "img id out: 13994\n",
      "img id in: 13995\n",
      "img id out: 13995\n",
      "img id in: 13996\n",
      "img id out: 13996\n",
      "img id in: 13997\n",
      "img id out: 13997\n",
      "img id in: 13998\n",
      "img id out: 13998\n",
      "img id in: 13999\n",
      "img id out: 13999\n",
      "img id in: 14000\n",
      "img id out: 14000\n",
      "img id in: 14001\n",
      "img id out: 14001\n",
      "img id in: 14002\n",
      "img id out: 14002\n",
      "img id in: 14003\n",
      "img id out: 14003\n",
      "img id in: 14004\n",
      "img id out: 14004\n",
      "img id in: 14005\n",
      "img id out: 14005\n",
      "img id in: 14006\n",
      "img id out: 14006\n",
      "img id in: 14007\n",
      "img id out: 14007\n",
      "img id in: 14008\n",
      "img id out: 14008\n",
      "img id in: 14009\n",
      "img id out: 14009\n",
      "img id in: 14010\n",
      "img id out: 14010\n",
      "img id in: 14011\n",
      "img id out: 14011\n",
      "img id in: 14012\n",
      "img id out: 14012\n",
      "img id in: 14013\n",
      "img id out: 14013\n",
      "img id in: 14014\n",
      "img id out: 14014\n",
      "img id in: 14015\n",
      "img id out: 14015\n",
      "img id in: 14016\n",
      "img id out: 14016\n",
      "img id in: 14017\n",
      "img id out: 14017\n",
      "img id in: 14018\n",
      "img id out: 14018\n",
      "img id in: 14019\n",
      "img id out: 14019\n",
      "img id in: 14020\n",
      "img id out: 14020\n",
      "img id in: 14021\n",
      "img id out: 14021\n",
      "img id in: 14022\n",
      "img id out: 14022\n",
      "img id in: 14023\n",
      "img id out: 14023\n",
      "img id in: 14024\n",
      "img id out: 14024\n",
      "img id in: 14025\n",
      "img id out: 14025\n",
      "img id in: 14026\n",
      "img id out: 14026\n",
      "img id in: 14027\n",
      "img id out: 14027\n",
      "img id in: 14028\n",
      "img id out: 14028\n",
      "img id in: 14029\n",
      "img id out: 14029\n",
      "img id in: 14030\n",
      "img id out: 14030\n",
      "img id in: 14031\n",
      "img id out: 14031\n",
      "img id in: 14032\n",
      "img id out: 14032\n",
      "img id in: 14033\n",
      "img id out: 14033\n",
      "img id in: 14034\n",
      "img id out: 14034\n",
      "img id in: 14035\n",
      "img id out: 14035\n",
      "img id in: 14036\n",
      "img id out: 14036\n",
      "img id in: 14037\n",
      "img id out: 14037\n",
      "img id in: 14038\n",
      "img id out: 14038\n",
      "img id in: 14039\n",
      "img id out: 14039\n",
      "img id in: 14040\n",
      "img id out: 14040\n",
      "img id in: 14041\n",
      "img id out: 14041\n",
      "img id in: 14042\n",
      "img id out: 14042\n",
      "img id in: 14043\n",
      "img id out: 14043\n",
      "img id in: 14044\n",
      "img id out: 14044\n",
      "img id in: 14045\n",
      "img id out: 14045\n",
      "img id in: 14046\n",
      "img id out: 14046\n",
      "img id in: 14047\n",
      "img id out: 14047\n",
      "img id in: 14048\n",
      "img id out: 14048\n",
      "img id in: 14049\n",
      "img id out: 14049\n",
      "img id in: 14050\n",
      "img id out: 14050\n",
      "img id in: 14051\n",
      "img id out: 14051\n",
      "img id in: 14052\n",
      "img id out: 14052\n",
      "img id in: 14053\n",
      "img id out: 14053\n",
      "img id in: 14054\n",
      "img id out: 14054\n",
      "img id in: 14055\n",
      "img id out: 14055\n",
      "img id in: 14056\n",
      "img id out: 14056\n",
      "img id in: 14057\n",
      "img id out: 14057\n",
      "img id in: 14058\n",
      "img id out: 14058\n",
      "img id in: 14059\n",
      "img id out: 14059\n",
      "img id in: 14060\n",
      "img id out: 14060\n",
      "img id in: 14061\n",
      "img id out: 14061\n",
      "img id in: 14062\n",
      "img id out: 14062\n",
      "img id in: 14063\n",
      "img id out: 14063\n",
      "img id in: 14064\n",
      "img id out: 14064\n",
      "img id in: 14065\n",
      "img id out: 14065\n",
      "img id in: 14066\n",
      "img id out: 14066\n",
      "img id in: 14067\n",
      "img id out: 14067\n",
      "img id in: 14068\n",
      "img id out: 14068\n",
      "img id in: 14069\n",
      "img id out: 14069\n",
      "img id in: 14070\n",
      "img id out: 14070\n",
      "img id in: 14071\n",
      "img id out: 14071\n",
      "img id in: 14072\n",
      "img id out: 14072\n",
      "img id in: 14073\n",
      "img id out: 14073\n",
      "img id in: 14074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 14074\n",
      "img id in: 14075\n",
      "img id out: 14075\n",
      "img id in: 14076\n",
      "img id out: 14076\n",
      "img id in: 14077\n",
      "img id out: 14077\n",
      "img id in: 14078\n",
      "img id out: 14078\n",
      "img id in: 14079\n",
      "img id out: 14079\n",
      "img id in: 14080\n",
      "img id out: 14080\n",
      "img id in: 14081\n",
      "img id out: 14081\n",
      "img id in: 14082\n",
      "img id out: 14082\n",
      "img id in: 14083\n",
      "img id out: 14083\n",
      "img id in: 14084\n",
      "img id out: 14084\n",
      "img id in: 14085\n",
      "img id out: 14085\n",
      "img id in: 14086\n",
      "img id out: 14086\n",
      "img id in: 14087\n",
      "img id out: 14087\n",
      "img id in: 14088\n",
      "img id out: 14088\n",
      "img id in: 14089\n",
      "img id out: 14089\n",
      "img id in: 14090\n",
      "img id out: 14090\n",
      "img id in: 14091\n",
      "img id out: 14091\n",
      "img id in: 14092\n",
      "img id out: 14092\n",
      "img id in: 14093\n",
      "img id out: 14093\n",
      "img id in: 14094\n",
      "img id out: 14094\n",
      "img id in: 14095\n",
      "img id out: 14095\n",
      "img id in: 14096\n",
      "img id out: 14096\n",
      "img id in: 14097\n",
      "img id out: 14097\n",
      "img id in: 14098\n",
      "img id out: 14098\n",
      "img id in: 14099\n",
      "img id out: 14099\n",
      "img id in: 14100\n",
      "img id out: 14100\n",
      "img id in: 14101\n",
      "img id out: 14101\n",
      "img id in: 14102\n",
      "img id out: 14102\n",
      "img id in: 14103\n",
      "img id out: 14103\n",
      "img id in: 14104\n",
      "img id out: 14104\n",
      "img id in: 14105\n",
      "img id out: 14105\n",
      "img id in: 14106\n",
      "img id out: 14106\n",
      "img id in: 14107\n",
      "img id out: 14107\n",
      "img id in: 14108\n",
      "img id out: 14108\n",
      "img id in: 14109\n",
      "img id out: 14109\n",
      "img id in: 14110\n",
      "img id out: 14110\n",
      "img id in: 14111\n",
      "img id out: 14111\n",
      "img id in: 14112\n",
      "img id out: 14112\n",
      "img id in: 14113\n",
      "img id out: 14113\n",
      "img id in: 14114\n",
      "img id out: 14114\n",
      "img id in: 14115\n",
      "img id out: 14115\n",
      "img id in: 14116\n",
      "img id out: 14116\n",
      "img id in: 14117\n",
      "img id out: 14117\n",
      "img id in: 14118\n",
      "img id out: 14118\n",
      "img id in: 14119\n",
      "img id out: 14119\n",
      "img id in: 14120\n",
      "img id out: 14120\n",
      "img id in: 14121\n",
      "img id out: 14121\n",
      "img id in: 14122\n",
      "img id out: 14122\n",
      "img id in: 14123\n",
      "img id out: 14123\n",
      "img id in: 14124\n",
      "img id out: 14124\n",
      "img id in: 14125\n",
      "img id out: 14125\n",
      "img id in: 14126\n",
      "img id out: 14126\n",
      "img id in: 14127\n",
      "img id out: 14127\n",
      "img id in: 14128\n",
      "img id out: 14128\n",
      "img id in: 14129\n",
      "img id out: 14129\n",
      "img id in: 14130\n",
      "img id out: 14130\n",
      "img id in: 14131\n",
      "img id out: 14131\n",
      "img id in: 14132\n",
      "img id out: 14132\n",
      "img id in: 14133\n",
      "img id out: 14133\n",
      "img id in: 14134\n",
      "img id out: 14134\n",
      "img id in: 14135\n",
      "img id out: 14135\n",
      "img id in: 14136\n",
      "img id out: 14136\n",
      "img id in: 14137\n",
      "img id out: 14137\n",
      "img id in: 14138\n",
      "img id out: 14138\n",
      "img id in: 14139\n",
      "img id out: 14139\n",
      "img id in: 14140\n",
      "img id out: 14140\n",
      "img id in: 14141\n",
      "img id out: 14141\n",
      "img id in: 14142\n",
      "img id out: 14142\n",
      "img id in: 14143\n",
      "img id out: 14143\n",
      "img id in: 14144\n",
      "img id out: 14144\n",
      "img id in: 14145\n",
      "img id out: 14145\n",
      "img id in: 14146\n",
      "img id out: 14146\n",
      "img id in: 14147\n",
      "img id out: 14147\n",
      "img id in: 14148\n",
      "img id out: 14148\n",
      "img id in: 14149\n",
      "img id out: 14149\n",
      "img id in: 14150\n",
      "img id out: 14150\n",
      "img id in: 14151\n",
      "img id out: 14151\n",
      "img id in: 14152\n",
      "img id out: 14152\n",
      "img id in: 14153\n",
      "img id out: 14153\n",
      "img id in: 14154\n",
      "img id out: 14154\n",
      "img id in: 14155\n",
      "img id out: 14155\n",
      "img id in: 14156\n",
      "img id out: 14156\n",
      "img id in: 14157\n",
      "img id out: 14157\n",
      "img id in: 14158\n",
      "img id out: 14158\n",
      "img id in: 14159\n",
      "img id out: 14159\n",
      "img id in: 14160\n",
      "img id out: 14160\n",
      "img id in: 14161\n",
      "img id out: 14161\n",
      "img id in: 14162\n",
      "img id out: 14162\n",
      "img id in: 14163\n",
      "img id out: 14163\n",
      "img id in: 14164\n",
      "img id out: 14164\n",
      "img id in: 14165\n",
      "img id out: 14165\n",
      "img id in: 14166\n",
      "img id out: 14166\n",
      "img id in: 14167\n",
      "img id out: 14167\n",
      "img id in: 14168\n",
      "img id out: 14168\n",
      "img id in: 14169\n",
      "img id out: 14169\n",
      "img id in: 14170\n",
      "img id out: 14170\n",
      "img id in: 14171\n",
      "img id out: 14171\n",
      "img id in: 14172\n",
      "img id out: 14172\n",
      "img id in: 14173\n",
      "img id out: 14173\n",
      "img id in: 14174\n",
      "img id out: 14174\n",
      "img id in: 14175\n",
      "img id out: 14175\n",
      "img id in: 14176\n",
      "img id out: 14176\n",
      "img id in: 14177\n",
      "img id out: 14177\n",
      "img id in: 14178\n",
      "img id out: 14178\n",
      "img id in: 14179\n",
      "img id out: 14179\n",
      "img id in: 14180\n",
      "img id out: 14180\n",
      "img id in: 14181\n",
      "img id out: 14181\n",
      "img id in: 14182\n",
      "img id out: 14182\n",
      "img id in: 14183\n",
      "img id out: 14183\n",
      "img id in: 14184\n",
      "img id out: 14184\n",
      "img id in: 14185\n",
      "img id out: 14185\n",
      "img id in: 14186\n",
      "img id out: 14186\n",
      "img id in: 14187\n",
      "img id out: 14187\n",
      "img id in: 14188\n",
      "img id out: 14188\n",
      "img id in: 14189\n",
      "img id out: 14189\n",
      "img id in: 14190\n",
      "img id out: 14190\n",
      "img id in: 14191\n",
      "img id out: 14191\n",
      "img id in: 14192\n",
      "img id out: 14192\n",
      "img id in: 14193\n",
      "img id out: 14193\n",
      "img id in: 14194\n",
      "img id out: 14194\n",
      "img id in: 14195\n",
      "img id out: 14195\n",
      "img id in: 14196\n",
      "img id out: 14196\n",
      "img id in: 14197\n",
      "img id out: 14197\n",
      "img id in: 14198\n",
      "img id out: 14198\n",
      "img id in: 14199\n",
      "img id out: 14199\n",
      "img id in: 14200\n",
      "img id out: 14200\n",
      "img id in: 14201\n",
      "img id out: 14201\n",
      "img id in: 14202\n",
      "img id out: 14202\n",
      "img id in: 14203\n",
      "img id out: 14203\n",
      "img id in: 14204\n",
      "img id out: 14204\n",
      "img id in: 14205\n",
      "img id out: 14205\n",
      "img id in: 14206\n",
      "img id out: 14206\n",
      "img id in: 14207\n",
      "img id out: 14207\n",
      "img id in: 14208\n",
      "img id out: 14208\n",
      "img id in: 14209\n",
      "img id out: 14209\n",
      "img id in: 14210\n",
      "img id out: 14210\n",
      "img id in: 14211\n",
      "img id out: 14211\n",
      "img id in: 14212\n",
      "img id out: 14212\n",
      "img id in: 14213\n",
      "img id out: 14213\n",
      "img id in: 14214\n",
      "img id out: 14214\n",
      "img id in: 14215\n",
      "img id out: 14215\n",
      "img id in: 14216\n",
      "img id out: 14216\n",
      "img id in: 14217\n",
      "img id out: 14217\n",
      "img id in: 14218\n",
      "img id out: 14218\n",
      "img id in: 14219\n",
      "img id out: 14219\n",
      "img id in: 14220\n",
      "img id out: 14220\n",
      "img id in: 14221\n",
      "img id out: 14221\n",
      "img id in: 14222\n",
      "img id out: 14222\n",
      "img id in: 14223\n",
      "img id out: 14223\n",
      "img id in: 14224\n",
      "img id out: 14224\n",
      "img id in: 14225\n",
      "img id out: 14225\n",
      "img id in: 14226\n",
      "img id out: 14226\n",
      "img id in: 14227\n",
      "img id out: 14227\n",
      "img id in: 14228\n",
      "img id out: 14228\n",
      "img id in: 14229\n",
      "img id out: 14229\n",
      "img id in: 14230\n",
      "img id out: 14230\n",
      "img id in: 14231\n",
      "img id out: 14231\n",
      "img id in: 14232\n",
      "img id out: 14232\n",
      "img id in: 14233\n",
      "img id out: 14233\n",
      "img id in: 14234\n",
      "img id out: 14234\n",
      "img id in: 14235\n",
      "img id out: 14235\n",
      "img id in: 14236\n",
      "img id out: 14236\n",
      "img id in: 14237\n",
      "img id out: 14237\n",
      "img id in: 14238\n",
      "img id out: 14238\n",
      "img id in: 14239\n",
      "img id out: 14239\n",
      "img id in: 14240\n",
      "img id out: 14240\n",
      "img id in: 14241\n",
      "img id out: 14241\n",
      "img id in: 14242\n",
      "img id out: 14242\n",
      "img id in: 14243\n",
      "img id out: 14243\n",
      "img id in: 14244\n",
      "img id out: 14244\n",
      "img id in: 14245\n",
      "img id out: 14245\n",
      "img id in: 14246\n",
      "img id out: 14246\n",
      "img id in: 14247\n",
      "img id out: 14247\n",
      "img id in: 14248\n",
      "img id out: 14248\n",
      "img id in: 14249\n",
      "img id out: 14249\n",
      "img id in: 14250\n",
      "img id out: 14250\n",
      "img id in: 14251\n",
      "img id out: 14251\n",
      "img id in: 14252\n",
      "img id out: 14252\n",
      "img id in: 14253\n",
      "img id out: 14253\n",
      "img id in: 14254\n",
      "img id out: 14254\n",
      "img id in: 14255\n",
      "img id out: 14255\n",
      "img id in: 14256\n",
      "img id out: 14256\n",
      "img id in: 14257\n",
      "img id out: 14257\n",
      "img id in: 14258\n",
      "img id out: 14258\n",
      "img id in: 14259\n",
      "img id out: 14259\n",
      "img id in: 14260\n",
      "img id out: 14260\n",
      "img id in: 14261\n",
      "img id out: 14261\n",
      "img id in: 14262\n",
      "img id out: 14262\n",
      "img id in: 14263\n",
      "img id out: 14263\n",
      "img id in: 14264\n",
      "img id out: 14264\n",
      "img id in: 14265\n",
      "img id out: 14265\n",
      "img id in: 14266\n",
      "img id out: 14266\n",
      "img id in: 14267\n",
      "img id out: 14267\n",
      "img id in: 14268\n",
      "img id out: 14268\n",
      "img id in: 14269\n",
      "img id out: 14269\n",
      "img id in: 14270\n",
      "img id out: 14270\n",
      "img id in: 14271\n",
      "img id out: 14271\n",
      "img id in: 14272\n",
      "img id out: 14272\n",
      "img id in: 14273\n",
      "img id out: 14273\n",
      "img id in: 14274\n",
      "img id out: 14274\n",
      "img id in: 14275\n",
      "img id out: 14275\n",
      "img id in: 14276\n",
      "img id out: 14276\n",
      "img id in: 14277\n",
      "img id out: 14277\n",
      "img id in: 14278\n",
      "img id out: 14278\n",
      "img id in: 14279\n",
      "img id out: 14279\n",
      "img id in: 14280\n",
      "img id out: 14280\n",
      "img id in: 14281\n",
      "img id out: 14281\n",
      "img id in: 14282\n",
      "img id out: 14282\n",
      "img id in: 14283\n",
      "img id out: 14283\n",
      "img id in: 14284\n",
      "img id out: 14284\n",
      "img id in: 14285\n",
      "img id out: 14285\n",
      "img id in: 14286\n",
      "img id out: 14286\n",
      "img id in: 14287\n",
      "img id out: 14287\n",
      "img id in: 14288\n",
      "img id out: 14288\n",
      "img id in: 14289\n",
      "img id out: 14289\n",
      "img id in: 14290\n",
      "img id out: 14290\n",
      "img id in: 14291\n",
      "img id out: 14291\n",
      "img id in: 14292\n",
      "img id out: 14292\n",
      "img id in: 14293\n",
      "img id out: 14293\n",
      "img id in: 14294\n",
      "img id out: 14294\n",
      "img id in: 14295\n",
      "img id out: 14295\n",
      "img id in: 14296\n",
      "img id out: 14296\n",
      "img id in: 14297\n",
      "img id out: 14297\n",
      "img id in: 14298\n",
      "img id out: 14298\n",
      "img id in: 14299\n",
      "img id out: 14299\n",
      "img id in: 14300\n",
      "img id out: 14300\n",
      "img id in: 14301\n",
      "img id out: 14301\n",
      "img id in: 14302\n",
      "img id out: 14302\n",
      "img id in: 14303\n",
      "img id out: 14303\n",
      "img id in: 14304\n",
      "img id out: 14304\n",
      "img id in: 14305\n",
      "img id out: 14305\n",
      "img id in: 14306\n",
      "img id out: 14306\n",
      "img id in: 14307\n",
      "img id out: 14307\n",
      "img id in: 14308\n",
      "img id out: 14308\n",
      "img id in: 14309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 14309\n",
      "img id in: 14310\n",
      "img id out: 14310\n",
      "img id in: 14311\n",
      "img id out: 14311\n",
      "img id in: 14312\n",
      "img id out: 14312\n",
      "img id in: 14313\n",
      "img id out: 14313\n",
      "img id in: 14314\n",
      "img id out: 14314\n",
      "img id in: 14315\n",
      "img id out: 14315\n",
      "img id in: 14316\n",
      "img id out: 14316\n",
      "img id in: 14317\n",
      "img id out: 14317\n",
      "img id in: 14318\n",
      "img id out: 14318\n",
      "img id in: 14319\n",
      "img id out: 14319\n",
      "img id in: 14320\n",
      "img id out: 14320\n",
      "img id in: 14321\n",
      "img id out: 14321\n",
      "img id in: 14322\n",
      "img id out: 14322\n",
      "img id in: 14323\n",
      "img id out: 14323\n",
      "img id in: 14324\n",
      "img id out: 14324\n",
      "img id in: 14325\n",
      "img id out: 14325\n",
      "img id in: 14326\n",
      "img id out: 14326\n",
      "img id in: 14327\n",
      "img id out: 14327\n",
      "img id in: 14328\n",
      "img id out: 14328\n",
      "img id in: 14329\n",
      "img id out: 14329\n",
      "img id in: 14330\n",
      "img id out: 14330\n",
      "img id in: 14331\n",
      "img id out: 14331\n",
      "img id in: 14332\n",
      "img id out: 14332\n",
      "img id in: 14333\n",
      "img id out: 14333\n",
      "img id in: 14334\n",
      "img id out: 14334\n",
      "img id in: 14335\n",
      "img id out: 14335\n",
      "img id in: 14336\n",
      "img id out: 14336\n",
      "img id in: 14337\n",
      "img id out: 14337\n",
      "img id in: 14338\n",
      "img id out: 14338\n",
      "img id in: 14339\n",
      "img id out: 14339\n",
      "img id in: 14340\n",
      "img id out: 14340\n",
      "img id in: 14341\n",
      "img id out: 14341\n",
      "img id in: 14342\n",
      "img id out: 14342\n",
      "img id in: 14343\n",
      "img id out: 14343\n",
      "img id in: 14344\n",
      "img id out: 14344\n",
      "img id in: 14345\n",
      "img id out: 14345\n",
      "img id in: 14346\n",
      "img id out: 14346\n",
      "img id in: 14347\n",
      "img id out: 14347\n",
      "img id in: 14348\n",
      "img id out: 14348\n",
      "img id in: 14349\n",
      "img id out: 14349\n",
      "img id in: 14350\n",
      "img id out: 14350\n",
      "img id in: 14351\n",
      "img id out: 14351\n",
      "img id in: 14352\n",
      "img id out: 14352\n",
      "img id in: 14353\n",
      "img id out: 14353\n",
      "img id in: 14354\n",
      "img id out: 14354\n",
      "img id in: 14355\n",
      "img id out: 14355\n",
      "img id in: 14356\n",
      "img id out: 14356\n",
      "img id in: 14357\n",
      "img id out: 14357\n",
      "img id in: 14358\n",
      "img id out: 14358\n",
      "img id in: 14359\n",
      "img id out: 14359\n",
      "img id in: 14360\n",
      "img id out: 14360\n",
      "img id in: 14361\n",
      "img id out: 14361\n",
      "img id in: 14362\n",
      "img id out: 14362\n",
      "img id in: 14363\n",
      "img id out: 14363\n",
      "img id in: 14364\n",
      "img id out: 14364\n",
      "img id in: 14365\n",
      "img id out: 14365\n",
      "img id in: 14366\n",
      "img id out: 14366\n",
      "img id in: 14367\n",
      "img id out: 14367\n",
      "img id in: 14368\n",
      "img id out: 14368\n",
      "img id in: 14369\n",
      "img id out: 14369\n",
      "img id in: 14370\n",
      "img id out: 14370\n",
      "img id in: 14371\n",
      "img id out: 14371\n",
      "img id in: 14372\n",
      "img id out: 14372\n",
      "img id in: 14373\n",
      "img id out: 14373\n",
      "img id in: 14374\n",
      "img id out: 14374\n",
      "img id in: 14375\n",
      "img id out: 14375\n",
      "img id in: 14376\n",
      "img id out: 14376\n",
      "img id in: 14377\n",
      "img id out: 14377\n",
      "img id in: 14378\n",
      "img id out: 14378\n",
      "img id in: 14379\n",
      "img id out: 14379\n",
      "img id in: 14380\n",
      "img id out: 14380\n",
      "img id in: 14381\n",
      "img id out: 14381\n",
      "img id in: 14382\n",
      "img id out: 14382\n",
      "img id in: 14383\n",
      "img id out: 14383\n",
      "img id in: 14384\n",
      "img id out: 14384\n",
      "img id in: 14385\n",
      "img id out: 14385\n",
      "img id in: 14386\n",
      "img id out: 14386\n",
      "img id in: 14387\n",
      "img id out: 14387\n",
      "img id in: 14388\n",
      "img id out: 14388\n",
      "img id in: 14389\n",
      "img id out: 14389\n",
      "img id in: 14390\n",
      "img id out: 14390\n",
      "img id in: 14391\n",
      "img id out: 14391\n",
      "img id in: 14392\n",
      "img id out: 14392\n",
      "img id in: 14393\n",
      "img id out: 14393\n",
      "img id in: 14394\n",
      "img id out: 14394\n",
      "img id in: 14395\n",
      "img id out: 14395\n",
      "img id in: 14396\n",
      "img id out: 14396\n",
      "img id in: 14397\n",
      "img id out: 14397\n",
      "img id in: 14398\n",
      "img id out: 14398\n",
      "img id in: 14399\n",
      "img id out: 14399\n",
      "img id in: 14400\n",
      "img id out: 14400\n",
      "img id in: 14401\n",
      "img id out: 14401\n",
      "img id in: 14402\n",
      "img id out: 14402\n",
      "img id in: 14403\n",
      "img id out: 14403\n",
      "img id in: 14404\n",
      "img id out: 14404\n",
      "img id in: 14405\n",
      "img id out: 14405\n",
      "img id in: 14406\n",
      "img id out: 14406\n",
      "img id in: 14407\n",
      "img id out: 14407\n",
      "img id in: 14408\n",
      "img id out: 14408\n",
      "img id in: 14409\n",
      "img id out: 14409\n",
      "img id in: 14410\n",
      "img id out: 14410\n",
      "img id in: 14411\n",
      "img id out: 14411\n",
      "img id in: 14412\n",
      "img id out: 14412\n",
      "img id in: 14413\n",
      "img id out: 14413\n",
      "img id in: 14414\n",
      "img id out: 14414\n",
      "img id in: 14415\n",
      "img id out: 14415\n",
      "img id in: 14416\n",
      "img id out: 14416\n",
      "img id in: 14417\n",
      "img id out: 14417\n",
      "img id in: 14418\n",
      "img id out: 14418\n",
      "img id in: 14419\n",
      "img id out: 14419\n",
      "img id in: 14420\n",
      "img id out: 14420\n",
      "img id in: 14421\n",
      "img id out: 14421\n",
      "img id in: 14422\n",
      "img id out: 14422\n",
      "img id in: 14423\n",
      "img id out: 14423\n",
      "img id in: 14424\n",
      "img id out: 14424\n",
      "img id in: 14425\n",
      "img id out: 14425\n",
      "img id in: 14426\n",
      "img id out: 14426\n",
      "img id in: 14427\n",
      "img id out: 14427\n",
      "img id in: 14428\n",
      "img id out: 14428\n",
      "img id in: 14429\n",
      "img id out: 14429\n",
      "img id in: 14430\n",
      "img id out: 14430\n",
      "img id in: 14431\n",
      "img id out: 14431\n",
      "img id in: 14432\n",
      "img id out: 14432\n",
      "img id in: 14433\n",
      "img id out: 14433\n",
      "img id in: 14434\n",
      "img id out: 14434\n",
      "img id in: 14435\n",
      "img id out: 14435\n",
      "img id in: 14436\n",
      "img id out: 14436\n",
      "img id in: 14437\n",
      "img id out: 14437\n",
      "img id in: 14438\n",
      "img id out: 14438\n",
      "img id in: 14439\n",
      "img id out: 14439\n",
      "img id in: 14440\n",
      "img id out: 14440\n",
      "img id in: 14441\n",
      "img id out: 14441\n",
      "img id in: 14442\n",
      "img id out: 14442\n",
      "img id in: 14443\n",
      "img id out: 14443\n",
      "img id in: 14444\n",
      "img id out: 14444\n",
      "img id in: 14445\n",
      "img id out: 14445\n",
      "img id in: 14446\n",
      "img id out: 14446\n",
      "img id in: 14447\n",
      "img id out: 14447\n",
      "img id in: 14448\n",
      "img id out: 14448\n",
      "img id in: 14449\n",
      "img id out: 14449\n",
      "img id in: 14450\n",
      "img id out: 14450\n",
      "img id in: 14451\n",
      "img id out: 14451\n",
      "img id in: 14452\n",
      "img id out: 14452\n",
      "img id in: 14453\n",
      "img id out: 14453\n",
      "img id in: 14454\n",
      "img id out: 14454\n",
      "img id in: 14455\n",
      "img id out: 14455\n",
      "img id in: 14456\n",
      "img id out: 14456\n",
      "img id in: 14457\n",
      "img id out: 14457\n",
      "img id in: 14458\n",
      "img id out: 14458\n",
      "img id in: 14459\n",
      "img id out: 14459\n",
      "img id in: 14460\n",
      "img id out: 14460\n",
      "img id in: 14461\n",
      "img id out: 14461\n",
      "img id in: 14462\n",
      "img id out: 14462\n",
      "img id in: 14463\n",
      "img id out: 14463\n",
      "img id in: 14464\n",
      "img id out: 14464\n",
      "img id in: 14465\n",
      "img id out: 14465\n",
      "img id in: 14466\n",
      "img id out: 14466\n",
      "img id in: 14467\n",
      "img id out: 14467\n",
      "img id in: 14468\n",
      "img id out: 14468\n",
      "img id in: 14469\n",
      "img id out: 14469\n",
      "img id in: 14470\n",
      "img id out: 14470\n",
      "img id in: 14471\n",
      "img id out: 14471\n",
      "img id in: 14472\n",
      "img id out: 14472\n",
      "img id in: 14473\n",
      "img id out: 14473\n",
      "img id in: 14474\n",
      "img id out: 14474\n",
      "img id in: 14475\n",
      "img id out: 14475\n",
      "img id in: 14476\n",
      "img id out: 14476\n",
      "img id in: 14477\n",
      "img id out: 14477\n",
      "img id in: 14478\n",
      "img id out: 14478\n",
      "img id in: 14479\n",
      "img id out: 14479\n",
      "img id in: 14480\n",
      "img id out: 14480\n",
      "img id in: 14481\n",
      "img id out: 14481\n",
      "img id in: 14482\n",
      "img id out: 14482\n",
      "img id in: 14483\n",
      "img id out: 14483\n",
      "img id in: 14484\n",
      "img id out: 14484\n",
      "img id in: 14485\n",
      "img id out: 14485\n",
      "img id in: 14486\n",
      "img id out: 14486\n",
      "img id in: 14487\n",
      "img id out: 14487\n",
      "img id in: 14488\n",
      "img id out: 14488\n",
      "img id in: 14489\n",
      "img id out: 14489\n",
      "img id in: 14490\n",
      "img id out: 14490\n",
      "img id in: 14491\n",
      "img id out: 14491\n",
      "img id in: 14492\n",
      "img id out: 14492\n",
      "img id in: 14493\n",
      "img id out: 14493\n",
      "img id in: 14494\n",
      "img id out: 14494\n",
      "img id in: 14495\n",
      "img id out: 14495\n",
      "img id in: 14496\n",
      "img id out: 14496\n",
      "img id in: 14497\n",
      "img id out: 14497\n",
      "img id in: 14498\n",
      "img id out: 14498\n",
      "img id in: 14499\n",
      "img id out: 14499\n",
      "img id in: 14500\n",
      "img id out: 14500\n",
      "img id in: 14501\n",
      "img id out: 14501\n",
      "img id in: 14502\n",
      "img id out: 14502\n",
      "img id in: 14503\n",
      "img id out: 14503\n",
      "img id in: 14504\n",
      "img id out: 14504\n",
      "img id in: 14505\n",
      "img id out: 14505\n",
      "img id in: 14506\n",
      "img id out: 14506\n",
      "img id in: 14507\n",
      "img id out: 14507\n",
      "img id in: 14508\n",
      "img id out: 14508\n",
      "img id in: 14509\n",
      "img id out: 14509\n",
      "img id in: 14510\n",
      "img id out: 14510\n",
      "img id in: 14511\n",
      "img id out: 14511\n",
      "img id in: 14512\n",
      "img id out: 14512\n",
      "img id in: 14513\n",
      "img id out: 14513\n",
      "img id in: 14514\n",
      "img id out: 14514\n",
      "img id in: 14515\n",
      "img id out: 14515\n",
      "img id in: 14516\n",
      "img id out: 14516\n",
      "img id in: 14517\n",
      "img id out: 14517\n",
      "img id in: 14518\n",
      "img id out: 14518\n",
      "img id in: 14519\n",
      "img id out: 14519\n",
      "img id in: 14520\n",
      "img id out: 14520\n",
      "img id in: 14521\n",
      "img id out: 14521\n",
      "img id in: 14522\n",
      "img id out: 14522\n",
      "img id in: 14523\n",
      "img id out: 14523\n",
      "img id in: 14524\n",
      "img id out: 14524\n",
      "img id in: 14525\n",
      "img id out: 14525\n",
      "img id in: 14526\n",
      "img id out: 14526\n",
      "img id in: 14527\n",
      "img id out: 14527\n",
      "img id in: 14528\n",
      "img id out: 14528\n",
      "img id in: 14529\n",
      "img id out: 14529\n",
      "img id in: 14530\n",
      "img id out: 14530\n",
      "img id in: 14531\n",
      "img id out: 14531\n",
      "img id in: 14532\n",
      "img id out: 14532\n",
      "img id in: 14533\n",
      "img id out: 14533\n",
      "img id in: 14534\n",
      "img id out: 14534\n",
      "img id in: 14535\n",
      "img id out: 14535\n",
      "img id in: 14536\n",
      "img id out: 14536\n",
      "img id in: 14537\n",
      "img id out: 14537\n",
      "img id in: 14538\n",
      "img id out: 14538\n",
      "img id in: 14539\n",
      "img id out: 14539\n",
      "img id in: 14540\n",
      "img id out: 14540\n",
      "img id in: 14541\n",
      "img id out: 14541\n",
      "img id in: 14542\n",
      "img id out: 14542\n",
      "img id in: 14543\n",
      "img id out: 14543\n",
      "img id in: 14544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 14544\n",
      "img id in: 14545\n",
      "img id out: 14545\n",
      "img id in: 14546\n",
      "img id out: 14546\n",
      "img id in: 14547\n",
      "img id out: 14547\n",
      "img id in: 14548\n",
      "img id out: 14548\n",
      "img id in: 14549\n",
      "img id out: 14549\n",
      "img id in: 14550\n",
      "img id out: 14550\n",
      "img id in: 14551\n",
      "img id out: 14551\n",
      "img id in: 14552\n",
      "img id out: 14552\n",
      "img id in: 14553\n",
      "img id out: 14553\n",
      "img id in: 14554\n",
      "img id out: 14554\n",
      "img id in: 14555\n",
      "img id out: 14555\n",
      "img id in: 14556\n",
      "img id out: 14556\n",
      "img id in: 14557\n",
      "img id out: 14557\n",
      "img id in: 14558\n",
      "img id out: 14558\n",
      "img id in: 14559\n",
      "img id out: 14559\n",
      "img id in: 14560\n",
      "img id out: 14560\n",
      "img id in: 14561\n",
      "img id out: 14561\n",
      "img id in: 14562\n",
      "img id out: 14562\n",
      "img id in: 14563\n",
      "img id out: 14563\n",
      "img id in: 14564\n",
      "img id out: 14564\n",
      "img id in: 14565\n",
      "img id out: 14565\n",
      "img id in: 14566\n",
      "img id out: 14566\n",
      "img id in: 14567\n",
      "img id out: 14567\n",
      "img id in: 14568\n",
      "img id out: 14568\n",
      "img id in: 14569\n",
      "img id out: 14569\n",
      "img id in: 14570\n",
      "img id out: 14570\n",
      "img id in: 14571\n",
      "img id out: 14571\n",
      "img id in: 14572\n",
      "img id out: 14572\n",
      "img id in: 14573\n",
      "img id out: 14573\n",
      "img id in: 14574\n",
      "img id out: 14574\n",
      "img id in: 14575\n",
      "img id out: 14575\n",
      "img id in: 14576\n",
      "img id out: 14576\n",
      "img id in: 14577\n",
      "img id out: 14577\n",
      "img id in: 14578\n",
      "img id out: 14578\n",
      "img id in: 14579\n",
      "img id out: 14579\n",
      "img id in: 14580\n",
      "img id out: 14580\n",
      "img id in: 14581\n",
      "img id out: 14581\n",
      "img id in: 14582\n",
      "img id out: 14582\n",
      "img id in: 14583\n",
      "img id out: 14583\n",
      "img id in: 14584\n",
      "img id out: 14584\n",
      "img id in: 14585\n",
      "img id out: 14585\n",
      "img id in: 14586\n",
      "img id out: 14586\n",
      "img id in: 14587\n",
      "img id out: 14587\n",
      "img id in: 14588\n",
      "img id out: 14588\n",
      "img id in: 14589\n",
      "img id out: 14589\n",
      "img id in: 14590\n",
      "img id out: 14590\n",
      "img id in: 14591\n",
      "img id out: 14591\n",
      "img id in: 14592\n",
      "img id out: 14592\n",
      "img id in: 14593\n",
      "img id out: 14593\n",
      "img id in: 14594\n",
      "img id out: 14594\n",
      "img id in: 14595\n",
      "img id out: 14595\n",
      "img id in: 14596\n",
      "img id out: 14596\n",
      "img id in: 14597\n",
      "img id out: 14597\n",
      "img id in: 14598\n",
      "img id out: 14598\n",
      "img id in: 14599\n",
      "img id out: 14599\n",
      "img id in: 14600\n",
      "img id out: 14600\n",
      "img id in: 14601\n",
      "img id out: 14601\n",
      "img id in: 14602\n",
      "img id out: 14602\n",
      "img id in: 14603\n",
      "img id out: 14603\n",
      "img id in: 14604\n",
      "img id out: 14604\n",
      "img id in: 14605\n",
      "img id out: 14605\n",
      "img id in: 14606\n",
      "img id out: 14606\n",
      "img id in: 14607\n",
      "img id out: 14607\n",
      "img id in: 14608\n",
      "img id out: 14608\n",
      "img id in: 14609\n",
      "img id out: 14609\n",
      "img id in: 14610\n",
      "img id out: 14610\n",
      "img id in: 14611\n",
      "img id out: 14611\n",
      "img id in: 14612\n",
      "img id out: 14612\n",
      "img id in: 14613\n",
      "img id out: 14613\n",
      "img id in: 14614\n",
      "img id out: 14614\n",
      "img id in: 14615\n",
      "img id out: 14615\n",
      "img id in: 14616\n",
      "img id out: 14616\n",
      "img id in: 14617\n",
      "img id out: 14617\n",
      "img id in: 14618\n",
      "img id out: 14618\n",
      "img id in: 14619\n",
      "img id out: 14619\n",
      "img id in: 14620\n",
      "img id out: 14620\n",
      "img id in: 14621\n",
      "img id out: 14621\n",
      "img id in: 14622\n",
      "img id out: 14622\n",
      "img id in: 14623\n",
      "img id out: 14623\n",
      "img id in: 14624\n",
      "img id out: 14624\n",
      "img id in: 14625\n",
      "img id out: 14625\n",
      "img id in: 14626\n",
      "img id out: 14626\n",
      "img id in: 14627\n",
      "img id out: 14627\n",
      "img id in: 14628\n",
      "img id out: 14628\n",
      "img id in: 14629\n",
      "img id out: 14629\n",
      "img id in: 14630\n",
      "img id out: 14630\n",
      "img id in: 14631\n",
      "img id out: 14631\n",
      "img id in: 14632\n",
      "img id out: 14632\n",
      "img id in: 14633\n",
      "img id out: 14633\n",
      "img id in: 14634\n",
      "img id out: 14634\n",
      "img id in: 14635\n",
      "img id out: 14635\n",
      "img id in: 14636\n",
      "img id out: 14636\n",
      "img id in: 14637\n",
      "img id out: 14637\n",
      "img id in: 14638\n",
      "img id out: 14638\n",
      "img id in: 14639\n",
      "img id out: 14639\n",
      "img id in: 14640\n",
      "img id out: 14640\n",
      "img id in: 14641\n",
      "img id out: 14641\n",
      "img id in: 14642\n",
      "img id out: 14642\n",
      "img id in: 14643\n",
      "img id out: 14643\n",
      "img id in: 14644\n",
      "img id out: 14644\n",
      "img id in: 14645\n",
      "img id out: 14645\n",
      "img id in: 14646\n",
      "img id out: 14646\n",
      "img id in: 14647\n",
      "img id out: 14647\n",
      "img id in: 14648\n",
      "img id out: 14648\n",
      "img id in: 14649\n",
      "img id out: 14649\n",
      "img id in: 14650\n",
      "img id out: 14650\n",
      "img id in: 14651\n",
      "img id out: 14651\n",
      "img id in: 14652\n",
      "img id out: 14652\n",
      "img id in: 14653\n",
      "img id out: 14653\n",
      "img id in: 14654\n",
      "img id out: 14654\n",
      "img id in: 14655\n",
      "img id out: 14655\n",
      "img id in: 14656\n",
      "img id out: 14656\n",
      "img id in: 14657\n",
      "img id out: 14657\n",
      "img id in: 14658\n",
      "img id out: 14658\n",
      "img id in: 14659\n",
      "img id out: 14659\n",
      "img id in: 14660\n",
      "img id out: 14660\n",
      "img id in: 14661\n",
      "img id out: 14661\n",
      "img id in: 14662\n",
      "img id out: 14662\n",
      "img id in: 14663\n",
      "img id out: 14663\n",
      "img id in: 14664\n",
      "img id out: 14664\n",
      "img id in: 14665\n",
      "img id out: 14665\n",
      "img id in: 14666\n",
      "img id out: 14666\n",
      "img id in: 14667\n",
      "img id out: 14667\n",
      "img id in: 14668\n",
      "img id out: 14668\n",
      "img id in: 14669\n",
      "img id out: 14669\n",
      "img id in: 14670\n",
      "img id out: 14670\n",
      "img id in: 14671\n",
      "img id out: 14671\n",
      "img id in: 14672\n",
      "img id out: 14672\n",
      "img id in: 14673\n",
      "img id out: 14673\n",
      "img id in: 14674\n",
      "img id out: 14674\n",
      "img id in: 14675\n",
      "img id out: 14675\n",
      "img id in: 14676\n",
      "img id out: 14676\n",
      "img id in: 14677\n",
      "img id out: 14677\n",
      "img id in: 14678\n",
      "img id out: 14678\n",
      "img id in: 14679\n",
      "img id out: 14679\n",
      "img id in: 14680\n",
      "img id out: 14680\n",
      "img id in: 14681\n",
      "img id out: 14681\n",
      "img id in: 14682\n",
      "img id out: 14682\n",
      "img id in: 14683\n",
      "img id out: 14683\n",
      "img id in: 14684\n",
      "img id out: 14684\n",
      "img id in: 14685\n",
      "img id out: 14685\n",
      "img id in: 14686\n",
      "img id out: 14686\n",
      "img id in: 14687\n",
      "img id out: 14687\n",
      "img id in: 14688\n",
      "img id out: 14688\n",
      "img id in: 14689\n",
      "img id out: 14689\n",
      "img id in: 14690\n",
      "img id out: 14690\n",
      "img id in: 14691\n",
      "img id out: 14691\n",
      "img id in: 14692\n",
      "img id out: 14692\n",
      "img id in: 14693\n",
      "img id out: 14693\n",
      "img id in: 14694\n",
      "img id out: 14694\n",
      "img id in: 14695\n",
      "img id out: 14695\n",
      "img id in: 14696\n",
      "img id out: 14696\n",
      "img id in: 14697\n",
      "img id out: 14697\n",
      "img id in: 14698\n",
      "img id out: 14698\n",
      "img id in: 14699\n",
      "img id out: 14699\n",
      "img id in: 14700\n",
      "img id out: 14700\n",
      "img id in: 14701\n",
      "img id out: 14701\n",
      "img id in: 14702\n",
      "img id out: 14702\n",
      "img id in: 14703\n",
      "img id out: 14703\n",
      "img id in: 14704\n",
      "img id out: 14704\n",
      "img id in: 14705\n",
      "img id out: 14705\n",
      "img id in: 14706\n",
      "img id out: 14706\n",
      "img id in: 14707\n",
      "img id out: 14707\n",
      "img id in: 14708\n",
      "img id out: 14708\n",
      "img id in: 14709\n",
      "img id out: 14709\n",
      "img id in: 14710\n",
      "img id out: 14710\n",
      "img id in: 14711\n",
      "img id out: 14711\n",
      "img id in: 14712\n",
      "img id out: 14712\n",
      "img id in: 14713\n",
      "img id out: 14713\n",
      "img id in: 14714\n",
      "img id out: 14714\n",
      "img id in: 14715\n",
      "img id out: 14715\n",
      "img id in: 14716\n",
      "img id out: 14716\n",
      "img id in: 14717\n",
      "img id out: 14717\n",
      "img id in: 14718\n",
      "img id out: 14718\n",
      "img id in: 14719\n",
      "img id out: 14719\n",
      "img id in: 14720\n",
      "img id out: 14720\n",
      "img id in: 14721\n",
      "img id out: 14721\n",
      "img id in: 14722\n",
      "img id out: 14722\n",
      "img id in: 14723\n",
      "img id out: 14723\n",
      "img id in: 14724\n",
      "img id out: 14724\n",
      "img id in: 14725\n",
      "img id out: 14725\n",
      "img id in: 14726\n",
      "img id out: 14726\n",
      "img id in: 14727\n",
      "img id out: 14727\n",
      "img id in: 14728\n",
      "img id out: 14728\n",
      "img id in: 14729\n",
      "img id out: 14729\n",
      "img id in: 14730\n",
      "img id out: 14730\n",
      "img id in: 14731\n",
      "img id out: 14731\n",
      "img id in: 14732\n",
      "img id out: 14732\n",
      "img id in: 14733\n",
      "img id out: 14733\n",
      "img id in: 14734\n",
      "img id out: 14734\n",
      "img id in: 14735\n",
      "img id out: 14735\n",
      "img id in: 14736\n",
      "img id out: 14736\n",
      "img id in: 14737\n",
      "img id out: 14737\n",
      "img id in: 14738\n",
      "img id out: 14738\n",
      "img id in: 14739\n",
      "img id out: 14739\n",
      "img id in: 14740\n",
      "img id out: 14740\n",
      "img id in: 14741\n",
      "img id out: 14741\n",
      "img id in: 14742\n",
      "img id out: 14742\n",
      "img id in: 14743\n",
      "img id out: 14743\n",
      "img id in: 14744\n",
      "img id out: 14744\n",
      "img id in: 14745\n",
      "img id out: 14745\n",
      "img id in: 14746\n",
      "img id out: 14746\n",
      "img id in: 14747\n",
      "img id out: 14747\n",
      "img id in: 14748\n",
      "img id out: 14748\n",
      "img id in: 14749\n",
      "img id out: 14749\n",
      "img id in: 14750\n",
      "img id out: 14750\n",
      "img id in: 14751\n",
      "img id out: 14751\n",
      "img id in: 14752\n",
      "img id out: 14752\n",
      "img id in: 14753\n",
      "img id out: 14753\n",
      "img id in: 14754\n",
      "img id out: 14754\n",
      "img id in: 14755\n",
      "img id out: 14755\n",
      "img id in: 14756\n",
      "img id out: 14756\n",
      "img id in: 14757\n",
      "img id out: 14757\n",
      "img id in: 14758\n",
      "img id out: 14758\n",
      "img id in: 14759\n",
      "img id out: 14759\n",
      "img id in: 14760\n",
      "img id out: 14760\n",
      "img id in: 14761\n",
      "img id out: 14761\n",
      "img id in: 14762\n",
      "img id out: 14762\n",
      "img id in: 14763\n",
      "img id out: 14763\n",
      "img id in: 14764\n",
      "img id out: 14764\n",
      "img id in: 14765\n",
      "img id out: 14765\n",
      "img id in: 14766\n",
      "img id out: 14766\n",
      "img id in: 14767\n",
      "img id out: 14767\n",
      "img id in: 14768\n",
      "img id out: 14768\n",
      "img id in: 14769\n",
      "img id out: 14769\n",
      "img id in: 14770\n",
      "img id out: 14770\n",
      "img id in: 14771\n",
      "img id out: 14771\n",
      "img id in: 14772\n",
      "img id out: 14772\n",
      "img id in: 14773\n",
      "img id out: 14773\n",
      "img id in: 14774\n",
      "img id out: 14774\n",
      "img id in: 14775\n",
      "img id out: 14775\n",
      "img id in: 14776\n",
      "img id out: 14776\n",
      "img id in: 14777\n",
      "img id out: 14777\n",
      "img id in: 14778\n",
      "img id out: 14778\n",
      "img id in: 14779\n",
      "img id out: 14779\n",
      "img id in: 14780\n",
      "img id out: 14780\n",
      "img id in: 14781\n",
      "img id out: 14781\n",
      "img id in: 14782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 14782\n",
      "img id in: 14783\n",
      "img id out: 14783\n",
      "img id in: 14784\n",
      "img id out: 14784\n",
      "img id in: 14785\n",
      "img id out: 14785\n",
      "img id in: 14786\n",
      "img id out: 14786\n",
      "img id in: 14787\n",
      "img id out: 14787\n",
      "img id in: 14788\n",
      "img id out: 14788\n",
      "img id in: 14789\n",
      "img id out: 14789\n",
      "img id in: 14790\n",
      "img id out: 14790\n",
      "img id in: 14791\n",
      "img id out: 14791\n",
      "img id in: 14792\n",
      "img id out: 14792\n",
      "img id in: 14793\n",
      "img id out: 14793\n",
      "img id in: 14794\n",
      "img id out: 14794\n",
      "img id in: 14795\n",
      "img id out: 14795\n",
      "img id in: 14796\n",
      "img id out: 14796\n",
      "img id in: 14797\n",
      "img id out: 14797\n",
      "img id in: 14798\n",
      "img id out: 14798\n",
      "img id in: 14799\n",
      "img id out: 14799\n",
      "img id in: 14800\n",
      "img id out: 14800\n",
      "img id in: 14801\n",
      "img id out: 14801\n",
      "img id in: 14802\n",
      "img id out: 14802\n",
      "img id in: 14803\n",
      "img id out: 14803\n",
      "img id in: 14804\n",
      "img id out: 14804\n",
      "img id in: 14805\n",
      "img id out: 14805\n",
      "img id in: 14806\n",
      "img id out: 14806\n",
      "img id in: 14807\n",
      "img id out: 14807\n",
      "img id in: 14808\n",
      "img id out: 14808\n",
      "img id in: 14809\n",
      "img id out: 14809\n",
      "img id in: 14810\n",
      "img id out: 14810\n",
      "img id in: 14811\n",
      "img id out: 14811\n",
      "img id in: 14812\n",
      "img id out: 14812\n",
      "img id in: 14813\n",
      "img id out: 14813\n",
      "img id in: 14814\n",
      "img id out: 14814\n",
      "img id in: 14815\n",
      "img id out: 14815\n",
      "img id in: 14816\n",
      "img id out: 14816\n",
      "img id in: 14817\n",
      "img id out: 14817\n",
      "img id in: 14818\n",
      "img id out: 14818\n",
      "img id in: 14819\n",
      "img id out: 14819\n",
      "img id in: 14820\n",
      "img id out: 14820\n",
      "img id in: 14821\n",
      "img id out: 14821\n",
      "img id in: 14822\n",
      "img id out: 14822\n",
      "img id in: 14823\n",
      "img id out: 14823\n",
      "img id in: 14824\n",
      "img id out: 14824\n",
      "img id in: 14825\n",
      "img id out: 14825\n",
      "img id in: 14826\n",
      "img id out: 14826\n",
      "img id in: 14827\n",
      "img id out: 14827\n",
      "img id in: 14828\n",
      "img id out: 14828\n",
      "img id in: 14829\n",
      "img id out: 14829\n",
      "img id in: 14830\n",
      "img id out: 14830\n",
      "img id in: 14831\n",
      "img id out: 14831\n",
      "img id in: 14832\n",
      "img id out: 14832\n",
      "img id in: 14833\n",
      "img id out: 14833\n",
      "img id in: 14834\n",
      "img id out: 14834\n",
      "img id in: 14835\n",
      "img id out: 14835\n",
      "img id in: 14836\n",
      "img id out: 14836\n",
      "img id in: 14837\n",
      "img id out: 14837\n",
      "img id in: 14838\n",
      "img id out: 14838\n",
      "img id in: 14839\n",
      "img id out: 14839\n",
      "img id in: 14840\n",
      "img id out: 14840\n",
      "img id in: 14841\n",
      "img id out: 14841\n",
      "img id in: 14842\n",
      "img id out: 14842\n",
      "img id in: 14843\n",
      "img id out: 14843\n",
      "img id in: 14844\n",
      "img id out: 14844\n",
      "img id in: 14845\n",
      "img id out: 14845\n",
      "img id in: 14846\n",
      "img id out: 14846\n",
      "img id in: 14847\n",
      "img id out: 14847\n",
      "img id in: 14848\n",
      "img id out: 14848\n",
      "img id in: 14849\n",
      "img id out: 14849\n",
      "img id in: 14850\n",
      "img id out: 14850\n",
      "img id in: 14851\n",
      "img id out: 14851\n",
      "img id in: 14852\n",
      "img id out: 14852\n",
      "img id in: 14853\n",
      "img id out: 14853\n",
      "img id in: 14854\n",
      "img id out: 14854\n",
      "img id in: 14855\n",
      "img id out: 14855\n",
      "img id in: 14856\n",
      "img id out: 14856\n",
      "img id in: 14857\n",
      "img id out: 14857\n",
      "img id in: 14858\n",
      "img id out: 14858\n",
      "img id in: 14859\n",
      "img id out: 14859\n",
      "img id in: 14860\n",
      "img id out: 14860\n",
      "img id in: 14861\n",
      "img id out: 14861\n",
      "img id in: 14862\n",
      "img id out: 14862\n",
      "img id in: 14863\n",
      "img id out: 14863\n",
      "img id in: 14864\n",
      "img id out: 14864\n",
      "img id in: 14865\n",
      "img id out: 14865\n",
      "img id in: 14866\n",
      "img id out: 14866\n",
      "img id in: 14867\n",
      "img id out: 14867\n",
      "img id in: 14868\n",
      "img id out: 14868\n",
      "img id in: 14869\n",
      "img id out: 14869\n",
      "img id in: 14870\n",
      "img id out: 14870\n",
      "img id in: 14871\n",
      "img id out: 14871\n",
      "img id in: 14872\n",
      "img id out: 14872\n",
      "img id in: 14873\n",
      "img id out: 14873\n",
      "img id in: 14874\n",
      "img id out: 14874\n",
      "img id in: 14875\n",
      "img id out: 14875\n",
      "img id in: 14876\n",
      "img id out: 14876\n",
      "img id in: 14877\n",
      "img id out: 14877\n",
      "img id in: 14878\n",
      "img id out: 14878\n",
      "img id in: 14879\n",
      "img id out: 14879\n",
      "img id in: 14880\n",
      "img id out: 14880\n",
      "img id in: 14881\n",
      "img id out: 14881\n",
      "img id in: 14882\n",
      "img id out: 14882\n",
      "img id in: 14883\n",
      "img id out: 14883\n",
      "img id in: 14884\n",
      "img id out: 14884\n",
      "img id in: 14885\n",
      "img id out: 14885\n",
      "img id in: 14886\n",
      "img id out: 14886\n",
      "img id in: 14887\n",
      "img id out: 14887\n",
      "img id in: 14888\n",
      "img id out: 14888\n",
      "img id in: 14889\n",
      "img id out: 14889\n",
      "img id in: 14890\n",
      "img id out: 14890\n",
      "img id in: 14891\n",
      "img id out: 14891\n",
      "img id in: 14892\n",
      "img id out: 14892\n",
      "img id in: 14893\n",
      "img id out: 14893\n",
      "img id in: 14894\n",
      "img id out: 14894\n",
      "img id in: 14895\n",
      "img id out: 14895\n",
      "img id in: 14896\n",
      "img id out: 14896\n",
      "img id in: 14897\n",
      "img id out: 14897\n",
      "img id in: 14898\n",
      "img id out: 14898\n",
      "img id in: 14899\n",
      "img id out: 14899\n",
      "img id in: 14900\n",
      "img id out: 14900\n",
      "img id in: 14901\n",
      "img id out: 14901\n",
      "img id in: 14902\n",
      "img id out: 14902\n",
      "img id in: 14903\n",
      "img id out: 14903\n",
      "img id in: 14904\n",
      "img id out: 14904\n",
      "img id in: 14905\n",
      "img id out: 14905\n",
      "img id in: 14906\n",
      "img id out: 14906\n",
      "img id in: 14907\n",
      "img id out: 14907\n",
      "img id in: 14908\n",
      "img id out: 14908\n",
      "img id in: 14909\n",
      "img id out: 14909\n",
      "img id in: 14910\n",
      "img id out: 14910\n",
      "img id in: 14911\n",
      "img id out: 14911\n",
      "img id in: 14912\n",
      "img id out: 14912\n",
      "img id in: 14913\n",
      "img id out: 14913\n",
      "img id in: 14914\n",
      "img id out: 14914\n",
      "img id in: 14915\n",
      "img id out: 14915\n",
      "img id in: 14916\n",
      "img id out: 14916\n",
      "img id in: 14917\n",
      "img id out: 14917\n",
      "img id in: 14918\n",
      "img id out: 14918\n",
      "img id in: 14919\n",
      "img id out: 14919\n",
      "img id in: 14920\n",
      "img id out: 14920\n",
      "img id in: 14921\n",
      "img id out: 14921\n",
      "img id in: 14922\n",
      "img id out: 14922\n",
      "img id in: 14923\n",
      "img id out: 14923\n",
      "img id in: 14924\n",
      "img id out: 14924\n",
      "img id in: 14925\n",
      "img id out: 14925\n",
      "img id in: 14926\n",
      "img id out: 14926\n",
      "img id in: 14927\n",
      "img id out: 14927\n",
      "img id in: 14928\n",
      "img id out: 14928\n",
      "img id in: 14929\n",
      "img id out: 14929\n",
      "img id in: 14930\n",
      "img id out: 14930\n",
      "img id in: 14931\n",
      "img id out: 14931\n",
      "img id in: 14932\n",
      "img id out: 14932\n",
      "img id in: 14933\n",
      "img id out: 14933\n",
      "img id in: 14934\n",
      "img id out: 14934\n",
      "img id in: 14935\n",
      "img id out: 14935\n",
      "img id in: 14936\n",
      "img id out: 14936\n",
      "img id in: 14937\n",
      "img id out: 14937\n",
      "img id in: 14938\n",
      "img id out: 14938\n",
      "img id in: 14939\n",
      "img id out: 14939\n",
      "img id in: 14940\n",
      "img id out: 14940\n",
      "img id in: 14941\n",
      "img id out: 14941\n",
      "img id in: 14942\n",
      "img id out: 14942\n",
      "img id in: 14943\n",
      "img id out: 14943\n",
      "img id in: 14944\n",
      "img id out: 14944\n",
      "img id in: 14945\n",
      "img id out: 14945\n",
      "img id in: 14946\n",
      "img id out: 14946\n",
      "img id in: 14947\n",
      "img id out: 14947\n",
      "img id in: 14948\n",
      "img id out: 14948\n",
      "img id in: 14949\n",
      "img id out: 14949\n",
      "img id in: 14950\n",
      "img id out: 14950\n",
      "img id in: 14951\n",
      "img id out: 14951\n",
      "img id in: 14952\n",
      "img id out: 14952\n",
      "img id in: 14953\n",
      "img id out: 14953\n",
      "img id in: 14954\n",
      "img id out: 14954\n",
      "img id in: 14955\n",
      "img id out: 14955\n",
      "img id in: 14956\n",
      "img id out: 14956\n",
      "img id in: 14957\n",
      "img id out: 14957\n",
      "img id in: 14958\n",
      "img id out: 14958\n",
      "img id in: 14959\n",
      "img id out: 14959\n",
      "img id in: 14960\n",
      "img id out: 14960\n",
      "img id in: 14961\n",
      "img id out: 14961\n",
      "img id in: 14962\n",
      "img id out: 14962\n",
      "img id in: 14963\n",
      "img id out: 14963\n",
      "img id in: 14964\n",
      "img id out: 14964\n",
      "img id in: 14965\n",
      "img id out: 14965\n",
      "img id in: 14966\n",
      "img id out: 14966\n",
      "img id in: 14967\n",
      "img id out: 14967\n",
      "img id in: 14968\n",
      "img id out: 14968\n",
      "img id in: 14969\n",
      "img id out: 14969\n",
      "img id in: 14970\n",
      "img id out: 14970\n",
      "img id in: 14971\n",
      "img id out: 14971\n",
      "img id in: 14972\n",
      "img id out: 14972\n",
      "img id in: 14973\n",
      "img id out: 14973\n",
      "img id in: 14974\n",
      "img id out: 14974\n",
      "img id in: 14975\n",
      "img id out: 14975\n",
      "img id in: 14976\n",
      "img id out: 14976\n",
      "img id in: 14977\n",
      "img id out: 14977\n",
      "img id in: 14978\n",
      "img id out: 14978\n",
      "img id in: 14979\n",
      "img id out: 14979\n",
      "img id in: 14980\n",
      "img id out: 14980\n",
      "img id in: 14981\n",
      "img id out: 14981\n",
      "img id in: 14982\n",
      "img id out: 14982\n",
      "img id in: 14983\n",
      "img id out: 14983\n",
      "img id in: 14984\n",
      "img id out: 14984\n",
      "img id in: 14985\n",
      "img id out: 14985\n",
      "img id in: 14986\n",
      "img id out: 14986\n",
      "img id in: 14987\n",
      "img id out: 14987\n",
      "img id in: 14988\n",
      "img id out: 14988\n",
      "img id in: 14989\n",
      "img id out: 14989\n",
      "img id in: 14990\n",
      "img id out: 14990\n",
      "img id in: 14991\n",
      "img id out: 14991\n",
      "img id in: 14992\n",
      "img id out: 14992\n",
      "img id in: 14993\n",
      "img id out: 14993\n",
      "img id in: 14994\n",
      "img id out: 14994\n",
      "img id in: 14995\n",
      "img id out: 14995\n",
      "img id in: 14996\n",
      "img id out: 14996\n",
      "img id in: 14997\n",
      "img id out: 14997\n",
      "img id in: 14998\n",
      "img id out: 14998\n",
      "img id in: 14999\n",
      "img id out: 14999\n",
      "img id in: 15000\n",
      "img id out: 15000\n",
      "img id in: 15001\n",
      "img id out: 15001\n",
      "img id in: 15002\n",
      "img id out: 15002\n",
      "img id in: 15003\n",
      "img id out: 15003\n",
      "img id in: 15004\n",
      "img id out: 15004\n",
      "img id in: 15005\n",
      "img id out: 15005\n",
      "img id in: 15006\n",
      "img id out: 15006\n",
      "img id in: 15007\n",
      "img id out: 15007\n",
      "img id in: 15008\n",
      "img id out: 15008\n",
      "img id in: 15009\n",
      "img id out: 15009\n",
      "img id in: 15010\n",
      "img id out: 15010\n",
      "img id in: 15011\n",
      "img id out: 15011\n",
      "img id in: 15012\n",
      "img id out: 15012\n",
      "img id in: 15013\n",
      "img id out: 15013\n",
      "img id in: 15014\n",
      "img id out: 15014\n",
      "img id in: 15015\n",
      "img id out: 15015\n",
      "img id in: 15016\n",
      "img id out: 15016\n",
      "img id in: 15017\n",
      "img id out: 15017\n",
      "img id in: 15018\n",
      "img id out: 15018\n",
      "img id in: 15019\n",
      "img id out: 15019\n",
      "img id in: 15020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 15020\n",
      "img id in: 15021\n",
      "img id out: 15021\n",
      "img id in: 15022\n",
      "img id out: 15022\n",
      "img id in: 15023\n",
      "img id out: 15023\n",
      "img id in: 15024\n",
      "img id out: 15024\n",
      "img id in: 15025\n",
      "img id out: 15025\n",
      "img id in: 15026\n",
      "img id out: 15026\n",
      "img id in: 15027\n",
      "img id out: 15027\n",
      "img id in: 15028\n",
      "img id out: 15028\n",
      "img id in: 15029\n",
      "img id out: 15029\n",
      "img id in: 15030\n",
      "img id out: 15030\n",
      "img id in: 15031\n",
      "img id out: 15031\n",
      "img id in: 15032\n",
      "img id out: 15032\n",
      "img id in: 15033\n",
      "img id out: 15033\n",
      "img id in: 15034\n",
      "img id out: 15034\n",
      "img id in: 15035\n",
      "img id out: 15035\n",
      "img id in: 15036\n",
      "img id out: 15036\n",
      "img id in: 15037\n",
      "img id out: 15037\n",
      "img id in: 15038\n",
      "img id out: 15038\n",
      "img id in: 15039\n",
      "img id out: 15039\n",
      "img id in: 15040\n",
      "img id out: 15040\n",
      "img id in: 15041\n",
      "img id out: 15041\n",
      "img id in: 15042\n",
      "img id out: 15042\n",
      "img id in: 15043\n",
      "img id out: 15043\n",
      "img id in: 15044\n",
      "img id out: 15044\n",
      "img id in: 15045\n",
      "img id out: 15045\n",
      "img id in: 15046\n",
      "img id out: 15046\n",
      "img id in: 15047\n",
      "img id out: 15047\n",
      "img id in: 15048\n",
      "img id out: 15048\n",
      "img id in: 15049\n",
      "img id out: 15049\n",
      "img id in: 15050\n",
      "img id out: 15050\n",
      "img id in: 15051\n",
      "img id out: 15051\n",
      "img id in: 15052\n",
      "img id out: 15052\n",
      "img id in: 15053\n",
      "img id out: 15053\n",
      "img id in: 15054\n",
      "img id out: 15054\n",
      "img id in: 15055\n",
      "img id out: 15055\n",
      "img id in: 15056\n",
      "img id out: 15056\n",
      "img id in: 15057\n",
      "img id out: 15057\n",
      "img id in: 15058\n",
      "img id out: 15058\n",
      "img id in: 15059\n",
      "img id out: 15059\n",
      "img id in: 15060\n",
      "img id out: 15060\n",
      "img id in: 15061\n",
      "img id out: 15061\n",
      "img id in: 15062\n",
      "img id out: 15062\n",
      "img id in: 15063\n",
      "img id out: 15063\n",
      "img id in: 15064\n",
      "img id out: 15064\n",
      "img id in: 15065\n",
      "img id out: 15065\n",
      "img id in: 15066\n",
      "img id out: 15066\n",
      "img id in: 15067\n",
      "img id out: 15067\n",
      "img id in: 15068\n",
      "img id out: 15068\n",
      "img id in: 15069\n",
      "img id out: 15069\n",
      "img id in: 15070\n",
      "img id out: 15070\n",
      "img id in: 15071\n",
      "img id out: 15071\n",
      "img id in: 15072\n",
      "img id out: 15072\n",
      "img id in: 15073\n",
      "img id out: 15073\n",
      "img id in: 15074\n",
      "img id out: 15074\n",
      "img id in: 15075\n",
      "img id out: 15075\n",
      "img id in: 15076\n",
      "img id out: 15076\n",
      "img id in: 15077\n",
      "img id out: 15077\n",
      "img id in: 15078\n",
      "img id out: 15078\n",
      "img id in: 15079\n",
      "img id out: 15079\n",
      "img id in: 15080\n",
      "img id out: 15080\n",
      "img id in: 15081\n",
      "img id out: 15081\n",
      "img id in: 15082\n",
      "img id out: 15082\n",
      "img id in: 15083\n",
      "img id out: 15083\n",
      "img id in: 15084\n",
      "img id out: 15084\n",
      "img id in: 15085\n",
      "img id out: 15085\n",
      "img id in: 15086\n",
      "img id out: 15086\n",
      "img id in: 15087\n",
      "img id out: 15087\n",
      "img id in: 15088\n",
      "img id out: 15088\n",
      "img id in: 15089\n",
      "img id out: 15089\n",
      "img id in: 15090\n",
      "img id out: 15090\n",
      "img id in: 15091\n",
      "img id out: 15091\n",
      "img id in: 15092\n",
      "img id out: 15092\n",
      "img id in: 15093\n",
      "img id out: 15093\n",
      "img id in: 15094\n",
      "img id out: 15094\n",
      "img id in: 15095\n",
      "img id out: 15095\n",
      "img id in: 15096\n",
      "img id out: 15096\n",
      "img id in: 15097\n",
      "img id out: 15097\n",
      "img id in: 15098\n",
      "img id out: 15098\n",
      "img id in: 15099\n",
      "img id out: 15099\n",
      "img id in: 15100\n",
      "img id out: 15100\n",
      "img id in: 15101\n",
      "img id out: 15101\n",
      "img id in: 15102\n",
      "img id out: 15102\n",
      "img id in: 15103\n",
      "img id out: 15103\n",
      "img id in: 15104\n",
      "img id out: 15104\n",
      "img id in: 15105\n",
      "img id out: 15105\n",
      "img id in: 15106\n",
      "img id out: 15106\n",
      "img id in: 15107\n",
      "img id out: 15107\n",
      "img id in: 15108\n",
      "img id out: 15108\n",
      "img id in: 15109\n",
      "img id out: 15109\n",
      "img id in: 15110\n",
      "img id out: 15110\n",
      "img id in: 15111\n",
      "img id out: 15111\n",
      "img id in: 15112\n",
      "img id out: 15112\n",
      "img id in: 15113\n",
      "img id out: 15113\n",
      "img id in: 15114\n",
      "img id out: 15114\n",
      "img id in: 15115\n",
      "img id out: 15115\n",
      "img id in: 15116\n",
      "img id out: 15116\n",
      "img id in: 15117\n",
      "img id out: 15117\n",
      "img id in: 15118\n",
      "img id out: 15118\n",
      "img id in: 15119\n",
      "img id out: 15119\n",
      "img id in: 15120\n",
      "img id out: 15120\n",
      "img id in: 15121\n",
      "img id out: 15121\n",
      "img id in: 15122\n",
      "img id out: 15122\n",
      "img id in: 15123\n",
      "img id out: 15123\n",
      "img id in: 15124\n",
      "img id out: 15124\n",
      "img id in: 15125\n",
      "img id out: 15125\n",
      "img id in: 15126\n",
      "img id out: 15126\n",
      "img id in: 15127\n",
      "img id out: 15127\n",
      "img id in: 15128\n",
      "img id out: 15128\n",
      "img id in: 15129\n",
      "img id out: 15129\n",
      "img id in: 15130\n",
      "img id out: 15130\n",
      "img id in: 15131\n",
      "img id out: 15131\n",
      "img id in: 15132\n",
      "img id out: 15132\n",
      "img id in: 15133\n",
      "img id out: 15133\n",
      "img id in: 15134\n",
      "img id out: 15134\n",
      "img id in: 15135\n",
      "img id out: 15135\n",
      "img id in: 15136\n",
      "img id out: 15136\n",
      "img id in: 15137\n",
      "img id out: 15137\n",
      "img id in: 15138\n",
      "img id out: 15138\n",
      "img id in: 15139\n",
      "img id out: 15139\n",
      "img id in: 15140\n",
      "img id out: 15140\n",
      "img id in: 15141\n",
      "img id out: 15141\n",
      "img id in: 15142\n",
      "img id out: 15142\n",
      "img id in: 15143\n",
      "img id out: 15143\n",
      "img id in: 15144\n",
      "img id out: 15144\n",
      "img id in: 15145\n",
      "img id out: 15145\n",
      "img id in: 15146\n",
      "img id out: 15146\n",
      "img id in: 15147\n",
      "img id out: 15147\n",
      "img id in: 15148\n",
      "img id out: 15148\n",
      "img id in: 15149\n",
      "img id out: 15149\n",
      "img id in: 15150\n",
      "img id out: 15150\n",
      "img id in: 15151\n",
      "img id out: 15151\n",
      "img id in: 15152\n",
      "img id out: 15152\n",
      "img id in: 15153\n",
      "img id out: 15153\n",
      "img id in: 15154\n",
      "img id out: 15154\n",
      "img id in: 15155\n",
      "img id out: 15155\n",
      "img id in: 15156\n",
      "img id out: 15156\n",
      "img id in: 15157\n",
      "img id out: 15157\n",
      "img id in: 15158\n",
      "img id out: 15158\n",
      "img id in: 15159\n",
      "img id out: 15159\n",
      "img id in: 15160\n",
      "img id out: 15160\n",
      "img id in: 15161\n",
      "img id out: 15161\n",
      "img id in: 15162\n",
      "img id out: 15162\n",
      "img id in: 15163\n",
      "img id out: 15163\n",
      "img id in: 15164\n",
      "img id out: 15164\n",
      "img id in: 15165\n",
      "img id out: 15165\n",
      "img id in: 15166\n",
      "img id out: 15166\n",
      "img id in: 15167\n",
      "img id out: 15167\n",
      "img id in: 15168\n",
      "img id out: 15168\n",
      "img id in: 15169\n",
      "img id out: 15169\n",
      "img id in: 15170\n",
      "img id out: 15170\n",
      "img id in: 15171\n",
      "img id out: 15171\n",
      "img id in: 15172\n",
      "img id out: 15172\n",
      "img id in: 15173\n",
      "img id out: 15173\n",
      "img id in: 15174\n",
      "img id out: 15174\n",
      "img id in: 15175\n",
      "img id out: 15175\n",
      "img id in: 15176\n",
      "img id out: 15176\n",
      "img id in: 15177\n",
      "img id out: 15177\n",
      "img id in: 15178\n",
      "img id out: 15178\n",
      "img id in: 15179\n",
      "img id out: 15179\n",
      "img id in: 15180\n",
      "img id out: 15180\n",
      "img id in: 15181\n",
      "img id out: 15181\n",
      "img id in: 15182\n",
      "img id out: 15182\n",
      "img id in: 15183\n",
      "img id out: 15183\n",
      "img id in: 15184\n",
      "img id out: 15184\n",
      "img id in: 15185\n",
      "img id out: 15185\n",
      "img id in: 15186\n",
      "img id out: 15186\n",
      "img id in: 15187\n",
      "img id out: 15187\n",
      "img id in: 15188\n",
      "img id out: 15188\n",
      "img id in: 15189\n",
      "img id out: 15189\n",
      "img id in: 15190\n",
      "img id out: 15190\n",
      "img id in: 15191\n",
      "img id out: 15191\n",
      "img id in: 15192\n",
      "img id out: 15192\n",
      "img id in: 15193\n",
      "img id out: 15193\n",
      "img id in: 15194\n",
      "img id out: 15194\n",
      "img id in: 15195\n",
      "img id out: 15195\n",
      "img id in: 15196\n",
      "img id out: 15196\n",
      "img id in: 15197\n",
      "img id out: 15197\n",
      "img id in: 15198\n",
      "img id out: 15198\n",
      "img id in: 15199\n",
      "img id out: 15199\n",
      "img id in: 15200\n",
      "img id out: 15200\n",
      "img id in: 15201\n",
      "img id out: 15201\n",
      "img id in: 15202\n",
      "img id out: 15202\n",
      "img id in: 15203\n",
      "img id out: 15203\n",
      "img id in: 15204\n",
      "img id out: 15204\n",
      "img id in: 15205\n",
      "img id out: 15205\n",
      "img id in: 15206\n",
      "img id out: 15206\n",
      "img id in: 15207\n",
      "img id out: 15207\n",
      "img id in: 15208\n",
      "img id out: 15208\n",
      "img id in: 15209\n",
      "img id out: 15209\n",
      "img id in: 15210\n",
      "img id out: 15210\n",
      "img id in: 15211\n",
      "img id out: 15211\n",
      "img id in: 15212\n",
      "img id out: 15212\n",
      "img id in: 15213\n",
      "img id out: 15213\n",
      "img id in: 15214\n",
      "img id out: 15214\n",
      "img id in: 15215\n",
      "img id out: 15215\n",
      "img id in: 15216\n",
      "img id out: 15216\n",
      "img id in: 15217\n",
      "img id out: 15217\n",
      "img id in: 15218\n",
      "img id out: 15218\n",
      "img id in: 15219\n",
      "img id out: 15219\n",
      "img id in: 15220\n",
      "img id out: 15220\n",
      "img id in: 15221\n",
      "img id out: 15221\n",
      "img id in: 15222\n",
      "img id out: 15222\n",
      "img id in: 15223\n",
      "img id out: 15223\n",
      "img id in: 15224\n",
      "img id out: 15224\n",
      "img id in: 15225\n",
      "img id out: 15225\n",
      "img id in: 15226\n",
      "img id out: 15226\n",
      "img id in: 15227\n",
      "img id out: 15227\n",
      "img id in: 15228\n",
      "img id out: 15228\n",
      "img id in: 15229\n",
      "img id out: 15229\n",
      "img id in: 15230\n",
      "img id out: 15230\n",
      "img id in: 15231\n",
      "img id out: 15231\n",
      "img id in: 15232\n",
      "img id out: 15232\n",
      "img id in: 15233\n",
      "img id out: 15233\n",
      "img id in: 15234\n",
      "img id out: 15234\n",
      "img id in: 15235\n",
      "img id out: 15235\n",
      "img id in: 15236\n",
      "img id out: 15236\n",
      "img id in: 15237\n",
      "img id out: 15237\n",
      "img id in: 15238\n",
      "img id out: 15238\n",
      "img id in: 15239\n",
      "img id out: 15239\n",
      "img id in: 15240\n",
      "img id out: 15240\n",
      "img id in: 15241\n",
      "img id out: 15241\n",
      "img id in: 15242\n",
      "img id out: 15242\n",
      "img id in: 15243\n",
      "img id out: 15243\n",
      "img id in: 15244\n",
      "img id out: 15244\n",
      "img id in: 15245\n",
      "img id out: 15245\n",
      "img id in: 15246\n",
      "img id out: 15246\n",
      "img id in: 15247\n",
      "img id out: 15247\n",
      "img id in: 15248\n",
      "img id out: 15248\n",
      "img id in: 15249\n",
      "img id out: 15249\n",
      "img id in: 15250\n",
      "img id out: 15250\n",
      "img id in: 15251\n",
      "img id out: 15251\n",
      "img id in: 15252\n",
      "img id out: 15252\n",
      "img id in: 15253\n",
      "img id out: 15253\n",
      "img id in: 15254\n",
      "img id out: 15254\n",
      "img id in: 15255\n",
      "img id out: 15255\n",
      "img id in: 15256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 15256\n",
      "img id in: 15257\n",
      "img id out: 15257\n",
      "img id in: 15258\n",
      "img id out: 15258\n",
      "img id in: 15259\n",
      "img id out: 15259\n",
      "img id in: 15260\n",
      "img id out: 15260\n",
      "img id in: 15261\n",
      "img id out: 15261\n",
      "img id in: 15262\n",
      "img id out: 15262\n",
      "img id in: 15263\n",
      "img id out: 15263\n",
      "img id in: 15264\n",
      "img id out: 15264\n",
      "img id in: 15265\n",
      "img id out: 15265\n",
      "img id in: 15266\n",
      "img id out: 15266\n",
      "img id in: 15267\n",
      "img id out: 15267\n",
      "img id in: 15268\n",
      "img id out: 15268\n",
      "img id in: 15269\n",
      "img id out: 15269\n",
      "img id in: 15270\n",
      "img id out: 15270\n",
      "img id in: 15271\n",
      "img id out: 15271\n",
      "img id in: 15272\n",
      "img id out: 15272\n",
      "img id in: 15273\n",
      "img id out: 15273\n",
      "img id in: 15274\n",
      "img id out: 15274\n",
      "img id in: 15275\n",
      "img id out: 15275\n",
      "img id in: 15276\n",
      "img id out: 15276\n",
      "img id in: 15277\n",
      "img id out: 15277\n",
      "img id in: 15278\n",
      "img id out: 15278\n",
      "img id in: 15279\n",
      "img id out: 15279\n",
      "img id in: 15280\n",
      "img id out: 15280\n",
      "img id in: 15281\n",
      "img id out: 15281\n",
      "img id in: 15282\n",
      "img id out: 15282\n",
      "img id in: 15283\n",
      "img id out: 15283\n",
      "img id in: 15284\n",
      "img id out: 15284\n",
      "img id in: 15285\n",
      "img id out: 15285\n",
      "img id in: 15286\n",
      "img id out: 15286\n",
      "img id in: 15287\n",
      "img id out: 15287\n",
      "img id in: 15288\n",
      "img id out: 15288\n",
      "img id in: 15289\n",
      "img id out: 15289\n",
      "img id in: 15290\n",
      "img id out: 15290\n",
      "img id in: 15291\n",
      "img id out: 15291\n",
      "img id in: 15292\n",
      "img id out: 15292\n",
      "img id in: 15293\n",
      "img id out: 15293\n",
      "img id in: 15294\n",
      "img id out: 15294\n",
      "img id in: 15295\n",
      "img id out: 15295\n",
      "img id in: 15296\n",
      "img id out: 15296\n",
      "img id in: 15297\n",
      "img id out: 15297\n",
      "img id in: 15298\n",
      "img id out: 15298\n",
      "img id in: 15299\n",
      "img id out: 15299\n",
      "img id in: 15300\n",
      "img id out: 15300\n",
      "img id in: 15301\n",
      "img id out: 15301\n",
      "img id in: 15302\n",
      "img id out: 15302\n",
      "img id in: 15303\n",
      "img id out: 15303\n",
      "img id in: 15304\n",
      "img id out: 15304\n",
      "img id in: 15305\n",
      "img id out: 15305\n",
      "img id in: 15306\n",
      "img id out: 15306\n",
      "img id in: 15307\n",
      "img id out: 15307\n",
      "img id in: 15308\n",
      "img id out: 15308\n",
      "img id in: 15309\n",
      "img id out: 15309\n",
      "img id in: 15310\n",
      "img id out: 15310\n",
      "img id in: 15311\n",
      "img id out: 15311\n",
      "img id in: 15312\n",
      "img id out: 15312\n",
      "img id in: 15313\n",
      "img id out: 15313\n",
      "img id in: 15314\n",
      "img id out: 15314\n",
      "img id in: 15315\n",
      "img id out: 15315\n",
      "img id in: 15316\n",
      "img id out: 15316\n",
      "img id in: 15317\n",
      "img id out: 15317\n",
      "img id in: 15318\n",
      "img id out: 15318\n",
      "img id in: 15319\n",
      "img id out: 15319\n",
      "img id in: 15320\n",
      "img id out: 15320\n",
      "img id in: 15321\n",
      "img id out: 15321\n",
      "img id in: 15322\n",
      "img id out: 15322\n",
      "img id in: 15323\n",
      "img id out: 15323\n",
      "img id in: 15324\n",
      "img id out: 15324\n",
      "img id in: 15325\n",
      "img id out: 15325\n",
      "img id in: 15326\n",
      "img id out: 15326\n",
      "img id in: 15327\n",
      "img id out: 15327\n",
      "img id in: 15328\n",
      "img id out: 15328\n",
      "img id in: 15329\n",
      "img id out: 15329\n",
      "img id in: 15330\n",
      "img id out: 15330\n",
      "img id in: 15331\n",
      "img id out: 15331\n",
      "img id in: 15332\n",
      "img id out: 15332\n",
      "img id in: 15333\n",
      "img id out: 15333\n",
      "img id in: 15334\n",
      "img id out: 15334\n",
      "img id in: 15335\n",
      "img id out: 15335\n",
      "img id in: 15336\n",
      "img id out: 15336\n",
      "img id in: 15337\n",
      "img id out: 15337\n",
      "img id in: 15338\n",
      "img id out: 15338\n",
      "img id in: 15339\n",
      "img id out: 15339\n",
      "img id in: 15340\n",
      "img id out: 15340\n",
      "img id in: 15341\n",
      "img id out: 15341\n",
      "img id in: 15342\n",
      "img id out: 15342\n",
      "img id in: 15343\n",
      "img id out: 15343\n",
      "img id in: 15344\n",
      "img id out: 15344\n",
      "img id in: 15345\n",
      "img id out: 15345\n",
      "img id in: 15346\n",
      "img id out: 15346\n",
      "img id in: 15347\n",
      "img id out: 15347\n",
      "img id in: 15348\n",
      "img id out: 15348\n",
      "img id in: 15349\n",
      "img id out: 15349\n",
      "img id in: 15350\n",
      "img id out: 15350\n",
      "img id in: 15351\n",
      "img id out: 15351\n",
      "img id in: 15352\n",
      "img id out: 15352\n",
      "img id in: 15353\n",
      "img id out: 15353\n",
      "img id in: 15354\n",
      "img id out: 15354\n",
      "img id in: 15355\n",
      "img id out: 15355\n",
      "img id in: 15356\n",
      "img id out: 15356\n",
      "img id in: 15357\n",
      "img id out: 15357\n",
      "img id in: 15358\n",
      "img id out: 15358\n",
      "img id in: 15359\n",
      "img id out: 15359\n",
      "img id in: 15360\n",
      "img id out: 15360\n",
      "img id in: 15361\n",
      "img id out: 15361\n",
      "img id in: 15362\n",
      "img id out: 15362\n",
      "img id in: 15363\n",
      "img id out: 15363\n",
      "img id in: 15364\n",
      "img id out: 15364\n",
      "img id in: 15365\n",
      "img id out: 15365\n",
      "img id in: 15366\n",
      "img id out: 15366\n",
      "img id in: 15367\n",
      "img id out: 15367\n",
      "img id in: 15368\n",
      "img id out: 15368\n",
      "img id in: 15369\n",
      "img id out: 15369\n",
      "img id in: 15370\n",
      "img id out: 15370\n",
      "img id in: 15371\n",
      "img id out: 15371\n",
      "img id in: 15372\n",
      "img id out: 15372\n",
      "img id in: 15373\n",
      "img id out: 15373\n",
      "img id in: 15374\n",
      "img id out: 15374\n",
      "img id in: 15375\n",
      "img id out: 15375\n",
      "img id in: 15376\n",
      "img id out: 15376\n",
      "img id in: 15377\n",
      "img id out: 15377\n",
      "img id in: 15378\n",
      "img id out: 15378\n",
      "img id in: 15379\n",
      "img id out: 15379\n",
      "img id in: 15380\n",
      "img id out: 15380\n",
      "img id in: 15381\n",
      "img id out: 15381\n",
      "img id in: 15382\n",
      "img id out: 15382\n",
      "img id in: 15383\n",
      "img id out: 15383\n",
      "img id in: 15384\n",
      "img id out: 15384\n",
      "img id in: 15385\n",
      "img id out: 15385\n",
      "img id in: 15386\n",
      "img id out: 15386\n",
      "img id in: 15387\n",
      "img id out: 15387\n",
      "img id in: 15388\n",
      "img id out: 15388\n",
      "img id in: 15389\n",
      "img id out: 15389\n",
      "img id in: 15390\n",
      "img id out: 15390\n",
      "img id in: 15391\n",
      "img id out: 15391\n",
      "img id in: 15392\n",
      "img id out: 15392\n",
      "img id in: 15393\n",
      "img id out: 15393\n",
      "img id in: 15394\n",
      "img id out: 15394\n",
      "img id in: 15395\n",
      "img id out: 15395\n",
      "img id in: 15396\n",
      "img id out: 15396\n",
      "img id in: 15397\n",
      "img id out: 15397\n",
      "img id in: 15398\n",
      "img id out: 15398\n",
      "img id in: 15399\n",
      "img id out: 15399\n",
      "img id in: 15400\n",
      "img id out: 15400\n",
      "img id in: 15401\n",
      "img id out: 15401\n",
      "img id in: 15402\n",
      "img id out: 15402\n",
      "img id in: 15403\n",
      "img id out: 15403\n",
      "img id in: 15404\n",
      "img id out: 15404\n",
      "img id in: 15405\n",
      "img id out: 15405\n",
      "img id in: 15406\n",
      "img id out: 15406\n",
      "img id in: 15407\n",
      "img id out: 15407\n",
      "img id in: 15408\n",
      "img id out: 15408\n",
      "img id in: 15409\n",
      "img id out: 15409\n",
      "img id in: 15410\n",
      "img id out: 15410\n",
      "img id in: 15411\n",
      "img id out: 15411\n",
      "img id in: 15412\n",
      "img id out: 15412\n",
      "img id in: 15413\n",
      "img id out: 15413\n",
      "img id in: 15414\n",
      "img id out: 15414\n",
      "img id in: 15415\n",
      "img id out: 15415\n",
      "img id in: 15416\n",
      "img id out: 15416\n",
      "img id in: 15417\n",
      "img id out: 15417\n",
      "img id in: 15418\n",
      "img id out: 15418\n",
      "img id in: 15419\n",
      "img id out: 15419\n",
      "img id in: 15420\n",
      "img id out: 15420\n",
      "img id in: 15421\n",
      "img id out: 15421\n",
      "img id in: 15422\n",
      "img id out: 15422\n",
      "img id in: 15423\n",
      "img id out: 15423\n",
      "img id in: 15424\n",
      "img id out: 15424\n",
      "img id in: 15425\n",
      "img id out: 15425\n",
      "img id in: 15426\n",
      "img id out: 15426\n",
      "img id in: 15427\n",
      "img id out: 15427\n",
      "img id in: 15428\n",
      "img id out: 15428\n",
      "img id in: 15429\n",
      "img id out: 15429\n",
      "img id in: 15430\n",
      "img id out: 15430\n",
      "img id in: 15431\n",
      "img id out: 15431\n",
      "img id in: 15432\n",
      "img id out: 15432\n",
      "img id in: 15433\n",
      "img id out: 15433\n",
      "img id in: 15434\n",
      "img id out: 15434\n",
      "img id in: 15435\n",
      "img id out: 15435\n",
      "img id in: 15436\n",
      "img id out: 15436\n",
      "img id in: 15437\n",
      "img id out: 15437\n",
      "img id in: 15438\n",
      "img id out: 15438\n",
      "img id in: 15439\n",
      "img id out: 15439\n",
      "img id in: 15440\n",
      "img id out: 15440\n",
      "img id in: 15441\n",
      "img id out: 15441\n",
      "img id in: 15442\n",
      "img id out: 15442\n",
      "img id in: 15443\n",
      "img id out: 15443\n",
      "img id in: 15444\n",
      "img id out: 15444\n",
      "img id in: 15445\n",
      "img id out: 15445\n",
      "img id in: 15446\n",
      "img id out: 15446\n",
      "img id in: 15447\n",
      "img id out: 15447\n",
      "img id in: 15448\n",
      "img id out: 15448\n",
      "img id in: 15449\n",
      "img id out: 15449\n",
      "img id in: 15450\n",
      "img id out: 15450\n",
      "img id in: 15451\n",
      "img id out: 15451\n",
      "img id in: 15452\n",
      "img id out: 15452\n",
      "img id in: 15453\n",
      "img id out: 15453\n",
      "img id in: 15454\n",
      "img id out: 15454\n",
      "img id in: 15455\n",
      "img id out: 15455\n",
      "img id in: 15456\n",
      "img id out: 15456\n",
      "img id in: 15457\n",
      "img id out: 15457\n",
      "img id in: 15458\n",
      "img id out: 15458\n",
      "img id in: 15459\n",
      "img id out: 15459\n",
      "img id in: 15460\n",
      "img id out: 15460\n",
      "img id in: 15461\n",
      "img id out: 15461\n",
      "img id in: 15462\n",
      "img id out: 15462\n",
      "img id in: 15463\n",
      "img id out: 15463\n",
      "img id in: 15464\n",
      "img id out: 15464\n",
      "img id in: 15465\n",
      "img id out: 15465\n",
      "img id in: 15466\n",
      "img id out: 15466\n",
      "img id in: 15467\n",
      "img id out: 15467\n",
      "img id in: 15468\n",
      "img id out: 15468\n",
      "img id in: 15469\n",
      "img id out: 15469\n",
      "img id in: 15470\n",
      "img id out: 15470\n",
      "img id in: 15471\n",
      "img id out: 15471\n",
      "img id in: 15472\n",
      "img id out: 15472\n",
      "img id in: 15473\n",
      "img id out: 15473\n",
      "img id in: 15474\n",
      "img id out: 15474\n",
      "img id in: 15475\n",
      "img id out: 15475\n",
      "img id in: 15476\n",
      "img id out: 15476\n",
      "img id in: 15477\n",
      "img id out: 15477\n",
      "img id in: 15478\n",
      "img id out: 15478\n",
      "img id in: 15479\n",
      "img id out: 15479\n",
      "img id in: 15480\n",
      "img id out: 15480\n",
      "img id in: 15481\n",
      "img id out: 15481\n",
      "img id in: 15482\n",
      "img id out: 15482\n",
      "img id in: 15483\n",
      "img id out: 15483\n",
      "img id in: 15484\n",
      "img id out: 15484\n",
      "img id in: 15485\n",
      "img id out: 15485\n",
      "img id in: 15486\n",
      "img id out: 15486\n",
      "img id in: 15487\n",
      "img id out: 15487\n",
      "img id in: 15488\n",
      "img id out: 15488\n",
      "img id in: 15489\n",
      "img id out: 15489\n",
      "img id in: 15490\n",
      "img id out: 15490\n",
      "img id in: 15491\n",
      "img id out: 15491\n",
      "img id in: 15492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 15492\n",
      "img id in: 15493\n",
      "img id out: 15493\n",
      "img id in: 15494\n",
      "img id out: 15494\n",
      "img id in: 15495\n",
      "img id out: 15495\n",
      "img id in: 15496\n",
      "img id out: 15496\n",
      "img id in: 15497\n",
      "img id out: 15497\n",
      "img id in: 15498\n",
      "img id out: 15498\n",
      "img id in: 15499\n",
      "img id out: 15499\n",
      "img id in: 15500\n",
      "img id out: 15500\n",
      "img id in: 15501\n",
      "img id out: 15501\n",
      "img id in: 15502\n",
      "img id out: 15502\n",
      "img id in: 15503\n",
      "img id out: 15503\n",
      "img id in: 15504\n",
      "img id out: 15504\n",
      "img id in: 15505\n",
      "img id out: 15505\n",
      "img id in: 15506\n",
      "img id out: 15506\n",
      "img id in: 15507\n",
      "img id out: 15507\n",
      "img id in: 15508\n",
      "img id out: 15508\n",
      "img id in: 15509\n",
      "img id out: 15509\n",
      "img id in: 15510\n",
      "img id out: 15510\n",
      "img id in: 15511\n",
      "img id out: 15511\n",
      "img id in: 15512\n",
      "img id out: 15512\n",
      "img id in: 15513\n",
      "img id out: 15513\n",
      "img id in: 15514\n",
      "img id out: 15514\n",
      "img id in: 15515\n",
      "img id out: 15515\n",
      "img id in: 15516\n",
      "img id out: 15516\n",
      "img id in: 15517\n",
      "img id out: 15517\n",
      "img id in: 15518\n",
      "img id out: 15518\n",
      "img id in: 15519\n",
      "img id out: 15519\n",
      "img id in: 15520\n",
      "img id out: 15520\n",
      "img id in: 15521\n",
      "img id out: 15521\n",
      "img id in: 15522\n",
      "img id out: 15522\n",
      "img id in: 15523\n",
      "img id out: 15523\n",
      "img id in: 15524\n",
      "img id out: 15524\n",
      "img id in: 15525\n",
      "img id out: 15525\n",
      "img id in: 15526\n",
      "img id out: 15526\n",
      "img id in: 15527\n",
      "img id out: 15527\n",
      "img id in: 15528\n",
      "img id out: 15528\n",
      "img id in: 15529\n",
      "img id out: 15529\n",
      "img id in: 15530\n",
      "img id out: 15530\n",
      "img id in: 15531\n",
      "img id out: 15531\n",
      "img id in: 15532\n",
      "img id out: 15532\n",
      "img id in: 15533\n",
      "img id out: 15533\n",
      "img id in: 15534\n",
      "img id out: 15534\n",
      "img id in: 15535\n",
      "img id out: 15535\n",
      "img id in: 15536\n",
      "img id out: 15536\n",
      "img id in: 15537\n",
      "img id out: 15537\n",
      "img id in: 15538\n",
      "img id out: 15538\n",
      "img id in: 15539\n",
      "img id out: 15539\n",
      "img id in: 15540\n",
      "img id out: 15540\n",
      "img id in: 15541\n",
      "img id out: 15541\n",
      "img id in: 15542\n",
      "img id out: 15542\n",
      "img id in: 15543\n",
      "img id out: 15543\n",
      "img id in: 15544\n",
      "img id out: 15544\n",
      "img id in: 15545\n",
      "img id out: 15545\n",
      "img id in: 15546\n",
      "img id out: 15546\n",
      "img id in: 15547\n",
      "img id out: 15547\n",
      "img id in: 15548\n",
      "img id out: 15548\n",
      "img id in: 15549\n",
      "img id out: 15549\n",
      "img id in: 15550\n",
      "img id out: 15550\n",
      "img id in: 15551\n",
      "img id out: 15551\n",
      "img id in: 15552\n",
      "img id out: 15552\n",
      "img id in: 15553\n",
      "img id out: 15553\n",
      "img id in: 15554\n",
      "img id out: 15554\n",
      "img id in: 15555\n",
      "img id out: 15555\n",
      "img id in: 15556\n",
      "img id out: 15556\n",
      "img id in: 15557\n",
      "img id out: 15557\n",
      "img id in: 15558\n",
      "img id out: 15558\n",
      "img id in: 15559\n",
      "img id out: 15559\n",
      "img id in: 15560\n",
      "img id out: 15560\n",
      "img id in: 15561\n",
      "img id out: 15561\n",
      "img id in: 15562\n",
      "img id out: 15562\n",
      "img id in: 15563\n",
      "img id out: 15563\n",
      "img id in: 15564\n",
      "img id out: 15564\n",
      "img id in: 15565\n",
      "img id out: 15565\n",
      "img id in: 15566\n",
      "img id out: 15566\n",
      "img id in: 15567\n",
      "img id out: 15567\n",
      "img id in: 15568\n",
      "img id out: 15568\n",
      "img id in: 15569\n",
      "img id out: 15569\n",
      "img id in: 15570\n",
      "img id out: 15570\n",
      "img id in: 15571\n",
      "img id out: 15571\n",
      "img id in: 15572\n",
      "img id out: 15572\n",
      "img id in: 15573\n",
      "img id out: 15573\n",
      "img id in: 15574\n",
      "img id out: 15574\n",
      "img id in: 15575\n",
      "img id out: 15575\n",
      "img id in: 15576\n",
      "img id out: 15576\n",
      "img id in: 15577\n",
      "img id out: 15577\n",
      "img id in: 15578\n",
      "img id out: 15578\n",
      "img id in: 15579\n",
      "img id out: 15579\n",
      "img id in: 15580\n",
      "img id out: 15580\n",
      "img id in: 15581\n",
      "img id out: 15581\n",
      "img id in: 15582\n",
      "img id out: 15582\n",
      "img id in: 15583\n",
      "img id out: 15583\n",
      "img id in: 15584\n",
      "img id out: 15584\n",
      "img id in: 15585\n",
      "img id out: 15585\n",
      "img id in: 15586\n",
      "img id out: 15586\n",
      "img id in: 15587\n",
      "img id out: 15587\n",
      "img id in: 15588\n",
      "img id out: 15588\n",
      "img id in: 15589\n",
      "img id out: 15589\n",
      "img id in: 15590\n",
      "img id out: 15590\n",
      "img id in: 15591\n",
      "img id out: 15591\n",
      "img id in: 15592\n",
      "img id out: 15592\n",
      "img id in: 15593\n",
      "img id out: 15593\n",
      "img id in: 15594\n",
      "img id out: 15594\n",
      "img id in: 15595\n",
      "img id out: 15595\n",
      "img id in: 15596\n",
      "img id out: 15596\n",
      "img id in: 15597\n",
      "img id out: 15597\n",
      "img id in: 15598\n",
      "img id out: 15598\n",
      "img id in: 15599\n",
      "img id out: 15599\n",
      "img id in: 15600\n",
      "img id out: 15600\n",
      "img id in: 15601\n",
      "img id out: 15601\n",
      "img id in: 15602\n",
      "img id out: 15602\n",
      "img id in: 15603\n",
      "img id out: 15603\n",
      "img id in: 15604\n",
      "img id out: 15604\n",
      "img id in: 15605\n",
      "img id out: 15605\n",
      "img id in: 15606\n",
      "img id out: 15606\n",
      "img id in: 15607\n",
      "img id out: 15607\n",
      "img id in: 15608\n",
      "img id out: 15608\n",
      "img id in: 15609\n",
      "img id out: 15609\n",
      "img id in: 15610\n",
      "img id out: 15610\n",
      "img id in: 15611\n",
      "img id out: 15611\n",
      "img id in: 15612\n",
      "img id out: 15612\n",
      "img id in: 15613\n",
      "img id out: 15613\n",
      "img id in: 15614\n",
      "img id out: 15614\n",
      "img id in: 15615\n",
      "img id out: 15615\n",
      "img id in: 15616\n",
      "img id out: 15616\n",
      "img id in: 15617\n",
      "img id out: 15617\n",
      "img id in: 15618\n",
      "img id out: 15618\n",
      "img id in: 15619\n",
      "img id out: 15619\n",
      "img id in: 15620\n",
      "img id out: 15620\n",
      "img id in: 15621\n",
      "img id out: 15621\n",
      "img id in: 15622\n",
      "img id out: 15622\n",
      "img id in: 15623\n",
      "img id out: 15623\n",
      "img id in: 15624\n",
      "img id out: 15624\n",
      "img id in: 15625\n",
      "img id out: 15625\n",
      "img id in: 15626\n",
      "img id out: 15626\n",
      "img id in: 15627\n",
      "img id out: 15627\n",
      "img id in: 15628\n",
      "img id out: 15628\n",
      "img id in: 15629\n",
      "img id out: 15629\n",
      "img id in: 15630\n",
      "img id out: 15630\n",
      "img id in: 15631\n",
      "img id out: 15631\n",
      "img id in: 15632\n",
      "img id out: 15632\n",
      "img id in: 15633\n",
      "img id out: 15633\n",
      "img id in: 15634\n",
      "img id out: 15634\n",
      "img id in: 15635\n",
      "img id out: 15635\n",
      "img id in: 15636\n",
      "img id out: 15636\n",
      "img id in: 15637\n",
      "img id out: 15637\n",
      "img id in: 15638\n",
      "img id out: 15638\n",
      "img id in: 15639\n",
      "img id out: 15639\n",
      "img id in: 15640\n",
      "img id out: 15640\n",
      "img id in: 15641\n",
      "img id out: 15641\n",
      "img id in: 15642\n",
      "img id out: 15642\n",
      "img id in: 15643\n",
      "img id out: 15643\n",
      "img id in: 15644\n",
      "img id out: 15644\n",
      "img id in: 15645\n",
      "img id out: 15645\n",
      "img id in: 15646\n",
      "img id out: 15646\n",
      "img id in: 15647\n",
      "img id out: 15647\n",
      "img id in: 15648\n",
      "img id out: 15648\n",
      "img id in: 15649\n",
      "img id out: 15649\n",
      "img id in: 15650\n",
      "img id out: 15650\n",
      "img id in: 15651\n",
      "img id out: 15651\n",
      "img id in: 15652\n",
      "img id out: 15652\n",
      "img id in: 15653\n",
      "img id out: 15653\n",
      "img id in: 15654\n",
      "img id out: 15654\n",
      "img id in: 15655\n",
      "img id out: 15655\n",
      "img id in: 15656\n",
      "img id out: 15656\n",
      "img id in: 15657\n",
      "img id out: 15657\n",
      "img id in: 15658\n",
      "img id out: 15658\n",
      "img id in: 15659\n",
      "img id out: 15659\n",
      "img id in: 15660\n",
      "img id out: 15660\n",
      "img id in: 15661\n",
      "img id out: 15661\n",
      "img id in: 15662\n",
      "img id out: 15662\n",
      "img id in: 15663\n",
      "img id out: 15663\n",
      "img id in: 15664\n",
      "img id out: 15664\n",
      "img id in: 15665\n",
      "img id out: 15665\n",
      "img id in: 15666\n",
      "img id out: 15666\n",
      "img id in: 15667\n",
      "img id out: 15667\n",
      "img id in: 15668\n",
      "img id out: 15668\n",
      "img id in: 15669\n",
      "img id out: 15669\n",
      "img id in: 15670\n",
      "img id out: 15670\n",
      "img id in: 15671\n",
      "img id out: 15671\n",
      "img id in: 15672\n",
      "img id out: 15672\n",
      "img id in: 15673\n",
      "img id out: 15673\n",
      "img id in: 15674\n",
      "img id out: 15674\n",
      "img id in: 15675\n",
      "img id out: 15675\n",
      "img id in: 15676\n",
      "img id out: 15676\n",
      "img id in: 15677\n",
      "img id out: 15677\n",
      "img id in: 15678\n",
      "img id out: 15678\n",
      "img id in: 15679\n",
      "img id out: 15679\n",
      "img id in: 15680\n",
      "img id out: 15680\n",
      "img id in: 15681\n",
      "img id out: 15681\n",
      "img id in: 15682\n",
      "img id out: 15682\n",
      "img id in: 15683\n",
      "img id out: 15683\n",
      "img id in: 15684\n",
      "img id out: 15684\n",
      "img id in: 15685\n",
      "img id out: 15685\n",
      "img id in: 15686\n",
      "img id out: 15686\n",
      "img id in: 15687\n",
      "img id out: 15687\n",
      "img id in: 15688\n",
      "img id out: 15688\n",
      "img id in: 15689\n",
      "img id out: 15689\n",
      "img id in: 15690\n",
      "img id out: 15690\n",
      "img id in: 15691\n",
      "img id out: 15691\n",
      "img id in: 15692\n",
      "img id out: 15692\n",
      "img id in: 15693\n",
      "img id out: 15693\n",
      "img id in: 15694\n",
      "img id out: 15694\n",
      "img id in: 15695\n",
      "img id out: 15695\n",
      "img id in: 15696\n",
      "img id out: 15696\n",
      "img id in: 15697\n",
      "img id out: 15697\n",
      "img id in: 15698\n",
      "img id out: 15698\n",
      "img id in: 15699\n",
      "img id out: 15699\n",
      "img id in: 15700\n",
      "img id out: 15700\n",
      "img id in: 15701\n",
      "img id out: 15701\n",
      "img id in: 15702\n",
      "img id out: 15702\n",
      "img id in: 15703\n",
      "img id out: 15703\n",
      "img id in: 15704\n",
      "img id out: 15704\n",
      "img id in: 15705\n",
      "img id out: 15705\n",
      "img id in: 15706\n",
      "img id out: 15706\n",
      "img id in: 15707\n",
      "img id out: 15707\n",
      "img id in: 15708\n",
      "img id out: 15708\n",
      "img id in: 15709\n",
      "img id out: 15709\n",
      "img id in: 15710\n",
      "img id out: 15710\n",
      "img id in: 15711\n",
      "img id out: 15711\n",
      "img id in: 15712\n",
      "img id out: 15712\n",
      "img id in: 15713\n",
      "img id out: 15713\n",
      "img id in: 15714\n",
      "img id out: 15714\n",
      "img id in: 15715\n",
      "img id out: 15715\n",
      "img id in: 15716\n",
      "img id out: 15716\n",
      "img id in: 15717\n",
      "img id out: 15717\n",
      "img id in: 15718\n",
      "img id out: 15718\n",
      "img id in: 15719\n",
      "img id out: 15719\n",
      "img id in: 15720\n",
      "img id out: 15720\n",
      "img id in: 15721\n",
      "img id out: 15721\n",
      "img id in: 15722\n",
      "img id out: 15722\n",
      "img id in: 15723\n",
      "img id out: 15723\n",
      "img id in: 15724\n",
      "img id out: 15724\n",
      "img id in: 15725\n",
      "img id out: 15725\n",
      "img id in: 15726\n",
      "img id out: 15726\n",
      "img id in: 15727\n",
      "img id out: 15727\n",
      "img id in: 15728\n",
      "img id out: 15728\n",
      "img id in: 15729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 15729\n",
      "img id in: 15730\n",
      "img id out: 15730\n",
      "img id in: 15731\n",
      "img id out: 15731\n",
      "img id in: 15732\n",
      "img id out: 15732\n",
      "img id in: 15733\n",
      "img id out: 15733\n",
      "img id in: 15734\n",
      "img id out: 15734\n",
      "img id in: 15735\n",
      "img id out: 15735\n",
      "img id in: 15736\n",
      "img id out: 15736\n",
      "img id in: 15737\n",
      "img id out: 15737\n",
      "img id in: 15738\n",
      "img id out: 15738\n",
      "img id in: 15739\n",
      "img id out: 15739\n",
      "img id in: 15740\n",
      "img id out: 15740\n",
      "img id in: 15741\n",
      "img id out: 15741\n",
      "img id in: 15742\n",
      "img id out: 15742\n",
      "img id in: 15743\n",
      "img id out: 15743\n",
      "img id in: 15744\n",
      "img id out: 15744\n",
      "img id in: 15745\n",
      "img id out: 15745\n",
      "img id in: 15746\n",
      "img id out: 15746\n",
      "img id in: 15747\n",
      "img id out: 15747\n",
      "img id in: 15748\n",
      "img id out: 15748\n",
      "img id in: 15749\n",
      "img id out: 15749\n",
      "img id in: 15750\n",
      "img id out: 15750\n",
      "img id in: 15751\n",
      "img id out: 15751\n",
      "img id in: 15752\n",
      "img id out: 15752\n",
      "img id in: 15753\n",
      "img id out: 15753\n",
      "img id in: 15754\n",
      "img id out: 15754\n",
      "img id in: 15755\n",
      "img id out: 15755\n",
      "img id in: 15756\n",
      "img id out: 15756\n",
      "img id in: 15757\n",
      "img id out: 15757\n",
      "img id in: 15758\n",
      "img id out: 15758\n",
      "img id in: 15759\n",
      "img id out: 15759\n",
      "img id in: 15760\n",
      "img id out: 15760\n",
      "img id in: 15761\n",
      "img id out: 15761\n",
      "img id in: 15762\n",
      "img id out: 15762\n",
      "img id in: 15763\n",
      "img id out: 15763\n",
      "img id in: 15764\n",
      "img id out: 15764\n",
      "img id in: 15765\n",
      "img id out: 15765\n",
      "img id in: 15766\n",
      "img id out: 15766\n",
      "img id in: 15767\n",
      "img id out: 15767\n",
      "img id in: 15768\n",
      "img id out: 15768\n",
      "img id in: 15769\n",
      "img id out: 15769\n",
      "img id in: 15770\n",
      "img id out: 15770\n",
      "img id in: 15771\n",
      "img id out: 15771\n",
      "img id in: 15772\n",
      "img id out: 15772\n",
      "img id in: 15773\n",
      "img id out: 15773\n",
      "img id in: 15774\n",
      "img id out: 15774\n",
      "img id in: 15775\n",
      "img id out: 15775\n",
      "img id in: 15776\n",
      "img id out: 15776\n",
      "img id in: 15777\n",
      "img id out: 15777\n",
      "img id in: 15778\n",
      "img id out: 15778\n",
      "img id in: 15779\n",
      "img id out: 15779\n",
      "img id in: 15780\n",
      "img id out: 15780\n",
      "img id in: 15781\n",
      "img id out: 15781\n",
      "img id in: 15782\n",
      "img id out: 15782\n",
      "img id in: 15783\n",
      "img id out: 15783\n",
      "img id in: 15784\n",
      "img id out: 15784\n",
      "img id in: 15785\n",
      "img id out: 15785\n",
      "img id in: 15786\n",
      "img id out: 15786\n",
      "img id in: 15787\n",
      "img id out: 15787\n",
      "img id in: 15788\n",
      "img id out: 15788\n",
      "img id in: 15789\n",
      "img id out: 15789\n",
      "img id in: 15790\n",
      "img id out: 15790\n",
      "img id in: 15791\n",
      "img id out: 15791\n",
      "img id in: 15792\n",
      "img id out: 15792\n",
      "img id in: 15793\n",
      "img id out: 15793\n",
      "img id in: 15794\n",
      "img id out: 15794\n",
      "img id in: 15795\n",
      "img id out: 15795\n",
      "img id in: 15796\n",
      "img id out: 15796\n",
      "img id in: 15797\n",
      "img id out: 15797\n",
      "img id in: 15798\n",
      "img id out: 15798\n",
      "img id in: 15799\n",
      "img id out: 15799\n",
      "img id in: 15800\n",
      "img id out: 15800\n",
      "img id in: 15801\n",
      "img id out: 15801\n",
      "img id in: 15802\n",
      "img id out: 15802\n",
      "img id in: 15803\n",
      "img id out: 15803\n",
      "img id in: 15804\n",
      "img id out: 15804\n",
      "img id in: 15805\n",
      "img id out: 15805\n",
      "img id in: 15806\n",
      "img id out: 15806\n",
      "img id in: 15807\n",
      "img id out: 15807\n",
      "img id in: 15808\n",
      "img id out: 15808\n",
      "img id in: 15809\n",
      "img id out: 15809\n",
      "img id in: 15810\n",
      "img id out: 15810\n",
      "img id in: 15811\n",
      "img id out: 15811\n",
      "img id in: 15812\n",
      "img id out: 15812\n",
      "img id in: 15813\n",
      "img id out: 15813\n",
      "img id in: 15814\n",
      "img id out: 15814\n",
      "img id in: 15815\n",
      "img id out: 15815\n",
      "img id in: 15816\n",
      "img id out: 15816\n",
      "img id in: 15817\n",
      "img id out: 15817\n",
      "img id in: 15818\n",
      "img id out: 15818\n",
      "img id in: 15819\n",
      "img id out: 15819\n",
      "img id in: 15820\n",
      "img id out: 15820\n",
      "img id in: 15821\n",
      "img id out: 15821\n",
      "img id in: 15822\n",
      "img id out: 15822\n",
      "img id in: 15823\n",
      "img id out: 15823\n",
      "img id in: 15824\n",
      "img id out: 15824\n",
      "img id in: 15825\n",
      "img id out: 15825\n",
      "img id in: 15826\n",
      "img id out: 15826\n",
      "img id in: 15827\n",
      "img id out: 15827\n",
      "img id in: 15828\n",
      "img id out: 15828\n",
      "img id in: 15829\n",
      "img id out: 15829\n",
      "img id in: 15830\n",
      "img id out: 15830\n",
      "img id in: 15831\n",
      "img id out: 15831\n",
      "img id in: 15832\n",
      "img id out: 15832\n",
      "img id in: 15833\n",
      "img id out: 15833\n",
      "img id in: 15834\n",
      "img id out: 15834\n",
      "img id in: 15835\n",
      "img id out: 15835\n",
      "img id in: 15836\n",
      "img id out: 15836\n",
      "img id in: 15837\n",
      "img id out: 15837\n",
      "img id in: 15838\n",
      "img id out: 15838\n",
      "img id in: 15839\n",
      "img id out: 15839\n",
      "img id in: 15840\n",
      "img id out: 15840\n",
      "img id in: 15841\n",
      "img id out: 15841\n",
      "img id in: 15842\n",
      "img id out: 15842\n",
      "img id in: 15843\n",
      "img id out: 15843\n",
      "img id in: 15844\n",
      "img id out: 15844\n",
      "img id in: 15845\n",
      "img id out: 15845\n",
      "img id in: 15846\n",
      "img id out: 15846\n",
      "img id in: 15847\n",
      "img id out: 15847\n",
      "img id in: 15848\n",
      "img id out: 15848\n",
      "img id in: 15849\n",
      "img id out: 15849\n",
      "img id in: 15850\n",
      "img id out: 15850\n",
      "img id in: 15851\n",
      "img id out: 15851\n",
      "img id in: 15852\n",
      "img id out: 15852\n",
      "img id in: 15853\n",
      "img id out: 15853\n",
      "img id in: 15854\n",
      "img id out: 15854\n",
      "img id in: 15855\n",
      "img id out: 15855\n",
      "img id in: 15856\n",
      "img id out: 15856\n",
      "img id in: 15857\n",
      "img id out: 15857\n",
      "img id in: 15858\n",
      "img id out: 15858\n",
      "img id in: 15859\n",
      "img id out: 15859\n",
      "img id in: 15860\n",
      "img id out: 15860\n",
      "img id in: 15861\n",
      "img id out: 15861\n",
      "img id in: 15862\n",
      "img id out: 15862\n",
      "img id in: 15863\n",
      "img id out: 15863\n",
      "img id in: 15864\n",
      "img id out: 15864\n",
      "img id in: 15865\n",
      "img id out: 15865\n",
      "img id in: 15866\n",
      "img id out: 15866\n",
      "img id in: 15867\n",
      "img id out: 15867\n",
      "img id in: 15868\n",
      "img id out: 15868\n",
      "img id in: 15869\n",
      "img id out: 15869\n",
      "img id in: 15870\n",
      "img id out: 15870\n",
      "img id in: 15871\n",
      "img id out: 15871\n",
      "img id in: 15872\n",
      "img id out: 15872\n",
      "img id in: 15873\n",
      "img id out: 15873\n",
      "img id in: 15874\n",
      "img id out: 15874\n",
      "img id in: 15875\n",
      "img id out: 15875\n",
      "img id in: 15876\n",
      "img id out: 15876\n",
      "img id in: 15877\n",
      "img id out: 15877\n",
      "img id in: 15878\n",
      "img id out: 15878\n",
      "img id in: 15879\n",
      "img id out: 15879\n",
      "img id in: 15880\n",
      "img id out: 15880\n",
      "img id in: 15881\n",
      "img id out: 15881\n",
      "img id in: 15882\n",
      "img id out: 15882\n",
      "img id in: 15883\n",
      "img id out: 15883\n",
      "img id in: 15884\n",
      "img id out: 15884\n",
      "img id in: 15885\n",
      "img id out: 15885\n",
      "img id in: 15886\n",
      "img id out: 15886\n",
      "img id in: 15887\n",
      "img id out: 15887\n",
      "img id in: 15888\n",
      "img id out: 15888\n",
      "img id in: 15889\n",
      "img id out: 15889\n",
      "img id in: 15890\n",
      "img id out: 15890\n",
      "img id in: 15891\n",
      "img id out: 15891\n",
      "img id in: 15892\n",
      "img id out: 15892\n",
      "img id in: 15893\n",
      "img id out: 15893\n",
      "img id in: 15894\n",
      "img id out: 15894\n",
      "img id in: 15895\n",
      "img id out: 15895\n",
      "img id in: 15896\n",
      "img id out: 15896\n",
      "img id in: 15897\n",
      "img id out: 15897\n",
      "img id in: 15898\n",
      "img id out: 15898\n",
      "img id in: 15899\n",
      "img id out: 15899\n",
      "img id in: 15900\n",
      "img id out: 15900\n",
      "img id in: 15901\n",
      "img id out: 15901\n",
      "img id in: 15902\n",
      "img id out: 15902\n",
      "img id in: 15903\n",
      "img id out: 15903\n",
      "img id in: 15904\n",
      "img id out: 15904\n",
      "img id in: 15905\n",
      "img id out: 15905\n",
      "img id in: 15906\n",
      "img id out: 15906\n",
      "img id in: 15907\n",
      "img id out: 15907\n",
      "img id in: 15908\n",
      "img id out: 15908\n",
      "img id in: 15909\n",
      "img id out: 15909\n",
      "img id in: 15910\n",
      "img id out: 15910\n",
      "img id in: 15911\n",
      "img id out: 15911\n",
      "img id in: 15912\n",
      "img id out: 15912\n",
      "img id in: 15913\n",
      "img id out: 15913\n",
      "img id in: 15914\n",
      "img id out: 15914\n",
      "img id in: 15915\n",
      "img id out: 15915\n",
      "img id in: 15916\n",
      "img id out: 15916\n",
      "img id in: 15917\n",
      "img id out: 15917\n",
      "img id in: 15918\n",
      "img id out: 15918\n",
      "img id in: 15919\n",
      "img id out: 15919\n",
      "img id in: 15920\n",
      "img id out: 15920\n",
      "img id in: 15921\n",
      "img id out: 15921\n",
      "img id in: 15922\n",
      "img id out: 15922\n",
      "img id in: 15923\n",
      "img id out: 15923\n",
      "img id in: 15924\n",
      "img id out: 15924\n",
      "img id in: 15925\n",
      "img id out: 15925\n",
      "img id in: 15926\n",
      "img id out: 15926\n",
      "img id in: 15927\n",
      "img id out: 15927\n",
      "img id in: 15928\n",
      "img id out: 15928\n",
      "img id in: 15929\n",
      "img id out: 15929\n",
      "img id in: 15930\n",
      "img id out: 15930\n",
      "img id in: 15931\n",
      "img id out: 15931\n",
      "img id in: 15932\n",
      "img id out: 15932\n",
      "img id in: 15933\n",
      "img id out: 15933\n",
      "img id in: 15934\n",
      "img id out: 15934\n",
      "img id in: 15935\n",
      "img id out: 15935\n",
      "img id in: 15936\n",
      "img id out: 15936\n",
      "img id in: 15937\n",
      "img id out: 15937\n",
      "img id in: 15938\n",
      "img id out: 15938\n",
      "img id in: 15939\n",
      "img id out: 15939\n",
      "img id in: 15940\n",
      "img id out: 15940\n",
      "img id in: 15941\n",
      "img id out: 15941\n",
      "img id in: 15942\n",
      "img id out: 15942\n",
      "img id in: 15943\n",
      "img id out: 15943\n",
      "img id in: 15944\n",
      "img id out: 15944\n",
      "img id in: 15945\n",
      "img id out: 15945\n",
      "img id in: 15946\n",
      "img id out: 15946\n",
      "img id in: 15947\n",
      "img id out: 15947\n",
      "img id in: 15948\n",
      "img id out: 15948\n",
      "img id in: 15949\n",
      "img id out: 15949\n",
      "img id in: 15950\n",
      "img id out: 15950\n",
      "img id in: 15951\n",
      "img id out: 15951\n",
      "img id in: 15952\n",
      "img id out: 15952\n",
      "img id in: 15953\n",
      "img id out: 15953\n",
      "img id in: 15954\n",
      "img id out: 15954\n",
      "img id in: 15955\n",
      "img id out: 15955\n",
      "img id in: 15956\n",
      "img id out: 15956\n",
      "img id in: 15957\n",
      "img id out: 15957\n",
      "img id in: 15958\n",
      "img id out: 15958\n",
      "img id in: 15959\n",
      "img id out: 15959\n",
      "img id in: 15960\n",
      "img id out: 15960\n",
      "img id in: 15961\n",
      "img id out: 15961\n",
      "img id in: 15962\n",
      "img id out: 15962\n",
      "img id in: 15963\n",
      "img id out: 15963\n",
      "img id in: 15964\n",
      "img id out: 15964\n",
      "img id in: 15965\n",
      "img id out: 15965\n",
      "img id in: 15966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 15966\n",
      "img id in: 15967\n",
      "img id out: 15967\n",
      "img id in: 15968\n",
      "img id out: 15968\n",
      "img id in: 15969\n",
      "img id out: 15969\n",
      "img id in: 15970\n",
      "img id out: 15970\n",
      "img id in: 15971\n",
      "img id out: 15971\n",
      "img id in: 15972\n",
      "img id out: 15972\n",
      "img id in: 15973\n",
      "img id out: 15973\n",
      "img id in: 15974\n",
      "img id out: 15974\n",
      "img id in: 15975\n",
      "img id out: 15975\n",
      "img id in: 15976\n",
      "img id out: 15976\n",
      "img id in: 15977\n",
      "img id out: 15977\n",
      "img id in: 15978\n",
      "img id out: 15978\n",
      "img id in: 15979\n",
      "img id out: 15979\n",
      "img id in: 15980\n",
      "img id out: 15980\n",
      "img id in: 15981\n",
      "img id out: 15981\n",
      "img id in: 15982\n",
      "img id out: 15982\n",
      "img id in: 15983\n",
      "img id out: 15983\n",
      "img id in: 15984\n",
      "img id out: 15984\n",
      "img id in: 15985\n",
      "img id out: 15985\n",
      "img id in: 15986\n",
      "img id out: 15986\n",
      "img id in: 15987\n",
      "img id out: 15987\n",
      "img id in: 15988\n",
      "img id out: 15988\n",
      "img id in: 15989\n",
      "img id out: 15989\n",
      "img id in: 15990\n",
      "img id out: 15990\n",
      "img id in: 15991\n",
      "img id out: 15991\n",
      "img id in: 15992\n",
      "img id out: 15992\n",
      "img id in: 15993\n",
      "img id out: 15993\n",
      "img id in: 15994\n",
      "img id out: 15994\n",
      "img id in: 15995\n",
      "img id out: 15995\n",
      "img id in: 15996\n",
      "img id out: 15996\n",
      "img id in: 15997\n",
      "img id out: 15997\n",
      "img id in: 15998\n",
      "img id out: 15998\n",
      "img id in: 15999\n",
      "img id out: 15999\n",
      "img id in: 16000\n",
      "img id out: 16000\n",
      "img id in: 16001\n",
      "img id out: 16001\n",
      "img id in: 16002\n",
      "img id out: 16002\n",
      "img id in: 16003\n",
      "img id out: 16003\n",
      "img id in: 16004\n",
      "img id out: 16004\n",
      "img id in: 16005\n",
      "img id out: 16005\n",
      "img id in: 16006\n",
      "img id out: 16006\n",
      "img id in: 16007\n",
      "img id out: 16007\n",
      "img id in: 16008\n",
      "img id out: 16008\n",
      "img id in: 16009\n",
      "img id out: 16009\n",
      "img id in: 16010\n",
      "img id out: 16010\n",
      "img id in: 16011\n",
      "img id out: 16011\n",
      "img id in: 16012\n",
      "img id out: 16012\n",
      "img id in: 16013\n",
      "img id out: 16013\n",
      "img id in: 16014\n",
      "img id out: 16014\n",
      "img id in: 16015\n",
      "img id out: 16015\n",
      "img id in: 16016\n",
      "img id out: 16016\n",
      "img id in: 16017\n",
      "img id out: 16017\n",
      "img id in: 16018\n",
      "img id out: 16018\n",
      "img id in: 16019\n",
      "img id out: 16019\n",
      "img id in: 16020\n",
      "img id out: 16020\n",
      "img id in: 16021\n",
      "img id out: 16021\n",
      "img id in: 16022\n",
      "img id out: 16022\n",
      "img id in: 16023\n",
      "img id out: 16023\n",
      "img id in: 16024\n",
      "img id out: 16024\n",
      "img id in: 16025\n",
      "img id out: 16025\n",
      "img id in: 16026\n",
      "img id out: 16026\n",
      "img id in: 16027\n",
      "img id out: 16027\n",
      "img id in: 16028\n",
      "img id out: 16028\n",
      "img id in: 16029\n",
      "img id out: 16029\n",
      "img id in: 16030\n",
      "img id out: 16030\n",
      "img id in: 16031\n",
      "img id out: 16031\n",
      "img id in: 16032\n",
      "img id out: 16032\n",
      "img id in: 16033\n",
      "img id out: 16033\n",
      "img id in: 16034\n",
      "img id out: 16034\n",
      "img id in: 16035\n",
      "img id out: 16035\n",
      "img id in: 16036\n",
      "img id out: 16036\n",
      "img id in: 16037\n",
      "img id out: 16037\n",
      "img id in: 16038\n",
      "img id out: 16038\n",
      "img id in: 16039\n",
      "img id out: 16039\n",
      "img id in: 16040\n",
      "img id out: 16040\n",
      "img id in: 16041\n",
      "img id out: 16041\n",
      "img id in: 16042\n",
      "img id out: 16042\n",
      "img id in: 16043\n",
      "img id out: 16043\n",
      "img id in: 16044\n",
      "img id out: 16044\n",
      "img id in: 16045\n",
      "img id out: 16045\n",
      "img id in: 16046\n",
      "img id out: 16046\n",
      "img id in: 16047\n",
      "img id out: 16047\n",
      "img id in: 16048\n",
      "img id out: 16048\n",
      "img id in: 16049\n",
      "img id out: 16049\n",
      "img id in: 16050\n",
      "img id out: 16050\n",
      "img id in: 16051\n",
      "img id out: 16051\n",
      "img id in: 16052\n",
      "img id out: 16052\n",
      "img id in: 16053\n",
      "img id out: 16053\n",
      "img id in: 16054\n",
      "img id out: 16054\n",
      "img id in: 16055\n",
      "img id out: 16055\n",
      "img id in: 16056\n",
      "img id out: 16056\n",
      "img id in: 16057\n",
      "img id out: 16057\n",
      "img id in: 16058\n",
      "img id out: 16058\n",
      "img id in: 16059\n",
      "img id out: 16059\n",
      "img id in: 16060\n",
      "img id out: 16060\n",
      "img id in: 16061\n",
      "img id out: 16061\n",
      "img id in: 16062\n",
      "img id out: 16062\n",
      "img id in: 16063\n",
      "img id out: 16063\n",
      "img id in: 16064\n",
      "img id out: 16064\n",
      "img id in: 16065\n",
      "img id out: 16065\n",
      "img id in: 16066\n",
      "img id out: 16066\n",
      "img id in: 16067\n",
      "img id out: 16067\n",
      "img id in: 16068\n",
      "img id out: 16068\n",
      "img id in: 16069\n",
      "img id out: 16069\n",
      "img id in: 16070\n",
      "img id out: 16070\n",
      "img id in: 16071\n",
      "img id out: 16071\n",
      "img id in: 16072\n",
      "img id out: 16072\n",
      "img id in: 16073\n",
      "img id out: 16073\n",
      "img id in: 16074\n",
      "img id out: 16074\n",
      "img id in: 16075\n",
      "img id out: 16075\n",
      "img id in: 16076\n",
      "img id out: 16076\n",
      "img id in: 16077\n",
      "img id out: 16077\n",
      "img id in: 16078\n",
      "img id out: 16078\n",
      "img id in: 16079\n",
      "img id out: 16079\n",
      "img id in: 16080\n",
      "img id out: 16080\n",
      "img id in: 16081\n",
      "img id out: 16081\n",
      "img id in: 16082\n",
      "img id out: 16082\n",
      "img id in: 16083\n",
      "img id out: 16083\n",
      "img id in: 16084\n",
      "img id out: 16084\n",
      "img id in: 16085\n",
      "img id out: 16085\n",
      "img id in: 16086\n",
      "img id out: 16086\n",
      "img id in: 16087\n",
      "img id out: 16087\n",
      "img id in: 16088\n",
      "img id out: 16088\n",
      "img id in: 16089\n",
      "img id out: 16089\n",
      "img id in: 16090\n",
      "img id out: 16090\n",
      "img id in: 16091\n",
      "img id out: 16091\n",
      "img id in: 16092\n",
      "img id out: 16092\n",
      "img id in: 16093\n",
      "img id out: 16093\n",
      "img id in: 16094\n",
      "img id out: 16094\n",
      "img id in: 16095\n",
      "img id out: 16095\n",
      "img id in: 16096\n",
      "img id out: 16096\n",
      "img id in: 16097\n",
      "img id out: 16097\n",
      "img id in: 16098\n",
      "img id out: 16098\n",
      "img id in: 16099\n",
      "img id out: 16099\n",
      "img id in: 16100\n",
      "img id out: 16100\n",
      "img id in: 16101\n",
      "img id out: 16101\n",
      "img id in: 16102\n",
      "img id out: 16102\n",
      "img id in: 16103\n",
      "img id out: 16103\n",
      "img id in: 16104\n",
      "img id out: 16104\n",
      "img id in: 16105\n",
      "img id out: 16105\n",
      "img id in: 16106\n",
      "img id out: 16106\n",
      "img id in: 16107\n",
      "img id out: 16107\n",
      "img id in: 16108\n",
      "img id out: 16108\n",
      "img id in: 16109\n",
      "img id out: 16109\n",
      "img id in: 16110\n",
      "img id out: 16110\n",
      "img id in: 16111\n",
      "img id out: 16111\n",
      "img id in: 16112\n",
      "img id out: 16112\n",
      "img id in: 16113\n",
      "img id out: 16113\n",
      "img id in: 16114\n",
      "img id out: 16114\n",
      "img id in: 16115\n",
      "img id out: 16115\n",
      "img id in: 16116\n",
      "img id out: 16116\n",
      "img id in: 16117\n",
      "img id out: 16117\n",
      "img id in: 16118\n",
      "img id out: 16118\n",
      "img id in: 16119\n",
      "img id out: 16119\n",
      "img id in: 16120\n",
      "img id out: 16120\n",
      "img id in: 16121\n",
      "img id out: 16121\n",
      "img id in: 16122\n",
      "img id out: 16122\n",
      "img id in: 16123\n",
      "img id out: 16123\n",
      "img id in: 16124\n",
      "img id out: 16124\n",
      "img id in: 16125\n",
      "img id out: 16125\n",
      "img id in: 16126\n",
      "img id out: 16126\n",
      "img id in: 16127\n",
      "img id out: 16127\n",
      "img id in: 16128\n",
      "img id out: 16128\n",
      "img id in: 16129\n",
      "img id out: 16129\n",
      "img id in: 16130\n",
      "img id out: 16130\n",
      "img id in: 16131\n",
      "img id out: 16131\n",
      "img id in: 16132\n",
      "img id out: 16132\n",
      "img id in: 16133\n",
      "img id out: 16133\n",
      "img id in: 16134\n",
      "img id out: 16134\n",
      "img id in: 16135\n",
      "img id out: 16135\n",
      "img id in: 16136\n",
      "img id out: 16136\n",
      "img id in: 16137\n",
      "img id out: 16137\n",
      "img id in: 16138\n",
      "img id out: 16138\n",
      "img id in: 16139\n",
      "img id out: 16139\n",
      "img id in: 16140\n",
      "img id out: 16140\n",
      "img id in: 16141\n",
      "img id out: 16141\n",
      "img id in: 16142\n",
      "img id out: 16142\n",
      "img id in: 16143\n",
      "img id out: 16143\n",
      "img id in: 16144\n",
      "img id out: 16144\n",
      "img id in: 16145\n",
      "img id out: 16145\n",
      "img id in: 16146\n",
      "img id out: 16146\n",
      "img id in: 16147\n",
      "img id out: 16147\n",
      "img id in: 16148\n",
      "img id out: 16148\n",
      "img id in: 16149\n",
      "img id out: 16149\n",
      "img id in: 16150\n",
      "img id out: 16150\n",
      "img id in: 16151\n",
      "img id out: 16151\n",
      "img id in: 16152\n",
      "img id out: 16152\n",
      "img id in: 16153\n",
      "img id out: 16153\n",
      "img id in: 16154\n",
      "img id out: 16154\n",
      "img id in: 16155\n",
      "img id out: 16155\n",
      "img id in: 16156\n",
      "img id out: 16156\n",
      "img id in: 16157\n",
      "img id out: 16157\n",
      "img id in: 16158\n",
      "img id out: 16158\n",
      "img id in: 16159\n",
      "img id out: 16159\n",
      "img id in: 16160\n",
      "img id out: 16160\n",
      "img id in: 16161\n",
      "img id out: 16161\n",
      "img id in: 16162\n",
      "img id out: 16162\n",
      "img id in: 16163\n",
      "img id out: 16163\n",
      "img id in: 16164\n",
      "img id out: 16164\n",
      "img id in: 16165\n",
      "img id out: 16165\n",
      "img id in: 16166\n",
      "img id out: 16166\n",
      "img id in: 16167\n",
      "img id out: 16167\n",
      "img id in: 16168\n",
      "img id out: 16168\n",
      "img id in: 16169\n",
      "img id out: 16169\n",
      "img id in: 16170\n",
      "img id out: 16170\n",
      "img id in: 16171\n",
      "img id out: 16171\n",
      "img id in: 16172\n",
      "img id out: 16172\n",
      "img id in: 16173\n",
      "img id out: 16173\n",
      "img id in: 16174\n",
      "img id out: 16174\n",
      "img id in: 16175\n",
      "img id out: 16175\n",
      "img id in: 16176\n",
      "img id out: 16176\n",
      "img id in: 16177\n",
      "img id out: 16177\n",
      "img id in: 16178\n",
      "img id out: 16178\n",
      "img id in: 16179\n",
      "img id out: 16179\n",
      "img id in: 16180\n",
      "img id out: 16180\n",
      "img id in: 16181\n",
      "img id out: 16181\n",
      "img id in: 16182\n",
      "img id out: 16182\n",
      "img id in: 16183\n",
      "img id out: 16183\n",
      "img id in: 16184\n",
      "img id out: 16184\n",
      "img id in: 16185\n",
      "img id out: 16185\n",
      "img id in: 16186\n",
      "img id out: 16186\n",
      "img id in: 16187\n",
      "img id out: 16187\n",
      "img id in: 16188\n",
      "img id out: 16188\n",
      "img id in: 16189\n",
      "img id out: 16189\n",
      "img id in: 16190\n",
      "img id out: 16190\n",
      "img id in: 16191\n",
      "img id out: 16191\n",
      "img id in: 16192\n",
      "img id out: 16192\n",
      "img id in: 16193\n",
      "img id out: 16193\n",
      "img id in: 16194\n",
      "img id out: 16194\n",
      "img id in: 16195\n",
      "img id out: 16195\n",
      "img id in: 16196\n",
      "img id out: 16196\n",
      "img id in: 16197\n",
      "img id out: 16197\n",
      "img id in: 16198\n",
      "img id out: 16198\n",
      "img id in: 16199\n",
      "img id out: 16199\n",
      "img id in: 16200\n",
      "img id out: 16200\n",
      "img id in: 16201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 16201\n",
      "img id in: 16202\n",
      "img id out: 16202\n",
      "img id in: 16203\n",
      "img id out: 16203\n",
      "img id in: 16204\n",
      "img id out: 16204\n",
      "img id in: 16205\n",
      "img id out: 16205\n",
      "img id in: 16206\n",
      "img id out: 16206\n",
      "img id in: 16207\n",
      "img id out: 16207\n",
      "img id in: 16208\n",
      "img id out: 16208\n",
      "img id in: 16209\n",
      "img id out: 16209\n",
      "img id in: 16210\n",
      "img id out: 16210\n",
      "img id in: 16211\n",
      "img id out: 16211\n",
      "img id in: 16212\n",
      "img id out: 16212\n",
      "img id in: 16213\n",
      "img id out: 16213\n",
      "img id in: 16214\n",
      "img id out: 16214\n",
      "img id in: 16215\n",
      "img id out: 16215\n",
      "img id in: 16216\n",
      "img id out: 16216\n",
      "img id in: 16217\n",
      "img id out: 16217\n",
      "img id in: 16218\n",
      "img id out: 16218\n",
      "img id in: 16219\n",
      "img id out: 16219\n",
      "img id in: 16220\n",
      "img id out: 16220\n",
      "img id in: 16221\n",
      "img id out: 16221\n",
      "img id in: 16222\n",
      "img id out: 16222\n",
      "img id in: 16223\n",
      "img id out: 16223\n",
      "img id in: 16224\n",
      "img id out: 16224\n",
      "img id in: 16225\n",
      "img id out: 16225\n",
      "img id in: 16226\n",
      "img id out: 16226\n",
      "img id in: 16227\n",
      "img id out: 16227\n",
      "img id in: 16228\n",
      "img id out: 16228\n",
      "img id in: 16229\n",
      "img id out: 16229\n",
      "img id in: 16230\n",
      "img id out: 16230\n",
      "img id in: 16231\n",
      "img id out: 16231\n",
      "img id in: 16232\n",
      "img id out: 16232\n",
      "img id in: 16233\n",
      "img id out: 16233\n",
      "img id in: 16234\n",
      "img id out: 16234\n",
      "img id in: 16235\n",
      "img id out: 16235\n",
      "img id in: 16236\n",
      "img id out: 16236\n",
      "img id in: 16237\n",
      "img id out: 16237\n",
      "img id in: 16238\n",
      "img id out: 16238\n",
      "img id in: 16239\n",
      "img id out: 16239\n",
      "img id in: 16240\n",
      "img id out: 16240\n",
      "img id in: 16241\n",
      "img id out: 16241\n",
      "img id in: 16242\n",
      "img id out: 16242\n",
      "img id in: 16243\n",
      "img id out: 16243\n",
      "img id in: 16244\n",
      "img id out: 16244\n",
      "img id in: 16245\n",
      "img id out: 16245\n",
      "img id in: 16246\n",
      "img id out: 16246\n",
      "img id in: 16247\n",
      "img id out: 16247\n",
      "img id in: 16248\n",
      "img id out: 16248\n",
      "img id in: 16249\n",
      "img id out: 16249\n",
      "img id in: 16250\n",
      "img id out: 16250\n",
      "img id in: 16251\n",
      "img id out: 16251\n",
      "img id in: 16252\n",
      "img id out: 16252\n",
      "img id in: 16253\n",
      "img id out: 16253\n",
      "img id in: 16254\n",
      "img id out: 16254\n",
      "img id in: 16255\n",
      "img id out: 16255\n",
      "img id in: 16256\n",
      "img id out: 16256\n",
      "img id in: 16257\n",
      "img id out: 16257\n",
      "img id in: 16258\n",
      "img id out: 16258\n",
      "img id in: 16259\n",
      "img id out: 16259\n",
      "img id in: 16260\n",
      "img id out: 16260\n",
      "img id in: 16261\n",
      "img id out: 16261\n",
      "img id in: 16262\n",
      "img id out: 16262\n",
      "img id in: 16263\n",
      "img id out: 16263\n",
      "img id in: 16264\n",
      "img id out: 16264\n",
      "img id in: 16265\n",
      "img id out: 16265\n",
      "img id in: 16266\n",
      "img id out: 16266\n",
      "img id in: 16267\n",
      "img id out: 16267\n",
      "img id in: 16268\n",
      "img id out: 16268\n",
      "img id in: 16269\n",
      "img id out: 16269\n",
      "img id in: 16270\n",
      "img id out: 16270\n",
      "img id in: 16271\n",
      "img id out: 16271\n",
      "img id in: 16272\n",
      "img id out: 16272\n",
      "img id in: 16273\n",
      "img id out: 16273\n",
      "img id in: 16274\n",
      "img id out: 16274\n",
      "img id in: 16275\n",
      "img id out: 16275\n",
      "img id in: 16276\n",
      "img id out: 16276\n",
      "img id in: 16277\n",
      "img id out: 16277\n",
      "img id in: 16278\n",
      "img id out: 16278\n",
      "img id in: 16279\n",
      "img id out: 16279\n",
      "img id in: 16280\n",
      "img id out: 16280\n",
      "img id in: 16281\n",
      "img id out: 16281\n",
      "img id in: 16282\n",
      "img id out: 16282\n",
      "img id in: 16283\n",
      "img id out: 16283\n",
      "img id in: 16284\n",
      "img id out: 16284\n",
      "img id in: 16285\n",
      "img id out: 16285\n",
      "img id in: 16286\n",
      "img id out: 16286\n",
      "img id in: 16287\n",
      "img id out: 16287\n",
      "img id in: 16288\n",
      "img id out: 16288\n",
      "img id in: 16289\n",
      "img id out: 16289\n",
      "img id in: 16290\n",
      "img id out: 16290\n",
      "img id in: 16291\n",
      "img id out: 16291\n",
      "img id in: 16292\n",
      "img id out: 16292\n",
      "img id in: 16293\n",
      "img id out: 16293\n",
      "img id in: 16294\n",
      "img id out: 16294\n",
      "img id in: 16295\n",
      "img id out: 16295\n",
      "img id in: 16296\n",
      "img id out: 16296\n",
      "img id in: 16297\n",
      "img id out: 16297\n",
      "img id in: 16298\n",
      "img id out: 16298\n",
      "img id in: 16299\n",
      "img id out: 16299\n",
      "img id in: 16300\n",
      "img id out: 16300\n",
      "img id in: 16301\n",
      "img id out: 16301\n",
      "img id in: 16302\n",
      "img id out: 16302\n",
      "img id in: 16303\n",
      "img id out: 16303\n",
      "img id in: 16304\n",
      "img id out: 16304\n",
      "img id in: 16305\n",
      "img id out: 16305\n",
      "img id in: 16306\n",
      "img id out: 16306\n",
      "img id in: 16307\n",
      "img id out: 16307\n",
      "img id in: 16308\n",
      "img id out: 16308\n",
      "img id in: 16309\n",
      "img id out: 16309\n",
      "img id in: 16310\n",
      "img id out: 16310\n",
      "img id in: 16311\n",
      "img id out: 16311\n",
      "img id in: 16312\n",
      "img id out: 16312\n",
      "img id in: 16313\n",
      "img id out: 16313\n",
      "img id in: 16314\n",
      "img id out: 16314\n",
      "img id in: 16315\n",
      "img id out: 16315\n",
      "img id in: 16316\n",
      "img id out: 16316\n",
      "img id in: 16317\n",
      "img id out: 16317\n",
      "img id in: 16318\n",
      "img id out: 16318\n",
      "img id in: 16319\n",
      "img id out: 16319\n",
      "img id in: 16320\n",
      "img id out: 16320\n",
      "img id in: 16321\n",
      "img id out: 16321\n",
      "img id in: 16322\n",
      "img id out: 16322\n",
      "img id in: 16323\n",
      "img id out: 16323\n",
      "img id in: 16324\n",
      "img id out: 16324\n",
      "img id in: 16325\n",
      "img id out: 16325\n",
      "img id in: 16326\n",
      "img id out: 16326\n",
      "img id in: 16327\n",
      "img id out: 16327\n",
      "img id in: 16328\n",
      "img id out: 16328\n",
      "img id in: 16329\n",
      "img id out: 16329\n",
      "img id in: 16330\n",
      "img id out: 16330\n",
      "img id in: 16331\n",
      "img id out: 16331\n",
      "img id in: 16332\n",
      "img id out: 16332\n",
      "img id in: 16333\n",
      "img id out: 16333\n",
      "img id in: 16334\n",
      "img id out: 16334\n",
      "img id in: 16335\n",
      "img id out: 16335\n",
      "img id in: 16336\n",
      "img id out: 16336\n",
      "img id in: 16337\n",
      "img id out: 16337\n",
      "img id in: 16338\n",
      "img id out: 16338\n",
      "img id in: 16339\n",
      "img id out: 16339\n",
      "img id in: 16340\n",
      "img id out: 16340\n",
      "img id in: 16341\n",
      "img id out: 16341\n",
      "img id in: 16342\n",
      "img id out: 16342\n",
      "img id in: 16343\n",
      "img id out: 16343\n",
      "img id in: 16344\n",
      "img id out: 16344\n",
      "img id in: 16345\n",
      "img id out: 16345\n",
      "img id in: 16346\n",
      "img id out: 16346\n",
      "img id in: 16347\n",
      "img id out: 16347\n",
      "img id in: 16348\n",
      "img id out: 16348\n",
      "img id in: 16349\n",
      "img id out: 16349\n",
      "img id in: 16350\n",
      "img id out: 16350\n",
      "img id in: 16351\n",
      "img id out: 16351\n",
      "img id in: 16352\n",
      "img id out: 16352\n",
      "img id in: 16353\n",
      "img id out: 16353\n",
      "img id in: 16354\n",
      "img id out: 16354\n",
      "img id in: 16355\n",
      "img id out: 16355\n",
      "img id in: 16356\n",
      "img id out: 16356\n",
      "img id in: 16357\n",
      "img id out: 16357\n",
      "img id in: 16358\n",
      "img id out: 16358\n",
      "img id in: 16359\n",
      "img id out: 16359\n",
      "img id in: 16360\n",
      "img id out: 16360\n",
      "img id in: 16361\n",
      "img id out: 16361\n",
      "img id in: 16362\n",
      "img id out: 16362\n",
      "img id in: 16363\n",
      "img id out: 16363\n",
      "img id in: 16364\n",
      "img id out: 16364\n",
      "img id in: 16365\n",
      "img id out: 16365\n",
      "img id in: 16366\n",
      "img id out: 16366\n",
      "img id in: 16367\n",
      "img id out: 16367\n",
      "img id in: 16368\n",
      "img id out: 16368\n",
      "img id in: 16369\n",
      "img id out: 16369\n",
      "img id in: 16370\n",
      "img id out: 16370\n",
      "img id in: 16371\n",
      "img id out: 16371\n",
      "img id in: 16372\n",
      "img id out: 16372\n",
      "img id in: 16373\n",
      "img id out: 16373\n",
      "img id in: 16374\n",
      "img id out: 16374\n",
      "img id in: 16375\n",
      "img id out: 16375\n",
      "img id in: 16376\n",
      "img id out: 16376\n",
      "img id in: 16377\n",
      "img id out: 16377\n",
      "img id in: 16378\n",
      "img id out: 16378\n",
      "img id in: 16379\n",
      "img id out: 16379\n",
      "img id in: 16380\n",
      "img id out: 16380\n",
      "img id in: 16381\n",
      "img id out: 16381\n",
      "img id in: 16382\n",
      "img id out: 16382\n",
      "img id in: 16383\n",
      "img id out: 16383\n",
      "img id in: 16384\n",
      "img id out: 16384\n",
      "img id in: 16385\n",
      "img id out: 16385\n",
      "img id in: 16386\n",
      "img id out: 16386\n",
      "img id in: 16387\n",
      "img id out: 16387\n",
      "img id in: 16388\n",
      "img id out: 16388\n",
      "img id in: 16389\n",
      "img id out: 16389\n",
      "img id in: 16390\n",
      "img id out: 16390\n",
      "img id in: 16391\n",
      "img id out: 16391\n",
      "img id in: 16392\n",
      "img id out: 16392\n",
      "img id in: 16393\n",
      "img id out: 16393\n",
      "img id in: 16394\n",
      "img id out: 16394\n",
      "img id in: 16395\n",
      "img id out: 16395\n",
      "img id in: 16396\n",
      "img id out: 16396\n",
      "img id in: 16397\n",
      "img id out: 16397\n",
      "img id in: 16398\n",
      "img id out: 16398\n",
      "img id in: 16399\n",
      "img id out: 16399\n",
      "img id in: 16400\n",
      "img id out: 16400\n",
      "img id in: 16401\n",
      "img id out: 16401\n",
      "img id in: 16402\n",
      "img id out: 16402\n",
      "img id in: 16403\n",
      "img id out: 16403\n",
      "img id in: 16404\n",
      "img id out: 16404\n",
      "img id in: 16405\n",
      "img id out: 16405\n",
      "img id in: 16406\n",
      "img id out: 16406\n",
      "img id in: 16407\n",
      "img id out: 16407\n",
      "img id in: 16408\n",
      "img id out: 16408\n",
      "img id in: 16409\n",
      "img id out: 16409\n",
      "img id in: 16410\n",
      "img id out: 16410\n",
      "img id in: 16411\n",
      "img id out: 16411\n",
      "img id in: 16412\n",
      "img id out: 16412\n",
      "img id in: 16413\n",
      "img id out: 16413\n",
      "img id in: 16414\n",
      "img id out: 16414\n",
      "img id in: 16415\n",
      "img id out: 16415\n",
      "img id in: 16416\n",
      "img id out: 16416\n",
      "img id in: 16417\n",
      "img id out: 16417\n",
      "img id in: 16418\n",
      "img id out: 16418\n",
      "img id in: 16419\n",
      "img id out: 16419\n",
      "img id in: 16420\n",
      "img id out: 16420\n",
      "img id in: 16421\n",
      "img id out: 16421\n",
      "img id in: 16422\n",
      "img id out: 16422\n",
      "img id in: 16423\n",
      "img id out: 16423\n",
      "img id in: 16424\n",
      "img id out: 16424\n",
      "img id in: 16425\n",
      "img id out: 16425\n",
      "img id in: 16426\n",
      "img id out: 16426\n",
      "img id in: 16427\n",
      "img id out: 16427\n",
      "img id in: 16428\n",
      "img id out: 16428\n",
      "img id in: 16429\n",
      "img id out: 16429\n",
      "img id in: 16430\n",
      "img id out: 16430\n",
      "img id in: 16431\n",
      "img id out: 16431\n",
      "img id in: 16432\n",
      "img id out: 16432\n",
      "img id in: 16433\n",
      "img id out: 16433\n",
      "img id in: 16434\n",
      "img id out: 16434\n",
      "img id in: 16435\n",
      "img id out: 16435\n",
      "img id in: 16436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 16436\n",
      "img id in: 16437\n",
      "img id out: 16437\n",
      "img id in: 16438\n",
      "img id out: 16438\n",
      "img id in: 16439\n",
      "img id out: 16439\n",
      "img id in: 16440\n",
      "img id out: 16440\n",
      "img id in: 16441\n",
      "img id out: 16441\n",
      "img id in: 16442\n",
      "img id out: 16442\n",
      "img id in: 16443\n",
      "img id out: 16443\n",
      "img id in: 16444\n",
      "img id out: 16444\n",
      "img id in: 16445\n",
      "img id out: 16445\n",
      "img id in: 16446\n",
      "img id out: 16446\n",
      "img id in: 16447\n",
      "img id out: 16447\n",
      "img id in: 16448\n",
      "img id out: 16448\n",
      "img id in: 16449\n",
      "img id out: 16449\n",
      "img id in: 16450\n",
      "img id out: 16450\n",
      "img id in: 16451\n",
      "img id out: 16451\n",
      "img id in: 16452\n",
      "img id out: 16452\n",
      "img id in: 16453\n",
      "img id out: 16453\n",
      "img id in: 16454\n",
      "img id out: 16454\n",
      "img id in: 16455\n",
      "img id out: 16455\n",
      "img id in: 16456\n",
      "img id out: 16456\n",
      "img id in: 16457\n",
      "img id out: 16457\n",
      "img id in: 16458\n",
      "img id out: 16458\n",
      "img id in: 16459\n",
      "img id out: 16459\n",
      "img id in: 16460\n",
      "img id out: 16460\n",
      "img id in: 16461\n",
      "img id out: 16461\n",
      "img id in: 16462\n",
      "img id out: 16462\n",
      "img id in: 16463\n",
      "img id out: 16463\n",
      "img id in: 16464\n",
      "img id out: 16464\n",
      "img id in: 16465\n",
      "img id out: 16465\n",
      "img id in: 16466\n",
      "img id out: 16466\n",
      "img id in: 16467\n",
      "img id out: 16467\n",
      "img id in: 16468\n",
      "img id out: 16468\n",
      "img id in: 16469\n",
      "img id out: 16469\n",
      "img id in: 16470\n",
      "img id out: 16470\n",
      "img id in: 16471\n",
      "img id out: 16471\n",
      "img id in: 16472\n",
      "img id out: 16472\n",
      "img id in: 16473\n",
      "img id out: 16473\n",
      "img id in: 16474\n",
      "img id out: 16474\n",
      "img id in: 16475\n",
      "img id out: 16475\n",
      "img id in: 16476\n",
      "img id out: 16476\n",
      "img id in: 16477\n",
      "img id out: 16477\n",
      "img id in: 16478\n",
      "img id out: 16478\n",
      "img id in: 16479\n",
      "img id out: 16479\n",
      "img id in: 16480\n",
      "img id out: 16480\n",
      "img id in: 16481\n",
      "img id out: 16481\n",
      "img id in: 16482\n",
      "img id out: 16482\n",
      "img id in: 16483\n",
      "img id out: 16483\n",
      "img id in: 16484\n",
      "img id out: 16484\n",
      "img id in: 16485\n",
      "img id out: 16485\n",
      "img id in: 16486\n",
      "img id out: 16486\n",
      "img id in: 16487\n",
      "img id out: 16487\n",
      "img id in: 16488\n",
      "img id out: 16488\n",
      "img id in: 16489\n",
      "img id out: 16489\n",
      "img id in: 16490\n",
      "img id out: 16490\n",
      "img id in: 16491\n",
      "img id out: 16491\n",
      "img id in: 16492\n",
      "img id out: 16492\n",
      "img id in: 16493\n",
      "img id out: 16493\n",
      "img id in: 16494\n",
      "img id out: 16494\n",
      "img id in: 16495\n",
      "img id out: 16495\n",
      "img id in: 16496\n",
      "img id out: 16496\n",
      "img id in: 16497\n",
      "img id out: 16497\n",
      "img id in: 16498\n",
      "img id out: 16498\n",
      "img id in: 16499\n",
      "img id out: 16499\n",
      "img id in: 16500\n",
      "img id out: 16500\n",
      "img id in: 16501\n",
      "img id out: 16501\n",
      "img id in: 16502\n",
      "img id out: 16502\n",
      "img id in: 16503\n",
      "img id out: 16503\n",
      "img id in: 16504\n",
      "img id out: 16504\n",
      "img id in: 16505\n",
      "img id out: 16505\n",
      "img id in: 16506\n",
      "img id out: 16506\n",
      "img id in: 16507\n",
      "img id out: 16507\n",
      "img id in: 16508\n",
      "img id out: 16508\n",
      "img id in: 16509\n",
      "img id out: 16509\n",
      "img id in: 16510\n",
      "img id out: 16510\n",
      "img id in: 16511\n",
      "img id out: 16511\n",
      "img id in: 16512\n",
      "img id out: 16512\n",
      "img id in: 16513\n",
      "img id out: 16513\n",
      "img id in: 16514\n",
      "img id out: 16514\n",
      "img id in: 16515\n",
      "img id out: 16515\n",
      "img id in: 16516\n",
      "img id out: 16516\n",
      "img id in: 16517\n",
      "img id out: 16517\n",
      "img id in: 16518\n",
      "img id out: 16518\n",
      "img id in: 16519\n",
      "img id out: 16519\n",
      "img id in: 16520\n",
      "img id out: 16520\n",
      "img id in: 16521\n",
      "img id out: 16521\n",
      "img id in: 16522\n",
      "img id out: 16522\n",
      "img id in: 16523\n",
      "img id out: 16523\n",
      "img id in: 16524\n",
      "img id out: 16524\n",
      "img id in: 16525\n",
      "img id out: 16525\n",
      "img id in: 16526\n",
      "img id out: 16526\n",
      "img id in: 16527\n",
      "img id out: 16527\n",
      "img id in: 16528\n",
      "img id out: 16528\n",
      "img id in: 16529\n",
      "img id out: 16529\n",
      "img id in: 16530\n",
      "img id out: 16530\n",
      "img id in: 16531\n",
      "img id out: 16531\n",
      "img id in: 16532\n",
      "img id out: 16532\n",
      "img id in: 16533\n",
      "img id out: 16533\n",
      "img id in: 16534\n",
      "img id out: 16534\n",
      "img id in: 16535\n",
      "img id out: 16535\n",
      "img id in: 16536\n",
      "img id out: 16536\n",
      "img id in: 16537\n",
      "img id out: 16537\n",
      "img id in: 16538\n",
      "img id out: 16538\n",
      "img id in: 16539\n",
      "img id out: 16539\n",
      "img id in: 16540\n",
      "img id out: 16540\n",
      "img id in: 16541\n",
      "img id out: 16541\n",
      "img id in: 16542\n",
      "img id out: 16542\n",
      "img id in: 16543\n",
      "img id out: 16543\n",
      "img id in: 16544\n",
      "img id out: 16544\n",
      "img id in: 16545\n",
      "img id out: 16545\n",
      "img id in: 16546\n",
      "img id out: 16546\n",
      "img id in: 16547\n",
      "img id out: 16547\n",
      "img id in: 16548\n",
      "img id out: 16548\n",
      "img id in: 16549\n",
      "img id out: 16549\n",
      "img id in: 16550\n",
      "img id out: 16550\n",
      "img id in: 16551\n",
      "img id out: 16551\n",
      "img id in: 16552\n",
      "img id out: 16552\n",
      "img id in: 16553\n",
      "img id out: 16553\n",
      "img id in: 16554\n",
      "img id out: 16554\n",
      "img id in: 16555\n",
      "img id out: 16555\n",
      "img id in: 16556\n",
      "img id out: 16556\n",
      "img id in: 16557\n",
      "img id out: 16557\n",
      "img id in: 16558\n",
      "img id out: 16558\n",
      "img id in: 16559\n",
      "img id out: 16559\n",
      "img id in: 16560\n",
      "img id out: 16560\n",
      "img id in: 16561\n",
      "img id out: 16561\n",
      "img id in: 16562\n",
      "img id out: 16562\n",
      "img id in: 16563\n",
      "img id out: 16563\n",
      "img id in: 16564\n",
      "img id out: 16564\n",
      "img id in: 16565\n",
      "img id out: 16565\n",
      "img id in: 16566\n",
      "img id out: 16566\n",
      "img id in: 16567\n",
      "img id out: 16567\n",
      "img id in: 16568\n",
      "img id out: 16568\n",
      "img id in: 16569\n",
      "img id out: 16569\n",
      "img id in: 16570\n",
      "img id out: 16570\n",
      "img id in: 16571\n",
      "img id out: 16571\n",
      "img id in: 16572\n",
      "img id out: 16572\n",
      "img id in: 16573\n",
      "img id out: 16573\n",
      "img id in: 16574\n",
      "img id out: 16574\n",
      "img id in: 16575\n",
      "img id out: 16575\n",
      "img id in: 16576\n",
      "img id out: 16576\n",
      "img id in: 16577\n",
      "img id out: 16577\n",
      "img id in: 16578\n",
      "img id out: 16578\n",
      "img id in: 16579\n",
      "img id out: 16579\n",
      "img id in: 16580\n",
      "img id out: 16580\n",
      "img id in: 16581\n",
      "img id out: 16581\n",
      "img id in: 16582\n",
      "img id out: 16582\n",
      "img id in: 16583\n",
      "img id out: 16583\n",
      "img id in: 16584\n",
      "img id out: 16584\n",
      "img id in: 16585\n",
      "img id out: 16585\n",
      "img id in: 16586\n",
      "img id out: 16586\n",
      "img id in: 16587\n",
      "img id out: 16587\n",
      "img id in: 16588\n",
      "img id out: 16588\n",
      "img id in: 16589\n",
      "img id out: 16589\n",
      "img id in: 16590\n",
      "img id out: 16590\n",
      "img id in: 16591\n",
      "img id out: 16591\n",
      "img id in: 16592\n",
      "img id out: 16592\n",
      "img id in: 16593\n",
      "img id out: 16593\n",
      "img id in: 16594\n",
      "img id out: 16594\n",
      "img id in: 16595\n",
      "img id out: 16595\n",
      "img id in: 16596\n",
      "img id out: 16596\n",
      "img id in: 16597\n",
      "img id out: 16597\n",
      "img id in: 16598\n",
      "img id out: 16598\n",
      "img id in: 16599\n",
      "img id out: 16599\n",
      "img id in: 16600\n",
      "img id out: 16600\n",
      "img id in: 16601\n",
      "img id out: 16601\n",
      "img id in: 16602\n",
      "img id out: 16602\n",
      "img id in: 16603\n",
      "img id out: 16603\n",
      "img id in: 16604\n",
      "img id out: 16604\n",
      "img id in: 16605\n",
      "img id out: 16605\n",
      "img id in: 16606\n",
      "img id out: 16606\n",
      "img id in: 16607\n",
      "img id out: 16607\n",
      "img id in: 16608\n",
      "img id out: 16608\n",
      "img id in: 16609\n",
      "img id out: 16609\n",
      "img id in: 16610\n",
      "img id out: 16610\n",
      "img id in: 16611\n",
      "img id out: 16611\n",
      "img id in: 16612\n",
      "img id out: 16612\n",
      "img id in: 16613\n",
      "img id out: 16613\n",
      "img id in: 16614\n",
      "img id out: 16614\n",
      "img id in: 16615\n",
      "img id out: 16615\n",
      "img id in: 16616\n",
      "img id out: 16616\n",
      "img id in: 16617\n",
      "img id out: 16617\n",
      "img id in: 16618\n",
      "img id out: 16618\n",
      "img id in: 16619\n",
      "img id out: 16619\n",
      "img id in: 16620\n",
      "img id out: 16620\n",
      "img id in: 16621\n",
      "img id out: 16621\n",
      "img id in: 16622\n",
      "img id out: 16622\n",
      "img id in: 16623\n",
      "img id out: 16623\n",
      "img id in: 16624\n",
      "img id out: 16624\n",
      "img id in: 16625\n",
      "img id out: 16625\n",
      "img id in: 16626\n",
      "img id out: 16626\n",
      "img id in: 16627\n",
      "img id out: 16627\n",
      "img id in: 16628\n",
      "img id out: 16628\n",
      "img id in: 16629\n",
      "img id out: 16629\n",
      "img id in: 16630\n",
      "img id out: 16630\n",
      "img id in: 16631\n",
      "img id out: 16631\n",
      "img id in: 16632\n",
      "img id out: 16632\n",
      "img id in: 16633\n",
      "img id out: 16633\n",
      "img id in: 16634\n",
      "img id out: 16634\n",
      "img id in: 16635\n",
      "img id out: 16635\n",
      "img id in: 16636\n",
      "img id out: 16636\n",
      "img id in: 16637\n",
      "img id out: 16637\n",
      "img id in: 16638\n",
      "img id out: 16638\n",
      "img id in: 16639\n",
      "img id out: 16639\n",
      "img id in: 16640\n",
      "img id out: 16640\n",
      "img id in: 16641\n",
      "img id out: 16641\n",
      "img id in: 16642\n",
      "img id out: 16642\n",
      "img id in: 16643\n",
      "img id out: 16643\n",
      "img id in: 16644\n",
      "img id out: 16644\n",
      "img id in: 16645\n",
      "img id out: 16645\n",
      "img id in: 16646\n",
      "img id out: 16646\n",
      "img id in: 16647\n",
      "img id out: 16647\n",
      "img id in: 16648\n",
      "img id out: 16648\n",
      "img id in: 16649\n",
      "img id out: 16649\n",
      "img id in: 16650\n",
      "img id out: 16650\n",
      "img id in: 16651\n",
      "img id out: 16651\n",
      "img id in: 16652\n",
      "img id out: 16652\n",
      "img id in: 16653\n",
      "img id out: 16653\n",
      "img id in: 16654\n",
      "img id out: 16654\n",
      "img id in: 16655\n",
      "img id out: 16655\n",
      "img id in: 16656\n",
      "img id out: 16656\n",
      "img id in: 16657\n",
      "img id out: 16657\n",
      "img id in: 16658\n",
      "img id out: 16658\n",
      "img id in: 16659\n",
      "img id out: 16659\n",
      "img id in: 16660\n",
      "img id out: 16660\n",
      "img id in: 16661\n",
      "img id out: 16661\n",
      "img id in: 16662\n",
      "img id out: 16662\n",
      "img id in: 16663\n",
      "img id out: 16663\n",
      "img id in: 16664\n",
      "img id out: 16664\n",
      "img id in: 16665\n",
      "img id out: 16665\n",
      "img id in: 16666\n",
      "img id out: 16666\n",
      "img id in: 16667\n",
      "img id out: 16667\n",
      "img id in: 16668\n",
      "img id out: 16668\n",
      "img id in: 16669\n",
      "img id out: 16669\n",
      "img id in: 16670\n",
      "img id out: 16670\n",
      "img id in: 16671\n",
      "img id out: 16671\n",
      "img id in: 16672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 16672\n",
      "img id in: 16673\n",
      "img id out: 16673\n",
      "img id in: 16674\n",
      "img id out: 16674\n",
      "img id in: 16675\n",
      "img id out: 16675\n",
      "img id in: 16676\n",
      "img id out: 16676\n",
      "img id in: 16677\n",
      "img id out: 16677\n",
      "img id in: 16678\n",
      "img id out: 16678\n",
      "img id in: 16679\n",
      "img id out: 16679\n",
      "img id in: 16680\n",
      "img id out: 16680\n",
      "img id in: 16681\n",
      "img id out: 16681\n",
      "img id in: 16682\n",
      "img id out: 16682\n",
      "img id in: 16683\n",
      "img id out: 16683\n",
      "img id in: 16684\n",
      "img id out: 16684\n",
      "img id in: 16685\n",
      "img id out: 16685\n",
      "img id in: 16686\n",
      "img id out: 16686\n",
      "img id in: 16687\n",
      "img id out: 16687\n",
      "img id in: 16688\n",
      "img id out: 16688\n",
      "img id in: 16689\n",
      "img id out: 16689\n",
      "img id in: 16690\n",
      "img id out: 16690\n",
      "img id in: 16691\n",
      "img id out: 16691\n",
      "img id in: 16692\n",
      "img id out: 16692\n",
      "img id in: 16693\n",
      "img id out: 16693\n",
      "img id in: 16694\n",
      "img id out: 16694\n",
      "img id in: 16695\n",
      "img id out: 16695\n",
      "img id in: 16696\n",
      "img id out: 16696\n",
      "img id in: 16697\n",
      "img id out: 16697\n",
      "img id in: 16698\n",
      "img id out: 16698\n",
      "img id in: 16699\n",
      "img id out: 16699\n",
      "img id in: 16700\n",
      "img id out: 16700\n",
      "img id in: 16701\n",
      "img id out: 16701\n",
      "img id in: 16702\n",
      "img id out: 16702\n",
      "img id in: 16703\n",
      "img id out: 16703\n",
      "img id in: 16704\n",
      "img id out: 16704\n",
      "img id in: 16705\n",
      "img id out: 16705\n",
      "img id in: 16706\n",
      "img id out: 16706\n",
      "img id in: 16707\n",
      "img id out: 16707\n",
      "img id in: 16708\n",
      "img id out: 16708\n",
      "img id in: 16709\n",
      "img id out: 16709\n",
      "img id in: 16710\n",
      "img id out: 16710\n",
      "img id in: 16711\n",
      "img id out: 16711\n",
      "img id in: 16712\n",
      "img id out: 16712\n",
      "img id in: 16713\n",
      "img id out: 16713\n",
      "img id in: 16714\n",
      "img id out: 16714\n",
      "img id in: 16715\n",
      "img id out: 16715\n",
      "img id in: 16716\n",
      "img id out: 16716\n",
      "img id in: 16717\n",
      "img id out: 16717\n",
      "img id in: 16718\n",
      "img id out: 16718\n",
      "img id in: 16719\n",
      "img id out: 16719\n",
      "img id in: 16720\n",
      "img id out: 16720\n",
      "img id in: 16721\n",
      "img id out: 16721\n",
      "img id in: 16722\n",
      "img id out: 16722\n",
      "img id in: 16723\n",
      "img id out: 16723\n",
      "img id in: 16724\n",
      "img id out: 16724\n",
      "img id in: 16725\n",
      "img id out: 16725\n",
      "img id in: 16726\n",
      "img id out: 16726\n",
      "img id in: 16727\n",
      "img id out: 16727\n",
      "img id in: 16728\n",
      "img id out: 16728\n",
      "img id in: 16729\n",
      "img id out: 16729\n",
      "img id in: 16730\n",
      "img id out: 16730\n",
      "img id in: 16731\n",
      "img id out: 16731\n",
      "img id in: 16732\n",
      "img id out: 16732\n",
      "img id in: 16733\n",
      "img id out: 16733\n",
      "img id in: 16734\n",
      "img id out: 16734\n",
      "img id in: 16735\n",
      "img id out: 16735\n",
      "img id in: 16736\n",
      "img id out: 16736\n",
      "img id in: 16737\n",
      "img id out: 16737\n",
      "img id in: 16738\n",
      "img id out: 16738\n",
      "img id in: 16739\n",
      "img id out: 16739\n",
      "img id in: 16740\n",
      "img id out: 16740\n",
      "img id in: 16741\n",
      "img id out: 16741\n",
      "img id in: 16742\n",
      "img id out: 16742\n",
      "img id in: 16743\n",
      "img id out: 16743\n",
      "img id in: 16744\n",
      "img id out: 16744\n",
      "img id in: 16745\n",
      "img id out: 16745\n",
      "img id in: 16746\n",
      "img id out: 16746\n",
      "img id in: 16747\n",
      "img id out: 16747\n",
      "img id in: 16748\n",
      "img id out: 16748\n",
      "img id in: 16749\n",
      "img id out: 16749\n",
      "img id in: 16750\n",
      "img id out: 16750\n",
      "img id in: 16751\n",
      "img id out: 16751\n",
      "img id in: 16752\n",
      "img id out: 16752\n",
      "img id in: 16753\n",
      "img id out: 16753\n",
      "img id in: 16754\n",
      "img id out: 16754\n",
      "img id in: 16755\n",
      "img id out: 16755\n",
      "img id in: 16756\n",
      "img id out: 16756\n",
      "img id in: 16757\n",
      "img id out: 16757\n",
      "img id in: 16758\n",
      "img id out: 16758\n",
      "img id in: 16759\n",
      "img id out: 16759\n",
      "img id in: 16760\n",
      "img id out: 16760\n",
      "img id in: 16761\n",
      "img id out: 16761\n",
      "img id in: 16762\n",
      "img id out: 16762\n",
      "img id in: 16763\n",
      "img id out: 16763\n",
      "img id in: 16764\n",
      "img id out: 16764\n",
      "img id in: 16765\n",
      "img id out: 16765\n",
      "img id in: 16766\n",
      "img id out: 16766\n",
      "img id in: 16767\n",
      "img id out: 16767\n",
      "img id in: 16768\n",
      "img id out: 16768\n",
      "img id in: 16769\n",
      "img id out: 16769\n",
      "img id in: 16770\n",
      "img id out: 16770\n",
      "img id in: 16771\n",
      "img id out: 16771\n",
      "img id in: 16772\n",
      "img id out: 16772\n",
      "img id in: 16773\n",
      "img id out: 16773\n",
      "img id in: 16774\n",
      "img id out: 16774\n",
      "img id in: 16775\n",
      "img id out: 16775\n",
      "img id in: 16776\n",
      "img id out: 16776\n",
      "img id in: 16777\n",
      "img id out: 16777\n",
      "img id in: 16778\n",
      "img id out: 16778\n",
      "img id in: 16779\n",
      "img id out: 16779\n",
      "img id in: 16780\n",
      "img id out: 16780\n",
      "img id in: 16781\n",
      "img id out: 16781\n",
      "img id in: 16782\n",
      "img id out: 16782\n",
      "img id in: 16783\n",
      "img id out: 16783\n",
      "img id in: 16784\n",
      "img id out: 16784\n",
      "img id in: 16785\n",
      "img id out: 16785\n",
      "img id in: 16786\n",
      "img id out: 16786\n",
      "img id in: 16787\n",
      "img id out: 16787\n",
      "img id in: 16788\n",
      "img id out: 16788\n",
      "img id in: 16789\n",
      "img id out: 16789\n",
      "img id in: 16790\n",
      "img id out: 16790\n",
      "img id in: 16791\n",
      "img id out: 16791\n",
      "img id in: 16792\n",
      "img id out: 16792\n",
      "img id in: 16793\n",
      "img id out: 16793\n",
      "img id in: 16794\n",
      "img id out: 16794\n",
      "img id in: 16795\n",
      "img id out: 16795\n",
      "img id in: 16796\n",
      "img id out: 16796\n",
      "img id in: 16797\n",
      "img id out: 16797\n",
      "img id in: 16798\n",
      "img id out: 16798\n",
      "img id in: 16799\n",
      "img id out: 16799\n",
      "img id in: 16800\n",
      "img id out: 16800\n",
      "img id in: 16801\n",
      "img id out: 16801\n",
      "img id in: 16802\n",
      "img id out: 16802\n",
      "img id in: 16803\n",
      "img id out: 16803\n",
      "img id in: 16804\n",
      "img id out: 16804\n",
      "img id in: 16805\n",
      "img id out: 16805\n",
      "img id in: 16806\n",
      "img id out: 16806\n",
      "img id in: 16807\n",
      "img id out: 16807\n",
      "img id in: 16808\n",
      "img id out: 16808\n",
      "img id in: 16809\n",
      "img id out: 16809\n",
      "img id in: 16810\n",
      "img id out: 16810\n",
      "img id in: 16811\n",
      "img id out: 16811\n",
      "img id in: 16812\n",
      "img id out: 16812\n",
      "img id in: 16813\n",
      "img id out: 16813\n",
      "img id in: 16814\n",
      "img id out: 16814\n",
      "img id in: 16815\n",
      "img id out: 16815\n",
      "img id in: 16816\n",
      "img id out: 16816\n",
      "img id in: 16817\n",
      "img id out: 16817\n",
      "img id in: 16818\n",
      "img id out: 16818\n",
      "img id in: 16819\n",
      "img id out: 16819\n",
      "img id in: 16820\n",
      "img id out: 16820\n",
      "img id in: 16821\n",
      "img id out: 16821\n",
      "img id in: 16822\n",
      "img id out: 16822\n",
      "img id in: 16823\n",
      "img id out: 16823\n",
      "img id in: 16824\n",
      "img id out: 16824\n",
      "img id in: 16825\n",
      "img id out: 16825\n",
      "img id in: 16826\n",
      "img id out: 16826\n",
      "img id in: 16827\n",
      "img id out: 16827\n",
      "img id in: 16828\n",
      "img id out: 16828\n",
      "img id in: 16829\n",
      "img id out: 16829\n",
      "img id in: 16830\n",
      "img id out: 16830\n",
      "img id in: 16831\n",
      "img id out: 16831\n",
      "img id in: 16832\n",
      "img id out: 16832\n",
      "img id in: 16833\n",
      "img id out: 16833\n",
      "img id in: 16834\n",
      "img id out: 16834\n",
      "img id in: 16835\n",
      "img id out: 16835\n",
      "img id in: 16836\n",
      "img id out: 16836\n",
      "img id in: 16837\n",
      "img id out: 16837\n",
      "img id in: 16838\n",
      "img id out: 16838\n",
      "img id in: 16839\n",
      "img id out: 16839\n",
      "img id in: 16840\n",
      "img id out: 16840\n",
      "img id in: 16841\n",
      "img id out: 16841\n",
      "img id in: 16842\n",
      "img id out: 16842\n",
      "img id in: 16843\n",
      "img id out: 16843\n",
      "img id in: 16844\n",
      "img id out: 16844\n",
      "img id in: 16845\n",
      "img id out: 16845\n",
      "img id in: 16846\n",
      "img id out: 16846\n",
      "img id in: 16847\n",
      "img id out: 16847\n",
      "img id in: 16848\n",
      "img id out: 16848\n",
      "img id in: 16849\n",
      "img id out: 16849\n",
      "img id in: 16850\n",
      "img id out: 16850\n",
      "img id in: 16851\n",
      "img id out: 16851\n",
      "img id in: 16852\n",
      "img id out: 16852\n",
      "img id in: 16853\n",
      "img id out: 16853\n",
      "img id in: 16854\n",
      "img id out: 16854\n",
      "img id in: 16855\n",
      "img id out: 16855\n",
      "img id in: 16856\n",
      "img id out: 16856\n",
      "img id in: 16857\n",
      "img id out: 16857\n",
      "img id in: 16858\n",
      "img id out: 16858\n",
      "img id in: 16859\n",
      "img id out: 16859\n",
      "img id in: 16860\n",
      "img id out: 16860\n",
      "img id in: 16861\n",
      "img id out: 16861\n",
      "img id in: 16862\n",
      "img id out: 16862\n",
      "img id in: 16863\n",
      "img id out: 16863\n",
      "img id in: 16864\n",
      "img id out: 16864\n",
      "img id in: 16865\n",
      "img id out: 16865\n",
      "img id in: 16866\n",
      "img id out: 16866\n",
      "img id in: 16867\n",
      "img id out: 16867\n",
      "img id in: 16868\n",
      "img id out: 16868\n",
      "img id in: 16869\n",
      "img id out: 16869\n",
      "img id in: 16870\n",
      "img id out: 16870\n",
      "img id in: 16871\n",
      "img id out: 16871\n",
      "img id in: 16872\n",
      "img id out: 16872\n",
      "img id in: 16873\n",
      "img id out: 16873\n",
      "img id in: 16874\n",
      "img id out: 16874\n",
      "img id in: 16875\n",
      "img id out: 16875\n",
      "img id in: 16876\n",
      "img id out: 16876\n",
      "img id in: 16877\n",
      "img id out: 16877\n",
      "img id in: 16878\n",
      "img id out: 16878\n",
      "img id in: 16879\n",
      "img id out: 16879\n",
      "img id in: 16880\n",
      "img id out: 16880\n",
      "img id in: 16881\n",
      "img id out: 16881\n",
      "img id in: 16882\n",
      "img id out: 16882\n",
      "img id in: 16883\n",
      "img id out: 16883\n",
      "img id in: 16884\n",
      "img id out: 16884\n",
      "img id in: 16885\n",
      "img id out: 16885\n",
      "img id in: 16886\n",
      "img id out: 16886\n",
      "img id in: 16887\n",
      "img id out: 16887\n",
      "img id in: 16888\n",
      "img id out: 16888\n",
      "img id in: 16889\n",
      "img id out: 16889\n",
      "img id in: 16890\n",
      "img id out: 16890\n",
      "img id in: 16891\n",
      "img id out: 16891\n",
      "img id in: 16892\n",
      "img id out: 16892\n",
      "img id in: 16893\n",
      "img id out: 16893\n",
      "img id in: 16894\n",
      "img id out: 16894\n",
      "img id in: 16895\n",
      "img id out: 16895\n",
      "img id in: 16896\n",
      "img id out: 16896\n",
      "img id in: 16897\n",
      "img id out: 16897\n",
      "img id in: 16898\n",
      "img id out: 16898\n",
      "img id in: 16899\n",
      "img id out: 16899\n",
      "img id in: 16900\n",
      "img id out: 16900\n",
      "img id in: 16901\n",
      "img id out: 16901\n",
      "img id in: 16902\n",
      "img id out: 16902\n",
      "img id in: 16903\n",
      "img id out: 16903\n",
      "img id in: 16904\n",
      "img id out: 16904\n",
      "img id in: 16905\n",
      "img id out: 16905\n",
      "img id in: 16906\n",
      "img id out: 16906\n",
      "img id in: 16907\n",
      "img id out: 16907\n",
      "img id in: 16908\n",
      "img id out: 16908\n",
      "img id in: 16909\n",
      "img id out: 16909\n",
      "img id in: 16910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 16910\n",
      "img id in: 16911\n",
      "img id out: 16911\n",
      "img id in: 16912\n",
      "img id out: 16912\n",
      "img id in: 16913\n",
      "img id out: 16913\n",
      "img id in: 16914\n",
      "img id out: 16914\n",
      "img id in: 16915\n",
      "img id out: 16915\n",
      "img id in: 16916\n",
      "img id out: 16916\n",
      "img id in: 16917\n",
      "img id out: 16917\n",
      "img id in: 16918\n",
      "img id out: 16918\n",
      "img id in: 16919\n",
      "img id out: 16919\n",
      "img id in: 16920\n",
      "img id out: 16920\n",
      "img id in: 16921\n",
      "img id out: 16921\n",
      "img id in: 16922\n",
      "img id out: 16922\n",
      "img id in: 16923\n",
      "img id out: 16923\n",
      "img id in: 16924\n",
      "img id out: 16924\n",
      "img id in: 16925\n",
      "img id out: 16925\n",
      "img id in: 16926\n",
      "img id out: 16926\n",
      "img id in: 16927\n",
      "img id out: 16927\n",
      "img id in: 16928\n",
      "img id out: 16928\n",
      "img id in: 16929\n",
      "img id out: 16929\n",
      "img id in: 16930\n",
      "img id out: 16930\n",
      "img id in: 16931\n",
      "img id out: 16931\n",
      "img id in: 16932\n",
      "img id out: 16932\n",
      "img id in: 16933\n",
      "img id out: 16933\n",
      "img id in: 16934\n",
      "img id out: 16934\n",
      "img id in: 16935\n",
      "img id out: 16935\n",
      "img id in: 16936\n",
      "img id out: 16936\n",
      "img id in: 16937\n",
      "img id out: 16937\n",
      "img id in: 16938\n",
      "img id out: 16938\n",
      "img id in: 16939\n",
      "img id out: 16939\n",
      "img id in: 16940\n",
      "img id out: 16940\n",
      "img id in: 16941\n",
      "img id out: 16941\n",
      "img id in: 16942\n",
      "img id out: 16942\n",
      "img id in: 16943\n",
      "img id out: 16943\n",
      "img id in: 16944\n",
      "img id out: 16944\n",
      "img id in: 16945\n",
      "img id out: 16945\n",
      "img id in: 16946\n",
      "img id out: 16946\n",
      "img id in: 16947\n",
      "img id out: 16947\n",
      "img id in: 16948\n",
      "img id out: 16948\n",
      "img id in: 16949\n",
      "img id out: 16949\n",
      "img id in: 16950\n",
      "img id out: 16950\n",
      "img id in: 16951\n",
      "img id out: 16951\n",
      "img id in: 16952\n",
      "img id out: 16952\n",
      "img id in: 16953\n",
      "img id out: 16953\n",
      "img id in: 16954\n",
      "img id out: 16954\n",
      "img id in: 16955\n",
      "img id out: 16955\n",
      "img id in: 16956\n",
      "img id out: 16956\n",
      "img id in: 16957\n",
      "img id out: 16957\n",
      "img id in: 16958\n",
      "img id out: 16958\n",
      "img id in: 16959\n",
      "img id out: 16959\n",
      "img id in: 16960\n",
      "img id out: 16960\n",
      "img id in: 16961\n",
      "img id out: 16961\n",
      "img id in: 16962\n",
      "img id out: 16962\n",
      "img id in: 16963\n",
      "img id out: 16963\n",
      "img id in: 16964\n",
      "img id out: 16964\n",
      "img id in: 16965\n",
      "img id out: 16965\n",
      "img id in: 16966\n",
      "img id out: 16966\n",
      "img id in: 16967\n",
      "img id out: 16967\n",
      "img id in: 16968\n",
      "img id out: 16968\n",
      "img id in: 16969\n",
      "img id out: 16969\n",
      "img id in: 16970\n",
      "img id out: 16970\n",
      "img id in: 16971\n",
      "img id out: 16971\n",
      "img id in: 16972\n",
      "img id out: 16972\n",
      "img id in: 16973\n",
      "img id out: 16973\n",
      "img id in: 16974\n",
      "img id out: 16974\n",
      "img id in: 16975\n",
      "img id out: 16975\n",
      "img id in: 16976\n",
      "img id out: 16976\n",
      "img id in: 16977\n",
      "img id out: 16977\n",
      "img id in: 16978\n",
      "img id out: 16978\n",
      "img id in: 16979\n",
      "img id out: 16979\n",
      "img id in: 16980\n",
      "img id out: 16980\n",
      "img id in: 16981\n",
      "img id out: 16981\n",
      "img id in: 16982\n",
      "img id out: 16982\n",
      "img id in: 16983\n",
      "img id out: 16983\n",
      "img id in: 16984\n",
      "img id out: 16984\n",
      "img id in: 16985\n",
      "img id out: 16985\n",
      "img id in: 16986\n",
      "img id out: 16986\n",
      "img id in: 16987\n",
      "img id out: 16987\n",
      "img id in: 16988\n",
      "img id out: 16988\n",
      "img id in: 16989\n",
      "img id out: 16989\n",
      "img id in: 16990\n",
      "img id out: 16990\n",
      "img id in: 16991\n",
      "img id out: 16991\n",
      "img id in: 16992\n",
      "img id out: 16992\n",
      "img id in: 16993\n",
      "img id out: 16993\n",
      "img id in: 16994\n",
      "img id out: 16994\n",
      "img id in: 16995\n",
      "img id out: 16995\n",
      "img id in: 16996\n",
      "img id out: 16996\n",
      "img id in: 16997\n",
      "img id out: 16997\n",
      "img id in: 16998\n",
      "img id out: 16998\n",
      "img id in: 16999\n",
      "img id out: 16999\n",
      "img id in: 17000\n",
      "img id out: 17000\n",
      "img id in: 17001\n",
      "img id out: 17001\n",
      "img id in: 17002\n",
      "img id out: 17002\n",
      "img id in: 17003\n",
      "img id out: 17003\n",
      "img id in: 17004\n",
      "img id out: 17004\n",
      "img id in: 17005\n",
      "img id out: 17005\n",
      "img id in: 17006\n",
      "img id out: 17006\n",
      "img id in: 17007\n",
      "img id out: 17007\n",
      "img id in: 17008\n",
      "img id out: 17008\n",
      "img id in: 17009\n",
      "img id out: 17009\n",
      "img id in: 17010\n",
      "img id out: 17010\n",
      "img id in: 17011\n",
      "img id out: 17011\n",
      "img id in: 17012\n",
      "img id out: 17012\n",
      "img id in: 17013\n",
      "img id out: 17013\n",
      "img id in: 17014\n",
      "img id out: 17014\n",
      "img id in: 17015\n",
      "img id out: 17015\n",
      "img id in: 17016\n",
      "img id out: 17016\n",
      "img id in: 17017\n",
      "img id out: 17017\n",
      "img id in: 17018\n",
      "img id out: 17018\n",
      "img id in: 17019\n",
      "img id out: 17019\n",
      "img id in: 17020\n",
      "img id out: 17020\n",
      "img id in: 17021\n",
      "img id out: 17021\n",
      "img id in: 17022\n",
      "img id out: 17022\n",
      "img id in: 17023\n",
      "img id out: 17023\n",
      "img id in: 17024\n",
      "img id out: 17024\n",
      "img id in: 17025\n",
      "img id out: 17025\n",
      "img id in: 17026\n",
      "img id out: 17026\n",
      "img id in: 17027\n",
      "img id out: 17027\n",
      "img id in: 17028\n",
      "img id out: 17028\n",
      "img id in: 17029\n",
      "img id out: 17029\n",
      "img id in: 17030\n",
      "img id out: 17030\n",
      "img id in: 17031\n",
      "img id out: 17031\n",
      "img id in: 17032\n",
      "img id out: 17032\n",
      "img id in: 17033\n",
      "img id out: 17033\n",
      "img id in: 17034\n",
      "img id out: 17034\n",
      "img id in: 17035\n",
      "img id out: 17035\n",
      "img id in: 17036\n",
      "img id out: 17036\n",
      "img id in: 17037\n",
      "img id out: 17037\n",
      "img id in: 17038\n",
      "img id out: 17038\n",
      "img id in: 17039\n",
      "img id out: 17039\n",
      "img id in: 17040\n",
      "img id out: 17040\n",
      "img id in: 17041\n",
      "img id out: 17041\n",
      "img id in: 17042\n",
      "img id out: 17042\n",
      "img id in: 17043\n",
      "img id out: 17043\n",
      "img id in: 17044\n",
      "img id out: 17044\n",
      "img id in: 17045\n",
      "img id out: 17045\n",
      "img id in: 17046\n",
      "img id out: 17046\n",
      "img id in: 17047\n",
      "img id out: 17047\n",
      "img id in: 17048\n",
      "img id out: 17048\n",
      "img id in: 17049\n",
      "img id out: 17049\n",
      "img id in: 17050\n",
      "img id out: 17050\n",
      "img id in: 17051\n",
      "img id out: 17051\n",
      "img id in: 17052\n",
      "img id out: 17052\n",
      "img id in: 17053\n",
      "img id out: 17053\n",
      "img id in: 17054\n",
      "img id out: 17054\n",
      "img id in: 17055\n",
      "img id out: 17055\n",
      "img id in: 17056\n",
      "img id out: 17056\n",
      "img id in: 17057\n",
      "img id out: 17057\n",
      "img id in: 17058\n",
      "img id out: 17058\n",
      "img id in: 17059\n",
      "img id out: 17059\n",
      "img id in: 17060\n",
      "img id out: 17060\n",
      "img id in: 17061\n",
      "img id out: 17061\n",
      "img id in: 17062\n",
      "img id out: 17062\n",
      "img id in: 17063\n",
      "img id out: 17063\n",
      "img id in: 17064\n",
      "img id out: 17064\n",
      "img id in: 17065\n",
      "img id out: 17065\n",
      "img id in: 17066\n",
      "img id out: 17066\n",
      "img id in: 17067\n",
      "img id out: 17067\n",
      "img id in: 17068\n",
      "img id out: 17068\n",
      "img id in: 17069\n",
      "img id out: 17069\n",
      "img id in: 17070\n",
      "img id out: 17070\n",
      "img id in: 17071\n",
      "img id out: 17071\n",
      "img id in: 17072\n",
      "img id out: 17072\n",
      "img id in: 17073\n",
      "img id out: 17073\n",
      "img id in: 17074\n",
      "img id out: 17074\n",
      "img id in: 17075\n",
      "img id out: 17075\n",
      "img id in: 17076\n",
      "img id out: 17076\n",
      "img id in: 17077\n",
      "img id out: 17077\n",
      "img id in: 17078\n",
      "img id out: 17078\n",
      "img id in: 17079\n",
      "img id out: 17079\n",
      "img id in: 17080\n",
      "img id out: 17080\n",
      "img id in: 17081\n",
      "img id out: 17081\n",
      "img id in: 17082\n",
      "img id out: 17082\n",
      "img id in: 17083\n",
      "img id out: 17083\n",
      "img id in: 17084\n",
      "img id out: 17084\n",
      "img id in: 17085\n",
      "img id out: 17085\n",
      "img id in: 17086\n",
      "img id out: 17086\n",
      "img id in: 17087\n",
      "img id out: 17087\n",
      "img id in: 17088\n",
      "img id out: 17088\n",
      "img id in: 17089\n",
      "img id out: 17089\n",
      "img id in: 17090\n",
      "img id out: 17090\n",
      "img id in: 17091\n",
      "img id out: 17091\n",
      "img id in: 17092\n",
      "img id out: 17092\n",
      "img id in: 17093\n",
      "img id out: 17093\n",
      "img id in: 17094\n",
      "img id out: 17094\n",
      "img id in: 17095\n",
      "img id out: 17095\n",
      "img id in: 17096\n",
      "img id out: 17096\n",
      "img id in: 17097\n",
      "img id out: 17097\n",
      "img id in: 17098\n",
      "img id out: 17098\n",
      "img id in: 17099\n",
      "img id out: 17099\n",
      "img id in: 17100\n",
      "img id out: 17100\n",
      "img id in: 17101\n",
      "img id out: 17101\n",
      "img id in: 17102\n",
      "img id out: 17102\n",
      "img id in: 17103\n",
      "img id out: 17103\n",
      "img id in: 17104\n",
      "img id out: 17104\n",
      "img id in: 17105\n",
      "img id out: 17105\n",
      "img id in: 17106\n",
      "img id out: 17106\n",
      "img id in: 17107\n",
      "img id out: 17107\n",
      "img id in: 17108\n",
      "img id out: 17108\n",
      "img id in: 17109\n",
      "img id out: 17109\n",
      "img id in: 17110\n",
      "img id out: 17110\n",
      "img id in: 17111\n",
      "img id out: 17111\n",
      "img id in: 17112\n",
      "img id out: 17112\n",
      "img id in: 17113\n",
      "img id out: 17113\n",
      "img id in: 17114\n",
      "img id out: 17114\n",
      "img id in: 17115\n",
      "img id out: 17115\n",
      "img id in: 17116\n",
      "img id out: 17116\n",
      "img id in: 17117\n",
      "img id out: 17117\n",
      "img id in: 17118\n",
      "img id out: 17118\n",
      "img id in: 17119\n",
      "img id out: 17119\n",
      "img id in: 17120\n",
      "img id out: 17120\n",
      "img id in: 17121\n",
      "img id out: 17121\n",
      "img id in: 17122\n",
      "img id out: 17122\n",
      "img id in: 17123\n",
      "img id out: 17123\n",
      "img id in: 17124\n",
      "img id out: 17124\n",
      "img id in: 17125\n",
      "img id out: 17125\n",
      "img id in: 17126\n",
      "img id out: 17126\n",
      "img id in: 17127\n",
      "img id out: 17127\n",
      "img id in: 17128\n",
      "img id out: 17128\n",
      "img id in: 17129\n",
      "img id out: 17129\n",
      "img id in: 17130\n",
      "img id out: 17130\n",
      "img id in: 17131\n",
      "img id out: 17131\n",
      "img id in: 17132\n",
      "img id out: 17132\n",
      "img id in: 17133\n",
      "img id out: 17133\n",
      "img id in: 17134\n",
      "img id out: 17134\n",
      "img id in: 17135\n",
      "img id out: 17135\n",
      "img id in: 17136\n",
      "img id out: 17136\n",
      "img id in: 17137\n",
      "img id out: 17137\n",
      "img id in: 17138\n",
      "img id out: 17138\n",
      "img id in: 17139\n",
      "img id out: 17139\n",
      "img id in: 17140\n",
      "img id out: 17140\n",
      "img id in: 17141\n",
      "img id out: 17141\n",
      "img id in: 17142\n",
      "img id out: 17142\n",
      "img id in: 17143\n",
      "img id out: 17143\n",
      "img id in: 17144\n",
      "img id out: 17144\n",
      "img id in: 17145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 17145\n",
      "img id in: 17146\n",
      "img id out: 17146\n",
      "img id in: 17147\n",
      "img id out: 17147\n",
      "img id in: 17148\n",
      "img id out: 17148\n",
      "img id in: 17149\n",
      "img id out: 17149\n",
      "img id in: 17150\n",
      "img id out: 17150\n",
      "img id in: 17151\n",
      "img id out: 17151\n",
      "img id in: 17152\n",
      "img id out: 17152\n",
      "img id in: 17153\n",
      "img id out: 17153\n",
      "img id in: 17154\n",
      "img id out: 17154\n",
      "img id in: 17155\n",
      "img id out: 17155\n",
      "img id in: 17156\n",
      "img id out: 17156\n",
      "img id in: 17157\n",
      "img id out: 17157\n",
      "img id in: 17158\n",
      "img id out: 17158\n",
      "img id in: 17159\n",
      "img id out: 17159\n",
      "img id in: 17160\n",
      "img id out: 17160\n",
      "img id in: 17161\n",
      "img id out: 17161\n",
      "img id in: 17162\n",
      "img id out: 17162\n",
      "img id in: 17163\n",
      "img id out: 17163\n",
      "img id in: 17164\n",
      "img id out: 17164\n",
      "img id in: 17165\n",
      "img id out: 17165\n",
      "img id in: 17166\n",
      "img id out: 17166\n",
      "img id in: 17167\n",
      "img id out: 17167\n",
      "img id in: 17168\n",
      "img id out: 17168\n",
      "img id in: 17169\n",
      "img id out: 17169\n",
      "img id in: 17170\n",
      "img id out: 17170\n",
      "img id in: 17171\n",
      "img id out: 17171\n",
      "img id in: 17172\n",
      "img id out: 17172\n",
      "img id in: 17173\n",
      "img id out: 17173\n",
      "img id in: 17174\n",
      "img id out: 17174\n",
      "img id in: 17175\n",
      "img id out: 17175\n",
      "img id in: 17176\n",
      "img id out: 17176\n",
      "img id in: 17177\n",
      "img id out: 17177\n",
      "img id in: 17178\n",
      "img id out: 17178\n",
      "img id in: 17179\n",
      "img id out: 17179\n",
      "img id in: 17180\n",
      "img id out: 17180\n",
      "img id in: 17181\n",
      "img id out: 17181\n",
      "img id in: 17182\n",
      "img id out: 17182\n",
      "img id in: 17183\n",
      "img id out: 17183\n",
      "img id in: 17184\n",
      "img id out: 17184\n",
      "img id in: 17185\n",
      "img id out: 17185\n",
      "img id in: 17186\n",
      "img id out: 17186\n",
      "img id in: 17187\n",
      "img id out: 17187\n",
      "img id in: 17188\n",
      "img id out: 17188\n",
      "img id in: 17189\n",
      "img id out: 17189\n",
      "img id in: 17190\n",
      "img id out: 17190\n",
      "img id in: 17191\n",
      "img id out: 17191\n",
      "img id in: 17192\n",
      "img id out: 17192\n",
      "img id in: 17193\n",
      "img id out: 17193\n",
      "img id in: 17194\n",
      "img id out: 17194\n",
      "img id in: 17195\n",
      "img id out: 17195\n",
      "img id in: 17196\n",
      "img id out: 17196\n",
      "img id in: 17197\n",
      "img id out: 17197\n",
      "img id in: 17198\n",
      "img id out: 17198\n",
      "img id in: 17199\n",
      "img id out: 17199\n",
      "img id in: 17200\n",
      "img id out: 17200\n",
      "img id in: 17201\n",
      "img id out: 17201\n",
      "img id in: 17202\n",
      "img id out: 17202\n",
      "img id in: 17203\n",
      "img id out: 17203\n",
      "img id in: 17204\n",
      "img id out: 17204\n",
      "img id in: 17205\n",
      "img id out: 17205\n",
      "img id in: 17206\n",
      "img id out: 17206\n",
      "img id in: 17207\n",
      "img id out: 17207\n",
      "img id in: 17208\n",
      "img id out: 17208\n",
      "img id in: 17209\n",
      "img id out: 17209\n",
      "img id in: 17210\n",
      "img id out: 17210\n",
      "img id in: 17211\n",
      "img id out: 17211\n",
      "img id in: 17212\n",
      "img id out: 17212\n",
      "img id in: 17213\n",
      "img id out: 17213\n",
      "img id in: 17214\n",
      "img id out: 17214\n",
      "img id in: 17215\n",
      "img id out: 17215\n",
      "img id in: 17216\n",
      "img id out: 17216\n",
      "img id in: 17217\n",
      "img id out: 17217\n",
      "img id in: 17218\n",
      "img id out: 17218\n",
      "img id in: 17219\n",
      "img id out: 17219\n",
      "img id in: 17220\n",
      "img id out: 17220\n",
      "img id in: 17221\n",
      "img id out: 17221\n",
      "img id in: 17222\n",
      "img id out: 17222\n",
      "img id in: 17223\n",
      "img id out: 17223\n",
      "img id in: 17224\n",
      "img id out: 17224\n",
      "img id in: 17225\n",
      "img id out: 17225\n",
      "img id in: 17226\n",
      "img id out: 17226\n",
      "img id in: 17227\n",
      "img id out: 17227\n",
      "img id in: 17228\n",
      "img id out: 17228\n",
      "img id in: 17229\n",
      "img id out: 17229\n",
      "img id in: 17230\n",
      "img id out: 17230\n",
      "img id in: 17231\n",
      "img id out: 17231\n",
      "img id in: 17232\n",
      "img id out: 17232\n",
      "img id in: 17233\n",
      "img id out: 17233\n",
      "img id in: 17234\n",
      "img id out: 17234\n",
      "img id in: 17235\n",
      "img id out: 17235\n",
      "img id in: 17236\n",
      "img id out: 17236\n",
      "img id in: 17237\n",
      "img id out: 17237\n",
      "img id in: 17238\n",
      "img id out: 17238\n",
      "img id in: 17239\n",
      "img id out: 17239\n",
      "img id in: 17240\n",
      "img id out: 17240\n",
      "img id in: 17241\n",
      "img id out: 17241\n",
      "img id in: 17242\n",
      "img id out: 17242\n",
      "img id in: 17243\n",
      "img id out: 17243\n",
      "img id in: 17244\n",
      "img id out: 17244\n",
      "img id in: 17245\n",
      "img id out: 17245\n",
      "img id in: 17246\n",
      "img id out: 17246\n",
      "img id in: 17247\n",
      "img id out: 17247\n",
      "img id in: 17248\n",
      "img id out: 17248\n",
      "img id in: 17249\n",
      "img id out: 17249\n",
      "img id in: 17250\n",
      "img id out: 17250\n",
      "img id in: 17251\n",
      "img id out: 17251\n",
      "img id in: 17252\n",
      "img id out: 17252\n",
      "img id in: 17253\n",
      "img id out: 17253\n",
      "img id in: 17254\n",
      "img id out: 17254\n",
      "img id in: 17255\n",
      "img id out: 17255\n",
      "img id in: 17256\n",
      "img id out: 17256\n",
      "img id in: 17257\n",
      "img id out: 17257\n",
      "img id in: 17258\n",
      "img id out: 17258\n",
      "img id in: 17259\n",
      "img id out: 17259\n",
      "img id in: 17260\n",
      "img id out: 17260\n",
      "img id in: 17261\n",
      "img id out: 17261\n",
      "img id in: 17262\n",
      "img id out: 17262\n",
      "img id in: 17263\n",
      "img id out: 17263\n",
      "img id in: 17264\n",
      "img id out: 17264\n",
      "img id in: 17265\n",
      "img id out: 17265\n",
      "img id in: 17266\n",
      "img id out: 17266\n",
      "img id in: 17267\n",
      "img id out: 17267\n",
      "img id in: 17268\n",
      "img id out: 17268\n",
      "img id in: 17269\n",
      "img id out: 17269\n",
      "img id in: 17270\n",
      "img id out: 17270\n",
      "img id in: 17271\n",
      "img id out: 17271\n",
      "img id in: 17272\n",
      "img id out: 17272\n",
      "img id in: 17273\n",
      "img id out: 17273\n",
      "img id in: 17274\n",
      "img id out: 17274\n",
      "img id in: 17275\n",
      "img id out: 17275\n",
      "img id in: 17276\n",
      "img id out: 17276\n",
      "img id in: 17277\n",
      "img id out: 17277\n",
      "img id in: 17278\n",
      "img id out: 17278\n",
      "img id in: 17279\n",
      "img id out: 17279\n",
      "img id in: 17280\n",
      "img id out: 17280\n",
      "img id in: 17281\n",
      "img id out: 17281\n",
      "img id in: 17282\n",
      "img id out: 17282\n",
      "img id in: 17283\n",
      "img id out: 17283\n",
      "img id in: 17284\n",
      "img id out: 17284\n",
      "img id in: 17285\n",
      "img id out: 17285\n",
      "img id in: 17286\n",
      "img id out: 17286\n",
      "img id in: 17287\n",
      "img id out: 17287\n",
      "img id in: 17288\n",
      "img id out: 17288\n",
      "img id in: 17289\n",
      "img id out: 17289\n",
      "img id in: 17290\n",
      "img id out: 17290\n",
      "img id in: 17291\n",
      "img id out: 17291\n",
      "img id in: 17292\n",
      "img id out: 17292\n",
      "img id in: 17293\n",
      "img id out: 17293\n",
      "img id in: 17294\n",
      "img id out: 17294\n",
      "img id in: 17295\n",
      "img id out: 17295\n",
      "img id in: 17296\n",
      "img id out: 17296\n",
      "img id in: 17297\n",
      "img id out: 17297\n",
      "img id in: 17298\n",
      "img id out: 17298\n",
      "img id in: 17299\n",
      "img id out: 17299\n",
      "img id in: 17300\n",
      "img id out: 17300\n",
      "img id in: 17301\n",
      "img id out: 17301\n",
      "img id in: 17302\n",
      "img id out: 17302\n",
      "img id in: 17303\n",
      "img id out: 17303\n",
      "img id in: 17304\n",
      "img id out: 17304\n",
      "img id in: 17305\n",
      "img id out: 17305\n",
      "img id in: 17306\n",
      "img id out: 17306\n",
      "img id in: 17307\n",
      "img id out: 17307\n",
      "img id in: 17308\n",
      "img id out: 17308\n",
      "img id in: 17309\n",
      "img id out: 17309\n",
      "img id in: 17310\n",
      "img id out: 17310\n",
      "img id in: 17311\n",
      "img id out: 17311\n",
      "img id in: 17312\n",
      "img id out: 17312\n",
      "img id in: 17313\n",
      "img id out: 17313\n",
      "img id in: 17314\n",
      "img id out: 17314\n",
      "img id in: 17315\n",
      "img id out: 17315\n",
      "img id in: 17316\n",
      "img id out: 17316\n",
      "img id in: 17317\n",
      "img id out: 17317\n",
      "img id in: 17318\n",
      "img id out: 17318\n",
      "img id in: 17319\n",
      "img id out: 17319\n",
      "img id in: 17320\n",
      "img id out: 17320\n",
      "img id in: 17321\n",
      "img id out: 17321\n",
      "img id in: 17322\n",
      "img id out: 17322\n",
      "img id in: 17323\n",
      "img id out: 17323\n",
      "img id in: 17324\n",
      "img id out: 17324\n",
      "img id in: 17325\n",
      "img id out: 17325\n",
      "img id in: 17326\n",
      "img id out: 17326\n",
      "img id in: 17327\n",
      "img id out: 17327\n",
      "img id in: 17328\n",
      "img id out: 17328\n",
      "img id in: 17329\n",
      "img id out: 17329\n",
      "img id in: 17330\n",
      "img id out: 17330\n",
      "img id in: 17331\n",
      "img id out: 17331\n",
      "img id in: 17332\n",
      "img id out: 17332\n",
      "img id in: 17333\n",
      "img id out: 17333\n",
      "img id in: 17334\n",
      "img id out: 17334\n",
      "img id in: 17335\n",
      "img id out: 17335\n",
      "img id in: 17336\n",
      "img id out: 17336\n",
      "img id in: 17337\n",
      "img id out: 17337\n",
      "img id in: 17338\n",
      "img id out: 17338\n",
      "img id in: 17339\n",
      "img id out: 17339\n",
      "img id in: 17340\n",
      "img id out: 17340\n",
      "img id in: 17341\n",
      "img id out: 17341\n",
      "img id in: 17342\n",
      "img id out: 17342\n",
      "img id in: 17343\n",
      "img id out: 17343\n",
      "img id in: 17344\n",
      "img id out: 17344\n",
      "img id in: 17345\n",
      "img id out: 17345\n",
      "img id in: 17346\n",
      "img id out: 17346\n",
      "img id in: 17347\n",
      "img id out: 17347\n",
      "img id in: 17348\n",
      "img id out: 17348\n",
      "img id in: 17349\n",
      "img id out: 17349\n",
      "img id in: 17350\n",
      "img id out: 17350\n",
      "img id in: 17351\n",
      "img id out: 17351\n",
      "img id in: 17352\n",
      "img id out: 17352\n",
      "img id in: 17353\n",
      "img id out: 17353\n",
      "img id in: 17354\n",
      "img id out: 17354\n",
      "img id in: 17355\n",
      "img id out: 17355\n",
      "img id in: 17356\n",
      "img id out: 17356\n",
      "img id in: 17357\n",
      "img id out: 17357\n",
      "img id in: 17358\n",
      "img id out: 17358\n",
      "img id in: 17359\n",
      "img id out: 17359\n",
      "img id in: 17360\n",
      "img id out: 17360\n",
      "img id in: 17361\n",
      "img id out: 17361\n",
      "img id in: 17362\n",
      "img id out: 17362\n",
      "img id in: 17363\n",
      "img id out: 17363\n",
      "img id in: 17364\n",
      "img id out: 17364\n",
      "img id in: 17365\n",
      "img id out: 17365\n",
      "img id in: 17366\n",
      "img id out: 17366\n",
      "img id in: 17367\n",
      "img id out: 17367\n",
      "img id in: 17368\n",
      "img id out: 17368\n",
      "img id in: 17369\n",
      "img id out: 17369\n",
      "img id in: 17370\n",
      "img id out: 17370\n",
      "img id in: 17371\n",
      "img id out: 17371\n",
      "img id in: 17372\n",
      "img id out: 17372\n",
      "img id in: 17373\n",
      "img id out: 17373\n",
      "img id in: 17374\n",
      "img id out: 17374\n",
      "img id in: 17375\n",
      "img id out: 17375\n",
      "img id in: 17376\n",
      "img id out: 17376\n",
      "img id in: 17377\n",
      "img id out: 17377\n",
      "img id in: 17378\n",
      "img id out: 17378\n",
      "img id in: 17379\n",
      "img id out: 17379\n",
      "img id in: 17380\n",
      "img id out: 17380\n",
      "img id in: 17381\n",
      "img id out: 17381\n",
      "img id in: 17382\n",
      "img id out: 17382\n",
      "img id in: 17383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 17383\n",
      "img id in: 17384\n",
      "img id out: 17384\n",
      "img id in: 17385\n",
      "img id out: 17385\n",
      "img id in: 17386\n",
      "img id out: 17386\n",
      "img id in: 17387\n",
      "img id out: 17387\n",
      "img id in: 17388\n",
      "img id out: 17388\n",
      "img id in: 17389\n",
      "img id out: 17389\n",
      "img id in: 17390\n",
      "img id out: 17390\n",
      "img id in: 17391\n",
      "img id out: 17391\n",
      "img id in: 17392\n",
      "img id out: 17392\n",
      "img id in: 17393\n",
      "img id out: 17393\n",
      "img id in: 17394\n",
      "img id out: 17394\n",
      "img id in: 17395\n",
      "img id out: 17395\n",
      "img id in: 17396\n",
      "img id out: 17396\n",
      "img id in: 17397\n",
      "img id out: 17397\n",
      "img id in: 17398\n",
      "img id out: 17398\n",
      "img id in: 17399\n",
      "img id out: 17399\n",
      "img id in: 17400\n",
      "img id out: 17400\n",
      "img id in: 17401\n",
      "img id out: 17401\n",
      "img id in: 17402\n",
      "img id out: 17402\n",
      "img id in: 17403\n",
      "img id out: 17403\n",
      "img id in: 17404\n",
      "img id out: 17404\n",
      "img id in: 17405\n",
      "img id out: 17405\n",
      "img id in: 17406\n",
      "img id out: 17406\n",
      "img id in: 17407\n",
      "img id out: 17407\n",
      "img id in: 17408\n",
      "img id out: 17408\n",
      "img id in: 17409\n",
      "img id out: 17409\n",
      "img id in: 17410\n",
      "img id out: 17410\n",
      "img id in: 17411\n",
      "img id out: 17411\n",
      "img id in: 17412\n",
      "img id out: 17412\n",
      "img id in: 17413\n",
      "img id out: 17413\n",
      "img id in: 17414\n",
      "img id out: 17414\n",
      "img id in: 17415\n",
      "img id out: 17415\n",
      "img id in: 17416\n",
      "img id out: 17416\n",
      "img id in: 17417\n",
      "img id out: 17417\n",
      "img id in: 17418\n",
      "img id out: 17418\n",
      "img id in: 17419\n",
      "img id out: 17419\n",
      "img id in: 17420\n",
      "img id out: 17420\n",
      "img id in: 17421\n",
      "img id out: 17421\n",
      "img id in: 17422\n",
      "img id out: 17422\n",
      "img id in: 17423\n",
      "img id out: 17423\n",
      "img id in: 17424\n",
      "img id out: 17424\n",
      "img id in: 17425\n",
      "img id out: 17425\n",
      "img id in: 17426\n",
      "img id out: 17426\n",
      "img id in: 17427\n",
      "img id out: 17427\n",
      "img id in: 17428\n",
      "img id out: 17428\n",
      "img id in: 17429\n",
      "img id out: 17429\n",
      "img id in: 17430\n",
      "img id out: 17430\n",
      "img id in: 17431\n",
      "img id out: 17431\n",
      "img id in: 17432\n",
      "img id out: 17432\n",
      "img id in: 17433\n",
      "img id out: 17433\n",
      "img id in: 17434\n",
      "img id out: 17434\n",
      "img id in: 17435\n",
      "img id out: 17435\n",
      "img id in: 17436\n",
      "img id out: 17436\n",
      "img id in: 17437\n",
      "img id out: 17437\n",
      "img id in: 17438\n",
      "img id out: 17438\n",
      "img id in: 17439\n",
      "img id out: 17439\n",
      "img id in: 17440\n",
      "img id out: 17440\n",
      "img id in: 17441\n",
      "img id out: 17441\n",
      "img id in: 17442\n",
      "img id out: 17442\n",
      "img id in: 17443\n",
      "img id out: 17443\n",
      "img id in: 17444\n",
      "img id out: 17444\n",
      "img id in: 17445\n",
      "img id out: 17445\n",
      "img id in: 17446\n",
      "img id out: 17446\n",
      "img id in: 17447\n",
      "img id out: 17447\n",
      "img id in: 17448\n",
      "img id out: 17448\n",
      "img id in: 17449\n",
      "img id out: 17449\n",
      "img id in: 17450\n",
      "img id out: 17450\n",
      "img id in: 17451\n",
      "img id out: 17451\n",
      "img id in: 17452\n",
      "img id out: 17452\n",
      "img id in: 17453\n",
      "img id out: 17453\n",
      "img id in: 17454\n",
      "img id out: 17454\n",
      "img id in: 17455\n",
      "img id out: 17455\n",
      "img id in: 17456\n",
      "img id out: 17456\n",
      "img id in: 17457\n",
      "img id out: 17457\n",
      "img id in: 17458\n",
      "img id out: 17458\n",
      "img id in: 17459\n",
      "img id out: 17459\n",
      "img id in: 17460\n",
      "img id out: 17460\n",
      "img id in: 17461\n",
      "img id out: 17461\n",
      "img id in: 17462\n",
      "img id out: 17462\n",
      "img id in: 17463\n",
      "img id out: 17463\n",
      "img id in: 17464\n",
      "img id out: 17464\n",
      "img id in: 17465\n",
      "img id out: 17465\n",
      "img id in: 17466\n",
      "img id out: 17466\n",
      "img id in: 17467\n",
      "img id out: 17467\n",
      "img id in: 17468\n",
      "img id out: 17468\n",
      "img id in: 17469\n",
      "img id out: 17469\n",
      "img id in: 17470\n",
      "img id out: 17470\n",
      "img id in: 17471\n",
      "img id out: 17471\n",
      "img id in: 17472\n",
      "img id out: 17472\n",
      "img id in: 17473\n",
      "img id out: 17473\n",
      "img id in: 17474\n",
      "img id out: 17474\n",
      "img id in: 17475\n",
      "img id out: 17475\n",
      "img id in: 17476\n",
      "img id out: 17476\n",
      "img id in: 17477\n",
      "img id out: 17477\n",
      "img id in: 17478\n",
      "img id out: 17478\n",
      "img id in: 17479\n",
      "img id out: 17479\n",
      "img id in: 17480\n",
      "img id out: 17480\n",
      "img id in: 17481\n",
      "img id out: 17481\n",
      "img id in: 17482\n",
      "img id out: 17482\n",
      "img id in: 17483\n",
      "img id out: 17483\n",
      "img id in: 17484\n",
      "img id out: 17484\n",
      "img id in: 17485\n",
      "img id out: 17485\n",
      "img id in: 17486\n",
      "img id out: 17486\n",
      "img id in: 17487\n",
      "img id out: 17487\n",
      "img id in: 17488\n",
      "img id out: 17488\n",
      "img id in: 17489\n",
      "img id out: 17489\n",
      "img id in: 17490\n",
      "img id out: 17490\n",
      "img id in: 17491\n",
      "img id out: 17491\n",
      "img id in: 17492\n",
      "img id out: 17492\n",
      "img id in: 17493\n",
      "img id out: 17493\n",
      "img id in: 17494\n",
      "img id out: 17494\n",
      "img id in: 17495\n",
      "img id out: 17495\n",
      "img id in: 17496\n",
      "img id out: 17496\n",
      "img id in: 17497\n",
      "img id out: 17497\n",
      "img id in: 17498\n",
      "img id out: 17498\n",
      "img id in: 17499\n",
      "img id out: 17499\n",
      "img id in: 17500\n",
      "img id out: 17500\n",
      "img id in: 17501\n",
      "img id out: 17501\n",
      "img id in: 17502\n",
      "img id out: 17502\n",
      "img id in: 17503\n",
      "img id out: 17503\n",
      "img id in: 17504\n",
      "img id out: 17504\n",
      "img id in: 17505\n",
      "img id out: 17505\n",
      "img id in: 17506\n",
      "img id out: 17506\n",
      "img id in: 17507\n",
      "img id out: 17507\n",
      "img id in: 17508\n",
      "img id out: 17508\n",
      "img id in: 17509\n",
      "img id out: 17509\n",
      "img id in: 17510\n",
      "img id out: 17510\n",
      "img id in: 17511\n",
      "img id out: 17511\n",
      "img id in: 17512\n",
      "img id out: 17512\n",
      "img id in: 17513\n",
      "img id out: 17513\n",
      "img id in: 17514\n",
      "img id out: 17514\n",
      "img id in: 17515\n",
      "img id out: 17515\n",
      "img id in: 17516\n",
      "img id out: 17516\n",
      "img id in: 17517\n",
      "img id out: 17517\n",
      "img id in: 17518\n",
      "img id out: 17518\n",
      "img id in: 17519\n",
      "img id out: 17519\n",
      "img id in: 17520\n",
      "img id out: 17520\n",
      "img id in: 17521\n",
      "img id out: 17521\n",
      "img id in: 17522\n",
      "img id out: 17522\n",
      "img id in: 17523\n",
      "img id out: 17523\n",
      "img id in: 17524\n",
      "img id out: 17524\n",
      "img id in: 17525\n",
      "img id out: 17525\n",
      "img id in: 17526\n",
      "img id out: 17526\n",
      "img id in: 17527\n",
      "img id out: 17527\n",
      "img id in: 17528\n",
      "img id out: 17528\n",
      "img id in: 17529\n",
      "img id out: 17529\n",
      "img id in: 17530\n",
      "img id out: 17530\n",
      "img id in: 17531\n",
      "img id out: 17531\n",
      "img id in: 17532\n",
      "img id out: 17532\n",
      "img id in: 17533\n",
      "img id out: 17533\n",
      "img id in: 17534\n",
      "img id out: 17534\n",
      "img id in: 17535\n",
      "img id out: 17535\n",
      "img id in: 17536\n",
      "img id out: 17536\n",
      "img id in: 17537\n",
      "img id out: 17537\n",
      "img id in: 17538\n",
      "img id out: 17538\n",
      "img id in: 17539\n",
      "img id out: 17539\n",
      "img id in: 17540\n",
      "img id out: 17540\n",
      "img id in: 17541\n",
      "img id out: 17541\n",
      "img id in: 17542\n",
      "img id out: 17542\n",
      "img id in: 17543\n",
      "img id out: 17543\n",
      "img id in: 17544\n",
      "img id out: 17544\n",
      "img id in: 17545\n",
      "img id out: 17545\n",
      "img id in: 17546\n",
      "img id out: 17546\n",
      "img id in: 17547\n",
      "img id out: 17547\n",
      "img id in: 17548\n",
      "img id out: 17548\n",
      "img id in: 17549\n",
      "img id out: 17549\n",
      "img id in: 17550\n",
      "img id out: 17550\n",
      "img id in: 17551\n",
      "img id out: 17551\n",
      "img id in: 17552\n",
      "img id out: 17552\n",
      "img id in: 17553\n",
      "img id out: 17553\n",
      "img id in: 17554\n",
      "img id out: 17554\n",
      "img id in: 17555\n",
      "img id out: 17555\n",
      "img id in: 17556\n",
      "img id out: 17556\n",
      "img id in: 17557\n",
      "img id out: 17557\n",
      "img id in: 17558\n",
      "img id out: 17558\n",
      "img id in: 17559\n",
      "img id out: 17559\n",
      "img id in: 17560\n",
      "img id out: 17560\n",
      "img id in: 17561\n",
      "img id out: 17561\n",
      "img id in: 17562\n",
      "img id out: 17562\n",
      "img id in: 17563\n",
      "img id out: 17563\n",
      "img id in: 17564\n",
      "img id out: 17564\n",
      "img id in: 17565\n",
      "img id out: 17565\n",
      "img id in: 17566\n",
      "img id out: 17566\n",
      "img id in: 17567\n",
      "img id out: 17567\n",
      "img id in: 17568\n",
      "img id out: 17568\n",
      "img id in: 17569\n",
      "img id out: 17569\n",
      "img id in: 17570\n",
      "img id out: 17570\n",
      "img id in: 17571\n",
      "img id out: 17571\n",
      "img id in: 17572\n",
      "img id out: 17572\n",
      "img id in: 17573\n",
      "img id out: 17573\n",
      "img id in: 17574\n",
      "img id out: 17574\n",
      "img id in: 17575\n",
      "img id out: 17575\n",
      "img id in: 17576\n",
      "img id out: 17576\n",
      "img id in: 17577\n",
      "img id out: 17577\n",
      "img id in: 17578\n",
      "img id out: 17578\n",
      "img id in: 17579\n",
      "img id out: 17579\n",
      "img id in: 17580\n",
      "img id out: 17580\n",
      "img id in: 17581\n",
      "img id out: 17581\n",
      "img id in: 17582\n",
      "img id out: 17582\n",
      "img id in: 17583\n",
      "img id out: 17583\n",
      "img id in: 17584\n",
      "img id out: 17584\n",
      "img id in: 17585\n",
      "img id out: 17585\n",
      "img id in: 17586\n",
      "img id out: 17586\n",
      "img id in: 17587\n",
      "img id out: 17587\n",
      "img id in: 17588\n",
      "img id out: 17588\n",
      "img id in: 17589\n",
      "img id out: 17589\n",
      "img id in: 17590\n",
      "img id out: 17590\n",
      "img id in: 17591\n",
      "img id out: 17591\n",
      "img id in: 17592\n",
      "img id out: 17592\n",
      "img id in: 17593\n",
      "img id out: 17593\n",
      "img id in: 17594\n",
      "img id out: 17594\n",
      "img id in: 17595\n",
      "img id out: 17595\n",
      "img id in: 17596\n",
      "img id out: 17596\n",
      "img id in: 17597\n",
      "img id out: 17597\n",
      "img id in: 17598\n",
      "img id out: 17598\n",
      "img id in: 17599\n",
      "img id out: 17599\n",
      "img id in: 17600\n",
      "img id out: 17600\n",
      "img id in: 17601\n",
      "img id out: 17601\n",
      "img id in: 17602\n",
      "img id out: 17602\n",
      "img id in: 17603\n",
      "img id out: 17603\n",
      "img id in: 17604\n",
      "img id out: 17604\n",
      "img id in: 17605\n",
      "img id out: 17605\n",
      "img id in: 17606\n",
      "img id out: 17606\n",
      "img id in: 17607\n",
      "img id out: 17607\n",
      "img id in: 17608\n",
      "img id out: 17608\n",
      "img id in: 17609\n",
      "img id out: 17609\n",
      "img id in: 17610\n",
      "img id out: 17610\n",
      "img id in: 17611\n",
      "img id out: 17611\n",
      "img id in: 17612\n",
      "img id out: 17612\n",
      "img id in: 17613\n",
      "img id out: 17613\n",
      "img id in: 17614\n",
      "img id out: 17614\n",
      "img id in: 17615\n",
      "img id out: 17615\n",
      "img id in: 17616\n",
      "img id out: 17616\n",
      "img id in: 17617\n",
      "img id out: 17617\n",
      "img id in: 17618\n",
      "img id out: 17618\n",
      "img id in: 17619\n",
      "img id out: 17619\n",
      "img id in: 17620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 17620\n",
      "img id in: 17621\n",
      "img id out: 17621\n",
      "img id in: 17622\n",
      "img id out: 17622\n",
      "img id in: 17623\n",
      "img id out: 17623\n",
      "img id in: 17624\n",
      "img id out: 17624\n",
      "img id in: 17625\n",
      "img id out: 17625\n",
      "img id in: 17626\n",
      "img id out: 17626\n",
      "img id in: 17627\n",
      "img id out: 17627\n",
      "img id in: 17628\n",
      "img id out: 17628\n",
      "img id in: 17629\n",
      "img id out: 17629\n",
      "img id in: 17630\n",
      "img id out: 17630\n",
      "img id in: 17631\n",
      "img id out: 17631\n",
      "img id in: 17632\n",
      "img id out: 17632\n",
      "img id in: 17633\n",
      "img id out: 17633\n",
      "img id in: 17634\n",
      "img id out: 17634\n",
      "img id in: 17635\n",
      "img id out: 17635\n",
      "img id in: 17636\n",
      "img id out: 17636\n",
      "img id in: 17637\n",
      "img id out: 17637\n",
      "img id in: 17638\n",
      "img id out: 17638\n",
      "img id in: 17639\n",
      "img id out: 17639\n",
      "img id in: 17640\n",
      "img id out: 17640\n",
      "img id in: 17641\n",
      "img id out: 17641\n",
      "img id in: 17642\n",
      "img id out: 17642\n",
      "img id in: 17643\n",
      "img id out: 17643\n",
      "img id in: 17644\n",
      "img id out: 17644\n",
      "img id in: 17645\n",
      "img id out: 17645\n",
      "img id in: 17646\n",
      "img id out: 17646\n",
      "img id in: 17647\n",
      "img id out: 17647\n",
      "img id in: 17648\n",
      "img id out: 17648\n",
      "img id in: 17649\n",
      "img id out: 17649\n",
      "img id in: 17650\n",
      "img id out: 17650\n",
      "img id in: 17651\n",
      "img id out: 17651\n",
      "img id in: 17652\n",
      "img id out: 17652\n",
      "img id in: 17653\n",
      "img id out: 17653\n",
      "img id in: 17654\n",
      "img id out: 17654\n",
      "img id in: 17655\n",
      "img id out: 17655\n",
      "img id in: 17656\n",
      "img id out: 17656\n",
      "img id in: 17657\n",
      "img id out: 17657\n",
      "img id in: 17658\n",
      "img id out: 17658\n",
      "img id in: 17659\n",
      "img id out: 17659\n",
      "img id in: 17660\n",
      "img id out: 17660\n",
      "img id in: 17661\n",
      "img id out: 17661\n",
      "img id in: 17662\n",
      "img id out: 17662\n",
      "img id in: 17663\n",
      "img id out: 17663\n",
      "img id in: 17664\n",
      "img id out: 17664\n",
      "img id in: 17665\n",
      "img id out: 17665\n",
      "img id in: 17666\n",
      "img id out: 17666\n",
      "img id in: 17667\n",
      "img id out: 17667\n",
      "img id in: 17668\n",
      "img id out: 17668\n",
      "img id in: 17669\n",
      "img id out: 17669\n",
      "img id in: 17670\n",
      "img id out: 17670\n",
      "img id in: 17671\n",
      "img id out: 17671\n",
      "img id in: 17672\n",
      "img id out: 17672\n",
      "img id in: 17673\n",
      "img id out: 17673\n",
      "img id in: 17674\n",
      "img id out: 17674\n",
      "img id in: 17675\n",
      "img id out: 17675\n",
      "img id in: 17676\n",
      "img id out: 17676\n",
      "img id in: 17677\n",
      "img id out: 17677\n",
      "img id in: 17678\n",
      "img id out: 17678\n",
      "img id in: 17679\n",
      "img id out: 17679\n",
      "img id in: 17680\n",
      "img id out: 17680\n",
      "img id in: 17681\n",
      "img id out: 17681\n",
      "img id in: 17682\n",
      "img id out: 17682\n",
      "img id in: 17683\n",
      "img id out: 17683\n",
      "img id in: 17684\n",
      "img id out: 17684\n",
      "img id in: 17685\n",
      "img id out: 17685\n",
      "img id in: 17686\n",
      "img id out: 17686\n",
      "img id in: 17687\n",
      "img id out: 17687\n",
      "img id in: 17688\n",
      "img id out: 17688\n",
      "img id in: 17689\n",
      "img id out: 17689\n",
      "img id in: 17690\n",
      "img id out: 17690\n",
      "img id in: 17691\n",
      "img id out: 17691\n",
      "img id in: 17692\n",
      "img id out: 17692\n",
      "img id in: 17693\n",
      "img id out: 17693\n",
      "img id in: 17694\n",
      "img id out: 17694\n",
      "img id in: 17695\n",
      "img id out: 17695\n",
      "img id in: 17696\n",
      "img id out: 17696\n",
      "img id in: 17697\n",
      "img id out: 17697\n",
      "img id in: 17698\n",
      "img id out: 17698\n",
      "img id in: 17699\n",
      "img id out: 17699\n",
      "img id in: 17700\n",
      "img id out: 17700\n",
      "img id in: 17701\n",
      "img id out: 17701\n",
      "img id in: 17702\n",
      "img id out: 17702\n",
      "img id in: 17703\n",
      "img id out: 17703\n",
      "img id in: 17704\n",
      "img id out: 17704\n",
      "img id in: 17705\n",
      "img id out: 17705\n",
      "img id in: 17706\n",
      "img id out: 17706\n",
      "img id in: 17707\n",
      "img id out: 17707\n",
      "img id in: 17708\n",
      "img id out: 17708\n",
      "img id in: 17709\n",
      "img id out: 17709\n",
      "img id in: 17710\n",
      "img id out: 17710\n",
      "img id in: 17711\n",
      "img id out: 17711\n",
      "img id in: 17712\n",
      "img id out: 17712\n",
      "img id in: 17713\n",
      "img id out: 17713\n",
      "img id in: 17714\n",
      "img id out: 17714\n",
      "img id in: 17715\n",
      "img id out: 17715\n",
      "img id in: 17716\n",
      "img id out: 17716\n",
      "img id in: 17717\n",
      "img id out: 17717\n",
      "img id in: 17718\n",
      "img id out: 17718\n",
      "img id in: 17719\n",
      "img id out: 17719\n",
      "img id in: 17720\n",
      "img id out: 17720\n",
      "img id in: 17721\n",
      "img id out: 17721\n",
      "img id in: 17722\n",
      "img id out: 17722\n",
      "img id in: 17723\n",
      "img id out: 17723\n",
      "img id in: 17724\n",
      "img id out: 17724\n",
      "img id in: 17725\n",
      "img id out: 17725\n",
      "img id in: 17726\n",
      "img id out: 17726\n",
      "img id in: 17727\n",
      "img id out: 17727\n",
      "img id in: 17728\n",
      "img id out: 17728\n",
      "img id in: 17729\n",
      "img id out: 17729\n",
      "img id in: 17730\n",
      "img id out: 17730\n",
      "img id in: 17731\n",
      "img id out: 17731\n",
      "img id in: 17732\n",
      "img id out: 17732\n",
      "img id in: 17733\n",
      "img id out: 17733\n",
      "img id in: 17734\n",
      "img id out: 17734\n",
      "img id in: 17735\n",
      "img id out: 17735\n",
      "img id in: 17736\n",
      "img id out: 17736\n",
      "img id in: 17737\n",
      "img id out: 17737\n",
      "img id in: 17738\n",
      "img id out: 17738\n",
      "img id in: 17739\n",
      "img id out: 17739\n",
      "img id in: 17740\n",
      "img id out: 17740\n",
      "img id in: 17741\n",
      "img id out: 17741\n",
      "img id in: 17742\n",
      "img id out: 17742\n",
      "img id in: 17743\n",
      "img id out: 17743\n",
      "img id in: 17744\n",
      "img id out: 17744\n",
      "img id in: 17745\n",
      "img id out: 17745\n",
      "img id in: 17746\n",
      "img id out: 17746\n",
      "img id in: 17747\n",
      "img id out: 17747\n",
      "img id in: 17748\n",
      "img id out: 17748\n",
      "img id in: 17749\n",
      "img id out: 17749\n",
      "img id in: 17750\n",
      "img id out: 17750\n",
      "img id in: 17751\n",
      "img id out: 17751\n",
      "img id in: 17752\n",
      "img id out: 17752\n",
      "img id in: 17753\n",
      "img id out: 17753\n",
      "img id in: 17754\n",
      "img id out: 17754\n",
      "img id in: 17755\n",
      "img id out: 17755\n",
      "img id in: 17756\n",
      "img id out: 17756\n",
      "img id in: 17757\n",
      "img id out: 17757\n",
      "img id in: 17758\n",
      "img id out: 17758\n",
      "img id in: 17759\n",
      "img id out: 17759\n",
      "img id in: 17760\n",
      "img id out: 17760\n",
      "img id in: 17761\n",
      "img id out: 17761\n",
      "img id in: 17762\n",
      "img id out: 17762\n",
      "img id in: 17763\n",
      "img id out: 17763\n",
      "img id in: 17764\n",
      "img id out: 17764\n",
      "img id in: 17765\n",
      "img id out: 17765\n",
      "img id in: 17766\n",
      "img id out: 17766\n",
      "img id in: 17767\n",
      "img id out: 17767\n",
      "img id in: 17768\n",
      "img id out: 17768\n",
      "img id in: 17769\n",
      "img id out: 17769\n",
      "img id in: 17770\n",
      "img id out: 17770\n",
      "img id in: 17771\n",
      "img id out: 17771\n",
      "img id in: 17772\n",
      "img id out: 17772\n",
      "img id in: 17773\n",
      "img id out: 17773\n",
      "img id in: 17774\n",
      "img id out: 17774\n",
      "img id in: 17775\n",
      "img id out: 17775\n",
      "img id in: 17776\n",
      "img id out: 17776\n",
      "img id in: 17777\n",
      "img id out: 17777\n",
      "img id in: 17778\n",
      "img id out: 17778\n",
      "img id in: 17779\n",
      "img id out: 17779\n",
      "img id in: 17780\n",
      "img id out: 17780\n",
      "img id in: 17781\n",
      "img id out: 17781\n",
      "img id in: 17782\n",
      "img id out: 17782\n",
      "img id in: 17783\n",
      "img id out: 17783\n",
      "img id in: 17784\n",
      "img id out: 17784\n",
      "img id in: 17785\n",
      "img id out: 17785\n",
      "img id in: 17786\n",
      "img id out: 17786\n",
      "img id in: 17787\n",
      "img id out: 17787\n",
      "img id in: 17788\n",
      "img id out: 17788\n",
      "img id in: 17789\n",
      "img id out: 17789\n",
      "img id in: 17790\n",
      "img id out: 17790\n",
      "img id in: 17791\n",
      "img id out: 17791\n",
      "img id in: 17792\n",
      "img id out: 17792\n",
      "img id in: 17793\n",
      "img id out: 17793\n",
      "img id in: 17794\n",
      "img id out: 17794\n",
      "img id in: 17795\n",
      "img id out: 17795\n",
      "img id in: 17796\n",
      "img id out: 17796\n",
      "img id in: 17797\n",
      "img id out: 17797\n",
      "img id in: 17798\n",
      "img id out: 17798\n",
      "img id in: 17799\n",
      "img id out: 17799\n",
      "img id in: 17800\n",
      "img id out: 17800\n",
      "img id in: 17801\n",
      "img id out: 17801\n",
      "img id in: 17802\n",
      "img id out: 17802\n",
      "img id in: 17803\n",
      "img id out: 17803\n",
      "img id in: 17804\n",
      "img id out: 17804\n",
      "img id in: 17805\n",
      "img id out: 17805\n",
      "img id in: 17806\n",
      "img id out: 17806\n",
      "img id in: 17807\n",
      "img id out: 17807\n",
      "img id in: 17808\n",
      "img id out: 17808\n",
      "img id in: 17809\n",
      "img id out: 17809\n",
      "img id in: 17810\n",
      "img id out: 17810\n",
      "img id in: 17811\n",
      "img id out: 17811\n",
      "img id in: 17812\n",
      "img id out: 17812\n",
      "img id in: 17813\n",
      "img id out: 17813\n",
      "img id in: 17814\n",
      "img id out: 17814\n",
      "img id in: 17815\n",
      "img id out: 17815\n",
      "img id in: 17816\n",
      "img id out: 17816\n",
      "img id in: 17817\n",
      "img id out: 17817\n",
      "img id in: 17818\n",
      "img id out: 17818\n",
      "img id in: 17819\n",
      "img id out: 17819\n",
      "img id in: 17820\n",
      "img id out: 17820\n",
      "img id in: 17821\n",
      "img id out: 17821\n",
      "img id in: 17822\n",
      "img id out: 17822\n",
      "img id in: 17823\n",
      "img id out: 17823\n",
      "img id in: 17824\n",
      "img id out: 17824\n",
      "img id in: 17825\n",
      "img id out: 17825\n",
      "img id in: 17826\n",
      "img id out: 17826\n",
      "img id in: 17827\n",
      "img id out: 17827\n",
      "img id in: 17828\n",
      "img id out: 17828\n",
      "img id in: 17829\n",
      "img id out: 17829\n",
      "img id in: 17830\n",
      "img id out: 17830\n",
      "img id in: 17831\n",
      "img id out: 17831\n",
      "img id in: 17832\n",
      "img id out: 17832\n",
      "img id in: 17833\n",
      "img id out: 17833\n",
      "img id in: 17834\n",
      "img id out: 17834\n",
      "img id in: 17835\n",
      "img id out: 17835\n",
      "img id in: 17836\n",
      "img id out: 17836\n",
      "img id in: 17837\n",
      "img id out: 17837\n",
      "img id in: 17838\n",
      "img id out: 17838\n",
      "img id in: 17839\n",
      "img id out: 17839\n",
      "img id in: 17840\n",
      "img id out: 17840\n",
      "img id in: 17841\n",
      "img id out: 17841\n",
      "img id in: 17842\n",
      "img id out: 17842\n",
      "img id in: 17843\n",
      "img id out: 17843\n",
      "img id in: 17844\n",
      "img id out: 17844\n",
      "img id in: 17845\n",
      "img id out: 17845\n",
      "img id in: 17846\n",
      "img id out: 17846\n",
      "img id in: 17847\n",
      "img id out: 17847\n",
      "img id in: 17848\n",
      "img id out: 17848\n",
      "img id in: 17849\n",
      "img id out: 17849\n",
      "img id in: 17850\n",
      "img id out: 17850\n",
      "img id in: 17851\n",
      "img id out: 17851\n",
      "img id in: 17852\n",
      "img id out: 17852\n",
      "img id in: 17853\n",
      "img id out: 17853\n",
      "img id in: 17854\n",
      "img id out: 17854\n",
      "img id in: 17855\n",
      "img id out: 17855\n",
      "img id in: 17856\n",
      "img id out: 17856\n",
      "img id in: 17857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 17857\n",
      "img id in: 17858\n",
      "img id out: 17858\n",
      "img id in: 17859\n",
      "img id out: 17859\n",
      "img id in: 17860\n",
      "img id out: 17860\n",
      "img id in: 17861\n",
      "img id out: 17861\n",
      "img id in: 17862\n",
      "img id out: 17862\n",
      "img id in: 17863\n",
      "img id out: 17863\n",
      "img id in: 17864\n",
      "img id out: 17864\n",
      "img id in: 17865\n",
      "img id out: 17865\n",
      "img id in: 17866\n",
      "img id out: 17866\n",
      "img id in: 17867\n",
      "img id out: 17867\n",
      "img id in: 17868\n",
      "img id out: 17868\n",
      "img id in: 17869\n",
      "img id out: 17869\n",
      "img id in: 17870\n",
      "img id out: 17870\n",
      "img id in: 17871\n",
      "img id out: 17871\n",
      "img id in: 17872\n",
      "img id out: 17872\n",
      "img id in: 17873\n",
      "img id out: 17873\n",
      "img id in: 17874\n",
      "img id out: 17874\n",
      "img id in: 17875\n",
      "img id out: 17875\n",
      "img id in: 17876\n",
      "img id out: 17876\n",
      "img id in: 17877\n",
      "img id out: 17877\n",
      "img id in: 17878\n",
      "img id out: 17878\n",
      "img id in: 17879\n",
      "img id out: 17879\n",
      "img id in: 17880\n",
      "img id out: 17880\n",
      "img id in: 17881\n",
      "img id out: 17881\n",
      "img id in: 17882\n",
      "img id out: 17882\n",
      "img id in: 17883\n",
      "img id out: 17883\n",
      "img id in: 17884\n",
      "img id out: 17884\n",
      "img id in: 17885\n",
      "img id out: 17885\n",
      "img id in: 17886\n",
      "img id out: 17886\n",
      "img id in: 17887\n",
      "img id out: 17887\n",
      "img id in: 17888\n",
      "img id out: 17888\n",
      "img id in: 17889\n",
      "img id out: 17889\n",
      "img id in: 17890\n",
      "img id out: 17890\n",
      "img id in: 17891\n",
      "img id out: 17891\n",
      "img id in: 17892\n",
      "img id out: 17892\n",
      "img id in: 17893\n",
      "img id out: 17893\n",
      "img id in: 17894\n",
      "img id out: 17894\n",
      "img id in: 17895\n",
      "img id out: 17895\n",
      "img id in: 17896\n",
      "img id out: 17896\n",
      "img id in: 17897\n",
      "img id out: 17897\n",
      "img id in: 17898\n",
      "img id out: 17898\n",
      "img id in: 17899\n",
      "img id out: 17899\n",
      "img id in: 17900\n",
      "img id out: 17900\n",
      "img id in: 17901\n",
      "img id out: 17901\n",
      "img id in: 17902\n",
      "img id out: 17902\n",
      "img id in: 17903\n",
      "img id out: 17903\n",
      "img id in: 17904\n",
      "img id out: 17904\n",
      "img id in: 17905\n",
      "img id out: 17905\n",
      "img id in: 17906\n",
      "img id out: 17906\n",
      "img id in: 17907\n",
      "img id out: 17907\n",
      "img id in: 17908\n",
      "img id out: 17908\n",
      "img id in: 17909\n",
      "img id out: 17909\n",
      "img id in: 17910\n",
      "img id out: 17910\n",
      "img id in: 17911\n",
      "img id out: 17911\n",
      "img id in: 17912\n",
      "img id out: 17912\n",
      "img id in: 17913\n",
      "img id out: 17913\n",
      "img id in: 17914\n",
      "img id out: 17914\n",
      "img id in: 17915\n",
      "img id out: 17915\n",
      "img id in: 17916\n",
      "img id out: 17916\n",
      "img id in: 17917\n",
      "img id out: 17917\n",
      "img id in: 17918\n",
      "img id out: 17918\n",
      "img id in: 17919\n",
      "img id out: 17919\n",
      "img id in: 17920\n",
      "img id out: 17920\n",
      "img id in: 17921\n",
      "img id out: 17921\n",
      "img id in: 17922\n",
      "img id out: 17922\n",
      "img id in: 17923\n",
      "img id out: 17923\n",
      "img id in: 17924\n",
      "img id out: 17924\n",
      "img id in: 17925\n",
      "img id out: 17925\n",
      "img id in: 17926\n",
      "img id out: 17926\n",
      "img id in: 17927\n",
      "img id out: 17927\n",
      "img id in: 17928\n",
      "img id out: 17928\n",
      "img id in: 17929\n",
      "img id out: 17929\n",
      "img id in: 17930\n",
      "img id out: 17930\n",
      "img id in: 17931\n",
      "img id out: 17931\n",
      "img id in: 17932\n",
      "img id out: 17932\n",
      "img id in: 17933\n",
      "img id out: 17933\n",
      "img id in: 17934\n",
      "img id out: 17934\n",
      "img id in: 17935\n",
      "img id out: 17935\n",
      "img id in: 17936\n",
      "img id out: 17936\n",
      "img id in: 17937\n",
      "img id out: 17937\n",
      "img id in: 17938\n",
      "img id out: 17938\n",
      "img id in: 17939\n",
      "img id out: 17939\n",
      "img id in: 17940\n",
      "img id out: 17940\n",
      "img id in: 17941\n",
      "img id out: 17941\n",
      "img id in: 17942\n",
      "img id out: 17942\n",
      "img id in: 17943\n",
      "img id out: 17943\n",
      "img id in: 17944\n",
      "img id out: 17944\n",
      "img id in: 17945\n",
      "img id out: 17945\n",
      "img id in: 17946\n",
      "img id out: 17946\n",
      "img id in: 17947\n",
      "img id out: 17947\n",
      "img id in: 17948\n",
      "img id out: 17948\n",
      "img id in: 17949\n",
      "img id out: 17949\n",
      "img id in: 17950\n",
      "img id out: 17950\n",
      "img id in: 17951\n",
      "img id out: 17951\n",
      "img id in: 17952\n",
      "img id out: 17952\n",
      "img id in: 17953\n",
      "img id out: 17953\n",
      "img id in: 17954\n",
      "img id out: 17954\n",
      "img id in: 17955\n",
      "img id out: 17955\n",
      "img id in: 17956\n",
      "img id out: 17956\n",
      "img id in: 17957\n",
      "img id out: 17957\n",
      "img id in: 17958\n",
      "img id out: 17958\n",
      "img id in: 17959\n",
      "img id out: 17959\n",
      "img id in: 17960\n",
      "img id out: 17960\n",
      "img id in: 17961\n",
      "img id out: 17961\n",
      "img id in: 17962\n",
      "img id out: 17962\n",
      "img id in: 17963\n",
      "img id out: 17963\n",
      "img id in: 17964\n",
      "img id out: 17964\n",
      "img id in: 17965\n",
      "img id out: 17965\n",
      "img id in: 17966\n",
      "img id out: 17966\n",
      "img id in: 17967\n",
      "img id out: 17967\n",
      "img id in: 17968\n",
      "img id out: 17968\n",
      "img id in: 17969\n",
      "img id out: 17969\n",
      "img id in: 17970\n",
      "img id out: 17970\n",
      "img id in: 17971\n",
      "img id out: 17971\n",
      "img id in: 17972\n",
      "img id out: 17972\n",
      "img id in: 17973\n",
      "img id out: 17973\n",
      "img id in: 17974\n",
      "img id out: 17974\n",
      "img id in: 17975\n",
      "img id out: 17975\n",
      "img id in: 17976\n",
      "img id out: 17976\n",
      "img id in: 17977\n",
      "img id out: 17977\n",
      "img id in: 17978\n",
      "img id out: 17978\n",
      "img id in: 17979\n",
      "img id out: 17979\n",
      "img id in: 17980\n",
      "img id out: 17980\n",
      "img id in: 17981\n",
      "img id out: 17981\n",
      "img id in: 17982\n",
      "img id out: 17982\n",
      "img id in: 17983\n",
      "img id out: 17983\n",
      "img id in: 17984\n",
      "img id out: 17984\n",
      "img id in: 17985\n",
      "img id out: 17985\n",
      "img id in: 17986\n",
      "img id out: 17986\n",
      "img id in: 17987\n",
      "img id out: 17987\n",
      "img id in: 17988\n",
      "img id out: 17988\n",
      "img id in: 17989\n",
      "img id out: 17989\n",
      "img id in: 17990\n",
      "img id out: 17990\n",
      "img id in: 17991\n",
      "img id out: 17991\n",
      "img id in: 17992\n",
      "img id out: 17992\n",
      "img id in: 17993\n",
      "img id out: 17993\n",
      "img id in: 17994\n",
      "img id out: 17994\n",
      "img id in: 17995\n",
      "img id out: 17995\n",
      "img id in: 17996\n",
      "img id out: 17996\n",
      "img id in: 17997\n",
      "img id out: 17997\n",
      "img id in: 17998\n",
      "img id out: 17998\n",
      "img id in: 17999\n",
      "img id out: 17999\n",
      "img id in: 18000\n",
      "img id out: 18000\n",
      "img id in: 18001\n",
      "img id out: 18001\n",
      "img id in: 18002\n",
      "img id out: 18002\n",
      "img id in: 18003\n",
      "img id out: 18003\n",
      "img id in: 18004\n",
      "img id out: 18004\n",
      "img id in: 18005\n",
      "img id out: 18005\n",
      "img id in: 18006\n",
      "img id out: 18006\n",
      "img id in: 18007\n",
      "img id out: 18007\n",
      "img id in: 18008\n",
      "img id out: 18008\n",
      "img id in: 18009\n",
      "img id out: 18009\n",
      "img id in: 18010\n",
      "img id out: 18010\n",
      "img id in: 18011\n",
      "img id out: 18011\n",
      "img id in: 18012\n",
      "img id out: 18012\n",
      "img id in: 18013\n",
      "img id out: 18013\n",
      "img id in: 18014\n",
      "img id out: 18014\n",
      "img id in: 18015\n",
      "img id out: 18015\n",
      "img id in: 18016\n",
      "img id out: 18016\n",
      "img id in: 18017\n",
      "img id out: 18017\n",
      "img id in: 18018\n",
      "img id out: 18018\n",
      "img id in: 18019\n",
      "img id out: 18019\n",
      "img id in: 18020\n",
      "img id out: 18020\n",
      "img id in: 18021\n",
      "img id out: 18021\n",
      "img id in: 18022\n",
      "img id out: 18022\n",
      "img id in: 18023\n",
      "img id out: 18023\n",
      "img id in: 18024\n",
      "img id out: 18024\n",
      "img id in: 18025\n",
      "img id out: 18025\n",
      "img id in: 18026\n",
      "img id out: 18026\n",
      "img id in: 18027\n",
      "img id out: 18027\n",
      "img id in: 18028\n",
      "img id out: 18028\n",
      "img id in: 18029\n",
      "img id out: 18029\n",
      "img id in: 18030\n",
      "img id out: 18030\n",
      "img id in: 18031\n",
      "img id out: 18031\n",
      "img id in: 18032\n",
      "img id out: 18032\n",
      "img id in: 18033\n",
      "img id out: 18033\n",
      "img id in: 18034\n",
      "img id out: 18034\n",
      "img id in: 18035\n",
      "img id out: 18035\n",
      "img id in: 18036\n",
      "img id out: 18036\n",
      "img id in: 18037\n",
      "img id out: 18037\n",
      "img id in: 18038\n",
      "img id out: 18038\n",
      "img id in: 18039\n",
      "img id out: 18039\n",
      "img id in: 18040\n",
      "img id out: 18040\n",
      "img id in: 18041\n",
      "img id out: 18041\n",
      "img id in: 18042\n",
      "img id out: 18042\n",
      "img id in: 18043\n",
      "img id out: 18043\n",
      "img id in: 18044\n",
      "img id out: 18044\n",
      "img id in: 18045\n",
      "img id out: 18045\n",
      "img id in: 18046\n",
      "img id out: 18046\n",
      "img id in: 18047\n",
      "img id out: 18047\n",
      "img id in: 18048\n",
      "img id out: 18048\n",
      "img id in: 18049\n",
      "img id out: 18049\n",
      "img id in: 18050\n",
      "img id out: 18050\n",
      "img id in: 18051\n",
      "img id out: 18051\n",
      "img id in: 18052\n",
      "img id out: 18052\n",
      "img id in: 18053\n",
      "img id out: 18053\n",
      "img id in: 18054\n",
      "img id out: 18054\n",
      "img id in: 18055\n",
      "img id out: 18055\n",
      "img id in: 18056\n",
      "img id out: 18056\n",
      "img id in: 18057\n",
      "img id out: 18057\n",
      "img id in: 18058\n",
      "img id out: 18058\n",
      "img id in: 18059\n",
      "img id out: 18059\n",
      "img id in: 18060\n",
      "img id out: 18060\n",
      "img id in: 18061\n",
      "img id out: 18061\n",
      "img id in: 18062\n",
      "img id out: 18062\n",
      "img id in: 18063\n",
      "img id out: 18063\n",
      "img id in: 18064\n",
      "img id out: 18064\n",
      "img id in: 18065\n",
      "img id out: 18065\n",
      "img id in: 18066\n",
      "img id out: 18066\n",
      "img id in: 18067\n",
      "img id out: 18067\n",
      "img id in: 18068\n",
      "img id out: 18068\n",
      "img id in: 18069\n",
      "img id out: 18069\n",
      "img id in: 18070\n",
      "img id out: 18070\n",
      "img id in: 18071\n",
      "img id out: 18071\n",
      "img id in: 18072\n",
      "img id out: 18072\n",
      "img id in: 18073\n",
      "img id out: 18073\n",
      "img id in: 18074\n",
      "img id out: 18074\n",
      "img id in: 18075\n",
      "img id out: 18075\n",
      "img id in: 18076\n",
      "img id out: 18076\n",
      "img id in: 18077\n",
      "img id out: 18077\n",
      "img id in: 18078\n",
      "img id out: 18078\n",
      "img id in: 18079\n",
      "img id out: 18079\n",
      "img id in: 18080\n",
      "img id out: 18080\n",
      "img id in: 18081\n",
      "img id out: 18081\n",
      "img id in: 18082\n",
      "img id out: 18082\n",
      "img id in: 18083\n",
      "img id out: 18083\n",
      "img id in: 18084\n",
      "img id out: 18084\n",
      "img id in: 18085\n",
      "img id out: 18085\n",
      "img id in: 18086\n",
      "img id out: 18086\n",
      "img id in: 18087\n",
      "img id out: 18087\n",
      "img id in: 18088\n",
      "img id out: 18088\n",
      "img id in: 18089\n",
      "img id out: 18089\n",
      "img id in: 18090\n",
      "img id out: 18090\n",
      "img id in: 18091\n",
      "img id out: 18091\n",
      "img id in: 18092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 18092\n",
      "img id in: 18093\n",
      "img id out: 18093\n",
      "img id in: 18094\n",
      "img id out: 18094\n",
      "img id in: 18095\n",
      "img id out: 18095\n",
      "img id in: 18096\n",
      "img id out: 18096\n",
      "img id in: 18097\n",
      "img id out: 18097\n",
      "img id in: 18098\n",
      "img id out: 18098\n",
      "img id in: 18099\n",
      "img id out: 18099\n",
      "img id in: 18100\n",
      "img id out: 18100\n",
      "img id in: 18101\n",
      "img id out: 18101\n",
      "img id in: 18102\n",
      "img id out: 18102\n",
      "img id in: 18103\n",
      "img id out: 18103\n",
      "img id in: 18104\n",
      "img id out: 18104\n",
      "img id in: 18105\n",
      "img id out: 18105\n",
      "img id in: 18106\n",
      "img id out: 18106\n",
      "img id in: 18107\n",
      "img id out: 18107\n",
      "img id in: 18108\n",
      "img id out: 18108\n",
      "img id in: 18109\n",
      "img id out: 18109\n",
      "img id in: 18110\n",
      "img id out: 18110\n",
      "img id in: 18111\n",
      "img id out: 18111\n",
      "img id in: 18112\n",
      "img id out: 18112\n",
      "img id in: 18113\n",
      "img id out: 18113\n",
      "img id in: 18114\n",
      "img id out: 18114\n",
      "img id in: 18115\n",
      "img id out: 18115\n",
      "img id in: 18116\n",
      "img id out: 18116\n",
      "img id in: 18117\n",
      "img id out: 18117\n",
      "img id in: 18118\n",
      "img id out: 18118\n",
      "img id in: 18119\n",
      "img id out: 18119\n",
      "img id in: 18120\n",
      "img id out: 18120\n",
      "img id in: 18121\n",
      "img id out: 18121\n",
      "img id in: 18122\n",
      "img id out: 18122\n",
      "img id in: 18123\n",
      "img id out: 18123\n",
      "img id in: 18124\n",
      "img id out: 18124\n",
      "img id in: 18125\n",
      "img id out: 18125\n",
      "img id in: 18126\n",
      "img id out: 18126\n",
      "img id in: 18127\n",
      "img id out: 18127\n",
      "img id in: 18128\n",
      "img id out: 18128\n",
      "img id in: 18129\n",
      "img id out: 18129\n",
      "img id in: 18130\n",
      "img id out: 18130\n",
      "img id in: 18131\n",
      "img id out: 18131\n",
      "img id in: 18132\n",
      "img id out: 18132\n",
      "img id in: 18133\n",
      "img id out: 18133\n",
      "img id in: 18134\n",
      "img id out: 18134\n",
      "img id in: 18135\n",
      "img id out: 18135\n",
      "img id in: 18136\n",
      "img id out: 18136\n",
      "img id in: 18137\n",
      "img id out: 18137\n",
      "img id in: 18138\n",
      "img id out: 18138\n",
      "img id in: 18139\n",
      "img id out: 18139\n",
      "img id in: 18140\n",
      "img id out: 18140\n",
      "img id in: 18141\n",
      "img id out: 18141\n",
      "img id in: 18142\n",
      "img id out: 18142\n",
      "img id in: 18143\n",
      "img id out: 18143\n",
      "img id in: 18144\n",
      "img id out: 18144\n",
      "img id in: 18145\n",
      "img id out: 18145\n",
      "img id in: 18146\n",
      "img id out: 18146\n",
      "img id in: 18147\n",
      "img id out: 18147\n",
      "img id in: 18148\n",
      "img id out: 18148\n",
      "img id in: 18149\n",
      "img id out: 18149\n",
      "img id in: 18150\n",
      "img id out: 18150\n",
      "img id in: 18151\n",
      "img id out: 18151\n",
      "img id in: 18152\n",
      "img id out: 18152\n",
      "img id in: 18153\n",
      "img id out: 18153\n",
      "img id in: 18154\n",
      "img id out: 18154\n",
      "img id in: 18155\n",
      "img id out: 18155\n",
      "img id in: 18156\n",
      "img id out: 18156\n",
      "img id in: 18157\n",
      "img id out: 18157\n",
      "img id in: 18158\n",
      "img id out: 18158\n",
      "img id in: 18159\n",
      "img id out: 18159\n",
      "img id in: 18160\n",
      "img id out: 18160\n",
      "img id in: 18161\n",
      "img id out: 18161\n",
      "img id in: 18162\n",
      "img id out: 18162\n",
      "img id in: 18163\n",
      "img id out: 18163\n",
      "img id in: 18164\n",
      "img id out: 18164\n",
      "img id in: 18165\n",
      "img id out: 18165\n",
      "img id in: 18166\n",
      "img id out: 18166\n",
      "img id in: 18167\n",
      "img id out: 18167\n",
      "img id in: 18168\n",
      "img id out: 18168\n",
      "img id in: 18169\n",
      "img id out: 18169\n",
      "img id in: 18170\n",
      "img id out: 18170\n",
      "img id in: 18171\n",
      "img id out: 18171\n",
      "img id in: 18172\n",
      "img id out: 18172\n",
      "img id in: 18173\n",
      "img id out: 18173\n",
      "img id in: 18174\n",
      "img id out: 18174\n",
      "img id in: 18175\n",
      "img id out: 18175\n",
      "img id in: 18176\n",
      "img id out: 18176\n",
      "img id in: 18177\n",
      "img id out: 18177\n",
      "img id in: 18178\n",
      "img id out: 18178\n",
      "img id in: 18179\n",
      "img id out: 18179\n",
      "img id in: 18180\n",
      "img id out: 18180\n",
      "img id in: 18181\n",
      "img id out: 18181\n",
      "img id in: 18182\n",
      "img id out: 18182\n",
      "img id in: 18183\n",
      "img id out: 18183\n",
      "img id in: 18184\n",
      "img id out: 18184\n",
      "img id in: 18185\n",
      "img id out: 18185\n",
      "img id in: 18186\n",
      "img id out: 18186\n",
      "img id in: 18187\n",
      "img id out: 18187\n",
      "img id in: 18188\n",
      "img id out: 18188\n",
      "img id in: 18189\n",
      "img id out: 18189\n",
      "img id in: 18190\n",
      "img id out: 18190\n",
      "img id in: 18191\n",
      "img id out: 18191\n",
      "img id in: 18192\n",
      "img id out: 18192\n",
      "img id in: 18193\n",
      "img id out: 18193\n",
      "img id in: 18194\n",
      "img id out: 18194\n",
      "img id in: 18195\n",
      "img id out: 18195\n",
      "img id in: 18196\n",
      "img id out: 18196\n",
      "img id in: 18197\n",
      "img id out: 18197\n",
      "img id in: 18198\n",
      "img id out: 18198\n",
      "img id in: 18199\n",
      "img id out: 18199\n",
      "img id in: 18200\n",
      "img id out: 18200\n",
      "img id in: 18201\n",
      "img id out: 18201\n",
      "img id in: 18202\n",
      "img id out: 18202\n",
      "img id in: 18203\n",
      "img id out: 18203\n",
      "img id in: 18204\n",
      "img id out: 18204\n",
      "img id in: 18205\n",
      "img id out: 18205\n",
      "img id in: 18206\n",
      "img id out: 18206\n",
      "img id in: 18207\n",
      "img id out: 18207\n",
      "img id in: 18208\n",
      "img id out: 18208\n",
      "img id in: 18209\n",
      "img id out: 18209\n",
      "img id in: 18210\n",
      "img id out: 18210\n",
      "img id in: 18211\n",
      "img id out: 18211\n",
      "img id in: 18212\n",
      "img id out: 18212\n",
      "img id in: 18213\n",
      "img id out: 18213\n",
      "img id in: 18214\n",
      "img id out: 18214\n",
      "img id in: 18215\n",
      "img id out: 18215\n",
      "img id in: 18216\n",
      "img id out: 18216\n",
      "img id in: 18217\n",
      "img id out: 18217\n",
      "img id in: 18218\n",
      "img id out: 18218\n",
      "img id in: 18219\n",
      "img id out: 18219\n",
      "img id in: 18220\n",
      "img id out: 18220\n",
      "img id in: 18221\n",
      "img id out: 18221\n",
      "img id in: 18222\n",
      "img id out: 18222\n",
      "img id in: 18223\n",
      "img id out: 18223\n",
      "img id in: 18224\n",
      "img id out: 18224\n",
      "img id in: 18225\n",
      "img id out: 18225\n",
      "img id in: 18226\n",
      "img id out: 18226\n",
      "img id in: 18227\n",
      "img id out: 18227\n",
      "img id in: 18228\n",
      "img id out: 18228\n",
      "img id in: 18229\n",
      "img id out: 18229\n",
      "img id in: 18230\n",
      "img id out: 18230\n",
      "img id in: 18231\n",
      "img id out: 18231\n",
      "img id in: 18232\n",
      "img id out: 18232\n",
      "img id in: 18233\n",
      "img id out: 18233\n",
      "img id in: 18234\n",
      "img id out: 18234\n",
      "img id in: 18235\n",
      "img id out: 18235\n",
      "img id in: 18236\n",
      "img id out: 18236\n",
      "img id in: 18237\n",
      "img id out: 18237\n",
      "img id in: 18238\n",
      "img id out: 18238\n",
      "img id in: 18239\n",
      "img id out: 18239\n",
      "img id in: 18240\n",
      "img id out: 18240\n",
      "img id in: 18241\n",
      "img id out: 18241\n",
      "img id in: 18242\n",
      "img id out: 18242\n",
      "img id in: 18243\n",
      "img id out: 18243\n",
      "img id in: 18244\n",
      "img id out: 18244\n",
      "img id in: 18245\n",
      "img id out: 18245\n",
      "img id in: 18246\n",
      "img id out: 18246\n",
      "img id in: 18247\n",
      "img id out: 18247\n",
      "img id in: 18248\n",
      "img id out: 18248\n",
      "img id in: 18249\n",
      "img id out: 18249\n",
      "img id in: 18250\n",
      "img id out: 18250\n",
      "img id in: 18251\n",
      "img id out: 18251\n",
      "img id in: 18252\n",
      "img id out: 18252\n",
      "img id in: 18253\n",
      "img id out: 18253\n",
      "img id in: 18254\n",
      "img id out: 18254\n",
      "img id in: 18255\n",
      "img id out: 18255\n",
      "img id in: 18256\n",
      "img id out: 18256\n",
      "img id in: 18257\n",
      "img id out: 18257\n",
      "img id in: 18258\n",
      "img id out: 18258\n",
      "img id in: 18259\n",
      "img id out: 18259\n",
      "img id in: 18260\n",
      "img id out: 18260\n",
      "img id in: 18261\n",
      "img id out: 18261\n",
      "img id in: 18262\n",
      "img id out: 18262\n",
      "img id in: 18263\n",
      "img id out: 18263\n",
      "img id in: 18264\n",
      "img id out: 18264\n",
      "img id in: 18265\n",
      "img id out: 18265\n",
      "img id in: 18266\n",
      "img id out: 18266\n",
      "img id in: 18267\n",
      "img id out: 18267\n",
      "img id in: 18268\n",
      "img id out: 18268\n",
      "img id in: 18269\n",
      "img id out: 18269\n",
      "img id in: 18270\n",
      "img id out: 18270\n",
      "img id in: 18271\n",
      "img id out: 18271\n",
      "img id in: 18272\n",
      "img id out: 18272\n",
      "img id in: 18273\n",
      "img id out: 18273\n",
      "img id in: 18274\n",
      "img id out: 18274\n",
      "img id in: 18275\n",
      "img id out: 18275\n",
      "img id in: 18276\n",
      "img id out: 18276\n",
      "img id in: 18277\n",
      "img id out: 18277\n",
      "img id in: 18278\n",
      "img id out: 18278\n",
      "img id in: 18279\n",
      "img id out: 18279\n",
      "img id in: 18280\n",
      "img id out: 18280\n",
      "img id in: 18281\n",
      "img id out: 18281\n",
      "img id in: 18282\n",
      "img id out: 18282\n",
      "img id in: 18283\n",
      "img id out: 18283\n",
      "img id in: 18284\n",
      "img id out: 18284\n",
      "img id in: 18285\n",
      "img id out: 18285\n",
      "img id in: 18286\n",
      "img id out: 18286\n",
      "img id in: 18287\n",
      "img id out: 18287\n",
      "img id in: 18288\n",
      "img id out: 18288\n",
      "img id in: 18289\n",
      "img id out: 18289\n",
      "img id in: 18290\n",
      "img id out: 18290\n",
      "img id in: 18291\n",
      "img id out: 18291\n",
      "img id in: 18292\n",
      "img id out: 18292\n",
      "img id in: 18293\n",
      "img id out: 18293\n",
      "img id in: 18294\n",
      "img id out: 18294\n",
      "img id in: 18295\n",
      "img id out: 18295\n",
      "img id in: 18296\n",
      "img id out: 18296\n",
      "img id in: 18297\n",
      "img id out: 18297\n",
      "img id in: 18298\n",
      "img id out: 18298\n",
      "img id in: 18299\n",
      "img id out: 18299\n",
      "img id in: 18300\n",
      "img id out: 18300\n",
      "img id in: 18301\n",
      "img id out: 18301\n",
      "img id in: 18302\n",
      "img id out: 18302\n",
      "img id in: 18303\n",
      "img id out: 18303\n",
      "img id in: 18304\n",
      "img id out: 18304\n",
      "img id in: 18305\n",
      "img id out: 18305\n",
      "img id in: 18306\n",
      "img id out: 18306\n",
      "img id in: 18307\n",
      "img id out: 18307\n",
      "img id in: 18308\n",
      "img id out: 18308\n",
      "img id in: 18309\n",
      "img id out: 18309\n",
      "img id in: 18310\n",
      "img id out: 18310\n",
      "img id in: 18311\n",
      "img id out: 18311\n",
      "img id in: 18312\n",
      "img id out: 18312\n",
      "img id in: 18313\n",
      "img id out: 18313\n",
      "img id in: 18314\n",
      "img id out: 18314\n",
      "img id in: 18315\n",
      "img id out: 18315\n",
      "img id in: 18316\n",
      "img id out: 18316\n",
      "img id in: 18317\n",
      "img id out: 18317\n",
      "img id in: 18318\n",
      "img id out: 18318\n",
      "img id in: 18319\n",
      "img id out: 18319\n",
      "img id in: 18320\n",
      "img id out: 18320\n",
      "img id in: 18321\n",
      "img id out: 18321\n",
      "img id in: 18322\n",
      "img id out: 18322\n",
      "img id in: 18323\n",
      "img id out: 18323\n",
      "img id in: 18324\n",
      "img id out: 18324\n",
      "img id in: 18325\n",
      "img id out: 18325\n",
      "img id in: 18326\n",
      "img id out: 18326\n",
      "img id in: 18327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 18327\n",
      "img id in: 18328\n",
      "img id out: 18328\n",
      "img id in: 18329\n",
      "img id out: 18329\n",
      "img id in: 18330\n",
      "img id out: 18330\n",
      "img id in: 18331\n",
      "img id out: 18331\n",
      "img id in: 18332\n",
      "img id out: 18332\n",
      "img id in: 18333\n",
      "img id out: 18333\n",
      "img id in: 18334\n",
      "img id out: 18334\n",
      "img id in: 18335\n",
      "img id out: 18335\n",
      "img id in: 18336\n",
      "img id out: 18336\n",
      "img id in: 18337\n",
      "img id out: 18337\n",
      "img id in: 18338\n",
      "img id out: 18338\n",
      "img id in: 18339\n",
      "img id out: 18339\n",
      "img id in: 18340\n",
      "img id out: 18340\n",
      "img id in: 18341\n",
      "img id out: 18341\n",
      "img id in: 18342\n",
      "img id out: 18342\n",
      "img id in: 18343\n",
      "img id out: 18343\n",
      "img id in: 18344\n",
      "img id out: 18344\n",
      "img id in: 18345\n",
      "img id out: 18345\n",
      "img id in: 18346\n",
      "img id out: 18346\n",
      "img id in: 18347\n",
      "img id out: 18347\n",
      "img id in: 18348\n",
      "img id out: 18348\n",
      "img id in: 18349\n",
      "img id out: 18349\n",
      "img id in: 18350\n",
      "img id out: 18350\n",
      "img id in: 18351\n",
      "img id out: 18351\n",
      "img id in: 18352\n",
      "img id out: 18352\n",
      "img id in: 18353\n",
      "img id out: 18353\n",
      "img id in: 18354\n",
      "img id out: 18354\n",
      "img id in: 18355\n",
      "img id out: 18355\n",
      "img id in: 18356\n",
      "img id out: 18356\n",
      "img id in: 18357\n",
      "img id out: 18357\n",
      "img id in: 18358\n",
      "img id out: 18358\n",
      "img id in: 18359\n",
      "img id out: 18359\n",
      "img id in: 18360\n",
      "img id out: 18360\n",
      "img id in: 18361\n",
      "img id out: 18361\n",
      "img id in: 18362\n",
      "img id out: 18362\n",
      "img id in: 18363\n",
      "img id out: 18363\n",
      "img id in: 18364\n",
      "img id out: 18364\n",
      "img id in: 18365\n",
      "img id out: 18365\n",
      "img id in: 18366\n",
      "img id out: 18366\n",
      "img id in: 18367\n",
      "img id out: 18367\n",
      "img id in: 18368\n",
      "img id out: 18368\n",
      "img id in: 18369\n",
      "img id out: 18369\n",
      "img id in: 18370\n",
      "img id out: 18370\n",
      "img id in: 18371\n",
      "img id out: 18371\n",
      "img id in: 18372\n",
      "img id out: 18372\n",
      "img id in: 18373\n",
      "img id out: 18373\n",
      "img id in: 18374\n",
      "img id out: 18374\n",
      "img id in: 18375\n",
      "img id out: 18375\n",
      "img id in: 18376\n",
      "img id out: 18376\n",
      "img id in: 18377\n",
      "img id out: 18377\n",
      "img id in: 18378\n",
      "img id out: 18378\n",
      "img id in: 18379\n",
      "img id out: 18379\n",
      "img id in: 18380\n",
      "img id out: 18380\n",
      "img id in: 18381\n",
      "img id out: 18381\n",
      "img id in: 18382\n",
      "img id out: 18382\n",
      "img id in: 18383\n",
      "img id out: 18383\n",
      "img id in: 18384\n",
      "img id out: 18384\n",
      "img id in: 18385\n",
      "img id out: 18385\n",
      "img id in: 18386\n",
      "img id out: 18386\n",
      "img id in: 18387\n",
      "img id out: 18387\n",
      "img id in: 18388\n",
      "img id out: 18388\n",
      "img id in: 18389\n",
      "img id out: 18389\n",
      "img id in: 18390\n",
      "img id out: 18390\n",
      "img id in: 18391\n",
      "img id out: 18391\n",
      "img id in: 18392\n",
      "img id out: 18392\n",
      "img id in: 18393\n",
      "img id out: 18393\n",
      "img id in: 18394\n",
      "img id out: 18394\n",
      "img id in: 18395\n",
      "img id out: 18395\n",
      "img id in: 18396\n",
      "img id out: 18396\n",
      "img id in: 18397\n",
      "img id out: 18397\n",
      "img id in: 18398\n",
      "img id out: 18398\n",
      "img id in: 18399\n",
      "img id out: 18399\n",
      "img id in: 18400\n",
      "img id out: 18400\n",
      "img id in: 18401\n",
      "img id out: 18401\n",
      "img id in: 18402\n",
      "img id out: 18402\n",
      "img id in: 18403\n",
      "img id out: 18403\n",
      "img id in: 18404\n",
      "img id out: 18404\n",
      "img id in: 18405\n",
      "img id out: 18405\n",
      "img id in: 18406\n",
      "img id out: 18406\n",
      "img id in: 18407\n",
      "img id out: 18407\n",
      "img id in: 18408\n",
      "img id out: 18408\n",
      "img id in: 18409\n",
      "img id out: 18409\n",
      "img id in: 18410\n",
      "img id out: 18410\n",
      "img id in: 18411\n",
      "img id out: 18411\n",
      "img id in: 18412\n",
      "img id out: 18412\n",
      "img id in: 18413\n",
      "img id out: 18413\n",
      "img id in: 18414\n",
      "img id out: 18414\n",
      "img id in: 18415\n",
      "img id out: 18415\n",
      "img id in: 18416\n",
      "img id out: 18416\n",
      "img id in: 18417\n",
      "img id out: 18417\n",
      "img id in: 18418\n",
      "img id out: 18418\n",
      "img id in: 18419\n",
      "img id out: 18419\n",
      "img id in: 18420\n",
      "img id out: 18420\n",
      "img id in: 18421\n",
      "img id out: 18421\n",
      "img id in: 18422\n",
      "img id out: 18422\n",
      "img id in: 18423\n",
      "img id out: 18423\n",
      "img id in: 18424\n",
      "img id out: 18424\n",
      "img id in: 18425\n",
      "img id out: 18425\n",
      "img id in: 18426\n",
      "img id out: 18426\n",
      "img id in: 18427\n",
      "img id out: 18427\n",
      "img id in: 18428\n",
      "img id out: 18428\n",
      "img id in: 18429\n",
      "img id out: 18429\n",
      "img id in: 18430\n",
      "img id out: 18430\n",
      "img id in: 18431\n",
      "img id out: 18431\n",
      "img id in: 18432\n",
      "img id out: 18432\n",
      "img id in: 18433\n",
      "img id out: 18433\n",
      "img id in: 18434\n",
      "img id out: 18434\n",
      "img id in: 18435\n",
      "img id out: 18435\n",
      "img id in: 18436\n",
      "img id out: 18436\n",
      "img id in: 18437\n",
      "img id out: 18437\n",
      "img id in: 18438\n",
      "img id out: 18438\n",
      "img id in: 18439\n",
      "img id out: 18439\n",
      "img id in: 18440\n",
      "img id out: 18440\n",
      "img id in: 18441\n",
      "img id out: 18441\n",
      "img id in: 18442\n",
      "img id out: 18442\n",
      "img id in: 18443\n",
      "img id out: 18443\n",
      "img id in: 18444\n",
      "img id out: 18444\n",
      "img id in: 18445\n",
      "img id out: 18445\n",
      "img id in: 18446\n",
      "img id out: 18446\n",
      "img id in: 18447\n",
      "img id out: 18447\n",
      "img id in: 18448\n",
      "img id out: 18448\n",
      "img id in: 18449\n",
      "img id out: 18449\n",
      "img id in: 18450\n",
      "img id out: 18450\n",
      "img id in: 18451\n",
      "img id out: 18451\n",
      "img id in: 18452\n",
      "img id out: 18452\n",
      "img id in: 18453\n",
      "img id out: 18453\n",
      "img id in: 18454\n",
      "img id out: 18454\n",
      "img id in: 18455\n",
      "img id out: 18455\n",
      "img id in: 18456\n",
      "img id out: 18456\n",
      "img id in: 18457\n",
      "img id out: 18457\n",
      "img id in: 18458\n",
      "img id out: 18458\n",
      "img id in: 18459\n",
      "img id out: 18459\n",
      "img id in: 18460\n",
      "img id out: 18460\n",
      "img id in: 18461\n",
      "img id out: 18461\n",
      "img id in: 18462\n",
      "img id out: 18462\n",
      "img id in: 18463\n",
      "img id out: 18463\n",
      "img id in: 18464\n",
      "img id out: 18464\n",
      "img id in: 18465\n",
      "img id out: 18465\n",
      "img id in: 18466\n",
      "img id out: 18466\n",
      "img id in: 18467\n",
      "img id out: 18467\n",
      "img id in: 18468\n",
      "img id out: 18468\n",
      "img id in: 18469\n",
      "img id out: 18469\n",
      "img id in: 18470\n",
      "img id out: 18470\n",
      "img id in: 18471\n",
      "img id out: 18471\n",
      "img id in: 18472\n",
      "img id out: 18472\n",
      "img id in: 18473\n",
      "img id out: 18473\n",
      "img id in: 18474\n",
      "img id out: 18474\n",
      "img id in: 18475\n",
      "img id out: 18475\n",
      "img id in: 18476\n",
      "img id out: 18476\n",
      "img id in: 18477\n",
      "img id out: 18477\n",
      "img id in: 18478\n",
      "img id out: 18478\n",
      "img id in: 18479\n",
      "img id out: 18479\n",
      "img id in: 18480\n",
      "img id out: 18480\n",
      "img id in: 18481\n",
      "img id out: 18481\n",
      "img id in: 18482\n",
      "img id out: 18482\n",
      "img id in: 18483\n",
      "img id out: 18483\n",
      "img id in: 18484\n",
      "img id out: 18484\n",
      "img id in: 18485\n",
      "img id out: 18485\n",
      "img id in: 18486\n",
      "img id out: 18486\n",
      "img id in: 18487\n",
      "img id out: 18487\n",
      "img id in: 18488\n",
      "img id out: 18488\n",
      "img id in: 18489\n",
      "img id out: 18489\n",
      "img id in: 18490\n",
      "img id out: 18490\n",
      "img id in: 18491\n",
      "img id out: 18491\n",
      "img id in: 18492\n",
      "img id out: 18492\n",
      "img id in: 18493\n",
      "img id out: 18493\n",
      "img id in: 18494\n",
      "img id out: 18494\n",
      "img id in: 18495\n",
      "img id out: 18495\n",
      "img id in: 18496\n",
      "img id out: 18496\n",
      "img id in: 18497\n",
      "img id out: 18497\n",
      "img id in: 18498\n",
      "img id out: 18498\n",
      "img id in: 18499\n",
      "img id out: 18499\n",
      "img id in: 18500\n",
      "img id out: 18500\n",
      "img id in: 18501\n",
      "img id out: 18501\n",
      "img id in: 18502\n",
      "img id out: 18502\n",
      "img id in: 18503\n",
      "img id out: 18503\n",
      "img id in: 18504\n",
      "img id out: 18504\n",
      "img id in: 18505\n",
      "img id out: 18505\n",
      "img id in: 18506\n",
      "img id out: 18506\n",
      "img id in: 18507\n",
      "img id out: 18507\n",
      "img id in: 18508\n",
      "img id out: 18508\n",
      "img id in: 18509\n",
      "img id out: 18509\n",
      "img id in: 18510\n",
      "img id out: 18510\n",
      "img id in: 18511\n",
      "img id out: 18511\n",
      "img id in: 18512\n",
      "img id out: 18512\n",
      "img id in: 18513\n",
      "img id out: 18513\n",
      "img id in: 18514\n",
      "img id out: 18514\n",
      "img id in: 18515\n",
      "img id out: 18515\n",
      "img id in: 18516\n",
      "img id out: 18516\n",
      "img id in: 18517\n",
      "img id out: 18517\n",
      "img id in: 18518\n",
      "img id out: 18518\n",
      "img id in: 18519\n",
      "img id out: 18519\n",
      "img id in: 18520\n",
      "img id out: 18520\n",
      "img id in: 18521\n",
      "img id out: 18521\n",
      "img id in: 18522\n",
      "img id out: 18522\n",
      "img id in: 18523\n",
      "img id out: 18523\n",
      "img id in: 18524\n",
      "img id out: 18524\n",
      "img id in: 18525\n",
      "img id out: 18525\n",
      "img id in: 18526\n",
      "img id out: 18526\n",
      "img id in: 18527\n",
      "img id out: 18527\n",
      "img id in: 18528\n",
      "img id out: 18528\n",
      "img id in: 18529\n",
      "img id out: 18529\n",
      "img id in: 18530\n",
      "img id out: 18530\n",
      "img id in: 18531\n",
      "img id out: 18531\n",
      "img id in: 18532\n",
      "img id out: 18532\n",
      "img id in: 18533\n",
      "img id out: 18533\n",
      "img id in: 18534\n",
      "img id out: 18534\n",
      "img id in: 18535\n",
      "img id out: 18535\n",
      "img id in: 18536\n",
      "img id out: 18536\n",
      "img id in: 18537\n",
      "img id out: 18537\n",
      "img id in: 18538\n",
      "img id out: 18538\n",
      "img id in: 18539\n",
      "img id out: 18539\n",
      "img id in: 18540\n",
      "img id out: 18540\n",
      "img id in: 18541\n",
      "img id out: 18541\n",
      "img id in: 18542\n",
      "img id out: 18542\n",
      "img id in: 18543\n",
      "img id out: 18543\n",
      "img id in: 18544\n",
      "img id out: 18544\n",
      "img id in: 18545\n",
      "img id out: 18545\n",
      "img id in: 18546\n",
      "img id out: 18546\n",
      "img id in: 18547\n",
      "img id out: 18547\n",
      "img id in: 18548\n",
      "img id out: 18548\n",
      "img id in: 18549\n",
      "img id out: 18549\n",
      "img id in: 18550\n",
      "img id out: 18550\n",
      "img id in: 18551\n",
      "img id out: 18551\n",
      "img id in: 18552\n",
      "img id out: 18552\n",
      "img id in: 18553\n",
      "img id out: 18553\n",
      "img id in: 18554\n",
      "img id out: 18554\n",
      "img id in: 18555\n",
      "img id out: 18555\n",
      "img id in: 18556\n",
      "img id out: 18556\n",
      "img id in: 18557\n",
      "img id out: 18557\n",
      "img id in: 18558\n",
      "img id out: 18558\n",
      "img id in: 18559\n",
      "img id out: 18559\n",
      "img id in: 18560\n",
      "img id out: 18560\n",
      "img id in: 18561\n",
      "img id out: 18561\n",
      "img id in: 18562\n",
      "img id out: 18562\n",
      "img id in: 18563\n",
      "img id out: 18563\n",
      "img id in: 18564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 18564\n",
      "img id in: 18565\n",
      "img id out: 18565\n",
      "img id in: 18566\n",
      "img id out: 18566\n",
      "img id in: 18567\n",
      "img id out: 18567\n",
      "img id in: 18568\n",
      "img id out: 18568\n",
      "img id in: 18569\n",
      "img id out: 18569\n",
      "img id in: 18570\n",
      "img id out: 18570\n",
      "img id in: 18571\n",
      "img id out: 18571\n",
      "img id in: 18572\n",
      "img id out: 18572\n",
      "img id in: 18573\n",
      "img id out: 18573\n",
      "img id in: 18574\n",
      "img id out: 18574\n",
      "img id in: 18575\n",
      "img id out: 18575\n",
      "img id in: 18576\n",
      "img id out: 18576\n",
      "img id in: 18577\n",
      "img id out: 18577\n",
      "img id in: 18578\n",
      "img id out: 18578\n",
      "img id in: 18579\n",
      "img id out: 18579\n",
      "img id in: 18580\n",
      "img id out: 18580\n",
      "img id in: 18581\n",
      "img id out: 18581\n",
      "img id in: 18582\n",
      "img id out: 18582\n",
      "img id in: 18583\n",
      "img id out: 18583\n",
      "img id in: 18584\n",
      "img id out: 18584\n",
      "img id in: 18585\n",
      "img id out: 18585\n",
      "img id in: 18586\n",
      "img id out: 18586\n",
      "img id in: 18587\n",
      "img id out: 18587\n",
      "img id in: 18588\n",
      "img id out: 18588\n",
      "img id in: 18589\n",
      "img id out: 18589\n",
      "img id in: 18590\n",
      "img id out: 18590\n",
      "img id in: 18591\n",
      "img id out: 18591\n",
      "img id in: 18592\n",
      "img id out: 18592\n",
      "img id in: 18593\n",
      "img id out: 18593\n",
      "img id in: 18594\n",
      "img id out: 18594\n",
      "img id in: 18595\n",
      "img id out: 18595\n",
      "img id in: 18596\n",
      "img id out: 18596\n",
      "img id in: 18597\n",
      "img id out: 18597\n",
      "img id in: 18598\n",
      "img id out: 18598\n",
      "img id in: 18599\n",
      "img id out: 18599\n",
      "img id in: 18600\n",
      "img id out: 18600\n",
      "img id in: 18601\n",
      "img id out: 18601\n",
      "img id in: 18602\n",
      "img id out: 18602\n",
      "img id in: 18603\n",
      "img id out: 18603\n",
      "img id in: 18604\n",
      "img id out: 18604\n",
      "img id in: 18605\n",
      "img id out: 18605\n",
      "img id in: 18606\n",
      "img id out: 18606\n",
      "img id in: 18607\n",
      "img id out: 18607\n",
      "img id in: 18608\n",
      "img id out: 18608\n",
      "img id in: 18609\n",
      "img id out: 18609\n",
      "img id in: 18610\n",
      "img id out: 18610\n",
      "img id in: 18611\n",
      "img id out: 18611\n",
      "img id in: 18612\n",
      "img id out: 18612\n",
      "img id in: 18613\n",
      "img id out: 18613\n",
      "img id in: 18614\n",
      "img id out: 18614\n",
      "img id in: 18615\n",
      "img id out: 18615\n",
      "img id in: 18616\n",
      "img id out: 18616\n",
      "img id in: 18617\n",
      "img id out: 18617\n",
      "img id in: 18618\n",
      "img id out: 18618\n",
      "img id in: 18619\n",
      "img id out: 18619\n",
      "img id in: 18620\n",
      "img id out: 18620\n",
      "img id in: 18621\n",
      "img id out: 18621\n",
      "img id in: 18622\n",
      "img id out: 18622\n",
      "img id in: 18623\n",
      "img id out: 18623\n",
      "img id in: 18624\n",
      "img id out: 18624\n",
      "img id in: 18625\n",
      "img id out: 18625\n",
      "img id in: 18626\n",
      "img id out: 18626\n",
      "img id in: 18627\n",
      "img id out: 18627\n",
      "img id in: 18628\n",
      "img id out: 18628\n",
      "img id in: 18629\n",
      "img id out: 18629\n",
      "img id in: 18630\n",
      "img id out: 18630\n",
      "img id in: 18631\n",
      "img id out: 18631\n",
      "img id in: 18632\n",
      "img id out: 18632\n",
      "img id in: 18633\n",
      "img id out: 18633\n",
      "img id in: 18634\n",
      "img id out: 18634\n",
      "img id in: 18635\n",
      "img id out: 18635\n",
      "img id in: 18636\n",
      "img id out: 18636\n",
      "img id in: 18637\n",
      "img id out: 18637\n",
      "img id in: 18638\n",
      "img id out: 18638\n",
      "img id in: 18639\n",
      "img id out: 18639\n",
      "img id in: 18640\n",
      "img id out: 18640\n",
      "img id in: 18641\n",
      "img id out: 18641\n",
      "img id in: 18642\n",
      "img id out: 18642\n",
      "img id in: 18643\n",
      "img id out: 18643\n",
      "img id in: 18644\n",
      "img id out: 18644\n",
      "img id in: 18645\n",
      "img id out: 18645\n",
      "img id in: 18646\n",
      "img id out: 18646\n",
      "img id in: 18647\n",
      "img id out: 18647\n",
      "img id in: 18648\n",
      "img id out: 18648\n",
      "img id in: 18649\n",
      "img id out: 18649\n",
      "img id in: 18650\n",
      "img id out: 18650\n",
      "img id in: 18651\n",
      "img id out: 18651\n",
      "img id in: 18652\n",
      "img id out: 18652\n",
      "img id in: 18653\n",
      "img id out: 18653\n",
      "img id in: 18654\n",
      "img id out: 18654\n",
      "img id in: 18655\n",
      "img id out: 18655\n",
      "img id in: 18656\n",
      "img id out: 18656\n",
      "img id in: 18657\n",
      "img id out: 18657\n",
      "img id in: 18658\n",
      "img id out: 18658\n",
      "img id in: 18659\n",
      "img id out: 18659\n",
      "img id in: 18660\n",
      "img id out: 18660\n",
      "img id in: 18661\n",
      "img id out: 18661\n",
      "img id in: 18662\n",
      "img id out: 18662\n",
      "img id in: 18663\n",
      "img id out: 18663\n",
      "img id in: 18664\n",
      "img id out: 18664\n",
      "img id in: 18665\n",
      "img id out: 18665\n",
      "img id in: 18666\n",
      "img id out: 18666\n",
      "img id in: 18667\n",
      "img id out: 18667\n",
      "img id in: 18668\n",
      "img id out: 18668\n",
      "img id in: 18669\n",
      "img id out: 18669\n",
      "img id in: 18670\n",
      "img id out: 18670\n",
      "img id in: 18671\n",
      "img id out: 18671\n",
      "img id in: 18672\n",
      "img id out: 18672\n",
      "img id in: 18673\n",
      "img id out: 18673\n",
      "img id in: 18674\n",
      "img id out: 18674\n",
      "img id in: 18675\n",
      "img id out: 18675\n",
      "img id in: 18676\n",
      "img id out: 18676\n",
      "img id in: 18677\n",
      "img id out: 18677\n",
      "img id in: 18678\n",
      "img id out: 18678\n",
      "img id in: 18679\n",
      "img id out: 18679\n",
      "img id in: 18680\n",
      "img id out: 18680\n",
      "img id in: 18681\n",
      "img id out: 18681\n",
      "img id in: 18682\n",
      "img id out: 18682\n",
      "img id in: 18683\n",
      "img id out: 18683\n",
      "img id in: 18684\n",
      "img id out: 18684\n",
      "img id in: 18685\n",
      "img id out: 18685\n",
      "img id in: 18686\n",
      "img id out: 18686\n",
      "img id in: 18687\n",
      "img id out: 18687\n",
      "img id in: 18688\n",
      "img id out: 18688\n",
      "img id in: 18689\n",
      "img id out: 18689\n",
      "img id in: 18690\n",
      "img id out: 18690\n",
      "img id in: 18691\n",
      "img id out: 18691\n",
      "img id in: 18692\n",
      "img id out: 18692\n",
      "img id in: 18693\n",
      "img id out: 18693\n",
      "img id in: 18694\n",
      "img id out: 18694\n",
      "img id in: 18695\n",
      "img id out: 18695\n",
      "img id in: 18696\n",
      "img id out: 18696\n",
      "img id in: 18697\n",
      "img id out: 18697\n",
      "img id in: 18698\n",
      "img id out: 18698\n",
      "img id in: 18699\n",
      "img id out: 18699\n",
      "img id in: 18700\n",
      "img id out: 18700\n",
      "img id in: 18701\n",
      "img id out: 18701\n",
      "img id in: 18702\n",
      "img id out: 18702\n",
      "img id in: 18703\n",
      "img id out: 18703\n",
      "img id in: 18704\n",
      "img id out: 18704\n",
      "img id in: 18705\n",
      "img id out: 18705\n",
      "img id in: 18706\n",
      "img id out: 18706\n",
      "img id in: 18707\n",
      "img id out: 18707\n",
      "img id in: 18708\n",
      "img id out: 18708\n",
      "img id in: 18709\n",
      "img id out: 18709\n",
      "img id in: 18710\n",
      "img id out: 18710\n",
      "img id in: 18711\n",
      "img id out: 18711\n",
      "img id in: 18712\n",
      "img id out: 18712\n",
      "img id in: 18713\n",
      "img id out: 18713\n",
      "img id in: 18714\n",
      "img id out: 18714\n",
      "img id in: 18715\n",
      "img id out: 18715\n",
      "img id in: 18716\n",
      "img id out: 18716\n",
      "img id in: 18717\n",
      "img id out: 18717\n",
      "img id in: 18718\n",
      "img id out: 18718\n",
      "img id in: 18719\n",
      "img id out: 18719\n",
      "img id in: 18720\n",
      "img id out: 18720\n",
      "img id in: 18721\n",
      "img id out: 18721\n",
      "img id in: 18722\n",
      "img id out: 18722\n",
      "img id in: 18723\n",
      "img id out: 18723\n",
      "img id in: 18724\n",
      "img id out: 18724\n",
      "img id in: 18725\n",
      "img id out: 18725\n",
      "img id in: 18726\n",
      "img id out: 18726\n",
      "img id in: 18727\n",
      "img id out: 18727\n",
      "img id in: 18728\n",
      "img id out: 18728\n",
      "img id in: 18729\n",
      "img id out: 18729\n",
      "img id in: 18730\n",
      "img id out: 18730\n",
      "img id in: 18731\n",
      "img id out: 18731\n",
      "img id in: 18732\n",
      "img id out: 18732\n",
      "img id in: 18733\n",
      "img id out: 18733\n",
      "img id in: 18734\n",
      "img id out: 18734\n",
      "img id in: 18735\n",
      "img id out: 18735\n",
      "img id in: 18736\n",
      "img id out: 18736\n",
      "img id in: 18737\n",
      "img id out: 18737\n",
      "img id in: 18738\n",
      "img id out: 18738\n",
      "img id in: 18739\n",
      "img id out: 18739\n",
      "img id in: 18740\n",
      "img id out: 18740\n",
      "img id in: 18741\n",
      "img id out: 18741\n",
      "img id in: 18742\n",
      "img id out: 18742\n",
      "img id in: 18743\n",
      "img id out: 18743\n",
      "img id in: 18744\n",
      "img id out: 18744\n",
      "img id in: 18745\n",
      "img id out: 18745\n",
      "img id in: 18746\n",
      "img id out: 18746\n",
      "img id in: 18747\n",
      "img id out: 18747\n",
      "img id in: 18748\n",
      "img id out: 18748\n",
      "img id in: 18749\n",
      "img id out: 18749\n",
      "img id in: 18750\n",
      "img id out: 18750\n",
      "img id in: 18751\n",
      "img id out: 18751\n",
      "img id in: 18752\n",
      "img id out: 18752\n",
      "img id in: 18753\n",
      "img id out: 18753\n",
      "img id in: 18754\n",
      "img id out: 18754\n",
      "img id in: 18755\n",
      "img id out: 18755\n",
      "img id in: 18756\n",
      "img id out: 18756\n",
      "img id in: 18757\n",
      "img id out: 18757\n",
      "img id in: 18758\n",
      "img id out: 18758\n",
      "img id in: 18759\n",
      "img id out: 18759\n",
      "img id in: 18760\n",
      "img id out: 18760\n",
      "img id in: 18761\n",
      "img id out: 18761\n",
      "img id in: 18762\n",
      "img id out: 18762\n",
      "img id in: 18763\n",
      "img id out: 18763\n",
      "img id in: 18764\n",
      "img id out: 18764\n",
      "img id in: 18765\n",
      "img id out: 18765\n",
      "img id in: 18766\n",
      "img id out: 18766\n",
      "img id in: 18767\n",
      "img id out: 18767\n",
      "img id in: 18768\n",
      "img id out: 18768\n",
      "img id in: 18769\n",
      "img id out: 18769\n",
      "img id in: 18770\n",
      "img id out: 18770\n",
      "img id in: 18771\n",
      "img id out: 18771\n",
      "img id in: 18772\n",
      "img id out: 18772\n",
      "img id in: 18773\n",
      "img id out: 18773\n",
      "img id in: 18774\n",
      "img id out: 18774\n",
      "img id in: 18775\n",
      "img id out: 18775\n",
      "img id in: 18776\n",
      "img id out: 18776\n",
      "img id in: 18777\n",
      "img id out: 18777\n",
      "img id in: 18778\n",
      "img id out: 18778\n",
      "img id in: 18779\n",
      "img id out: 18779\n",
      "img id in: 18780\n",
      "img id out: 18780\n",
      "img id in: 18781\n",
      "img id out: 18781\n",
      "img id in: 18782\n",
      "img id out: 18782\n",
      "img id in: 18783\n",
      "img id out: 18783\n",
      "img id in: 18784\n",
      "img id out: 18784\n",
      "img id in: 18785\n",
      "img id out: 18785\n",
      "img id in: 18786\n",
      "img id out: 18786\n",
      "img id in: 18787\n",
      "img id out: 18787\n",
      "img id in: 18788\n",
      "img id out: 18788\n",
      "img id in: 18789\n",
      "img id out: 18789\n",
      "img id in: 18790\n",
      "img id out: 18790\n",
      "img id in: 18791\n",
      "img id out: 18791\n",
      "img id in: 18792\n",
      "img id out: 18792\n",
      "img id in: 18793\n",
      "img id out: 18793\n",
      "img id in: 18794\n",
      "img id out: 18794\n",
      "img id in: 18795\n",
      "img id out: 18795\n",
      "img id in: 18796\n",
      "img id out: 18796\n",
      "img id in: 18797\n",
      "img id out: 18797\n",
      "img id in: 18798\n",
      "img id out: 18798\n",
      "img id in: 18799\n",
      "img id out: 18799\n",
      "img id in: 18800\n",
      "img id out: 18800\n",
      "img id in: 18801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 18801\n",
      "img id in: 18802\n",
      "img id out: 18802\n",
      "img id in: 18803\n",
      "img id out: 18803\n",
      "img id in: 18804\n",
      "img id out: 18804\n",
      "img id in: 18805\n",
      "img id out: 18805\n",
      "img id in: 18806\n",
      "img id out: 18806\n",
      "img id in: 18807\n",
      "img id out: 18807\n",
      "img id in: 18808\n",
      "img id out: 18808\n",
      "img id in: 18809\n",
      "img id out: 18809\n",
      "img id in: 18810\n",
      "img id out: 18810\n",
      "img id in: 18811\n",
      "img id out: 18811\n",
      "img id in: 18812\n",
      "img id out: 18812\n",
      "img id in: 18813\n",
      "img id out: 18813\n",
      "img id in: 18814\n",
      "img id out: 18814\n",
      "img id in: 18815\n",
      "img id out: 18815\n",
      "img id in: 18816\n",
      "img id out: 18816\n",
      "img id in: 18817\n",
      "img id out: 18817\n",
      "img id in: 18818\n",
      "img id out: 18818\n",
      "img id in: 18819\n",
      "img id out: 18819\n",
      "img id in: 18820\n",
      "img id out: 18820\n",
      "img id in: 18821\n",
      "img id out: 18821\n",
      "img id in: 18822\n",
      "img id out: 18822\n",
      "img id in: 18823\n",
      "img id out: 18823\n",
      "img id in: 18824\n",
      "img id out: 18824\n",
      "img id in: 18825\n",
      "img id out: 18825\n",
      "img id in: 18826\n",
      "img id out: 18826\n",
      "img id in: 18827\n",
      "img id out: 18827\n",
      "img id in: 18828\n",
      "img id out: 18828\n",
      "img id in: 18829\n",
      "img id out: 18829\n",
      "img id in: 18830\n",
      "img id out: 18830\n",
      "img id in: 18831\n",
      "img id out: 18831\n",
      "img id in: 18832\n",
      "img id out: 18832\n",
      "img id in: 18833\n",
      "img id out: 18833\n",
      "img id in: 18834\n",
      "img id out: 18834\n",
      "img id in: 18835\n",
      "img id out: 18835\n",
      "img id in: 18836\n",
      "img id out: 18836\n",
      "img id in: 18837\n",
      "img id out: 18837\n",
      "img id in: 18838\n",
      "img id out: 18838\n",
      "img id in: 18839\n",
      "img id out: 18839\n",
      "img id in: 18840\n",
      "img id out: 18840\n",
      "img id in: 18841\n",
      "img id out: 18841\n",
      "img id in: 18842\n",
      "img id out: 18842\n",
      "img id in: 18843\n",
      "img id out: 18843\n",
      "img id in: 18844\n",
      "img id out: 18844\n",
      "img id in: 18845\n",
      "img id out: 18845\n",
      "img id in: 18846\n",
      "img id out: 18846\n",
      "img id in: 18847\n",
      "img id out: 18847\n",
      "img id in: 18848\n",
      "img id out: 18848\n",
      "img id in: 18849\n",
      "img id out: 18849\n",
      "img id in: 18850\n",
      "img id out: 18850\n",
      "img id in: 18851\n",
      "img id out: 18851\n",
      "img id in: 18852\n",
      "img id out: 18852\n",
      "img id in: 18853\n",
      "img id out: 18853\n",
      "img id in: 18854\n",
      "img id out: 18854\n",
      "img id in: 18855\n",
      "img id out: 18855\n",
      "img id in: 18856\n",
      "img id out: 18856\n",
      "img id in: 18857\n",
      "img id out: 18857\n",
      "img id in: 18858\n",
      "img id out: 18858\n",
      "img id in: 18859\n",
      "img id out: 18859\n",
      "img id in: 18860\n",
      "img id out: 18860\n",
      "img id in: 18861\n",
      "img id out: 18861\n",
      "img id in: 18862\n",
      "img id out: 18862\n",
      "img id in: 18863\n",
      "img id out: 18863\n",
      "img id in: 18864\n",
      "img id out: 18864\n",
      "img id in: 18865\n",
      "img id out: 18865\n",
      "img id in: 18866\n",
      "img id out: 18866\n",
      "img id in: 18867\n",
      "img id out: 18867\n",
      "img id in: 18868\n",
      "img id out: 18868\n",
      "img id in: 18869\n",
      "img id out: 18869\n",
      "img id in: 18870\n",
      "img id out: 18870\n",
      "img id in: 18871\n",
      "img id out: 18871\n",
      "img id in: 18872\n",
      "img id out: 18872\n",
      "img id in: 18873\n",
      "img id out: 18873\n",
      "img id in: 18874\n",
      "img id out: 18874\n",
      "img id in: 18875\n",
      "img id out: 18875\n",
      "img id in: 18876\n",
      "img id out: 18876\n",
      "img id in: 18877\n",
      "img id out: 18877\n",
      "img id in: 18878\n",
      "img id out: 18878\n",
      "img id in: 18879\n",
      "img id out: 18879\n",
      "img id in: 18880\n",
      "img id out: 18880\n",
      "img id in: 18881\n",
      "img id out: 18881\n",
      "img id in: 18882\n",
      "img id out: 18882\n",
      "img id in: 18883\n",
      "img id out: 18883\n",
      "img id in: 18884\n",
      "img id out: 18884\n",
      "img id in: 18885\n",
      "img id out: 18885\n",
      "img id in: 18886\n",
      "img id out: 18886\n",
      "img id in: 18887\n",
      "img id out: 18887\n",
      "img id in: 18888\n",
      "img id out: 18888\n",
      "img id in: 18889\n",
      "img id out: 18889\n",
      "img id in: 18890\n",
      "img id out: 18890\n",
      "img id in: 18891\n",
      "img id out: 18891\n",
      "img id in: 18892\n",
      "img id out: 18892\n",
      "img id in: 18893\n",
      "img id out: 18893\n",
      "img id in: 18894\n",
      "img id out: 18894\n",
      "img id in: 18895\n",
      "img id out: 18895\n",
      "img id in: 18896\n",
      "img id out: 18896\n",
      "img id in: 18897\n",
      "img id out: 18897\n",
      "img id in: 18898\n",
      "img id out: 18898\n",
      "img id in: 18899\n",
      "img id out: 18899\n",
      "img id in: 18900\n",
      "img id out: 18900\n",
      "img id in: 18901\n",
      "img id out: 18901\n",
      "img id in: 18902\n",
      "img id out: 18902\n",
      "img id in: 18903\n",
      "img id out: 18903\n",
      "img id in: 18904\n",
      "img id out: 18904\n",
      "img id in: 18905\n",
      "img id out: 18905\n",
      "img id in: 18906\n",
      "img id out: 18906\n",
      "img id in: 18907\n",
      "img id out: 18907\n",
      "img id in: 18908\n",
      "img id out: 18908\n",
      "img id in: 18909\n",
      "img id out: 18909\n",
      "img id in: 18910\n",
      "img id out: 18910\n",
      "img id in: 18911\n",
      "img id out: 18911\n",
      "img id in: 18912\n",
      "img id out: 18912\n",
      "img id in: 18913\n",
      "img id out: 18913\n",
      "img id in: 18914\n",
      "img id out: 18914\n",
      "img id in: 18915\n",
      "img id out: 18915\n",
      "img id in: 18916\n",
      "img id out: 18916\n",
      "img id in: 18917\n",
      "img id out: 18917\n",
      "img id in: 18918\n",
      "img id out: 18918\n",
      "img id in: 18919\n",
      "img id out: 18919\n",
      "img id in: 18920\n",
      "img id out: 18920\n",
      "img id in: 18921\n",
      "img id out: 18921\n",
      "img id in: 18922\n",
      "img id out: 18922\n",
      "img id in: 18923\n",
      "img id out: 18923\n",
      "img id in: 18924\n",
      "img id out: 18924\n",
      "img id in: 18925\n",
      "img id out: 18925\n",
      "img id in: 18926\n",
      "img id out: 18926\n",
      "img id in: 18927\n",
      "img id out: 18927\n",
      "img id in: 18928\n",
      "img id out: 18928\n",
      "img id in: 18929\n",
      "img id out: 18929\n",
      "img id in: 18930\n",
      "img id out: 18930\n",
      "img id in: 18931\n",
      "img id out: 18931\n",
      "img id in: 18932\n",
      "img id out: 18932\n",
      "img id in: 18933\n",
      "img id out: 18933\n",
      "img id in: 18934\n",
      "img id out: 18934\n",
      "img id in: 18935\n",
      "img id out: 18935\n",
      "img id in: 18936\n",
      "img id out: 18936\n",
      "img id in: 18937\n",
      "img id out: 18937\n",
      "img id in: 18938\n",
      "img id out: 18938\n",
      "img id in: 18939\n",
      "img id out: 18939\n",
      "img id in: 18940\n",
      "img id out: 18940\n",
      "img id in: 18941\n",
      "img id out: 18941\n",
      "img id in: 18942\n",
      "img id out: 18942\n",
      "img id in: 18943\n",
      "img id out: 18943\n",
      "img id in: 18944\n",
      "img id out: 18944\n",
      "img id in: 18945\n",
      "img id out: 18945\n",
      "img id in: 18946\n",
      "img id out: 18946\n",
      "img id in: 18947\n",
      "img id out: 18947\n",
      "img id in: 18948\n",
      "img id out: 18948\n",
      "img id in: 18949\n",
      "img id out: 18949\n",
      "img id in: 18950\n",
      "img id out: 18950\n",
      "img id in: 18951\n",
      "img id out: 18951\n",
      "img id in: 18952\n",
      "img id out: 18952\n",
      "img id in: 18953\n",
      "img id out: 18953\n",
      "img id in: 18954\n",
      "img id out: 18954\n",
      "img id in: 18955\n",
      "img id out: 18955\n",
      "img id in: 18956\n",
      "img id out: 18956\n",
      "img id in: 18957\n",
      "img id out: 18957\n",
      "img id in: 18958\n",
      "img id out: 18958\n",
      "img id in: 18959\n",
      "img id out: 18959\n",
      "img id in: 18960\n",
      "img id out: 18960\n",
      "img id in: 18961\n",
      "img id out: 18961\n",
      "img id in: 18962\n",
      "img id out: 18962\n",
      "img id in: 18963\n",
      "img id out: 18963\n",
      "img id in: 18964\n",
      "img id out: 18964\n",
      "img id in: 18965\n",
      "img id out: 18965\n",
      "img id in: 18966\n",
      "img id out: 18966\n",
      "img id in: 18967\n",
      "img id out: 18967\n",
      "img id in: 18968\n",
      "img id out: 18968\n",
      "img id in: 18969\n",
      "img id out: 18969\n",
      "img id in: 18970\n",
      "img id out: 18970\n",
      "img id in: 18971\n",
      "img id out: 18971\n",
      "img id in: 18972\n",
      "img id out: 18972\n",
      "img id in: 18973\n",
      "img id out: 18973\n",
      "img id in: 18974\n",
      "img id out: 18974\n",
      "img id in: 18975\n",
      "img id out: 18975\n",
      "img id in: 18976\n",
      "img id out: 18976\n",
      "img id in: 18977\n",
      "img id out: 18977\n",
      "img id in: 18978\n",
      "img id out: 18978\n",
      "img id in: 18979\n",
      "img id out: 18979\n",
      "img id in: 18980\n",
      "img id out: 18980\n",
      "img id in: 18981\n",
      "img id out: 18981\n",
      "img id in: 18982\n",
      "img id out: 18982\n",
      "img id in: 18983\n",
      "img id out: 18983\n",
      "img id in: 18984\n",
      "img id out: 18984\n",
      "img id in: 18985\n",
      "img id out: 18985\n",
      "img id in: 18986\n",
      "img id out: 18986\n",
      "img id in: 18987\n",
      "img id out: 18987\n",
      "img id in: 18988\n",
      "img id out: 18988\n",
      "img id in: 18989\n",
      "img id out: 18989\n",
      "img id in: 18990\n",
      "img id out: 18990\n",
      "img id in: 18991\n",
      "img id out: 18991\n",
      "img id in: 18992\n",
      "img id out: 18992\n",
      "img id in: 18993\n",
      "img id out: 18993\n",
      "img id in: 18994\n",
      "img id out: 18994\n",
      "img id in: 18995\n",
      "img id out: 18995\n",
      "img id in: 18996\n",
      "img id out: 18996\n",
      "img id in: 18997\n",
      "img id out: 18997\n",
      "img id in: 18998\n",
      "img id out: 18998\n",
      "img id in: 18999\n",
      "img id out: 18999\n",
      "img id in: 19000\n",
      "img id out: 19000\n",
      "img id in: 19001\n",
      "img id out: 19001\n",
      "img id in: 19002\n",
      "img id out: 19002\n",
      "img id in: 19003\n",
      "img id out: 19003\n",
      "img id in: 19004\n",
      "img id out: 19004\n",
      "img id in: 19005\n",
      "img id out: 19005\n",
      "img id in: 19006\n",
      "img id out: 19006\n",
      "img id in: 19007\n",
      "img id out: 19007\n",
      "img id in: 19008\n",
      "img id out: 19008\n",
      "img id in: 19009\n",
      "img id out: 19009\n",
      "img id in: 19010\n",
      "img id out: 19010\n",
      "img id in: 19011\n",
      "img id out: 19011\n",
      "img id in: 19012\n",
      "img id out: 19012\n",
      "img id in: 19013\n",
      "img id out: 19013\n",
      "img id in: 19014\n",
      "img id out: 19014\n",
      "img id in: 19015\n",
      "img id out: 19015\n",
      "img id in: 19016\n",
      "img id out: 19016\n",
      "img id in: 19017\n",
      "img id out: 19017\n",
      "img id in: 19018\n",
      "img id out: 19018\n",
      "img id in: 19019\n",
      "img id out: 19019\n",
      "img id in: 19020\n",
      "img id out: 19020\n",
      "img id in: 19021\n",
      "img id out: 19021\n",
      "img id in: 19022\n",
      "img id out: 19022\n",
      "img id in: 19023\n",
      "img id out: 19023\n",
      "img id in: 19024\n",
      "img id out: 19024\n",
      "img id in: 19025\n",
      "img id out: 19025\n",
      "img id in: 19026\n",
      "img id out: 19026\n",
      "img id in: 19027\n",
      "img id out: 19027\n",
      "img id in: 19028\n",
      "img id out: 19028\n",
      "img id in: 19029\n",
      "img id out: 19029\n",
      "img id in: 19030\n",
      "img id out: 19030\n",
      "img id in: 19031\n",
      "img id out: 19031\n",
      "img id in: 19032\n",
      "img id out: 19032\n",
      "img id in: 19033\n",
      "img id out: 19033\n",
      "img id in: 19034\n",
      "img id out: 19034\n",
      "img id in: 19035\n",
      "img id out: 19035\n",
      "img id in: 19036\n",
      "img id out: 19036\n",
      "img id in: 19037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 19037\n",
      "img id in: 19038\n",
      "img id out: 19038\n",
      "img id in: 19039\n",
      "img id out: 19039\n",
      "img id in: 19040\n",
      "img id out: 19040\n",
      "img id in: 19041\n",
      "img id out: 19041\n",
      "img id in: 19042\n",
      "img id out: 19042\n",
      "img id in: 19043\n",
      "img id out: 19043\n",
      "img id in: 19044\n",
      "img id out: 19044\n",
      "img id in: 19045\n",
      "img id out: 19045\n",
      "img id in: 19046\n",
      "img id out: 19046\n",
      "img id in: 19047\n",
      "img id out: 19047\n",
      "img id in: 19048\n",
      "img id out: 19048\n",
      "img id in: 19049\n",
      "img id out: 19049\n",
      "img id in: 19050\n",
      "img id out: 19050\n",
      "img id in: 19051\n",
      "img id out: 19051\n",
      "img id in: 19052\n",
      "img id out: 19052\n",
      "img id in: 19053\n",
      "img id out: 19053\n",
      "img id in: 19054\n",
      "img id out: 19054\n",
      "img id in: 19055\n",
      "img id out: 19055\n",
      "img id in: 19056\n",
      "img id out: 19056\n",
      "img id in: 19057\n",
      "img id out: 19057\n",
      "img id in: 19058\n",
      "img id out: 19058\n",
      "img id in: 19059\n",
      "img id out: 19059\n",
      "img id in: 19060\n",
      "img id out: 19060\n",
      "img id in: 19061\n",
      "img id out: 19061\n",
      "img id in: 19062\n",
      "img id out: 19062\n",
      "img id in: 19063\n",
      "img id out: 19063\n",
      "img id in: 19064\n",
      "img id out: 19064\n",
      "img id in: 19065\n",
      "img id out: 19065\n",
      "img id in: 19066\n",
      "img id out: 19066\n",
      "img id in: 19067\n",
      "img id out: 19067\n",
      "img id in: 19068\n",
      "img id out: 19068\n",
      "img id in: 19069\n",
      "img id out: 19069\n",
      "img id in: 19070\n",
      "img id out: 19070\n",
      "img id in: 19071\n",
      "img id out: 19071\n",
      "img id in: 19072\n",
      "img id out: 19072\n",
      "img id in: 19073\n",
      "img id out: 19073\n",
      "img id in: 19074\n",
      "img id out: 19074\n",
      "img id in: 19075\n",
      "img id out: 19075\n",
      "img id in: 19076\n",
      "img id out: 19076\n",
      "img id in: 19077\n",
      "img id out: 19077\n",
      "img id in: 19078\n",
      "img id out: 19078\n",
      "img id in: 19079\n",
      "img id out: 19079\n",
      "img id in: 19080\n",
      "img id out: 19080\n",
      "img id in: 19081\n",
      "img id out: 19081\n",
      "img id in: 19082\n",
      "img id out: 19082\n",
      "img id in: 19083\n",
      "img id out: 19083\n",
      "img id in: 19084\n",
      "img id out: 19084\n",
      "img id in: 19085\n",
      "img id out: 19085\n",
      "img id in: 19086\n",
      "img id out: 19086\n",
      "img id in: 19087\n",
      "img id out: 19087\n",
      "img id in: 19088\n",
      "img id out: 19088\n",
      "img id in: 19089\n",
      "img id out: 19089\n",
      "img id in: 19090\n",
      "img id out: 19090\n",
      "img id in: 19091\n",
      "img id out: 19091\n",
      "img id in: 19092\n",
      "img id out: 19092\n",
      "img id in: 19093\n",
      "img id out: 19093\n",
      "img id in: 19094\n",
      "img id out: 19094\n",
      "img id in: 19095\n",
      "img id out: 19095\n",
      "img id in: 19096\n",
      "img id out: 19096\n",
      "img id in: 19097\n",
      "img id out: 19097\n",
      "img id in: 19098\n",
      "img id out: 19098\n",
      "img id in: 19099\n",
      "img id out: 19099\n",
      "img id in: 19100\n",
      "img id out: 19100\n",
      "img id in: 19101\n",
      "img id out: 19101\n",
      "img id in: 19102\n",
      "img id out: 19102\n",
      "img id in: 19103\n",
      "img id out: 19103\n",
      "img id in: 19104\n",
      "img id out: 19104\n",
      "img id in: 19105\n",
      "img id out: 19105\n",
      "img id in: 19106\n",
      "img id out: 19106\n",
      "img id in: 19107\n",
      "img id out: 19107\n",
      "img id in: 19108\n",
      "img id out: 19108\n",
      "img id in: 19109\n",
      "img id out: 19109\n",
      "img id in: 19110\n",
      "img id out: 19110\n",
      "img id in: 19111\n",
      "img id out: 19111\n",
      "img id in: 19112\n",
      "img id out: 19112\n",
      "img id in: 19113\n",
      "img id out: 19113\n",
      "img id in: 19114\n",
      "img id out: 19114\n",
      "img id in: 19115\n",
      "img id out: 19115\n",
      "img id in: 19116\n",
      "img id out: 19116\n",
      "img id in: 19117\n",
      "img id out: 19117\n",
      "img id in: 19118\n",
      "img id out: 19118\n",
      "img id in: 19119\n",
      "img id out: 19119\n",
      "img id in: 19120\n",
      "img id out: 19120\n",
      "img id in: 19121\n",
      "img id out: 19121\n",
      "img id in: 19122\n",
      "img id out: 19122\n",
      "img id in: 19123\n",
      "img id out: 19123\n",
      "img id in: 19124\n",
      "img id out: 19124\n",
      "img id in: 19125\n",
      "img id out: 19125\n",
      "img id in: 19126\n",
      "img id out: 19126\n",
      "img id in: 19127\n",
      "img id out: 19127\n",
      "img id in: 19128\n",
      "img id out: 19128\n",
      "img id in: 19129\n",
      "img id out: 19129\n",
      "img id in: 19130\n",
      "img id out: 19130\n",
      "img id in: 19131\n",
      "img id out: 19131\n",
      "img id in: 19132\n",
      "img id out: 19132\n",
      "img id in: 19133\n",
      "img id out: 19133\n",
      "img id in: 19134\n",
      "img id out: 19134\n",
      "img id in: 19135\n",
      "img id out: 19135\n",
      "img id in: 19136\n",
      "img id out: 19136\n",
      "img id in: 19137\n",
      "img id out: 19137\n",
      "img id in: 19138\n",
      "img id out: 19138\n",
      "img id in: 19139\n",
      "img id out: 19139\n",
      "img id in: 19140\n",
      "img id out: 19140\n",
      "img id in: 19141\n",
      "img id out: 19141\n",
      "img id in: 19142\n",
      "img id out: 19142\n",
      "img id in: 19143\n",
      "img id out: 19143\n",
      "img id in: 19144\n",
      "img id out: 19144\n",
      "img id in: 19145\n",
      "img id out: 19145\n",
      "img id in: 19146\n",
      "img id out: 19146\n",
      "img id in: 19147\n",
      "img id out: 19147\n",
      "img id in: 19148\n",
      "img id out: 19148\n",
      "img id in: 19149\n",
      "img id out: 19149\n",
      "img id in: 19150\n",
      "img id out: 19150\n",
      "img id in: 19151\n",
      "img id out: 19151\n",
      "img id in: 19152\n",
      "img id out: 19152\n",
      "img id in: 19153\n",
      "img id out: 19153\n",
      "img id in: 19154\n",
      "img id out: 19154\n",
      "img id in: 19155\n",
      "img id out: 19155\n",
      "img id in: 19156\n",
      "img id out: 19156\n",
      "img id in: 19157\n",
      "img id out: 19157\n",
      "img id in: 19158\n",
      "img id out: 19158\n",
      "img id in: 19159\n",
      "img id out: 19159\n",
      "img id in: 19160\n",
      "img id out: 19160\n",
      "img id in: 19161\n",
      "img id out: 19161\n",
      "img id in: 19162\n",
      "img id out: 19162\n",
      "img id in: 19163\n",
      "img id out: 19163\n",
      "img id in: 19164\n",
      "img id out: 19164\n",
      "img id in: 19165\n",
      "img id out: 19165\n",
      "img id in: 19166\n",
      "img id out: 19166\n",
      "img id in: 19167\n",
      "img id out: 19167\n",
      "img id in: 19168\n",
      "img id out: 19168\n",
      "img id in: 19169\n",
      "img id out: 19169\n",
      "img id in: 19170\n",
      "img id out: 19170\n",
      "img id in: 19171\n",
      "img id out: 19171\n",
      "img id in: 19172\n",
      "img id out: 19172\n",
      "img id in: 19173\n",
      "img id out: 19173\n",
      "img id in: 19174\n",
      "img id out: 19174\n",
      "img id in: 19175\n",
      "img id out: 19175\n",
      "img id in: 19176\n",
      "img id out: 19176\n",
      "img id in: 19177\n",
      "img id out: 19177\n",
      "img id in: 19178\n",
      "img id out: 19178\n",
      "img id in: 19179\n",
      "img id out: 19179\n",
      "img id in: 19180\n",
      "img id out: 19180\n",
      "img id in: 19181\n",
      "img id out: 19181\n",
      "img id in: 19182\n",
      "img id out: 19182\n",
      "img id in: 19183\n",
      "img id out: 19183\n",
      "img id in: 19184\n",
      "img id out: 19184\n",
      "img id in: 19185\n",
      "img id out: 19185\n",
      "img id in: 19186\n",
      "img id out: 19186\n",
      "img id in: 19187\n",
      "img id out: 19187\n",
      "img id in: 19188\n",
      "img id out: 19188\n",
      "img id in: 19189\n",
      "img id out: 19189\n",
      "img id in: 19190\n",
      "img id out: 19190\n",
      "img id in: 19191\n",
      "img id out: 19191\n",
      "img id in: 19192\n",
      "img id out: 19192\n",
      "img id in: 19193\n",
      "img id out: 19193\n",
      "img id in: 19194\n",
      "img id out: 19194\n",
      "img id in: 19195\n",
      "img id out: 19195\n",
      "img id in: 19196\n",
      "img id out: 19196\n",
      "img id in: 19197\n",
      "img id out: 19197\n",
      "img id in: 19198\n",
      "img id out: 19198\n",
      "img id in: 19199\n",
      "img id out: 19199\n",
      "img id in: 19200\n",
      "img id out: 19200\n",
      "img id in: 19201\n",
      "img id out: 19201\n",
      "img id in: 19202\n",
      "img id out: 19202\n",
      "img id in: 19203\n",
      "img id out: 19203\n",
      "img id in: 19204\n",
      "img id out: 19204\n",
      "img id in: 19205\n",
      "img id out: 19205\n",
      "img id in: 19206\n",
      "img id out: 19206\n",
      "img id in: 19207\n",
      "img id out: 19207\n",
      "img id in: 19208\n",
      "img id out: 19208\n",
      "img id in: 19209\n",
      "img id out: 19209\n",
      "img id in: 19210\n",
      "img id out: 19210\n",
      "img id in: 19211\n",
      "img id out: 19211\n",
      "img id in: 19212\n",
      "img id out: 19212\n",
      "img id in: 19213\n",
      "img id out: 19213\n",
      "img id in: 19214\n",
      "img id out: 19214\n",
      "img id in: 19215\n",
      "img id out: 19215\n",
      "img id in: 19216\n",
      "img id out: 19216\n",
      "img id in: 19217\n",
      "img id out: 19217\n",
      "img id in: 19218\n",
      "img id out: 19218\n",
      "img id in: 19219\n",
      "img id out: 19219\n",
      "img id in: 19220\n",
      "img id out: 19220\n",
      "img id in: 19221\n",
      "img id out: 19221\n",
      "img id in: 19222\n",
      "img id out: 19222\n",
      "img id in: 19223\n",
      "img id out: 19223\n",
      "img id in: 19224\n",
      "img id out: 19224\n",
      "img id in: 19225\n",
      "img id out: 19225\n",
      "img id in: 19226\n",
      "img id out: 19226\n",
      "img id in: 19227\n",
      "img id out: 19227\n",
      "img id in: 19228\n",
      "img id out: 19228\n",
      "img id in: 19229\n",
      "img id out: 19229\n",
      "img id in: 19230\n",
      "img id out: 19230\n",
      "img id in: 19231\n",
      "img id out: 19231\n",
      "img id in: 19232\n",
      "img id out: 19232\n",
      "img id in: 19233\n",
      "img id out: 19233\n",
      "img id in: 19234\n",
      "img id out: 19234\n",
      "img id in: 19235\n",
      "img id out: 19235\n",
      "img id in: 19236\n",
      "img id out: 19236\n",
      "img id in: 19237\n",
      "img id out: 19237\n",
      "img id in: 19238\n",
      "img id out: 19238\n",
      "img id in: 19239\n",
      "img id out: 19239\n",
      "img id in: 19240\n",
      "img id out: 19240\n",
      "img id in: 19241\n",
      "img id out: 19241\n",
      "img id in: 19242\n",
      "img id out: 19242\n",
      "img id in: 19243\n",
      "img id out: 19243\n",
      "img id in: 19244\n",
      "img id out: 19244\n",
      "img id in: 19245\n",
      "img id out: 19245\n",
      "img id in: 19246\n",
      "img id out: 19246\n",
      "img id in: 19247\n",
      "img id out: 19247\n",
      "img id in: 19248\n",
      "img id out: 19248\n",
      "img id in: 19249\n",
      "img id out: 19249\n",
      "img id in: 19250\n",
      "img id out: 19250\n",
      "img id in: 19251\n",
      "img id out: 19251\n",
      "img id in: 19252\n",
      "img id out: 19252\n",
      "img id in: 19253\n",
      "img id out: 19253\n",
      "img id in: 19254\n",
      "img id out: 19254\n",
      "img id in: 19255\n",
      "img id out: 19255\n",
      "img id in: 19256\n",
      "img id out: 19256\n",
      "img id in: 19257\n",
      "img id out: 19257\n",
      "img id in: 19258\n",
      "img id out: 19258\n",
      "img id in: 19259\n",
      "img id out: 19259\n",
      "img id in: 19260\n",
      "img id out: 19260\n",
      "img id in: 19261\n",
      "img id out: 19261\n",
      "img id in: 19262\n",
      "img id out: 19262\n",
      "img id in: 19263\n",
      "img id out: 19263\n",
      "img id in: 19264\n",
      "img id out: 19264\n",
      "img id in: 19265\n",
      "img id out: 19265\n",
      "img id in: 19266\n",
      "img id out: 19266\n",
      "img id in: 19267\n",
      "img id out: 19267\n",
      "img id in: 19268\n",
      "img id out: 19268\n",
      "img id in: 19269\n",
      "img id out: 19269\n",
      "img id in: 19270\n",
      "img id out: 19270\n",
      "img id in: 19271\n",
      "img id out: 19271\n",
      "img id in: 19272\n",
      "img id out: 19272\n",
      "img id in: 19273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 19273\n",
      "img id in: 19274\n",
      "img id out: 19274\n",
      "img id in: 19275\n",
      "img id out: 19275\n",
      "img id in: 19276\n",
      "img id out: 19276\n",
      "img id in: 19277\n",
      "img id out: 19277\n",
      "img id in: 19278\n",
      "img id out: 19278\n",
      "img id in: 19279\n",
      "img id out: 19279\n",
      "img id in: 19280\n",
      "img id out: 19280\n",
      "img id in: 19281\n",
      "img id out: 19281\n",
      "img id in: 19282\n",
      "img id out: 19282\n",
      "img id in: 19283\n",
      "img id out: 19283\n",
      "img id in: 19284\n",
      "img id out: 19284\n",
      "img id in: 19285\n",
      "img id out: 19285\n",
      "img id in: 19286\n",
      "img id out: 19286\n",
      "img id in: 19287\n",
      "img id out: 19287\n",
      "img id in: 19288\n",
      "img id out: 19288\n",
      "img id in: 19289\n",
      "img id out: 19289\n",
      "img id in: 19290\n",
      "img id out: 19290\n",
      "img id in: 19291\n",
      "img id out: 19291\n",
      "img id in: 19292\n",
      "img id out: 19292\n",
      "img id in: 19293\n",
      "img id out: 19293\n",
      "img id in: 19294\n",
      "img id out: 19294\n",
      "img id in: 19295\n",
      "img id out: 19295\n",
      "img id in: 19296\n",
      "img id out: 19296\n",
      "img id in: 19297\n",
      "img id out: 19297\n",
      "img id in: 19298\n",
      "img id out: 19298\n",
      "img id in: 19299\n",
      "img id out: 19299\n",
      "img id in: 19300\n",
      "img id out: 19300\n",
      "img id in: 19301\n",
      "img id out: 19301\n",
      "img id in: 19302\n",
      "img id out: 19302\n",
      "img id in: 19303\n",
      "img id out: 19303\n",
      "img id in: 19304\n",
      "img id out: 19304\n",
      "img id in: 19305\n",
      "img id out: 19305\n",
      "img id in: 19306\n",
      "img id out: 19306\n",
      "img id in: 19307\n",
      "img id out: 19307\n",
      "img id in: 19308\n",
      "img id out: 19308\n",
      "img id in: 19309\n",
      "img id out: 19309\n",
      "img id in: 19310\n",
      "img id out: 19310\n",
      "img id in: 19311\n",
      "img id out: 19311\n",
      "img id in: 19312\n",
      "img id out: 19312\n",
      "img id in: 19313\n",
      "img id out: 19313\n",
      "img id in: 19314\n",
      "img id out: 19314\n",
      "img id in: 19315\n",
      "img id out: 19315\n",
      "img id in: 19316\n",
      "img id out: 19316\n",
      "img id in: 19317\n",
      "img id out: 19317\n",
      "img id in: 19318\n",
      "img id out: 19318\n",
      "img id in: 19319\n",
      "img id out: 19319\n",
      "img id in: 19320\n",
      "img id out: 19320\n",
      "img id in: 19321\n",
      "img id out: 19321\n",
      "img id in: 19322\n",
      "img id out: 19322\n",
      "img id in: 19323\n",
      "img id out: 19323\n",
      "img id in: 19324\n",
      "img id out: 19324\n",
      "img id in: 19325\n",
      "img id out: 19325\n",
      "img id in: 19326\n",
      "img id out: 19326\n",
      "img id in: 19327\n",
      "img id out: 19327\n",
      "img id in: 19328\n",
      "img id out: 19328\n",
      "img id in: 19329\n",
      "img id out: 19329\n",
      "img id in: 19330\n",
      "img id out: 19330\n",
      "img id in: 19331\n",
      "img id out: 19331\n",
      "img id in: 19332\n",
      "img id out: 19332\n",
      "img id in: 19333\n",
      "img id out: 19333\n",
      "img id in: 19334\n",
      "img id out: 19334\n",
      "img id in: 19335\n",
      "img id out: 19335\n",
      "img id in: 19336\n",
      "img id out: 19336\n",
      "img id in: 19337\n",
      "img id out: 19337\n",
      "img id in: 19338\n",
      "img id out: 19338\n",
      "img id in: 19339\n",
      "img id out: 19339\n",
      "img id in: 19340\n",
      "img id out: 19340\n",
      "img id in: 19341\n",
      "img id out: 19341\n",
      "img id in: 19342\n",
      "img id out: 19342\n",
      "img id in: 19343\n",
      "img id out: 19343\n",
      "img id in: 19344\n",
      "img id out: 19344\n",
      "img id in: 19345\n",
      "img id out: 19345\n",
      "img id in: 19346\n",
      "img id out: 19346\n",
      "img id in: 19347\n",
      "img id out: 19347\n",
      "img id in: 19348\n",
      "img id out: 19348\n",
      "img id in: 19349\n",
      "img id out: 19349\n",
      "img id in: 19350\n",
      "img id out: 19350\n",
      "img id in: 19351\n",
      "img id out: 19351\n",
      "img id in: 19352\n",
      "img id out: 19352\n",
      "img id in: 19353\n",
      "img id out: 19353\n",
      "img id in: 19354\n",
      "img id out: 19354\n",
      "img id in: 19355\n",
      "img id out: 19355\n",
      "img id in: 19356\n",
      "img id out: 19356\n",
      "img id in: 19357\n",
      "img id out: 19357\n",
      "img id in: 19358\n",
      "img id out: 19358\n",
      "img id in: 19359\n",
      "img id out: 19359\n",
      "img id in: 19360\n",
      "img id out: 19360\n",
      "img id in: 19361\n",
      "img id out: 19361\n",
      "img id in: 19362\n",
      "img id out: 19362\n",
      "img id in: 19363\n",
      "img id out: 19363\n",
      "img id in: 19364\n",
      "img id out: 19364\n",
      "img id in: 19365\n",
      "img id out: 19365\n",
      "img id in: 19366\n",
      "img id out: 19366\n",
      "img id in: 19367\n",
      "img id out: 19367\n",
      "img id in: 19368\n",
      "img id out: 19368\n",
      "img id in: 19369\n",
      "img id out: 19369\n",
      "img id in: 19370\n",
      "img id out: 19370\n",
      "img id in: 19371\n",
      "img id out: 19371\n",
      "img id in: 19372\n",
      "img id out: 19372\n",
      "img id in: 19373\n",
      "img id out: 19373\n",
      "img id in: 19374\n",
      "img id out: 19374\n",
      "img id in: 19375\n",
      "img id out: 19375\n",
      "img id in: 19376\n",
      "img id out: 19376\n",
      "img id in: 19377\n",
      "img id out: 19377\n",
      "img id in: 19378\n",
      "img id out: 19378\n",
      "img id in: 19379\n",
      "img id out: 19379\n",
      "img id in: 19380\n",
      "img id out: 19380\n",
      "img id in: 19381\n",
      "img id out: 19381\n",
      "img id in: 19382\n",
      "img id out: 19382\n",
      "img id in: 19383\n",
      "img id out: 19383\n",
      "img id in: 19384\n",
      "img id out: 19384\n",
      "img id in: 19385\n",
      "img id out: 19385\n",
      "img id in: 19386\n",
      "img id out: 19386\n",
      "img id in: 19387\n",
      "img id out: 19387\n",
      "img id in: 19388\n",
      "img id out: 19388\n",
      "img id in: 19389\n",
      "img id out: 19389\n",
      "img id in: 19390\n",
      "img id out: 19390\n",
      "img id in: 19391\n",
      "img id out: 19391\n",
      "img id in: 19392\n",
      "img id out: 19392\n",
      "img id in: 19393\n",
      "img id out: 19393\n",
      "img id in: 19394\n",
      "img id out: 19394\n",
      "img id in: 19395\n",
      "img id out: 19395\n",
      "img id in: 19396\n",
      "img id out: 19396\n",
      "img id in: 19397\n",
      "img id out: 19397\n",
      "img id in: 19398\n",
      "img id out: 19398\n",
      "img id in: 19399\n",
      "img id out: 19399\n",
      "img id in: 19400\n",
      "img id out: 19400\n",
      "img id in: 19401\n",
      "img id out: 19401\n",
      "img id in: 19402\n",
      "img id out: 19402\n",
      "img id in: 19403\n",
      "img id out: 19403\n",
      "img id in: 19404\n",
      "img id out: 19404\n",
      "img id in: 19405\n",
      "img id out: 19405\n",
      "img id in: 19406\n",
      "img id out: 19406\n",
      "img id in: 19407\n",
      "img id out: 19407\n",
      "img id in: 19408\n",
      "img id out: 19408\n",
      "img id in: 19409\n",
      "img id out: 19409\n",
      "img id in: 19410\n",
      "img id out: 19410\n",
      "img id in: 19411\n",
      "img id out: 19411\n",
      "img id in: 19412\n",
      "img id out: 19412\n",
      "img id in: 19413\n",
      "img id out: 19413\n",
      "img id in: 19414\n",
      "img id out: 19414\n",
      "img id in: 19415\n",
      "img id out: 19415\n",
      "img id in: 19416\n",
      "img id out: 19416\n",
      "img id in: 19417\n",
      "img id out: 19417\n",
      "img id in: 19418\n",
      "img id out: 19418\n",
      "img id in: 19419\n",
      "img id out: 19419\n",
      "img id in: 19420\n",
      "img id out: 19420\n",
      "img id in: 19421\n",
      "img id out: 19421\n",
      "img id in: 19422\n",
      "img id out: 19422\n",
      "img id in: 19423\n",
      "img id out: 19423\n",
      "img id in: 19424\n",
      "img id out: 19424\n",
      "img id in: 19425\n",
      "img id out: 19425\n",
      "img id in: 19426\n",
      "img id out: 19426\n",
      "img id in: 19427\n",
      "img id out: 19427\n",
      "img id in: 19428\n",
      "img id out: 19428\n",
      "img id in: 19429\n",
      "img id out: 19429\n",
      "img id in: 19430\n",
      "img id out: 19430\n",
      "img id in: 19431\n",
      "img id out: 19431\n",
      "img id in: 19432\n",
      "img id out: 19432\n",
      "img id in: 19433\n",
      "img id out: 19433\n",
      "img id in: 19434\n",
      "img id out: 19434\n",
      "img id in: 19435\n",
      "img id out: 19435\n",
      "img id in: 19436\n",
      "img id out: 19436\n",
      "img id in: 19437\n",
      "img id out: 19437\n",
      "img id in: 19438\n",
      "img id out: 19438\n",
      "img id in: 19439\n",
      "img id out: 19439\n",
      "img id in: 19440\n",
      "img id out: 19440\n",
      "img id in: 19441\n",
      "img id out: 19441\n",
      "img id in: 19442\n",
      "img id out: 19442\n",
      "img id in: 19443\n",
      "img id out: 19443\n",
      "img id in: 19444\n",
      "img id out: 19444\n",
      "img id in: 19445\n",
      "img id out: 19445\n",
      "img id in: 19446\n",
      "img id out: 19446\n",
      "img id in: 19447\n",
      "img id out: 19447\n",
      "img id in: 19448\n",
      "img id out: 19448\n",
      "img id in: 19449\n",
      "img id out: 19449\n",
      "img id in: 19450\n",
      "img id out: 19450\n",
      "img id in: 19451\n",
      "img id out: 19451\n",
      "img id in: 19452\n",
      "img id out: 19452\n",
      "img id in: 19453\n",
      "img id out: 19453\n",
      "img id in: 19454\n",
      "img id out: 19454\n",
      "img id in: 19455\n",
      "img id out: 19455\n",
      "img id in: 19456\n",
      "img id out: 19456\n",
      "img id in: 19457\n",
      "img id out: 19457\n",
      "img id in: 19458\n",
      "img id out: 19458\n",
      "img id in: 19459\n",
      "img id out: 19459\n",
      "img id in: 19460\n",
      "img id out: 19460\n",
      "img id in: 19461\n",
      "img id out: 19461\n",
      "img id in: 19462\n",
      "img id out: 19462\n",
      "img id in: 19463\n",
      "img id out: 19463\n",
      "img id in: 19464\n",
      "img id out: 19464\n",
      "img id in: 19465\n",
      "img id out: 19465\n",
      "img id in: 19466\n",
      "img id out: 19466\n",
      "img id in: 19467\n",
      "img id out: 19467\n",
      "img id in: 19468\n",
      "img id out: 19468\n",
      "img id in: 19469\n",
      "img id out: 19469\n",
      "img id in: 19470\n",
      "img id out: 19470\n",
      "img id in: 19471\n",
      "img id out: 19471\n",
      "img id in: 19472\n",
      "img id out: 19472\n",
      "img id in: 19473\n",
      "img id out: 19473\n",
      "img id in: 19474\n",
      "img id out: 19474\n",
      "img id in: 19475\n",
      "img id out: 19475\n",
      "img id in: 19476\n",
      "img id out: 19476\n",
      "img id in: 19477\n",
      "img id out: 19477\n",
      "img id in: 19478\n",
      "img id out: 19478\n",
      "img id in: 19479\n",
      "img id out: 19479\n",
      "img id in: 19480\n",
      "img id out: 19480\n",
      "img id in: 19481\n",
      "img id out: 19481\n",
      "img id in: 19482\n",
      "img id out: 19482\n",
      "img id in: 19483\n",
      "img id out: 19483\n",
      "img id in: 19484\n",
      "img id out: 19484\n",
      "img id in: 19485\n",
      "img id out: 19485\n",
      "img id in: 19486\n",
      "img id out: 19486\n",
      "img id in: 19487\n",
      "img id out: 19487\n",
      "img id in: 19488\n",
      "img id out: 19488\n",
      "img id in: 19489\n",
      "img id out: 19489\n",
      "img id in: 19490\n",
      "img id out: 19490\n",
      "img id in: 19491\n",
      "img id out: 19491\n",
      "img id in: 19492\n",
      "img id out: 19492\n",
      "img id in: 19493\n",
      "img id out: 19493\n",
      "img id in: 19494\n",
      "img id out: 19494\n",
      "img id in: 19495\n",
      "img id out: 19495\n",
      "img id in: 19496\n",
      "img id out: 19496\n",
      "img id in: 19497\n",
      "img id out: 19497\n",
      "img id in: 19498\n",
      "img id out: 19498\n",
      "img id in: 19499\n",
      "img id out: 19499\n",
      "img id in: 19500\n",
      "img id out: 19500\n",
      "img id in: 19501\n",
      "img id out: 19501\n",
      "img id in: 19502\n",
      "img id out: 19502\n",
      "img id in: 19503\n",
      "img id out: 19503\n",
      "img id in: 19504\n",
      "img id out: 19504\n",
      "img id in: 19505\n",
      "img id out: 19505\n",
      "img id in: 19506\n",
      "img id out: 19506\n",
      "img id in: 19507\n",
      "img id out: 19507\n",
      "img id in: 19508\n",
      "img id out: 19508\n",
      "img id in: 19509\n",
      "img id out: 19509\n",
      "img id in: 19510\n",
      "img id out: 19510\n",
      "img id in: 19511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 19511\n",
      "img id in: 19512\n",
      "img id out: 19512\n",
      "img id in: 19513\n",
      "img id out: 19513\n",
      "img id in: 19514\n",
      "img id out: 19514\n",
      "img id in: 19515\n",
      "img id out: 19515\n",
      "img id in: 19516\n",
      "img id out: 19516\n",
      "img id in: 19517\n",
      "img id out: 19517\n",
      "img id in: 19518\n",
      "img id out: 19518\n",
      "img id in: 19519\n",
      "img id out: 19519\n",
      "img id in: 19520\n",
      "img id out: 19520\n",
      "img id in: 19521\n",
      "img id out: 19521\n",
      "img id in: 19522\n",
      "img id out: 19522\n",
      "img id in: 19523\n",
      "img id out: 19523\n",
      "img id in: 19524\n",
      "img id out: 19524\n",
      "img id in: 19525\n",
      "img id out: 19525\n",
      "img id in: 19526\n",
      "img id out: 19526\n",
      "img id in: 19527\n",
      "img id out: 19527\n",
      "img id in: 19528\n",
      "img id out: 19528\n",
      "img id in: 19529\n",
      "img id out: 19529\n",
      "img id in: 19530\n",
      "img id out: 19530\n",
      "img id in: 19531\n",
      "img id out: 19531\n",
      "img id in: 19532\n",
      "img id out: 19532\n",
      "img id in: 19533\n",
      "img id out: 19533\n",
      "img id in: 19534\n",
      "img id out: 19534\n",
      "img id in: 19535\n",
      "img id out: 19535\n",
      "img id in: 19536\n",
      "img id out: 19536\n",
      "img id in: 19537\n",
      "img id out: 19537\n",
      "img id in: 19538\n",
      "img id out: 19538\n",
      "img id in: 19539\n",
      "img id out: 19539\n",
      "img id in: 19540\n",
      "img id out: 19540\n",
      "img id in: 19541\n",
      "img id out: 19541\n",
      "img id in: 19542\n",
      "img id out: 19542\n",
      "img id in: 19543\n",
      "img id out: 19543\n",
      "img id in: 19544\n",
      "img id out: 19544\n",
      "img id in: 19545\n",
      "img id out: 19545\n",
      "img id in: 19546\n",
      "img id out: 19546\n",
      "img id in: 19547\n",
      "img id out: 19547\n",
      "img id in: 19548\n",
      "img id out: 19548\n",
      "img id in: 19549\n",
      "img id out: 19549\n",
      "img id in: 19550\n",
      "img id out: 19550\n",
      "img id in: 19551\n",
      "img id out: 19551\n",
      "img id in: 19552\n",
      "img id out: 19552\n",
      "img id in: 19553\n",
      "img id out: 19553\n",
      "img id in: 19554\n",
      "img id out: 19554\n",
      "img id in: 19555\n",
      "img id out: 19555\n",
      "img id in: 19556\n",
      "img id out: 19556\n",
      "img id in: 19557\n",
      "img id out: 19557\n",
      "img id in: 19558\n",
      "img id out: 19558\n",
      "img id in: 19559\n",
      "img id out: 19559\n",
      "img id in: 19560\n",
      "img id out: 19560\n",
      "img id in: 19561\n",
      "img id out: 19561\n",
      "img id in: 19562\n",
      "img id out: 19562\n",
      "img id in: 19563\n",
      "img id out: 19563\n",
      "img id in: 19564\n",
      "img id out: 19564\n",
      "img id in: 19565\n",
      "img id out: 19565\n",
      "img id in: 19566\n",
      "img id out: 19566\n",
      "img id in: 19567\n",
      "img id out: 19567\n",
      "img id in: 19568\n",
      "img id out: 19568\n",
      "img id in: 19569\n",
      "img id out: 19569\n",
      "img id in: 19570\n",
      "img id out: 19570\n",
      "img id in: 19571\n",
      "img id out: 19571\n",
      "img id in: 19572\n",
      "img id out: 19572\n",
      "img id in: 19573\n",
      "img id out: 19573\n",
      "img id in: 19574\n",
      "img id out: 19574\n",
      "img id in: 19575\n",
      "img id out: 19575\n",
      "img id in: 19576\n",
      "img id out: 19576\n",
      "img id in: 19577\n",
      "img id out: 19577\n",
      "img id in: 19578\n",
      "img id out: 19578\n",
      "img id in: 19579\n",
      "img id out: 19579\n",
      "img id in: 19580\n",
      "img id out: 19580\n",
      "img id in: 19581\n",
      "img id out: 19581\n",
      "img id in: 19582\n",
      "img id out: 19582\n",
      "img id in: 19583\n",
      "img id out: 19583\n",
      "img id in: 19584\n",
      "img id out: 19584\n",
      "img id in: 19585\n",
      "img id out: 19585\n",
      "img id in: 19586\n",
      "img id out: 19586\n",
      "img id in: 19587\n",
      "img id out: 19587\n",
      "img id in: 19588\n",
      "img id out: 19588\n",
      "img id in: 19589\n",
      "img id out: 19589\n",
      "img id in: 19590\n",
      "img id out: 19590\n",
      "img id in: 19591\n",
      "img id out: 19591\n",
      "img id in: 19592\n",
      "img id out: 19592\n",
      "img id in: 19593\n",
      "img id out: 19593\n",
      "img id in: 19594\n",
      "img id out: 19594\n",
      "img id in: 19595\n",
      "img id out: 19595\n",
      "img id in: 19596\n",
      "img id out: 19596\n",
      "img id in: 19597\n",
      "img id out: 19597\n",
      "img id in: 19598\n",
      "img id out: 19598\n",
      "img id in: 19599\n",
      "img id out: 19599\n",
      "img id in: 19600\n",
      "img id out: 19600\n",
      "img id in: 19601\n",
      "img id out: 19601\n",
      "img id in: 19602\n",
      "img id out: 19602\n",
      "img id in: 19603\n",
      "img id out: 19603\n",
      "img id in: 19604\n",
      "img id out: 19604\n",
      "img id in: 19605\n",
      "img id out: 19605\n",
      "img id in: 19606\n",
      "img id out: 19606\n",
      "img id in: 19607\n",
      "img id out: 19607\n",
      "img id in: 19608\n",
      "img id out: 19608\n",
      "img id in: 19609\n",
      "img id out: 19609\n",
      "img id in: 19610\n",
      "img id out: 19610\n",
      "img id in: 19611\n",
      "img id out: 19611\n",
      "img id in: 19612\n",
      "img id out: 19612\n",
      "img id in: 19613\n",
      "img id out: 19613\n",
      "img id in: 19614\n",
      "img id out: 19614\n",
      "img id in: 19615\n",
      "img id out: 19615\n",
      "img id in: 19616\n",
      "img id out: 19616\n",
      "img id in: 19617\n",
      "img id out: 19617\n",
      "img id in: 19618\n",
      "img id out: 19618\n",
      "img id in: 19619\n",
      "img id out: 19619\n",
      "img id in: 19620\n",
      "img id out: 19620\n",
      "img id in: 19621\n",
      "img id out: 19621\n",
      "img id in: 19622\n",
      "img id out: 19622\n",
      "img id in: 19623\n",
      "img id out: 19623\n",
      "img id in: 19624\n",
      "img id out: 19624\n",
      "img id in: 19625\n",
      "img id out: 19625\n",
      "img id in: 19626\n",
      "img id out: 19626\n",
      "img id in: 19627\n",
      "img id out: 19627\n",
      "img id in: 19628\n",
      "img id out: 19628\n",
      "img id in: 19629\n",
      "img id out: 19629\n",
      "img id in: 19630\n",
      "img id out: 19630\n",
      "img id in: 19631\n",
      "img id out: 19631\n",
      "img id in: 19632\n",
      "img id out: 19632\n",
      "img id in: 19633\n",
      "img id out: 19633\n",
      "img id in: 19634\n",
      "img id out: 19634\n",
      "img id in: 19635\n",
      "img id out: 19635\n",
      "img id in: 19636\n",
      "img id out: 19636\n",
      "img id in: 19637\n",
      "img id out: 19637\n",
      "img id in: 19638\n",
      "img id out: 19638\n",
      "img id in: 19639\n",
      "img id out: 19639\n",
      "img id in: 19640\n",
      "img id out: 19640\n",
      "img id in: 19641\n",
      "img id out: 19641\n",
      "img id in: 19642\n",
      "img id out: 19642\n",
      "img id in: 19643\n",
      "img id out: 19643\n",
      "img id in: 19644\n",
      "img id out: 19644\n",
      "img id in: 19645\n",
      "img id out: 19645\n",
      "img id in: 19646\n",
      "img id out: 19646\n",
      "img id in: 19647\n",
      "img id out: 19647\n",
      "img id in: 19648\n",
      "img id out: 19648\n",
      "img id in: 19649\n",
      "img id out: 19649\n",
      "img id in: 19650\n",
      "img id out: 19650\n",
      "img id in: 19651\n",
      "img id out: 19651\n",
      "img id in: 19652\n",
      "img id out: 19652\n",
      "img id in: 19653\n",
      "img id out: 19653\n",
      "img id in: 19654\n",
      "img id out: 19654\n",
      "img id in: 19655\n",
      "img id out: 19655\n",
      "img id in: 19656\n",
      "img id out: 19656\n",
      "img id in: 19657\n",
      "img id out: 19657\n",
      "img id in: 19658\n",
      "img id out: 19658\n",
      "img id in: 19659\n",
      "img id out: 19659\n",
      "img id in: 19660\n",
      "img id out: 19660\n",
      "img id in: 19661\n",
      "img id out: 19661\n",
      "img id in: 19662\n",
      "img id out: 19662\n",
      "img id in: 19663\n",
      "img id out: 19663\n",
      "img id in: 19664\n",
      "img id out: 19664\n",
      "img id in: 19665\n",
      "img id out: 19665\n",
      "img id in: 19666\n",
      "img id out: 19666\n",
      "img id in: 19667\n",
      "img id out: 19667\n",
      "img id in: 19668\n",
      "img id out: 19668\n",
      "img id in: 19669\n",
      "img id out: 19669\n",
      "img id in: 19670\n",
      "img id out: 19670\n",
      "img id in: 19671\n",
      "img id out: 19671\n",
      "img id in: 19672\n",
      "img id out: 19672\n",
      "img id in: 19673\n",
      "img id out: 19673\n",
      "img id in: 19674\n",
      "img id out: 19674\n",
      "img id in: 19675\n",
      "img id out: 19675\n",
      "img id in: 19676\n",
      "img id out: 19676\n",
      "img id in: 19677\n",
      "img id out: 19677\n",
      "img id in: 19678\n",
      "img id out: 19678\n",
      "img id in: 19679\n",
      "img id out: 19679\n",
      "img id in: 19680\n",
      "img id out: 19680\n",
      "img id in: 19681\n",
      "img id out: 19681\n",
      "img id in: 19682\n",
      "img id out: 19682\n",
      "img id in: 19683\n",
      "img id out: 19683\n",
      "img id in: 19684\n",
      "img id out: 19684\n",
      "img id in: 19685\n",
      "img id out: 19685\n",
      "img id in: 19686\n",
      "img id out: 19686\n",
      "img id in: 19687\n",
      "img id out: 19687\n",
      "img id in: 19688\n",
      "img id out: 19688\n",
      "img id in: 19689\n",
      "img id out: 19689\n",
      "img id in: 19690\n",
      "img id out: 19690\n",
      "img id in: 19691\n",
      "img id out: 19691\n",
      "img id in: 19692\n",
      "img id out: 19692\n",
      "img id in: 19693\n",
      "img id out: 19693\n",
      "img id in: 19694\n",
      "img id out: 19694\n",
      "img id in: 19695\n",
      "img id out: 19695\n",
      "img id in: 19696\n",
      "img id out: 19696\n",
      "img id in: 19697\n",
      "img id out: 19697\n",
      "img id in: 19698\n",
      "img id out: 19698\n",
      "img id in: 19699\n",
      "img id out: 19699\n",
      "img id in: 19700\n",
      "img id out: 19700\n",
      "img id in: 19701\n",
      "img id out: 19701\n",
      "img id in: 19702\n",
      "img id out: 19702\n",
      "img id in: 19703\n",
      "img id out: 19703\n",
      "img id in: 19704\n",
      "img id out: 19704\n",
      "img id in: 19705\n",
      "img id out: 19705\n",
      "img id in: 19706\n",
      "img id out: 19706\n",
      "img id in: 19707\n",
      "img id out: 19707\n",
      "img id in: 19708\n",
      "img id out: 19708\n",
      "img id in: 19709\n",
      "img id out: 19709\n",
      "img id in: 19710\n",
      "img id out: 19710\n",
      "img id in: 19711\n",
      "img id out: 19711\n",
      "img id in: 19712\n",
      "img id out: 19712\n",
      "img id in: 19713\n",
      "img id out: 19713\n",
      "img id in: 19714\n",
      "img id out: 19714\n",
      "img id in: 19715\n",
      "img id out: 19715\n",
      "img id in: 19716\n",
      "img id out: 19716\n",
      "img id in: 19717\n",
      "img id out: 19717\n",
      "img id in: 19718\n",
      "img id out: 19718\n",
      "img id in: 19719\n",
      "img id out: 19719\n",
      "img id in: 19720\n",
      "img id out: 19720\n",
      "img id in: 19721\n",
      "img id out: 19721\n",
      "img id in: 19722\n",
      "img id out: 19722\n",
      "img id in: 19723\n",
      "img id out: 19723\n",
      "img id in: 19724\n",
      "img id out: 19724\n",
      "img id in: 19725\n",
      "img id out: 19725\n",
      "img id in: 19726\n",
      "img id out: 19726\n",
      "img id in: 19727\n",
      "img id out: 19727\n",
      "img id in: 19728\n",
      "img id out: 19728\n",
      "img id in: 19729\n",
      "img id out: 19729\n",
      "img id in: 19730\n",
      "img id out: 19730\n",
      "img id in: 19731\n",
      "img id out: 19731\n",
      "img id in: 19732\n",
      "img id out: 19732\n",
      "img id in: 19733\n",
      "img id out: 19733\n",
      "img id in: 19734\n",
      "img id out: 19734\n",
      "img id in: 19735\n",
      "img id out: 19735\n",
      "img id in: 19736\n",
      "img id out: 19736\n",
      "img id in: 19737\n",
      "img id out: 19737\n",
      "img id in: 19738\n",
      "img id out: 19738\n",
      "img id in: 19739\n",
      "img id out: 19739\n",
      "img id in: 19740\n",
      "img id out: 19740\n",
      "img id in: 19741\n",
      "img id out: 19741\n",
      "img id in: 19742\n",
      "img id out: 19742\n",
      "img id in: 19743\n",
      "img id out: 19743\n",
      "img id in: 19744\n",
      "img id out: 19744\n",
      "img id in: 19745\n",
      "img id out: 19745\n",
      "img id in: 19746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 19746\n",
      "img id in: 19747\n",
      "img id out: 19747\n",
      "img id in: 19748\n",
      "img id out: 19748\n",
      "img id in: 19749\n",
      "img id out: 19749\n",
      "img id in: 19750\n",
      "img id out: 19750\n",
      "img id in: 19751\n",
      "img id out: 19751\n",
      "img id in: 19752\n",
      "img id out: 19752\n",
      "img id in: 19753\n",
      "img id out: 19753\n",
      "img id in: 19754\n",
      "img id out: 19754\n",
      "img id in: 19755\n",
      "img id out: 19755\n",
      "img id in: 19756\n",
      "img id out: 19756\n",
      "img id in: 19757\n",
      "img id out: 19757\n",
      "img id in: 19758\n",
      "img id out: 19758\n",
      "img id in: 19759\n",
      "img id out: 19759\n",
      "img id in: 19760\n",
      "img id out: 19760\n",
      "img id in: 19761\n",
      "img id out: 19761\n",
      "img id in: 19762\n",
      "img id out: 19762\n",
      "img id in: 19763\n",
      "img id out: 19763\n",
      "img id in: 19764\n",
      "img id out: 19764\n",
      "img id in: 19765\n",
      "img id out: 19765\n",
      "img id in: 19766\n",
      "img id out: 19766\n",
      "img id in: 19767\n",
      "img id out: 19767\n",
      "img id in: 19768\n",
      "img id out: 19768\n",
      "img id in: 19769\n",
      "img id out: 19769\n",
      "img id in: 19770\n",
      "img id out: 19770\n",
      "img id in: 19771\n",
      "img id out: 19771\n",
      "img id in: 19772\n",
      "img id out: 19772\n",
      "img id in: 19773\n",
      "img id out: 19773\n",
      "img id in: 19774\n",
      "img id out: 19774\n",
      "img id in: 19775\n",
      "img id out: 19775\n",
      "img id in: 19776\n",
      "img id out: 19776\n",
      "img id in: 19777\n",
      "img id out: 19777\n",
      "img id in: 19778\n",
      "img id out: 19778\n",
      "img id in: 19779\n",
      "img id out: 19779\n",
      "img id in: 19780\n",
      "img id out: 19780\n",
      "img id in: 19781\n",
      "img id out: 19781\n",
      "img id in: 19782\n",
      "img id out: 19782\n",
      "img id in: 19783\n",
      "img id out: 19783\n",
      "img id in: 19784\n",
      "img id out: 19784\n",
      "img id in: 19785\n",
      "img id out: 19785\n",
      "img id in: 19786\n",
      "img id out: 19786\n",
      "img id in: 19787\n",
      "img id out: 19787\n",
      "img id in: 19788\n",
      "img id out: 19788\n",
      "img id in: 19789\n",
      "img id out: 19789\n",
      "img id in: 19790\n",
      "img id out: 19790\n",
      "img id in: 19791\n",
      "img id out: 19791\n",
      "img id in: 19792\n",
      "img id out: 19792\n",
      "img id in: 19793\n",
      "img id out: 19793\n",
      "img id in: 19794\n",
      "img id out: 19794\n",
      "img id in: 19795\n",
      "img id out: 19795\n",
      "img id in: 19796\n",
      "img id out: 19796\n",
      "img id in: 19797\n",
      "img id out: 19797\n",
      "img id in: 19798\n",
      "img id out: 19798\n",
      "img id in: 19799\n",
      "img id out: 19799\n",
      "img id in: 19800\n",
      "img id out: 19800\n",
      "img id in: 19801\n",
      "img id out: 19801\n",
      "img id in: 19802\n",
      "img id out: 19802\n",
      "img id in: 19803\n",
      "img id out: 19803\n",
      "img id in: 19804\n",
      "img id out: 19804\n",
      "img id in: 19805\n",
      "img id out: 19805\n",
      "img id in: 19806\n",
      "img id out: 19806\n",
      "img id in: 19807\n",
      "img id out: 19807\n",
      "img id in: 19808\n",
      "img id out: 19808\n",
      "img id in: 19809\n",
      "img id out: 19809\n",
      "img id in: 19810\n",
      "img id out: 19810\n",
      "img id in: 19811\n",
      "img id out: 19811\n",
      "img id in: 19812\n",
      "img id out: 19812\n",
      "img id in: 19813\n",
      "img id out: 19813\n",
      "img id in: 19814\n",
      "img id out: 19814\n",
      "img id in: 19815\n",
      "img id out: 19815\n",
      "img id in: 19816\n",
      "img id out: 19816\n",
      "img id in: 19817\n",
      "img id out: 19817\n",
      "img id in: 19818\n",
      "img id out: 19818\n",
      "img id in: 19819\n",
      "img id out: 19819\n",
      "img id in: 19820\n",
      "img id out: 19820\n",
      "img id in: 19821\n",
      "img id out: 19821\n",
      "img id in: 19822\n",
      "img id out: 19822\n",
      "img id in: 19823\n",
      "img id out: 19823\n",
      "img id in: 19824\n",
      "img id out: 19824\n",
      "img id in: 19825\n",
      "img id out: 19825\n",
      "img id in: 19826\n",
      "img id out: 19826\n",
      "img id in: 19827\n",
      "img id out: 19827\n",
      "img id in: 19828\n",
      "img id out: 19828\n",
      "img id in: 19829\n",
      "img id out: 19829\n",
      "img id in: 19830\n",
      "img id out: 19830\n",
      "img id in: 19831\n",
      "img id out: 19831\n",
      "img id in: 19832\n",
      "img id out: 19832\n",
      "img id in: 19833\n",
      "img id out: 19833\n",
      "img id in: 19834\n",
      "img id out: 19834\n",
      "img id in: 19835\n",
      "img id out: 19835\n",
      "img id in: 19836\n",
      "img id out: 19836\n",
      "img id in: 19837\n",
      "img id out: 19837\n",
      "img id in: 19838\n",
      "img id out: 19838\n",
      "img id in: 19839\n",
      "img id out: 19839\n",
      "img id in: 19840\n",
      "img id out: 19840\n",
      "img id in: 19841\n",
      "img id out: 19841\n",
      "img id in: 19842\n",
      "img id out: 19842\n",
      "img id in: 19843\n",
      "img id out: 19843\n",
      "img id in: 19844\n",
      "img id out: 19844\n",
      "img id in: 19845\n",
      "img id out: 19845\n",
      "img id in: 19846\n",
      "img id out: 19846\n",
      "img id in: 19847\n",
      "img id out: 19847\n",
      "img id in: 19848\n",
      "img id out: 19848\n",
      "img id in: 19849\n",
      "img id out: 19849\n",
      "img id in: 19850\n",
      "img id out: 19850\n",
      "img id in: 19851\n",
      "img id out: 19851\n",
      "img id in: 19852\n",
      "img id out: 19852\n",
      "img id in: 19853\n",
      "img id out: 19853\n",
      "img id in: 19854\n",
      "img id out: 19854\n",
      "img id in: 19855\n",
      "img id out: 19855\n",
      "img id in: 19856\n",
      "img id out: 19856\n",
      "img id in: 19857\n",
      "img id out: 19857\n",
      "img id in: 19858\n",
      "img id out: 19858\n",
      "img id in: 19859\n",
      "img id out: 19859\n",
      "img id in: 19860\n",
      "img id out: 19860\n",
      "img id in: 19861\n",
      "img id out: 19861\n",
      "img id in: 19862\n",
      "img id out: 19862\n",
      "img id in: 19863\n",
      "img id out: 19863\n",
      "img id in: 19864\n",
      "img id out: 19864\n",
      "img id in: 19865\n",
      "img id out: 19865\n",
      "img id in: 19866\n",
      "img id out: 19866\n",
      "img id in: 19867\n",
      "img id out: 19867\n",
      "img id in: 19868\n",
      "img id out: 19868\n",
      "img id in: 19869\n",
      "img id out: 19869\n",
      "img id in: 19870\n",
      "img id out: 19870\n",
      "img id in: 19871\n",
      "img id out: 19871\n",
      "img id in: 19872\n",
      "img id out: 19872\n",
      "img id in: 19873\n",
      "img id out: 19873\n",
      "img id in: 19874\n",
      "img id out: 19874\n",
      "img id in: 19875\n",
      "img id out: 19875\n",
      "img id in: 19876\n",
      "img id out: 19876\n",
      "img id in: 19877\n",
      "img id out: 19877\n",
      "img id in: 19878\n",
      "img id out: 19878\n",
      "img id in: 19879\n",
      "img id out: 19879\n",
      "img id in: 19880\n",
      "img id out: 19880\n",
      "img id in: 19881\n",
      "img id out: 19881\n",
      "img id in: 19882\n",
      "img id out: 19882\n",
      "img id in: 19883\n",
      "img id out: 19883\n",
      "img id in: 19884\n",
      "img id out: 19884\n",
      "img id in: 19885\n",
      "img id out: 19885\n",
      "img id in: 19886\n",
      "img id out: 19886\n",
      "img id in: 19887\n",
      "img id out: 19887\n",
      "img id in: 19888\n",
      "img id out: 19888\n",
      "img id in: 19889\n",
      "img id out: 19889\n",
      "img id in: 19890\n",
      "img id out: 19890\n",
      "img id in: 19891\n",
      "img id out: 19891\n",
      "img id in: 19892\n",
      "img id out: 19892\n",
      "img id in: 19893\n",
      "img id out: 19893\n",
      "img id in: 19894\n",
      "img id out: 19894\n",
      "img id in: 19895\n",
      "img id out: 19895\n",
      "img id in: 19896\n",
      "img id out: 19896\n",
      "img id in: 19897\n",
      "img id out: 19897\n",
      "img id in: 19898\n",
      "img id out: 19898\n",
      "img id in: 19899\n",
      "img id out: 19899\n",
      "img id in: 19900\n",
      "img id out: 19900\n",
      "img id in: 19901\n",
      "img id out: 19901\n",
      "img id in: 19902\n",
      "img id out: 19902\n",
      "img id in: 19903\n",
      "img id out: 19903\n",
      "img id in: 19904\n",
      "img id out: 19904\n",
      "img id in: 19905\n",
      "img id out: 19905\n",
      "img id in: 19906\n",
      "img id out: 19906\n",
      "img id in: 19907\n",
      "img id out: 19907\n",
      "img id in: 19908\n",
      "img id out: 19908\n",
      "img id in: 19909\n",
      "img id out: 19909\n",
      "img id in: 19910\n",
      "img id out: 19910\n",
      "img id in: 19911\n",
      "img id out: 19911\n",
      "img id in: 19912\n",
      "img id out: 19912\n",
      "img id in: 19913\n",
      "img id out: 19913\n",
      "img id in: 19914\n",
      "img id out: 19914\n",
      "img id in: 19915\n",
      "img id out: 19915\n",
      "img id in: 19916\n",
      "img id out: 19916\n",
      "img id in: 19917\n",
      "img id out: 19917\n",
      "img id in: 19918\n",
      "img id out: 19918\n",
      "img id in: 19919\n",
      "img id out: 19919\n",
      "img id in: 19920\n",
      "img id out: 19920\n",
      "img id in: 19921\n",
      "img id out: 19921\n",
      "img id in: 19922\n",
      "img id out: 19922\n",
      "img id in: 19923\n",
      "img id out: 19923\n",
      "img id in: 19924\n",
      "img id out: 19924\n",
      "img id in: 19925\n",
      "img id out: 19925\n",
      "img id in: 19926\n",
      "img id out: 19926\n",
      "img id in: 19927\n",
      "img id out: 19927\n",
      "img id in: 19928\n",
      "img id out: 19928\n",
      "img id in: 19929\n",
      "img id out: 19929\n",
      "img id in: 19930\n",
      "img id out: 19930\n",
      "img id in: 19931\n",
      "img id out: 19931\n",
      "img id in: 19932\n",
      "img id out: 19932\n",
      "img id in: 19933\n",
      "img id out: 19933\n",
      "img id in: 19934\n",
      "img id out: 19934\n",
      "img id in: 19935\n",
      "img id out: 19935\n",
      "img id in: 19936\n",
      "img id out: 19936\n",
      "img id in: 19937\n",
      "img id out: 19937\n",
      "img id in: 19938\n",
      "img id out: 19938\n",
      "img id in: 19939\n",
      "img id out: 19939\n",
      "img id in: 19940\n",
      "img id out: 19940\n",
      "img id in: 19941\n",
      "img id out: 19941\n",
      "img id in: 19942\n",
      "img id out: 19942\n",
      "img id in: 19943\n",
      "img id out: 19943\n",
      "img id in: 19944\n",
      "img id out: 19944\n",
      "img id in: 19945\n",
      "img id out: 19945\n",
      "img id in: 19946\n",
      "img id out: 19946\n",
      "img id in: 19947\n",
      "img id out: 19947\n",
      "img id in: 19948\n",
      "img id out: 19948\n",
      "img id in: 19949\n",
      "img id out: 19949\n",
      "img id in: 19950\n",
      "img id out: 19950\n",
      "img id in: 19951\n",
      "img id out: 19951\n",
      "img id in: 19952\n",
      "img id out: 19952\n",
      "img id in: 19953\n",
      "img id out: 19953\n",
      "img id in: 19954\n",
      "img id out: 19954\n",
      "img id in: 19955\n",
      "img id out: 19955\n",
      "img id in: 19956\n",
      "img id out: 19956\n",
      "img id in: 19957\n",
      "img id out: 19957\n",
      "img id in: 19958\n",
      "img id out: 19958\n",
      "img id in: 19959\n",
      "img id out: 19959\n",
      "img id in: 19960\n",
      "img id out: 19960\n",
      "img id in: 19961\n",
      "img id out: 19961\n",
      "img id in: 19962\n",
      "img id out: 19962\n",
      "img id in: 19963\n",
      "img id out: 19963\n",
      "img id in: 19964\n",
      "img id out: 19964\n",
      "img id in: 19965\n",
      "img id out: 19965\n",
      "img id in: 19966\n",
      "img id out: 19966\n",
      "img id in: 19967\n",
      "img id out: 19967\n",
      "img id in: 19968\n",
      "img id out: 19968\n",
      "img id in: 19969\n",
      "img id out: 19969\n",
      "img id in: 19970\n",
      "img id out: 19970\n",
      "img id in: 19971\n",
      "img id out: 19971\n",
      "img id in: 19972\n",
      "img id out: 19972\n",
      "img id in: 19973\n",
      "img id out: 19973\n",
      "img id in: 19974\n",
      "img id out: 19974\n",
      "img id in: 19975\n",
      "img id out: 19975\n",
      "img id in: 19976\n",
      "img id out: 19976\n",
      "img id in: 19977\n",
      "img id out: 19977\n",
      "img id in: 19978\n",
      "img id out: 19978\n",
      "img id in: 19979\n",
      "img id out: 19979\n",
      "img id in: 19980\n",
      "img id out: 19980\n",
      "img id in: 19981\n",
      "img id out: 19981\n",
      "img id in: 19982\n",
      "img id out: 19982\n",
      "img id in: 19983\n",
      "img id out: 19983\n",
      "img id in: 19984\n",
      "img id out: 19984\n",
      "img id in: 19985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 19985\n",
      "img id in: 19986\n",
      "img id out: 19986\n",
      "img id in: 19987\n",
      "img id out: 19987\n",
      "img id in: 19988\n",
      "img id out: 19988\n",
      "img id in: 19989\n",
      "img id out: 19989\n",
      "img id in: 19990\n",
      "img id out: 19990\n",
      "img id in: 19991\n",
      "img id out: 19991\n",
      "img id in: 19992\n",
      "img id out: 19992\n",
      "img id in: 19993\n",
      "img id out: 19993\n",
      "img id in: 19994\n",
      "img id out: 19994\n",
      "img id in: 19995\n",
      "img id out: 19995\n",
      "img id in: 19996\n",
      "img id out: 19996\n",
      "img id in: 19997\n",
      "img id out: 19997\n",
      "img id in: 19998\n",
      "img id out: 19998\n",
      "img id in: 19999\n",
      "img id out: 19999\n",
      "img id in: 20000\n",
      "img id out: 20000\n",
      "img id in: 20001\n",
      "img id out: 20001\n",
      "img id in: 20002\n",
      "img id out: 20002\n",
      "img id in: 20003\n",
      "img id out: 20003\n",
      "img id in: 20004\n",
      "img id out: 20004\n",
      "img id in: 20005\n",
      "img id out: 20005\n",
      "img id in: 20006\n",
      "img id out: 20006\n",
      "img id in: 20007\n",
      "img id out: 20007\n",
      "img id in: 20008\n",
      "img id out: 20008\n",
      "img id in: 20009\n",
      "img id out: 20009\n",
      "img id in: 20010\n",
      "img id out: 20010\n",
      "img id in: 20011\n",
      "img id out: 20011\n",
      "img id in: 20012\n",
      "img id out: 20012\n",
      "img id in: 20013\n",
      "img id out: 20013\n",
      "img id in: 20014\n",
      "img id out: 20014\n",
      "img id in: 20015\n",
      "img id out: 20015\n",
      "img id in: 20016\n",
      "img id out: 20016\n",
      "img id in: 20017\n",
      "img id out: 20017\n",
      "img id in: 20018\n",
      "img id out: 20018\n",
      "img id in: 20019\n",
      "img id out: 20019\n",
      "img id in: 20020\n",
      "img id out: 20020\n",
      "img id in: 20021\n",
      "img id out: 20021\n",
      "img id in: 20022\n",
      "img id out: 20022\n",
      "img id in: 20023\n",
      "img id out: 20023\n",
      "img id in: 20024\n",
      "img id out: 20024\n",
      "img id in: 20025\n",
      "img id out: 20025\n",
      "img id in: 20026\n",
      "img id out: 20026\n",
      "img id in: 20027\n",
      "img id out: 20027\n",
      "img id in: 20028\n",
      "img id out: 20028\n",
      "img id in: 20029\n",
      "img id out: 20029\n",
      "img id in: 20030\n",
      "img id out: 20030\n",
      "img id in: 20031\n",
      "img id out: 20031\n",
      "img id in: 20032\n",
      "img id out: 20032\n",
      "img id in: 20033\n",
      "img id out: 20033\n",
      "img id in: 20034\n",
      "img id out: 20034\n",
      "img id in: 20035\n",
      "img id out: 20035\n",
      "img id in: 20036\n",
      "img id out: 20036\n",
      "img id in: 20037\n",
      "img id out: 20037\n",
      "img id in: 20038\n",
      "img id out: 20038\n",
      "img id in: 20039\n",
      "img id out: 20039\n",
      "img id in: 20040\n",
      "img id out: 20040\n",
      "img id in: 20041\n",
      "img id out: 20041\n",
      "img id in: 20042\n",
      "img id out: 20042\n",
      "img id in: 20043\n",
      "img id out: 20043\n",
      "img id in: 20044\n",
      "img id out: 20044\n",
      "img id in: 20045\n",
      "img id out: 20045\n",
      "img id in: 20046\n",
      "img id out: 20046\n",
      "img id in: 20047\n",
      "img id out: 20047\n",
      "img id in: 20048\n",
      "img id out: 20048\n",
      "img id in: 20049\n",
      "img id out: 20049\n",
      "img id in: 20050\n",
      "img id out: 20050\n",
      "img id in: 20051\n",
      "img id out: 20051\n",
      "img id in: 20052\n",
      "img id out: 20052\n",
      "img id in: 20053\n",
      "img id out: 20053\n",
      "img id in: 20054\n",
      "img id out: 20054\n",
      "img id in: 20055\n",
      "img id out: 20055\n",
      "img id in: 20056\n",
      "img id out: 20056\n",
      "img id in: 20057\n",
      "img id out: 20057\n",
      "img id in: 20058\n",
      "img id out: 20058\n",
      "img id in: 20059\n",
      "img id out: 20059\n",
      "img id in: 20060\n",
      "img id out: 20060\n",
      "img id in: 20061\n",
      "img id out: 20061\n",
      "img id in: 20062\n",
      "img id out: 20062\n",
      "img id in: 20063\n",
      "img id out: 20063\n",
      "img id in: 20064\n",
      "img id out: 20064\n",
      "img id in: 20065\n",
      "img id out: 20065\n",
      "img id in: 20066\n",
      "img id out: 20066\n",
      "img id in: 20067\n",
      "img id out: 20067\n",
      "img id in: 20068\n",
      "img id out: 20068\n",
      "img id in: 20069\n",
      "img id out: 20069\n",
      "img id in: 20070\n",
      "img id out: 20070\n",
      "img id in: 20071\n",
      "img id out: 20071\n",
      "img id in: 20072\n",
      "img id out: 20072\n",
      "img id in: 20073\n",
      "img id out: 20073\n",
      "img id in: 20074\n",
      "img id out: 20074\n",
      "img id in: 20075\n",
      "img id out: 20075\n",
      "img id in: 20076\n",
      "img id out: 20076\n",
      "img id in: 20077\n",
      "img id out: 20077\n",
      "img id in: 20078\n",
      "img id out: 20078\n",
      "img id in: 20079\n",
      "img id out: 20079\n",
      "img id in: 20080\n",
      "img id out: 20080\n",
      "img id in: 20081\n",
      "img id out: 20081\n",
      "img id in: 20082\n",
      "img id out: 20082\n",
      "img id in: 20083\n",
      "img id out: 20083\n",
      "img id in: 20084\n",
      "img id out: 20084\n",
      "img id in: 20085\n",
      "img id out: 20085\n",
      "img id in: 20086\n",
      "img id out: 20086\n",
      "img id in: 20087\n",
      "img id out: 20087\n",
      "img id in: 20088\n",
      "img id out: 20088\n",
      "img id in: 20089\n",
      "img id out: 20089\n",
      "img id in: 20090\n",
      "img id out: 20090\n",
      "img id in: 20091\n",
      "img id out: 20091\n",
      "img id in: 20092\n",
      "img id out: 20092\n",
      "img id in: 20093\n",
      "img id out: 20093\n",
      "img id in: 20094\n",
      "img id out: 20094\n",
      "img id in: 20095\n",
      "img id out: 20095\n",
      "img id in: 20096\n",
      "img id out: 20096\n",
      "img id in: 20097\n",
      "img id out: 20097\n",
      "img id in: 20098\n",
      "img id out: 20098\n",
      "img id in: 20099\n",
      "img id out: 20099\n",
      "img id in: 20100\n",
      "img id out: 20100\n",
      "img id in: 20101\n",
      "img id out: 20101\n",
      "img id in: 20102\n",
      "img id out: 20102\n",
      "img id in: 20103\n",
      "img id out: 20103\n",
      "img id in: 20104\n",
      "img id out: 20104\n",
      "img id in: 20105\n",
      "img id out: 20105\n",
      "img id in: 20106\n",
      "img id out: 20106\n",
      "img id in: 20107\n",
      "img id out: 20107\n",
      "img id in: 20108\n",
      "img id out: 20108\n",
      "img id in: 20109\n",
      "img id out: 20109\n",
      "img id in: 20110\n",
      "img id out: 20110\n",
      "img id in: 20111\n",
      "img id out: 20111\n",
      "img id in: 20112\n",
      "img id out: 20112\n",
      "img id in: 20113\n",
      "img id out: 20113\n",
      "img id in: 20114\n",
      "img id out: 20114\n",
      "img id in: 20115\n",
      "img id out: 20115\n",
      "img id in: 20116\n",
      "img id out: 20116\n",
      "img id in: 20117\n",
      "img id out: 20117\n",
      "img id in: 20118\n",
      "img id out: 20118\n",
      "img id in: 20119\n",
      "img id out: 20119\n",
      "img id in: 20120\n",
      "img id out: 20120\n",
      "img id in: 20121\n",
      "img id out: 20121\n",
      "img id in: 20122\n",
      "img id out: 20122\n",
      "img id in: 20123\n",
      "img id out: 20123\n",
      "img id in: 20124\n",
      "img id out: 20124\n",
      "img id in: 20125\n",
      "img id out: 20125\n",
      "img id in: 20126\n",
      "img id out: 20126\n",
      "img id in: 20127\n",
      "img id out: 20127\n",
      "img id in: 20128\n",
      "img id out: 20128\n",
      "img id in: 20129\n",
      "img id out: 20129\n",
      "img id in: 20130\n",
      "img id out: 20130\n",
      "img id in: 20131\n",
      "img id out: 20131\n",
      "img id in: 20132\n",
      "img id out: 20132\n",
      "img id in: 20133\n",
      "img id out: 20133\n",
      "img id in: 20134\n",
      "img id out: 20134\n",
      "img id in: 20135\n",
      "img id out: 20135\n",
      "img id in: 20136\n",
      "img id out: 20136\n",
      "img id in: 20137\n",
      "img id out: 20137\n",
      "img id in: 20138\n",
      "img id out: 20138\n",
      "img id in: 20139\n",
      "img id out: 20139\n",
      "img id in: 20140\n",
      "img id out: 20140\n",
      "img id in: 20141\n",
      "img id out: 20141\n",
      "img id in: 20142\n",
      "img id out: 20142\n",
      "img id in: 20143\n",
      "img id out: 20143\n",
      "img id in: 20144\n",
      "img id out: 20144\n",
      "img id in: 20145\n",
      "img id out: 20145\n",
      "img id in: 20146\n",
      "img id out: 20146\n",
      "img id in: 20147\n",
      "img id out: 20147\n",
      "img id in: 20148\n",
      "img id out: 20148\n",
      "img id in: 20149\n",
      "img id out: 20149\n",
      "img id in: 20150\n",
      "img id out: 20150\n",
      "img id in: 20151\n",
      "img id out: 20151\n",
      "img id in: 20152\n",
      "img id out: 20152\n",
      "img id in: 20153\n",
      "img id out: 20153\n",
      "img id in: 20154\n",
      "img id out: 20154\n",
      "img id in: 20155\n",
      "img id out: 20155\n",
      "img id in: 20156\n",
      "img id out: 20156\n",
      "img id in: 20157\n",
      "img id out: 20157\n",
      "img id in: 20158\n",
      "img id out: 20158\n",
      "img id in: 20159\n",
      "img id out: 20159\n",
      "img id in: 20160\n",
      "img id out: 20160\n",
      "img id in: 20161\n",
      "img id out: 20161\n",
      "img id in: 20162\n",
      "img id out: 20162\n",
      "img id in: 20163\n",
      "img id out: 20163\n",
      "img id in: 20164\n",
      "img id out: 20164\n",
      "img id in: 20165\n",
      "img id out: 20165\n",
      "img id in: 20166\n",
      "img id out: 20166\n",
      "img id in: 20167\n",
      "img id out: 20167\n",
      "img id in: 20168\n",
      "img id out: 20168\n",
      "img id in: 20169\n",
      "img id out: 20169\n",
      "img id in: 20170\n",
      "img id out: 20170\n",
      "img id in: 20171\n",
      "img id out: 20171\n",
      "img id in: 20172\n",
      "img id out: 20172\n",
      "img id in: 20173\n",
      "img id out: 20173\n",
      "img id in: 20174\n",
      "img id out: 20174\n",
      "img id in: 20175\n",
      "img id out: 20175\n",
      "img id in: 20176\n",
      "img id out: 20176\n",
      "img id in: 20177\n",
      "img id out: 20177\n",
      "img id in: 20178\n",
      "img id out: 20178\n",
      "img id in: 20179\n",
      "img id out: 20179\n",
      "img id in: 20180\n",
      "img id out: 20180\n",
      "img id in: 20181\n",
      "img id out: 20181\n",
      "img id in: 20182\n",
      "img id out: 20182\n",
      "img id in: 20183\n",
      "img id out: 20183\n",
      "img id in: 20184\n",
      "img id out: 20184\n",
      "img id in: 20185\n",
      "img id out: 20185\n",
      "img id in: 20186\n",
      "img id out: 20186\n",
      "img id in: 20187\n",
      "img id out: 20187\n",
      "img id in: 20188\n",
      "img id out: 20188\n",
      "img id in: 20189\n",
      "img id out: 20189\n",
      "img id in: 20190\n",
      "img id out: 20190\n",
      "img id in: 20191\n",
      "img id out: 20191\n",
      "img id in: 20192\n",
      "img id out: 20192\n",
      "img id in: 20193\n",
      "img id out: 20193\n",
      "img id in: 20194\n",
      "img id out: 20194\n",
      "img id in: 20195\n",
      "img id out: 20195\n",
      "img id in: 20196\n",
      "img id out: 20196\n",
      "img id in: 20197\n",
      "img id out: 20197\n",
      "img id in: 20198\n",
      "img id out: 20198\n",
      "img id in: 20199\n",
      "img id out: 20199\n",
      "img id in: 20200\n",
      "img id out: 20200\n",
      "img id in: 20201\n",
      "img id out: 20201\n",
      "img id in: 20202\n",
      "img id out: 20202\n",
      "img id in: 20203\n",
      "img id out: 20203\n",
      "img id in: 20204\n",
      "img id out: 20204\n",
      "img id in: 20205\n",
      "img id out: 20205\n",
      "img id in: 20206\n",
      "img id out: 20206\n",
      "img id in: 20207\n",
      "img id out: 20207\n",
      "img id in: 20208\n",
      "img id out: 20208\n",
      "img id in: 20209\n",
      "img id out: 20209\n",
      "img id in: 20210\n",
      "img id out: 20210\n",
      "img id in: 20211\n",
      "img id out: 20211\n",
      "img id in: 20212\n",
      "img id out: 20212\n",
      "img id in: 20213\n",
      "img id out: 20213\n",
      "img id in: 20214\n",
      "img id out: 20214\n",
      "img id in: 20215\n",
      "img id out: 20215\n",
      "img id in: 20216\n",
      "img id out: 20216\n",
      "img id in: 20217\n",
      "img id out: 20217\n",
      "img id in: 20218\n",
      "img id out: 20218\n",
      "img id in: 20219\n",
      "img id out: 20219\n",
      "img id in: 20220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 20220\n",
      "img id in: 20221\n",
      "img id out: 20221\n",
      "img id in: 20222\n",
      "img id out: 20222\n",
      "img id in: 20223\n",
      "img id out: 20223\n",
      "img id in: 20224\n",
      "img id out: 20224\n",
      "img id in: 20225\n",
      "img id out: 20225\n",
      "img id in: 20226\n",
      "img id out: 20226\n",
      "img id in: 20227\n",
      "img id out: 20227\n",
      "img id in: 20228\n",
      "img id out: 20228\n",
      "img id in: 20229\n",
      "img id out: 20229\n",
      "img id in: 20230\n",
      "img id out: 20230\n",
      "img id in: 20231\n",
      "img id out: 20231\n",
      "img id in: 20232\n",
      "img id out: 20232\n",
      "img id in: 20233\n",
      "img id out: 20233\n",
      "img id in: 20234\n",
      "img id out: 20234\n",
      "img id in: 20235\n",
      "img id out: 20235\n",
      "img id in: 20236\n",
      "img id out: 20236\n",
      "img id in: 20237\n",
      "img id out: 20237\n",
      "img id in: 20238\n",
      "img id out: 20238\n",
      "img id in: 20239\n",
      "img id out: 20239\n",
      "img id in: 20240\n",
      "img id out: 20240\n",
      "img id in: 20241\n",
      "img id out: 20241\n",
      "img id in: 20242\n",
      "img id out: 20242\n",
      "img id in: 20243\n",
      "img id out: 20243\n",
      "img id in: 20244\n",
      "img id out: 20244\n",
      "img id in: 20245\n",
      "img id out: 20245\n",
      "img id in: 20246\n",
      "img id out: 20246\n",
      "img id in: 20247\n",
      "img id out: 20247\n",
      "img id in: 20248\n",
      "img id out: 20248\n",
      "img id in: 20249\n",
      "img id out: 20249\n",
      "img id in: 20250\n",
      "img id out: 20250\n",
      "img id in: 20251\n",
      "img id out: 20251\n",
      "img id in: 20252\n",
      "img id out: 20252\n",
      "img id in: 20253\n",
      "img id out: 20253\n",
      "img id in: 20254\n",
      "img id out: 20254\n",
      "img id in: 20255\n",
      "img id out: 20255\n",
      "img id in: 20256\n",
      "img id out: 20256\n",
      "img id in: 20257\n",
      "img id out: 20257\n",
      "img id in: 20258\n",
      "img id out: 20258\n",
      "img id in: 20259\n",
      "img id out: 20259\n",
      "img id in: 20260\n",
      "img id out: 20260\n",
      "img id in: 20261\n",
      "img id out: 20261\n",
      "img id in: 20262\n",
      "img id out: 20262\n",
      "img id in: 20263\n",
      "img id out: 20263\n",
      "img id in: 20264\n",
      "img id out: 20264\n",
      "img id in: 20265\n",
      "img id out: 20265\n",
      "img id in: 20266\n",
      "img id out: 20266\n",
      "img id in: 20267\n",
      "img id out: 20267\n",
      "img id in: 20268\n",
      "img id out: 20268\n",
      "img id in: 20269\n",
      "img id out: 20269\n",
      "img id in: 20270\n",
      "img id out: 20270\n",
      "img id in: 20271\n",
      "img id out: 20271\n",
      "img id in: 20272\n",
      "img id out: 20272\n",
      "img id in: 20273\n",
      "img id out: 20273\n",
      "img id in: 20274\n",
      "img id out: 20274\n",
      "img id in: 20275\n",
      "img id out: 20275\n",
      "img id in: 20276\n",
      "img id out: 20276\n",
      "img id in: 20277\n",
      "img id out: 20277\n",
      "img id in: 20278\n",
      "img id out: 20278\n",
      "img id in: 20279\n",
      "img id out: 20279\n",
      "img id in: 20280\n",
      "img id out: 20280\n",
      "img id in: 20281\n",
      "img id out: 20281\n",
      "img id in: 20282\n",
      "img id out: 20282\n",
      "img id in: 20283\n",
      "img id out: 20283\n",
      "img id in: 20284\n",
      "img id out: 20284\n",
      "img id in: 20285\n",
      "img id out: 20285\n",
      "img id in: 20286\n",
      "img id out: 20286\n",
      "img id in: 20287\n",
      "img id out: 20287\n",
      "img id in: 20288\n",
      "img id out: 20288\n",
      "img id in: 20289\n",
      "img id out: 20289\n",
      "img id in: 20290\n",
      "img id out: 20290\n",
      "img id in: 20291\n",
      "img id out: 20291\n",
      "img id in: 20292\n",
      "img id out: 20292\n",
      "img id in: 20293\n",
      "img id out: 20293\n",
      "img id in: 20294\n",
      "img id out: 20294\n",
      "img id in: 20295\n",
      "img id out: 20295\n",
      "img id in: 20296\n",
      "img id out: 20296\n",
      "img id in: 20297\n",
      "img id out: 20297\n",
      "img id in: 20298\n",
      "img id out: 20298\n",
      "img id in: 20299\n",
      "img id out: 20299\n",
      "img id in: 20300\n",
      "img id out: 20300\n",
      "img id in: 20301\n",
      "img id out: 20301\n",
      "img id in: 20302\n",
      "img id out: 20302\n",
      "img id in: 20303\n",
      "img id out: 20303\n",
      "img id in: 20304\n",
      "img id out: 20304\n",
      "img id in: 20305\n",
      "img id out: 20305\n",
      "img id in: 20306\n",
      "img id out: 20306\n",
      "img id in: 20307\n",
      "img id out: 20307\n",
      "img id in: 20308\n",
      "img id out: 20308\n",
      "img id in: 20309\n",
      "img id out: 20309\n",
      "img id in: 20310\n",
      "img id out: 20310\n",
      "img id in: 20311\n",
      "img id out: 20311\n",
      "img id in: 20312\n",
      "img id out: 20312\n",
      "img id in: 20313\n",
      "img id out: 20313\n",
      "img id in: 20314\n",
      "img id out: 20314\n",
      "img id in: 20315\n",
      "img id out: 20315\n",
      "img id in: 20316\n",
      "img id out: 20316\n",
      "img id in: 20317\n",
      "img id out: 20317\n",
      "img id in: 20318\n",
      "img id out: 20318\n",
      "img id in: 20319\n",
      "img id out: 20319\n",
      "img id in: 20320\n",
      "img id out: 20320\n",
      "img id in: 20321\n",
      "img id out: 20321\n",
      "img id in: 20322\n",
      "img id out: 20322\n",
      "img id in: 20323\n",
      "img id out: 20323\n",
      "img id in: 20324\n",
      "img id out: 20324\n",
      "img id in: 20325\n",
      "img id out: 20325\n",
      "img id in: 20326\n",
      "img id out: 20326\n",
      "img id in: 20327\n",
      "img id out: 20327\n",
      "img id in: 20328\n",
      "img id out: 20328\n",
      "img id in: 20329\n",
      "img id out: 20329\n",
      "img id in: 20330\n",
      "img id out: 20330\n",
      "img id in: 20331\n",
      "img id out: 20331\n",
      "img id in: 20332\n",
      "img id out: 20332\n",
      "img id in: 20333\n",
      "img id out: 20333\n",
      "img id in: 20334\n",
      "img id out: 20334\n",
      "img id in: 20335\n",
      "img id out: 20335\n",
      "img id in: 20336\n",
      "img id out: 20336\n",
      "img id in: 20337\n",
      "img id out: 20337\n",
      "img id in: 20338\n",
      "img id out: 20338\n",
      "img id in: 20339\n",
      "img id out: 20339\n",
      "img id in: 20340\n",
      "img id out: 20340\n",
      "img id in: 20341\n",
      "img id out: 20341\n",
      "img id in: 20342\n",
      "img id out: 20342\n",
      "img id in: 20343\n",
      "img id out: 20343\n",
      "img id in: 20344\n",
      "img id out: 20344\n",
      "img id in: 20345\n",
      "img id out: 20345\n",
      "img id in: 20346\n",
      "img id out: 20346\n",
      "img id in: 20347\n",
      "img id out: 20347\n",
      "img id in: 20348\n",
      "img id out: 20348\n",
      "img id in: 20349\n",
      "img id out: 20349\n",
      "img id in: 20350\n",
      "img id out: 20350\n",
      "img id in: 20351\n",
      "img id out: 20351\n",
      "img id in: 20352\n",
      "img id out: 20352\n",
      "img id in: 20353\n",
      "img id out: 20353\n",
      "img id in: 20354\n",
      "img id out: 20354\n",
      "img id in: 20355\n",
      "img id out: 20355\n",
      "img id in: 20356\n",
      "img id out: 20356\n",
      "img id in: 20357\n",
      "img id out: 20357\n",
      "img id in: 20358\n",
      "img id out: 20358\n",
      "img id in: 20359\n",
      "img id out: 20359\n",
      "img id in: 20360\n",
      "img id out: 20360\n",
      "img id in: 20361\n",
      "img id out: 20361\n",
      "img id in: 20362\n",
      "img id out: 20362\n",
      "img id in: 20363\n",
      "img id out: 20363\n",
      "img id in: 20364\n",
      "img id out: 20364\n",
      "img id in: 20365\n",
      "img id out: 20365\n",
      "img id in: 20366\n",
      "img id out: 20366\n",
      "img id in: 20367\n",
      "img id out: 20367\n",
      "img id in: 20368\n",
      "img id out: 20368\n",
      "img id in: 20369\n",
      "img id out: 20369\n",
      "img id in: 20370\n",
      "img id out: 20370\n",
      "img id in: 20371\n",
      "img id out: 20371\n",
      "img id in: 20372\n",
      "img id out: 20372\n",
      "img id in: 20373\n",
      "img id out: 20373\n",
      "img id in: 20374\n",
      "img id out: 20374\n",
      "img id in: 20375\n",
      "img id out: 20375\n",
      "img id in: 20376\n",
      "img id out: 20376\n",
      "img id in: 20377\n",
      "img id out: 20377\n",
      "img id in: 20378\n",
      "img id out: 20378\n",
      "img id in: 20379\n",
      "img id out: 20379\n",
      "img id in: 20380\n",
      "img id out: 20380\n",
      "img id in: 20381\n",
      "img id out: 20381\n",
      "img id in: 20382\n",
      "img id out: 20382\n",
      "img id in: 20383\n",
      "img id out: 20383\n",
      "img id in: 20384\n",
      "img id out: 20384\n",
      "img id in: 20385\n",
      "img id out: 20385\n",
      "img id in: 20386\n",
      "img id out: 20386\n",
      "img id in: 20387\n",
      "img id out: 20387\n",
      "img id in: 20388\n",
      "img id out: 20388\n",
      "img id in: 20389\n",
      "img id out: 20389\n",
      "img id in: 20390\n",
      "img id out: 20390\n",
      "img id in: 20391\n",
      "img id out: 20391\n",
      "img id in: 20392\n",
      "img id out: 20392\n",
      "img id in: 20393\n",
      "img id out: 20393\n",
      "img id in: 20394\n",
      "img id out: 20394\n",
      "img id in: 20395\n",
      "img id out: 20395\n",
      "img id in: 20396\n",
      "img id out: 20396\n",
      "img id in: 20397\n",
      "img id out: 20397\n",
      "img id in: 20398\n",
      "img id out: 20398\n",
      "img id in: 20399\n",
      "img id out: 20399\n",
      "img id in: 20400\n",
      "img id out: 20400\n",
      "img id in: 20401\n",
      "img id out: 20401\n",
      "img id in: 20402\n",
      "img id out: 20402\n",
      "img id in: 20403\n",
      "img id out: 20403\n",
      "img id in: 20404\n",
      "img id out: 20404\n",
      "img id in: 20405\n",
      "img id out: 20405\n",
      "img id in: 20406\n",
      "img id out: 20406\n",
      "img id in: 20407\n",
      "img id out: 20407\n",
      "img id in: 20408\n",
      "img id out: 20408\n",
      "img id in: 20409\n",
      "img id out: 20409\n",
      "img id in: 20410\n",
      "img id out: 20410\n",
      "img id in: 20411\n",
      "img id out: 20411\n",
      "img id in: 20412\n",
      "img id out: 20412\n",
      "img id in: 20413\n",
      "img id out: 20413\n",
      "img id in: 20414\n",
      "img id out: 20414\n",
      "img id in: 20415\n",
      "img id out: 20415\n",
      "img id in: 20416\n",
      "img id out: 20416\n",
      "img id in: 20417\n",
      "img id out: 20417\n",
      "img id in: 20418\n",
      "img id out: 20418\n",
      "img id in: 20419\n",
      "img id out: 20419\n",
      "img id in: 20420\n",
      "img id out: 20420\n",
      "img id in: 20421\n",
      "img id out: 20421\n",
      "img id in: 20422\n",
      "img id out: 20422\n",
      "img id in: 20423\n",
      "img id out: 20423\n",
      "img id in: 20424\n",
      "img id out: 20424\n",
      "img id in: 20425\n",
      "img id out: 20425\n",
      "img id in: 20426\n",
      "img id out: 20426\n",
      "img id in: 20427\n",
      "img id out: 20427\n",
      "img id in: 20428\n",
      "img id out: 20428\n",
      "img id in: 20429\n",
      "img id out: 20429\n",
      "img id in: 20430\n",
      "img id out: 20430\n",
      "img id in: 20431\n",
      "img id out: 20431\n",
      "img id in: 20432\n",
      "img id out: 20432\n",
      "img id in: 20433\n",
      "img id out: 20433\n",
      "img id in: 20434\n",
      "img id out: 20434\n",
      "img id in: 20435\n",
      "img id out: 20435\n",
      "img id in: 20436\n",
      "img id out: 20436\n",
      "img id in: 20437\n",
      "img id out: 20437\n",
      "img id in: 20438\n",
      "img id out: 20438\n",
      "img id in: 20439\n",
      "img id out: 20439\n",
      "img id in: 20440\n",
      "img id out: 20440\n",
      "img id in: 20441\n",
      "img id out: 20441\n",
      "img id in: 20442\n",
      "img id out: 20442\n",
      "img id in: 20443\n",
      "img id out: 20443\n",
      "img id in: 20444\n",
      "img id out: 20444\n",
      "img id in: 20445\n",
      "img id out: 20445\n",
      "img id in: 20446\n",
      "img id out: 20446\n",
      "img id in: 20447\n",
      "img id out: 20447\n",
      "img id in: 20448\n",
      "img id out: 20448\n",
      "img id in: 20449\n",
      "img id out: 20449\n",
      "img id in: 20450\n",
      "img id out: 20450\n",
      "img id in: 20451\n",
      "img id out: 20451\n",
      "img id in: 20452\n",
      "img id out: 20452\n",
      "img id in: 20453\n",
      "img id out: 20453\n",
      "img id in: 20454\n",
      "img id out: 20454\n",
      "img id in: 20455\n",
      "img id out: 20455\n",
      "img id in: 20456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 20456\n",
      "img id in: 20457\n",
      "img id out: 20457\n",
      "img id in: 20458\n",
      "img id out: 20458\n",
      "img id in: 20459\n",
      "img id out: 20459\n",
      "img id in: 20460\n",
      "img id out: 20460\n",
      "img id in: 20461\n",
      "img id out: 20461\n",
      "img id in: 20462\n",
      "img id out: 20462\n",
      "img id in: 20463\n",
      "img id out: 20463\n",
      "img id in: 20464\n",
      "img id out: 20464\n",
      "img id in: 20465\n",
      "img id out: 20465\n",
      "img id in: 20466\n",
      "img id out: 20466\n",
      "img id in: 20467\n",
      "img id out: 20467\n",
      "img id in: 20468\n",
      "img id out: 20468\n",
      "img id in: 20469\n",
      "img id out: 20469\n",
      "img id in: 20470\n",
      "img id out: 20470\n",
      "img id in: 20471\n",
      "img id out: 20471\n",
      "img id in: 20472\n",
      "img id out: 20472\n",
      "img id in: 20473\n",
      "img id out: 20473\n",
      "img id in: 20474\n",
      "img id out: 20474\n",
      "img id in: 20475\n",
      "img id out: 20475\n",
      "img id in: 20476\n",
      "img id out: 20476\n",
      "img id in: 20477\n",
      "img id out: 20477\n",
      "img id in: 20478\n",
      "img id out: 20478\n",
      "img id in: 20479\n",
      "img id out: 20479\n",
      "img id in: 20480\n",
      "img id out: 20480\n",
      "img id in: 20481\n",
      "img id out: 20481\n",
      "img id in: 20482\n",
      "img id out: 20482\n",
      "img id in: 20483\n",
      "img id out: 20483\n",
      "img id in: 20484\n",
      "img id out: 20484\n",
      "img id in: 20485\n",
      "img id out: 20485\n",
      "img id in: 20486\n",
      "img id out: 20486\n",
      "img id in: 20487\n",
      "img id out: 20487\n",
      "img id in: 20488\n",
      "img id out: 20488\n",
      "img id in: 20489\n",
      "img id out: 20489\n",
      "img id in: 20490\n",
      "img id out: 20490\n",
      "img id in: 20491\n",
      "img id out: 20491\n",
      "img id in: 20492\n",
      "img id out: 20492\n",
      "img id in: 20493\n",
      "img id out: 20493\n",
      "img id in: 20494\n",
      "img id out: 20494\n",
      "img id in: 20495\n",
      "img id out: 20495\n",
      "img id in: 20496\n",
      "img id out: 20496\n",
      "img id in: 20497\n",
      "img id out: 20497\n",
      "img id in: 20498\n",
      "img id out: 20498\n",
      "img id in: 20499\n",
      "img id out: 20499\n",
      "img id in: 20500\n",
      "img id out: 20500\n",
      "img id in: 20501\n",
      "img id out: 20501\n",
      "img id in: 20502\n",
      "img id out: 20502\n",
      "img id in: 20503\n",
      "img id out: 20503\n",
      "img id in: 20504\n",
      "img id out: 20504\n",
      "img id in: 20505\n",
      "img id out: 20505\n",
      "img id in: 20506\n",
      "img id out: 20506\n",
      "img id in: 20507\n",
      "img id out: 20507\n",
      "img id in: 20508\n",
      "img id out: 20508\n",
      "img id in: 20509\n",
      "img id out: 20509\n",
      "img id in: 20510\n",
      "img id out: 20510\n",
      "img id in: 20511\n",
      "img id out: 20511\n",
      "img id in: 20512\n",
      "img id out: 20512\n",
      "img id in: 20513\n",
      "img id out: 20513\n",
      "img id in: 20514\n",
      "img id out: 20514\n",
      "img id in: 20515\n",
      "img id out: 20515\n",
      "img id in: 20516\n",
      "img id out: 20516\n",
      "img id in: 20517\n",
      "img id out: 20517\n",
      "img id in: 20518\n",
      "img id out: 20518\n",
      "img id in: 20519\n",
      "img id out: 20519\n",
      "img id in: 20520\n",
      "img id out: 20520\n",
      "img id in: 20521\n",
      "img id out: 20521\n",
      "img id in: 20522\n",
      "img id out: 20522\n",
      "img id in: 20523\n",
      "img id out: 20523\n",
      "img id in: 20524\n",
      "img id out: 20524\n",
      "img id in: 20525\n",
      "img id out: 20525\n",
      "img id in: 20526\n",
      "img id out: 20526\n",
      "img id in: 20527\n",
      "img id out: 20527\n",
      "img id in: 20528\n",
      "img id out: 20528\n",
      "img id in: 20529\n",
      "img id out: 20529\n",
      "img id in: 20530\n",
      "img id out: 20530\n",
      "img id in: 20531\n",
      "img id out: 20531\n",
      "img id in: 20532\n",
      "img id out: 20532\n",
      "img id in: 20533\n",
      "img id out: 20533\n",
      "img id in: 20534\n",
      "img id out: 20534\n",
      "img id in: 20535\n",
      "img id out: 20535\n",
      "img id in: 20536\n",
      "img id out: 20536\n",
      "img id in: 20537\n",
      "img id out: 20537\n",
      "img id in: 20538\n",
      "img id out: 20538\n",
      "img id in: 20539\n",
      "img id out: 20539\n",
      "img id in: 20540\n",
      "img id out: 20540\n",
      "img id in: 20541\n",
      "img id out: 20541\n",
      "img id in: 20542\n",
      "img id out: 20542\n",
      "img id in: 20543\n",
      "img id out: 20543\n",
      "img id in: 20544\n",
      "img id out: 20544\n",
      "img id in: 20545\n",
      "img id out: 20545\n",
      "img id in: 20546\n",
      "img id out: 20546\n",
      "img id in: 20547\n",
      "img id out: 20547\n",
      "img id in: 20548\n",
      "img id out: 20548\n",
      "img id in: 20549\n",
      "img id out: 20549\n",
      "img id in: 20550\n",
      "img id out: 20550\n",
      "img id in: 20551\n",
      "img id out: 20551\n",
      "img id in: 20552\n",
      "img id out: 20552\n",
      "img id in: 20553\n",
      "img id out: 20553\n",
      "img id in: 20554\n",
      "img id out: 20554\n",
      "img id in: 20555\n",
      "img id out: 20555\n",
      "img id in: 20556\n",
      "img id out: 20556\n",
      "img id in: 20557\n",
      "img id out: 20557\n",
      "img id in: 20558\n",
      "img id out: 20558\n",
      "img id in: 20559\n",
      "img id out: 20559\n",
      "img id in: 20560\n",
      "img id out: 20560\n",
      "img id in: 20561\n",
      "img id out: 20561\n",
      "img id in: 20562\n",
      "img id out: 20562\n",
      "img id in: 20563\n",
      "img id out: 20563\n",
      "img id in: 20564\n",
      "img id out: 20564\n",
      "img id in: 20565\n",
      "img id out: 20565\n",
      "img id in: 20566\n",
      "img id out: 20566\n",
      "img id in: 20567\n",
      "img id out: 20567\n",
      "img id in: 20568\n",
      "img id out: 20568\n",
      "img id in: 20569\n",
      "img id out: 20569\n",
      "img id in: 20570\n",
      "img id out: 20570\n",
      "img id in: 20571\n",
      "img id out: 20571\n",
      "img id in: 20572\n",
      "img id out: 20572\n",
      "img id in: 20573\n",
      "img id out: 20573\n",
      "img id in: 20574\n",
      "img id out: 20574\n",
      "img id in: 20575\n",
      "img id out: 20575\n",
      "img id in: 20576\n",
      "img id out: 20576\n",
      "img id in: 20577\n",
      "img id out: 20577\n",
      "img id in: 20578\n",
      "img id out: 20578\n",
      "img id in: 20579\n",
      "img id out: 20579\n",
      "img id in: 20580\n",
      "img id out: 20580\n",
      "img id in: 20581\n",
      "img id out: 20581\n",
      "img id in: 20582\n",
      "img id out: 20582\n",
      "img id in: 20583\n",
      "img id out: 20583\n",
      "img id in: 20584\n",
      "img id out: 20584\n",
      "img id in: 20585\n",
      "img id out: 20585\n",
      "img id in: 20586\n",
      "img id out: 20586\n",
      "img id in: 20587\n",
      "img id out: 20587\n",
      "img id in: 20588\n",
      "img id out: 20588\n",
      "img id in: 20589\n",
      "img id out: 20589\n",
      "img id in: 20590\n",
      "img id out: 20590\n",
      "img id in: 20591\n",
      "img id out: 20591\n",
      "img id in: 20592\n",
      "img id out: 20592\n",
      "img id in: 20593\n",
      "img id out: 20593\n",
      "img id in: 20594\n",
      "img id out: 20594\n",
      "img id in: 20595\n",
      "img id out: 20595\n",
      "img id in: 20596\n",
      "img id out: 20596\n",
      "img id in: 20597\n",
      "img id out: 20597\n",
      "img id in: 20598\n",
      "img id out: 20598\n",
      "img id in: 20599\n",
      "img id out: 20599\n",
      "img id in: 20600\n",
      "img id out: 20600\n",
      "img id in: 20601\n",
      "img id out: 20601\n",
      "img id in: 20602\n",
      "img id out: 20602\n",
      "img id in: 20603\n",
      "img id out: 20603\n",
      "img id in: 20604\n",
      "img id out: 20604\n",
      "img id in: 20605\n",
      "img id out: 20605\n",
      "img id in: 20606\n",
      "img id out: 20606\n",
      "img id in: 20607\n",
      "img id out: 20607\n",
      "img id in: 20608\n",
      "img id out: 20608\n",
      "img id in: 20609\n",
      "img id out: 20609\n",
      "img id in: 20610\n",
      "img id out: 20610\n",
      "img id in: 20611\n",
      "img id out: 20611\n",
      "img id in: 20612\n",
      "img id out: 20612\n",
      "img id in: 20613\n",
      "img id out: 20613\n",
      "img id in: 20614\n",
      "img id out: 20614\n",
      "img id in: 20615\n",
      "img id out: 20615\n",
      "img id in: 20616\n",
      "img id out: 20616\n",
      "img id in: 20617\n",
      "img id out: 20617\n",
      "img id in: 20618\n",
      "img id out: 20618\n",
      "img id in: 20619\n",
      "img id out: 20619\n",
      "img id in: 20620\n",
      "img id out: 20620\n",
      "img id in: 20621\n",
      "img id out: 20621\n",
      "img id in: 20622\n",
      "img id out: 20622\n",
      "img id in: 20623\n",
      "img id out: 20623\n",
      "img id in: 20624\n",
      "img id out: 20624\n",
      "img id in: 20625\n",
      "img id out: 20625\n",
      "img id in: 20626\n",
      "img id out: 20626\n",
      "img id in: 20627\n",
      "img id out: 20627\n",
      "img id in: 20628\n",
      "img id out: 20628\n",
      "img id in: 20629\n",
      "img id out: 20629\n",
      "img id in: 20630\n",
      "img id out: 20630\n",
      "img id in: 20631\n",
      "img id out: 20631\n",
      "img id in: 20632\n",
      "img id out: 20632\n",
      "img id in: 20633\n",
      "img id out: 20633\n",
      "img id in: 20634\n",
      "img id out: 20634\n",
      "img id in: 20635\n",
      "img id out: 20635\n",
      "img id in: 20636\n",
      "img id out: 20636\n",
      "img id in: 20637\n",
      "img id out: 20637\n",
      "img id in: 20638\n",
      "img id out: 20638\n",
      "img id in: 20639\n",
      "img id out: 20639\n",
      "img id in: 20640\n",
      "img id out: 20640\n",
      "img id in: 20641\n",
      "img id out: 20641\n",
      "img id in: 20642\n",
      "img id out: 20642\n",
      "img id in: 20643\n",
      "img id out: 20643\n",
      "img id in: 20644\n",
      "img id out: 20644\n",
      "img id in: 20645\n",
      "img id out: 20645\n",
      "img id in: 20646\n",
      "img id out: 20646\n",
      "img id in: 20647\n",
      "img id out: 20647\n",
      "img id in: 20648\n",
      "img id out: 20648\n",
      "img id in: 20649\n",
      "img id out: 20649\n",
      "img id in: 20650\n",
      "img id out: 20650\n",
      "img id in: 20651\n",
      "img id out: 20651\n",
      "img id in: 20652\n",
      "img id out: 20652\n",
      "img id in: 20653\n",
      "img id out: 20653\n",
      "img id in: 20654\n",
      "img id out: 20654\n",
      "img id in: 20655\n",
      "img id out: 20655\n",
      "img id in: 20656\n",
      "img id out: 20656\n",
      "img id in: 20657\n",
      "img id out: 20657\n",
      "img id in: 20658\n",
      "img id out: 20658\n",
      "img id in: 20659\n",
      "img id out: 20659\n",
      "img id in: 20660\n",
      "img id out: 20660\n",
      "img id in: 20661\n",
      "img id out: 20661\n",
      "img id in: 20662\n",
      "img id out: 20662\n",
      "img id in: 20663\n",
      "img id out: 20663\n",
      "img id in: 20664\n",
      "img id out: 20664\n",
      "img id in: 20665\n",
      "img id out: 20665\n",
      "img id in: 20666\n",
      "img id out: 20666\n",
      "img id in: 20667\n",
      "img id out: 20667\n",
      "img id in: 20668\n",
      "img id out: 20668\n",
      "img id in: 20669\n",
      "img id out: 20669\n",
      "img id in: 20670\n",
      "img id out: 20670\n",
      "img id in: 20671\n",
      "img id out: 20671\n",
      "img id in: 20672\n",
      "img id out: 20672\n",
      "img id in: 20673\n",
      "img id out: 20673\n",
      "img id in: 20674\n",
      "img id out: 20674\n",
      "img id in: 20675\n",
      "img id out: 20675\n",
      "img id in: 20676\n",
      "img id out: 20676\n",
      "img id in: 20677\n",
      "img id out: 20677\n",
      "img id in: 20678\n",
      "img id out: 20678\n",
      "img id in: 20679\n",
      "img id out: 20679\n",
      "img id in: 20680\n",
      "img id out: 20680\n",
      "img id in: 20681\n",
      "img id out: 20681\n",
      "img id in: 20682\n",
      "img id out: 20682\n",
      "img id in: 20683\n",
      "img id out: 20683\n",
      "img id in: 20684\n",
      "img id out: 20684\n",
      "img id in: 20685\n",
      "img id out: 20685\n",
      "img id in: 20686\n",
      "img id out: 20686\n",
      "img id in: 20687\n",
      "img id out: 20687\n",
      "img id in: 20688\n",
      "img id out: 20688\n",
      "img id in: 20689\n",
      "img id out: 20689\n",
      "img id in: 20690\n",
      "img id out: 20690\n",
      "img id in: 20691\n",
      "img id out: 20691\n",
      "img id in: 20692\n",
      "img id out: 20692\n",
      "img id in: 20693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 20693\n",
      "img id in: 20694\n",
      "img id out: 20694\n",
      "img id in: 20695\n",
      "img id out: 20695\n",
      "img id in: 20696\n",
      "img id out: 20696\n",
      "img id in: 20697\n",
      "img id out: 20697\n",
      "img id in: 20698\n",
      "img id out: 20698\n",
      "img id in: 20699\n",
      "img id out: 20699\n",
      "img id in: 20700\n",
      "img id out: 20700\n",
      "img id in: 20701\n",
      "img id out: 20701\n",
      "img id in: 20702\n",
      "img id out: 20702\n",
      "img id in: 20703\n",
      "img id out: 20703\n",
      "img id in: 20704\n",
      "img id out: 20704\n",
      "img id in: 20705\n",
      "img id out: 20705\n",
      "img id in: 20706\n",
      "img id out: 20706\n",
      "img id in: 20707\n",
      "img id out: 20707\n",
      "img id in: 20708\n",
      "img id out: 20708\n",
      "img id in: 20709\n",
      "img id out: 20709\n",
      "img id in: 20710\n",
      "img id out: 20710\n",
      "img id in: 20711\n",
      "img id out: 20711\n",
      "img id in: 20712\n",
      "img id out: 20712\n",
      "img id in: 20713\n",
      "img id out: 20713\n",
      "img id in: 20714\n",
      "img id out: 20714\n",
      "img id in: 20715\n",
      "img id out: 20715\n",
      "img id in: 20716\n",
      "img id out: 20716\n",
      "img id in: 20717\n",
      "img id out: 20717\n",
      "img id in: 20718\n",
      "img id out: 20718\n",
      "img id in: 20719\n",
      "img id out: 20719\n",
      "img id in: 20720\n",
      "img id out: 20720\n",
      "img id in: 20721\n",
      "img id out: 20721\n",
      "img id in: 20722\n",
      "img id out: 20722\n",
      "img id in: 20723\n",
      "img id out: 20723\n",
      "img id in: 20724\n",
      "img id out: 20724\n",
      "img id in: 20725\n",
      "img id out: 20725\n",
      "img id in: 20726\n",
      "img id out: 20726\n",
      "img id in: 20727\n",
      "img id out: 20727\n",
      "img id in: 20728\n",
      "img id out: 20728\n",
      "img id in: 20729\n",
      "img id out: 20729\n",
      "img id in: 20730\n",
      "img id out: 20730\n",
      "img id in: 20731\n",
      "img id out: 20731\n",
      "img id in: 20732\n",
      "img id out: 20732\n",
      "img id in: 20733\n",
      "img id out: 20733\n",
      "img id in: 20734\n",
      "img id out: 20734\n",
      "img id in: 20735\n",
      "img id out: 20735\n",
      "img id in: 20736\n",
      "img id out: 20736\n",
      "img id in: 20737\n",
      "img id out: 20737\n",
      "img id in: 20738\n",
      "img id out: 20738\n",
      "img id in: 20739\n",
      "img id out: 20739\n",
      "img id in: 20740\n",
      "img id out: 20740\n",
      "img id in: 20741\n",
      "img id out: 20741\n",
      "img id in: 20742\n",
      "img id out: 20742\n",
      "img id in: 20743\n",
      "img id out: 20743\n",
      "img id in: 20744\n",
      "img id out: 20744\n",
      "img id in: 20745\n",
      "img id out: 20745\n",
      "img id in: 20746\n",
      "img id out: 20746\n",
      "img id in: 20747\n",
      "img id out: 20747\n",
      "img id in: 20748\n",
      "img id out: 20748\n",
      "img id in: 20749\n",
      "img id out: 20749\n",
      "img id in: 20750\n",
      "img id out: 20750\n",
      "img id in: 20751\n",
      "img id out: 20751\n",
      "img id in: 20752\n",
      "img id out: 20752\n",
      "img id in: 20753\n",
      "img id out: 20753\n",
      "img id in: 20754\n",
      "img id out: 20754\n",
      "img id in: 20755\n",
      "img id out: 20755\n",
      "img id in: 20756\n",
      "img id out: 20756\n",
      "img id in: 20757\n",
      "img id out: 20757\n",
      "img id in: 20758\n",
      "img id out: 20758\n",
      "img id in: 20759\n",
      "img id out: 20759\n",
      "img id in: 20760\n",
      "img id out: 20760\n",
      "img id in: 20761\n",
      "img id out: 20761\n",
      "img id in: 20762\n",
      "img id out: 20762\n",
      "img id in: 20763\n",
      "img id out: 20763\n",
      "img id in: 20764\n",
      "img id out: 20764\n",
      "img id in: 20765\n",
      "img id out: 20765\n",
      "img id in: 20766\n",
      "img id out: 20766\n",
      "img id in: 20767\n",
      "img id out: 20767\n",
      "img id in: 20768\n",
      "img id out: 20768\n",
      "img id in: 20769\n",
      "img id out: 20769\n",
      "img id in: 20770\n",
      "img id out: 20770\n",
      "img id in: 20771\n",
      "img id out: 20771\n",
      "img id in: 20772\n",
      "img id out: 20772\n",
      "img id in: 20773\n",
      "img id out: 20773\n",
      "img id in: 20774\n",
      "img id out: 20774\n",
      "img id in: 20775\n",
      "img id out: 20775\n",
      "img id in: 20776\n",
      "img id out: 20776\n",
      "img id in: 20777\n",
      "img id out: 20777\n",
      "img id in: 20778\n",
      "img id out: 20778\n",
      "img id in: 20779\n",
      "img id out: 20779\n",
      "img id in: 20780\n",
      "img id out: 20780\n",
      "img id in: 20781\n",
      "img id out: 20781\n",
      "img id in: 20782\n",
      "img id out: 20782\n",
      "img id in: 20783\n",
      "img id out: 20783\n",
      "img id in: 20784\n",
      "img id out: 20784\n",
      "img id in: 20785\n",
      "img id out: 20785\n",
      "img id in: 20786\n",
      "img id out: 20786\n",
      "img id in: 20787\n",
      "img id out: 20787\n",
      "img id in: 20788\n",
      "img id out: 20788\n",
      "img id in: 20789\n",
      "img id out: 20789\n",
      "img id in: 20790\n",
      "img id out: 20790\n",
      "img id in: 20791\n",
      "img id out: 20791\n",
      "img id in: 20792\n",
      "img id out: 20792\n",
      "img id in: 20793\n",
      "img id out: 20793\n",
      "img id in: 20794\n",
      "img id out: 20794\n",
      "img id in: 20795\n",
      "img id out: 20795\n",
      "img id in: 20796\n",
      "img id out: 20796\n",
      "img id in: 20797\n",
      "img id out: 20797\n",
      "img id in: 20798\n",
      "img id out: 20798\n",
      "img id in: 20799\n",
      "img id out: 20799\n",
      "img id in: 20800\n",
      "img id out: 20800\n",
      "img id in: 20801\n",
      "img id out: 20801\n",
      "img id in: 20802\n",
      "img id out: 20802\n",
      "img id in: 20803\n",
      "img id out: 20803\n",
      "img id in: 20804\n",
      "img id out: 20804\n",
      "img id in: 20805\n",
      "img id out: 20805\n",
      "img id in: 20806\n",
      "img id out: 20806\n",
      "img id in: 20807\n",
      "img id out: 20807\n",
      "img id in: 20808\n",
      "img id out: 20808\n",
      "img id in: 20809\n",
      "img id out: 20809\n",
      "img id in: 20810\n",
      "img id out: 20810\n",
      "img id in: 20811\n",
      "img id out: 20811\n",
      "img id in: 20812\n",
      "img id out: 20812\n",
      "img id in: 20813\n",
      "img id out: 20813\n",
      "img id in: 20814\n",
      "img id out: 20814\n",
      "img id in: 20815\n",
      "img id out: 20815\n",
      "img id in: 20816\n",
      "img id out: 20816\n",
      "img id in: 20817\n",
      "img id out: 20817\n",
      "img id in: 20818\n",
      "img id out: 20818\n",
      "img id in: 20819\n",
      "img id out: 20819\n",
      "img id in: 20820\n",
      "img id out: 20820\n",
      "img id in: 20821\n",
      "img id out: 20821\n",
      "img id in: 20822\n",
      "img id out: 20822\n",
      "img id in: 20823\n",
      "img id out: 20823\n",
      "img id in: 20824\n",
      "img id out: 20824\n",
      "img id in: 20825\n",
      "img id out: 20825\n",
      "img id in: 20826\n",
      "img id out: 20826\n",
      "img id in: 20827\n",
      "img id out: 20827\n",
      "img id in: 20828\n",
      "img id out: 20828\n",
      "img id in: 20829\n",
      "img id out: 20829\n",
      "img id in: 20830\n",
      "img id out: 20830\n",
      "img id in: 20831\n",
      "img id out: 20831\n",
      "img id in: 20832\n",
      "img id out: 20832\n",
      "img id in: 20833\n",
      "img id out: 20833\n",
      "img id in: 20834\n",
      "img id out: 20834\n",
      "img id in: 20835\n",
      "img id out: 20835\n",
      "img id in: 20836\n",
      "img id out: 20836\n",
      "img id in: 20837\n",
      "img id out: 20837\n",
      "img id in: 20838\n",
      "img id out: 20838\n",
      "img id in: 20839\n",
      "img id out: 20839\n",
      "img id in: 20840\n",
      "img id out: 20840\n",
      "img id in: 20841\n",
      "img id out: 20841\n",
      "img id in: 20842\n",
      "img id out: 20842\n",
      "img id in: 20843\n",
      "img id out: 20843\n",
      "img id in: 20844\n",
      "img id out: 20844\n",
      "img id in: 20845\n",
      "img id out: 20845\n",
      "img id in: 20846\n",
      "img id out: 20846\n",
      "img id in: 20847\n",
      "img id out: 20847\n",
      "img id in: 20848\n",
      "img id out: 20848\n",
      "img id in: 20849\n",
      "img id out: 20849\n",
      "img id in: 20850\n",
      "img id out: 20850\n",
      "img id in: 20851\n",
      "img id out: 20851\n",
      "img id in: 20852\n",
      "img id out: 20852\n",
      "img id in: 20853\n",
      "img id out: 20853\n",
      "img id in: 20854\n",
      "img id out: 20854\n",
      "img id in: 20855\n",
      "img id out: 20855\n",
      "img id in: 20856\n",
      "img id out: 20856\n",
      "img id in: 20857\n",
      "img id out: 20857\n",
      "img id in: 20858\n",
      "img id out: 20858\n",
      "img id in: 20859\n",
      "img id out: 20859\n",
      "img id in: 20860\n",
      "img id out: 20860\n",
      "img id in: 20861\n",
      "img id out: 20861\n",
      "img id in: 20862\n",
      "img id out: 20862\n",
      "img id in: 20863\n",
      "img id out: 20863\n",
      "img id in: 20864\n",
      "img id out: 20864\n",
      "img id in: 20865\n",
      "img id out: 20865\n",
      "img id in: 20866\n",
      "img id out: 20866\n",
      "img id in: 20867\n",
      "img id out: 20867\n",
      "img id in: 20868\n",
      "img id out: 20868\n",
      "img id in: 20869\n",
      "img id out: 20869\n",
      "img id in: 20870\n",
      "img id out: 20870\n",
      "img id in: 20871\n",
      "img id out: 20871\n",
      "img id in: 20872\n",
      "img id out: 20872\n",
      "img id in: 20873\n",
      "img id out: 20873\n",
      "img id in: 20874\n",
      "img id out: 20874\n",
      "img id in: 20875\n",
      "img id out: 20875\n",
      "img id in: 20876\n",
      "img id out: 20876\n",
      "img id in: 20877\n",
      "img id out: 20877\n",
      "img id in: 20878\n",
      "img id out: 20878\n",
      "img id in: 20879\n",
      "img id out: 20879\n",
      "img id in: 20880\n",
      "img id out: 20880\n",
      "img id in: 20881\n",
      "img id out: 20881\n",
      "img id in: 20882\n",
      "img id out: 20882\n",
      "img id in: 20883\n",
      "img id out: 20883\n",
      "img id in: 20884\n",
      "img id out: 20884\n",
      "img id in: 20885\n",
      "img id out: 20885\n",
      "img id in: 20886\n",
      "img id out: 20886\n",
      "img id in: 20887\n",
      "img id out: 20887\n",
      "img id in: 20888\n",
      "img id out: 20888\n",
      "img id in: 20889\n",
      "img id out: 20889\n",
      "img id in: 20890\n",
      "img id out: 20890\n",
      "img id in: 20891\n",
      "img id out: 20891\n",
      "img id in: 20892\n",
      "img id out: 20892\n",
      "img id in: 20893\n",
      "img id out: 20893\n",
      "img id in: 20894\n",
      "img id out: 20894\n",
      "img id in: 20895\n",
      "img id out: 20895\n",
      "img id in: 20896\n",
      "img id out: 20896\n",
      "img id in: 20897\n",
      "img id out: 20897\n",
      "img id in: 20898\n",
      "img id out: 20898\n",
      "img id in: 20899\n",
      "img id out: 20899\n",
      "img id in: 20900\n",
      "img id out: 20900\n",
      "img id in: 20901\n",
      "img id out: 20901\n",
      "img id in: 20902\n",
      "img id out: 20902\n",
      "img id in: 20903\n",
      "img id out: 20903\n",
      "img id in: 20904\n",
      "img id out: 20904\n",
      "img id in: 20905\n",
      "img id out: 20905\n",
      "img id in: 20906\n",
      "img id out: 20906\n",
      "img id in: 20907\n",
      "img id out: 20907\n",
      "img id in: 20908\n",
      "img id out: 20908\n",
      "img id in: 20909\n",
      "img id out: 20909\n",
      "img id in: 20910\n",
      "img id out: 20910\n",
      "img id in: 20911\n",
      "img id out: 20911\n",
      "img id in: 20912\n",
      "img id out: 20912\n",
      "img id in: 20913\n",
      "img id out: 20913\n",
      "img id in: 20914\n",
      "img id out: 20914\n",
      "img id in: 20915\n",
      "img id out: 20915\n",
      "img id in: 20916\n",
      "img id out: 20916\n",
      "img id in: 20917\n",
      "img id out: 20917\n",
      "img id in: 20918\n",
      "img id out: 20918\n",
      "img id in: 20919\n",
      "img id out: 20919\n",
      "img id in: 20920\n",
      "img id out: 20920\n",
      "img id in: 20921\n",
      "img id out: 20921\n",
      "img id in: 20922\n",
      "img id out: 20922\n",
      "img id in: 20923\n",
      "img id out: 20923\n",
      "img id in: 20924\n",
      "img id out: 20924\n",
      "img id in: 20925\n",
      "img id out: 20925\n",
      "img id in: 20926\n",
      "img id out: 20926\n",
      "img id in: 20927\n",
      "img id out: 20927\n",
      "img id in: 20928\n",
      "img id out: 20928\n",
      "img id in: 20929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 20929\n",
      "img id in: 20930\n",
      "img id out: 20930\n",
      "img id in: 20931\n",
      "img id out: 20931\n",
      "img id in: 20932\n",
      "img id out: 20932\n",
      "img id in: 20933\n",
      "img id out: 20933\n",
      "img id in: 20934\n",
      "img id out: 20934\n",
      "img id in: 20935\n",
      "img id out: 20935\n",
      "img id in: 20936\n",
      "img id out: 20936\n",
      "img id in: 20937\n",
      "img id out: 20937\n",
      "img id in: 20938\n",
      "img id out: 20938\n",
      "img id in: 20939\n",
      "img id out: 20939\n",
      "img id in: 20940\n",
      "img id out: 20940\n",
      "img id in: 20941\n",
      "img id out: 20941\n",
      "img id in: 20942\n",
      "img id out: 20942\n",
      "img id in: 20943\n",
      "img id out: 20943\n",
      "img id in: 20944\n",
      "img id out: 20944\n",
      "img id in: 20945\n",
      "img id out: 20945\n",
      "img id in: 20946\n",
      "img id out: 20946\n",
      "img id in: 20947\n",
      "img id out: 20947\n",
      "img id in: 20948\n",
      "img id out: 20948\n",
      "img id in: 20949\n",
      "img id out: 20949\n",
      "img id in: 20950\n",
      "img id out: 20950\n",
      "img id in: 20951\n",
      "img id out: 20951\n",
      "img id in: 20952\n",
      "img id out: 20952\n",
      "img id in: 20953\n",
      "img id out: 20953\n",
      "img id in: 20954\n",
      "img id out: 20954\n",
      "img id in: 20955\n",
      "img id out: 20955\n",
      "img id in: 20956\n",
      "img id out: 20956\n",
      "img id in: 20957\n",
      "img id out: 20957\n",
      "img id in: 20958\n",
      "img id out: 20958\n",
      "img id in: 20959\n",
      "img id out: 20959\n",
      "img id in: 20960\n",
      "img id out: 20960\n",
      "img id in: 20961\n",
      "img id out: 20961\n",
      "img id in: 20962\n",
      "img id out: 20962\n",
      "img id in: 20963\n",
      "img id out: 20963\n",
      "img id in: 20964\n",
      "img id out: 20964\n",
      "img id in: 20965\n",
      "img id out: 20965\n",
      "img id in: 20966\n",
      "img id out: 20966\n",
      "img id in: 20967\n",
      "img id out: 20967\n",
      "img id in: 20968\n",
      "img id out: 20968\n",
      "img id in: 20969\n",
      "img id out: 20969\n",
      "img id in: 20970\n",
      "img id out: 20970\n",
      "img id in: 20971\n",
      "img id out: 20971\n",
      "img id in: 20972\n",
      "img id out: 20972\n",
      "img id in: 20973\n",
      "img id out: 20973\n",
      "img id in: 20974\n",
      "img id out: 20974\n",
      "img id in: 20975\n",
      "img id out: 20975\n",
      "img id in: 20976\n",
      "img id out: 20976\n",
      "img id in: 20977\n",
      "img id out: 20977\n",
      "img id in: 20978\n",
      "img id out: 20978\n",
      "img id in: 20979\n",
      "img id out: 20979\n",
      "img id in: 20980\n",
      "img id out: 20980\n",
      "img id in: 20981\n",
      "img id out: 20981\n",
      "img id in: 20982\n",
      "img id out: 20982\n",
      "img id in: 20983\n",
      "img id out: 20983\n",
      "img id in: 20984\n",
      "img id out: 20984\n",
      "img id in: 20985\n",
      "img id out: 20985\n",
      "img id in: 20986\n",
      "img id out: 20986\n",
      "img id in: 20987\n",
      "img id out: 20987\n",
      "img id in: 20988\n",
      "img id out: 20988\n",
      "img id in: 20989\n",
      "img id out: 20989\n",
      "img id in: 20990\n",
      "img id out: 20990\n",
      "img id in: 20991\n",
      "img id out: 20991\n",
      "img id in: 20992\n",
      "img id out: 20992\n",
      "img id in: 20993\n",
      "img id out: 20993\n",
      "img id in: 20994\n",
      "img id out: 20994\n",
      "img id in: 20995\n",
      "img id out: 20995\n",
      "img id in: 20996\n",
      "img id out: 20996\n",
      "img id in: 20997\n",
      "img id out: 20997\n",
      "img id in: 20998\n",
      "img id out: 20998\n",
      "img id in: 20999\n",
      "img id out: 20999\n",
      "img id in: 21000\n",
      "img id out: 21000\n",
      "img id in: 21001\n",
      "img id out: 21001\n",
      "img id in: 21002\n",
      "img id out: 21002\n",
      "img id in: 21003\n",
      "img id out: 21003\n",
      "img id in: 21004\n",
      "img id out: 21004\n",
      "img id in: 21005\n",
      "img id out: 21005\n",
      "img id in: 21006\n",
      "img id out: 21006\n",
      "img id in: 21007\n",
      "img id out: 21007\n",
      "img id in: 21008\n",
      "img id out: 21008\n",
      "img id in: 21009\n",
      "img id out: 21009\n",
      "img id in: 21010\n",
      "img id out: 21010\n",
      "img id in: 21011\n",
      "img id out: 21011\n",
      "img id in: 21012\n",
      "img id out: 21012\n",
      "img id in: 21013\n",
      "img id out: 21013\n",
      "img id in: 21014\n",
      "img id out: 21014\n",
      "img id in: 21015\n",
      "img id out: 21015\n",
      "img id in: 21016\n",
      "img id out: 21016\n",
      "img id in: 21017\n",
      "img id out: 21017\n",
      "img id in: 21018\n",
      "img id out: 21018\n",
      "img id in: 21019\n",
      "img id out: 21019\n",
      "img id in: 21020\n",
      "img id out: 21020\n",
      "img id in: 21021\n",
      "img id out: 21021\n",
      "img id in: 21022\n",
      "img id out: 21022\n",
      "img id in: 21023\n",
      "img id out: 21023\n",
      "img id in: 21024\n",
      "img id out: 21024\n",
      "img id in: 21025\n",
      "img id out: 21025\n",
      "img id in: 21026\n",
      "img id out: 21026\n",
      "img id in: 21027\n",
      "img id out: 21027\n",
      "img id in: 21028\n",
      "img id out: 21028\n",
      "img id in: 21029\n",
      "img id out: 21029\n",
      "img id in: 21030\n",
      "img id out: 21030\n",
      "img id in: 21031\n",
      "img id out: 21031\n",
      "img id in: 21032\n",
      "img id out: 21032\n",
      "img id in: 21033\n",
      "img id out: 21033\n",
      "img id in: 21034\n",
      "img id out: 21034\n",
      "img id in: 21035\n",
      "img id out: 21035\n",
      "img id in: 21036\n",
      "img id out: 21036\n",
      "img id in: 21037\n",
      "img id out: 21037\n",
      "img id in: 21038\n",
      "img id out: 21038\n",
      "img id in: 21039\n",
      "img id out: 21039\n",
      "img id in: 21040\n",
      "img id out: 21040\n",
      "img id in: 21041\n",
      "img id out: 21041\n",
      "img id in: 21042\n",
      "img id out: 21042\n",
      "img id in: 21043\n",
      "img id out: 21043\n",
      "img id in: 21044\n",
      "img id out: 21044\n",
      "img id in: 21045\n",
      "img id out: 21045\n",
      "img id in: 21046\n",
      "img id out: 21046\n",
      "img id in: 21047\n",
      "img id out: 21047\n",
      "img id in: 21048\n",
      "img id out: 21048\n",
      "img id in: 21049\n",
      "img id out: 21049\n",
      "img id in: 21050\n",
      "img id out: 21050\n",
      "img id in: 21051\n",
      "img id out: 21051\n",
      "img id in: 21052\n",
      "img id out: 21052\n",
      "img id in: 21053\n",
      "img id out: 21053\n",
      "img id in: 21054\n",
      "img id out: 21054\n",
      "img id in: 21055\n",
      "img id out: 21055\n",
      "img id in: 21056\n",
      "img id out: 21056\n",
      "img id in: 21057\n",
      "img id out: 21057\n",
      "img id in: 21058\n",
      "img id out: 21058\n",
      "img id in: 21059\n",
      "img id out: 21059\n",
      "img id in: 21060\n",
      "img id out: 21060\n",
      "img id in: 21061\n",
      "img id out: 21061\n",
      "img id in: 21062\n",
      "img id out: 21062\n",
      "img id in: 21063\n",
      "img id out: 21063\n",
      "img id in: 21064\n",
      "img id out: 21064\n",
      "img id in: 21065\n",
      "img id out: 21065\n",
      "img id in: 21066\n",
      "img id out: 21066\n",
      "img id in: 21067\n",
      "img id out: 21067\n",
      "img id in: 21068\n",
      "img id out: 21068\n",
      "img id in: 21069\n",
      "img id out: 21069\n",
      "img id in: 21070\n",
      "img id out: 21070\n",
      "img id in: 21071\n",
      "img id out: 21071\n",
      "img id in: 21072\n",
      "img id out: 21072\n",
      "img id in: 21073\n",
      "img id out: 21073\n",
      "img id in: 21074\n",
      "img id out: 21074\n",
      "img id in: 21075\n",
      "img id out: 21075\n",
      "img id in: 21076\n",
      "img id out: 21076\n",
      "img id in: 21077\n",
      "img id out: 21077\n",
      "img id in: 21078\n",
      "img id out: 21078\n",
      "img id in: 21079\n",
      "img id out: 21079\n",
      "img id in: 21080\n",
      "img id out: 21080\n",
      "img id in: 21081\n",
      "img id out: 21081\n",
      "img id in: 21082\n",
      "img id out: 21082\n",
      "img id in: 21083\n",
      "img id out: 21083\n",
      "img id in: 21084\n",
      "img id out: 21084\n",
      "img id in: 21085\n",
      "img id out: 21085\n",
      "img id in: 21086\n",
      "img id out: 21086\n",
      "img id in: 21087\n",
      "img id out: 21087\n",
      "img id in: 21088\n",
      "img id out: 21088\n",
      "img id in: 21089\n",
      "img id out: 21089\n",
      "img id in: 21090\n",
      "img id out: 21090\n",
      "img id in: 21091\n",
      "img id out: 21091\n",
      "img id in: 21092\n",
      "img id out: 21092\n",
      "img id in: 21093\n",
      "img id out: 21093\n",
      "img id in: 21094\n",
      "img id out: 21094\n",
      "img id in: 21095\n",
      "img id out: 21095\n",
      "img id in: 21096\n",
      "img id out: 21096\n",
      "img id in: 21097\n",
      "img id out: 21097\n",
      "img id in: 21098\n",
      "img id out: 21098\n",
      "img id in: 21099\n",
      "img id out: 21099\n",
      "img id in: 21100\n",
      "img id out: 21100\n",
      "img id in: 21101\n",
      "img id out: 21101\n",
      "img id in: 21102\n",
      "img id out: 21102\n",
      "img id in: 21103\n",
      "img id out: 21103\n",
      "img id in: 21104\n",
      "img id out: 21104\n",
      "img id in: 21105\n",
      "img id out: 21105\n",
      "img id in: 21106\n",
      "img id out: 21106\n",
      "img id in: 21107\n",
      "img id out: 21107\n",
      "img id in: 21108\n",
      "img id out: 21108\n",
      "img id in: 21109\n",
      "img id out: 21109\n",
      "img id in: 21110\n",
      "img id out: 21110\n",
      "img id in: 21111\n",
      "img id out: 21111\n",
      "img id in: 21112\n",
      "img id out: 21112\n",
      "img id in: 21113\n",
      "img id out: 21113\n",
      "img id in: 21114\n",
      "img id out: 21114\n",
      "img id in: 21115\n",
      "img id out: 21115\n",
      "img id in: 21116\n",
      "img id out: 21116\n",
      "img id in: 21117\n",
      "img id out: 21117\n",
      "img id in: 21118\n",
      "img id out: 21118\n",
      "img id in: 21119\n",
      "img id out: 21119\n",
      "img id in: 21120\n",
      "img id out: 21120\n",
      "img id in: 21121\n",
      "img id out: 21121\n",
      "img id in: 21122\n",
      "img id out: 21122\n",
      "img id in: 21123\n",
      "img id out: 21123\n",
      "img id in: 21124\n",
      "img id out: 21124\n",
      "img id in: 21125\n",
      "img id out: 21125\n",
      "img id in: 21126\n",
      "img id out: 21126\n",
      "img id in: 21127\n",
      "img id out: 21127\n",
      "img id in: 21128\n",
      "img id out: 21128\n",
      "img id in: 21129\n",
      "img id out: 21129\n",
      "img id in: 21130\n",
      "img id out: 21130\n",
      "img id in: 21131\n",
      "img id out: 21131\n",
      "img id in: 21132\n",
      "img id out: 21132\n",
      "img id in: 21133\n",
      "img id out: 21133\n",
      "img id in: 21134\n",
      "img id out: 21134\n",
      "img id in: 21135\n",
      "img id out: 21135\n",
      "img id in: 21136\n",
      "img id out: 21136\n",
      "img id in: 21137\n",
      "img id out: 21137\n",
      "img id in: 21138\n",
      "img id out: 21138\n",
      "img id in: 21139\n",
      "img id out: 21139\n",
      "img id in: 21140\n",
      "img id out: 21140\n",
      "img id in: 21141\n",
      "img id out: 21141\n",
      "img id in: 21142\n",
      "img id out: 21142\n",
      "img id in: 21143\n",
      "img id out: 21143\n",
      "img id in: 21144\n",
      "img id out: 21144\n",
      "img id in: 21145\n",
      "img id out: 21145\n",
      "img id in: 21146\n",
      "img id out: 21146\n",
      "img id in: 21147\n",
      "img id out: 21147\n",
      "img id in: 21148\n",
      "img id out: 21148\n",
      "img id in: 21149\n",
      "img id out: 21149\n",
      "img id in: 21150\n",
      "img id out: 21150\n",
      "img id in: 21151\n",
      "img id out: 21151\n",
      "img id in: 21152\n",
      "img id out: 21152\n",
      "img id in: 21153\n",
      "img id out: 21153\n",
      "img id in: 21154\n",
      "img id out: 21154\n",
      "img id in: 21155\n",
      "img id out: 21155\n",
      "img id in: 21156\n",
      "img id out: 21156\n",
      "img id in: 21157\n",
      "img id out: 21157\n",
      "img id in: 21158\n",
      "img id out: 21158\n",
      "img id in: 21159\n",
      "img id out: 21159\n",
      "img id in: 21160\n",
      "img id out: 21160\n",
      "img id in: 21161\n",
      "img id out: 21161\n",
      "img id in: 21162\n",
      "img id out: 21162\n",
      "img id in: 21163\n",
      "img id out: 21163\n",
      "img id in: 21164\n",
      "img id out: 21164\n",
      "img id in: 21165\n",
      "img id out: 21165\n",
      "img id in: 21166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 21166\n",
      "img id in: 21167\n",
      "img id out: 21167\n",
      "img id in: 21168\n",
      "img id out: 21168\n",
      "img id in: 21169\n",
      "img id out: 21169\n",
      "img id in: 21170\n",
      "img id out: 21170\n",
      "img id in: 21171\n",
      "img id out: 21171\n",
      "img id in: 21172\n",
      "img id out: 21172\n",
      "img id in: 21173\n",
      "img id out: 21173\n",
      "img id in: 21174\n",
      "img id out: 21174\n",
      "img id in: 21175\n",
      "img id out: 21175\n",
      "img id in: 21176\n",
      "img id out: 21176\n",
      "img id in: 21177\n",
      "img id out: 21177\n",
      "img id in: 21178\n",
      "img id out: 21178\n",
      "img id in: 21179\n",
      "img id out: 21179\n",
      "img id in: 21180\n",
      "img id out: 21180\n",
      "img id in: 21181\n",
      "img id out: 21181\n",
      "img id in: 21182\n",
      "img id out: 21182\n",
      "img id in: 21183\n",
      "img id out: 21183\n",
      "img id in: 21184\n",
      "img id out: 21184\n",
      "img id in: 21185\n",
      "img id out: 21185\n",
      "img id in: 21186\n",
      "img id out: 21186\n",
      "img id in: 21187\n",
      "img id out: 21187\n",
      "img id in: 21188\n",
      "img id out: 21188\n",
      "img id in: 21189\n",
      "img id out: 21189\n",
      "img id in: 21190\n",
      "img id out: 21190\n",
      "img id in: 21191\n",
      "img id out: 21191\n",
      "img id in: 21192\n",
      "img id out: 21192\n",
      "img id in: 21193\n",
      "img id out: 21193\n",
      "img id in: 21194\n",
      "img id out: 21194\n",
      "img id in: 21195\n",
      "img id out: 21195\n",
      "img id in: 21196\n",
      "img id out: 21196\n",
      "img id in: 21197\n",
      "img id out: 21197\n",
      "img id in: 21198\n",
      "img id out: 21198\n",
      "img id in: 21199\n",
      "img id out: 21199\n",
      "img id in: 21200\n",
      "img id out: 21200\n",
      "img id in: 21201\n",
      "img id out: 21201\n",
      "img id in: 21202\n",
      "img id out: 21202\n",
      "img id in: 21203\n",
      "img id out: 21203\n",
      "img id in: 21204\n",
      "img id out: 21204\n",
      "img id in: 21205\n",
      "img id out: 21205\n",
      "img id in: 21206\n",
      "img id out: 21206\n",
      "img id in: 21207\n",
      "img id out: 21207\n",
      "img id in: 21208\n",
      "img id out: 21208\n",
      "img id in: 21209\n",
      "img id out: 21209\n",
      "img id in: 21210\n",
      "img id out: 21210\n",
      "img id in: 21211\n",
      "img id out: 21211\n",
      "img id in: 21212\n",
      "img id out: 21212\n",
      "img id in: 21213\n",
      "img id out: 21213\n",
      "img id in: 21214\n",
      "img id out: 21214\n",
      "img id in: 21215\n",
      "img id out: 21215\n",
      "img id in: 21216\n",
      "img id out: 21216\n",
      "img id in: 21217\n",
      "img id out: 21217\n",
      "img id in: 21218\n",
      "img id out: 21218\n",
      "img id in: 21219\n",
      "img id out: 21219\n",
      "img id in: 21220\n",
      "img id out: 21220\n",
      "img id in: 21221\n",
      "img id out: 21221\n",
      "img id in: 21222\n",
      "img id out: 21222\n",
      "img id in: 21223\n",
      "img id out: 21223\n",
      "img id in: 21224\n",
      "img id out: 21224\n",
      "img id in: 21225\n",
      "img id out: 21225\n",
      "img id in: 21226\n",
      "img id out: 21226\n",
      "img id in: 21227\n",
      "img id out: 21227\n",
      "img id in: 21228\n",
      "img id out: 21228\n",
      "img id in: 21229\n",
      "img id out: 21229\n",
      "img id in: 21230\n",
      "img id out: 21230\n",
      "img id in: 21231\n",
      "img id out: 21231\n",
      "img id in: 21232\n",
      "img id out: 21232\n",
      "img id in: 21233\n",
      "img id out: 21233\n",
      "img id in: 21234\n",
      "img id out: 21234\n",
      "img id in: 21235\n",
      "img id out: 21235\n",
      "img id in: 21236\n",
      "img id out: 21236\n",
      "img id in: 21237\n",
      "img id out: 21237\n",
      "img id in: 21238\n",
      "img id out: 21238\n",
      "img id in: 21239\n",
      "img id out: 21239\n",
      "img id in: 21240\n",
      "img id out: 21240\n",
      "img id in: 21241\n",
      "img id out: 21241\n",
      "img id in: 21242\n",
      "img id out: 21242\n",
      "img id in: 21243\n",
      "img id out: 21243\n",
      "img id in: 21244\n",
      "img id out: 21244\n",
      "img id in: 21245\n",
      "img id out: 21245\n",
      "img id in: 21246\n",
      "img id out: 21246\n",
      "img id in: 21247\n",
      "img id out: 21247\n",
      "img id in: 21248\n",
      "img id out: 21248\n",
      "img id in: 21249\n",
      "img id out: 21249\n",
      "img id in: 21250\n",
      "img id out: 21250\n",
      "img id in: 21251\n",
      "img id out: 21251\n",
      "img id in: 21252\n",
      "img id out: 21252\n",
      "img id in: 21253\n",
      "img id out: 21253\n",
      "img id in: 21254\n",
      "img id out: 21254\n",
      "img id in: 21255\n",
      "img id out: 21255\n",
      "img id in: 21256\n",
      "img id out: 21256\n",
      "img id in: 21257\n",
      "img id out: 21257\n",
      "img id in: 21258\n",
      "img id out: 21258\n",
      "img id in: 21259\n",
      "img id out: 21259\n",
      "img id in: 21260\n",
      "img id out: 21260\n",
      "img id in: 21261\n",
      "img id out: 21261\n",
      "img id in: 21262\n",
      "img id out: 21262\n",
      "img id in: 21263\n",
      "img id out: 21263\n",
      "img id in: 21264\n",
      "img id out: 21264\n",
      "img id in: 21265\n",
      "img id out: 21265\n",
      "img id in: 21266\n",
      "img id out: 21266\n",
      "img id in: 21267\n",
      "img id out: 21267\n",
      "img id in: 21268\n",
      "img id out: 21268\n",
      "img id in: 21269\n",
      "img id out: 21269\n",
      "img id in: 21270\n",
      "img id out: 21270\n",
      "img id in: 21271\n",
      "img id out: 21271\n",
      "img id in: 21272\n",
      "img id out: 21272\n",
      "img id in: 21273\n",
      "img id out: 21273\n",
      "img id in: 21274\n",
      "img id out: 21274\n",
      "img id in: 21275\n",
      "img id out: 21275\n",
      "img id in: 21276\n",
      "img id out: 21276\n",
      "img id in: 21277\n",
      "img id out: 21277\n",
      "img id in: 21278\n",
      "img id out: 21278\n",
      "img id in: 21279\n",
      "img id out: 21279\n",
      "img id in: 21280\n",
      "img id out: 21280\n",
      "img id in: 21281\n",
      "img id out: 21281\n",
      "img id in: 21282\n",
      "img id out: 21282\n",
      "img id in: 21283\n",
      "img id out: 21283\n",
      "img id in: 21284\n",
      "img id out: 21284\n",
      "img id in: 21285\n",
      "img id out: 21285\n",
      "img id in: 21286\n",
      "img id out: 21286\n",
      "img id in: 21287\n",
      "img id out: 21287\n",
      "img id in: 21288\n",
      "img id out: 21288\n",
      "img id in: 21289\n",
      "img id out: 21289\n",
      "img id in: 21290\n",
      "img id out: 21290\n",
      "img id in: 21291\n",
      "img id out: 21291\n",
      "img id in: 21292\n",
      "img id out: 21292\n",
      "img id in: 21293\n",
      "img id out: 21293\n",
      "img id in: 21294\n",
      "img id out: 21294\n",
      "img id in: 21295\n",
      "img id out: 21295\n",
      "img id in: 21296\n",
      "img id out: 21296\n",
      "img id in: 21297\n",
      "img id out: 21297\n",
      "img id in: 21298\n",
      "img id out: 21298\n",
      "img id in: 21299\n",
      "img id out: 21299\n",
      "img id in: 21300\n",
      "img id out: 21300\n",
      "img id in: 21301\n",
      "img id out: 21301\n",
      "img id in: 21302\n",
      "img id out: 21302\n",
      "img id in: 21303\n",
      "img id out: 21303\n",
      "img id in: 21304\n",
      "img id out: 21304\n",
      "img id in: 21305\n",
      "img id out: 21305\n",
      "img id in: 21306\n",
      "img id out: 21306\n",
      "img id in: 21307\n",
      "img id out: 21307\n",
      "img id in: 21308\n",
      "img id out: 21308\n",
      "img id in: 21309\n",
      "img id out: 21309\n",
      "img id in: 21310\n",
      "img id out: 21310\n",
      "img id in: 21311\n",
      "img id out: 21311\n",
      "img id in: 21312\n",
      "img id out: 21312\n",
      "img id in: 21313\n",
      "img id out: 21313\n",
      "img id in: 21314\n",
      "img id out: 21314\n",
      "img id in: 21315\n",
      "img id out: 21315\n",
      "img id in: 21316\n",
      "img id out: 21316\n",
      "img id in: 21317\n",
      "img id out: 21317\n",
      "img id in: 21318\n",
      "img id out: 21318\n",
      "img id in: 21319\n",
      "img id out: 21319\n",
      "img id in: 21320\n",
      "img id out: 21320\n",
      "img id in: 21321\n",
      "img id out: 21321\n",
      "img id in: 21322\n",
      "img id out: 21322\n",
      "img id in: 21323\n",
      "img id out: 21323\n",
      "img id in: 21324\n",
      "img id out: 21324\n",
      "img id in: 21325\n",
      "img id out: 21325\n",
      "img id in: 21326\n",
      "img id out: 21326\n",
      "img id in: 21327\n",
      "img id out: 21327\n",
      "img id in: 21328\n",
      "img id out: 21328\n",
      "img id in: 21329\n",
      "img id out: 21329\n",
      "img id in: 21330\n",
      "img id out: 21330\n",
      "img id in: 21331\n",
      "img id out: 21331\n",
      "img id in: 21332\n",
      "img id out: 21332\n",
      "img id in: 21333\n",
      "img id out: 21333\n",
      "img id in: 21334\n",
      "img id out: 21334\n",
      "img id in: 21335\n",
      "img id out: 21335\n",
      "img id in: 21336\n",
      "img id out: 21336\n",
      "img id in: 21337\n",
      "img id out: 21337\n",
      "img id in: 21338\n",
      "img id out: 21338\n",
      "img id in: 21339\n",
      "img id out: 21339\n",
      "img id in: 21340\n",
      "img id out: 21340\n",
      "img id in: 21341\n",
      "img id out: 21341\n",
      "img id in: 21342\n",
      "img id out: 21342\n",
      "img id in: 21343\n",
      "img id out: 21343\n",
      "img id in: 21344\n",
      "img id out: 21344\n",
      "img id in: 21345\n",
      "img id out: 21345\n",
      "img id in: 21346\n",
      "img id out: 21346\n",
      "img id in: 21347\n",
      "img id out: 21347\n",
      "img id in: 21348\n",
      "img id out: 21348\n",
      "img id in: 21349\n",
      "img id out: 21349\n",
      "img id in: 21350\n",
      "img id out: 21350\n",
      "img id in: 21351\n",
      "img id out: 21351\n",
      "img id in: 21352\n",
      "img id out: 21352\n",
      "img id in: 21353\n",
      "img id out: 21353\n",
      "img id in: 21354\n",
      "img id out: 21354\n",
      "img id in: 21355\n",
      "img id out: 21355\n",
      "img id in: 21356\n",
      "img id out: 21356\n",
      "img id in: 21357\n",
      "img id out: 21357\n",
      "img id in: 21358\n",
      "img id out: 21358\n",
      "img id in: 21359\n",
      "img id out: 21359\n",
      "img id in: 21360\n",
      "img id out: 21360\n",
      "img id in: 21361\n",
      "img id out: 21361\n",
      "img id in: 21362\n",
      "img id out: 21362\n",
      "img id in: 21363\n",
      "img id out: 21363\n",
      "img id in: 21364\n",
      "img id out: 21364\n",
      "img id in: 21365\n",
      "img id out: 21365\n",
      "img id in: 21366\n",
      "img id out: 21366\n",
      "img id in: 21367\n",
      "img id out: 21367\n",
      "img id in: 21368\n",
      "img id out: 21368\n",
      "img id in: 21369\n",
      "img id out: 21369\n",
      "img id in: 21370\n",
      "img id out: 21370\n",
      "img id in: 21371\n",
      "img id out: 21371\n",
      "img id in: 21372\n",
      "img id out: 21372\n",
      "img id in: 21373\n",
      "img id out: 21373\n",
      "img id in: 21374\n",
      "img id out: 21374\n",
      "img id in: 21375\n",
      "img id out: 21375\n",
      "img id in: 21376\n",
      "img id out: 21376\n",
      "img id in: 21377\n",
      "img id out: 21377\n",
      "img id in: 21378\n",
      "img id out: 21378\n",
      "img id in: 21379\n",
      "img id out: 21379\n",
      "img id in: 21380\n",
      "img id out: 21380\n",
      "img id in: 21381\n",
      "img id out: 21381\n",
      "img id in: 21382\n",
      "img id out: 21382\n",
      "img id in: 21383\n",
      "img id out: 21383\n",
      "img id in: 21384\n",
      "img id out: 21384\n",
      "img id in: 21385\n",
      "img id out: 21385\n",
      "img id in: 21386\n",
      "img id out: 21386\n",
      "img id in: 21387\n",
      "img id out: 21387\n",
      "img id in: 21388\n",
      "img id out: 21388\n",
      "img id in: 21389\n",
      "img id out: 21389\n",
      "img id in: 21390\n",
      "img id out: 21390\n",
      "img id in: 21391\n",
      "img id out: 21391\n",
      "img id in: 21392\n",
      "img id out: 21392\n",
      "img id in: 21393\n",
      "img id out: 21393\n",
      "img id in: 21394\n",
      "img id out: 21394\n",
      "img id in: 21395\n",
      "img id out: 21395\n",
      "img id in: 21396\n",
      "img id out: 21396\n",
      "img id in: 21397\n",
      "img id out: 21397\n",
      "img id in: 21398\n",
      "img id out: 21398\n",
      "img id in: 21399\n",
      "img id out: 21399\n",
      "img id in: 21400\n",
      "img id out: 21400\n",
      "img id in: 21401\n",
      "img id out: 21401\n",
      "img id in: 21402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 21402\n",
      "img id in: 21403\n",
      "img id out: 21403\n",
      "img id in: 21404\n",
      "img id out: 21404\n",
      "img id in: 21405\n",
      "img id out: 21405\n",
      "img id in: 21406\n",
      "img id out: 21406\n",
      "img id in: 21407\n",
      "img id out: 21407\n",
      "img id in: 21408\n",
      "img id out: 21408\n",
      "img id in: 21409\n",
      "img id out: 21409\n",
      "img id in: 21410\n",
      "img id out: 21410\n",
      "img id in: 21411\n",
      "img id out: 21411\n",
      "img id in: 21412\n",
      "img id out: 21412\n",
      "img id in: 21413\n",
      "img id out: 21413\n",
      "img id in: 21414\n",
      "img id out: 21414\n",
      "img id in: 21415\n",
      "img id out: 21415\n",
      "img id in: 21416\n",
      "img id out: 21416\n",
      "img id in: 21417\n",
      "img id out: 21417\n",
      "img id in: 21418\n",
      "img id out: 21418\n",
      "img id in: 21419\n",
      "img id out: 21419\n",
      "img id in: 21420\n",
      "img id out: 21420\n",
      "img id in: 21421\n",
      "img id out: 21421\n",
      "img id in: 21422\n",
      "img id out: 21422\n",
      "img id in: 21423\n",
      "img id out: 21423\n",
      "img id in: 21424\n",
      "img id out: 21424\n",
      "img id in: 21425\n",
      "img id out: 21425\n",
      "img id in: 21426\n",
      "img id out: 21426\n",
      "img id in: 21427\n",
      "img id out: 21427\n",
      "img id in: 21428\n",
      "img id out: 21428\n",
      "img id in: 21429\n",
      "img id out: 21429\n",
      "img id in: 21430\n",
      "img id out: 21430\n",
      "img id in: 21431\n",
      "img id out: 21431\n",
      "img id in: 21432\n",
      "img id out: 21432\n",
      "img id in: 21433\n",
      "img id out: 21433\n",
      "img id in: 21434\n",
      "img id out: 21434\n",
      "img id in: 21435\n",
      "img id out: 21435\n",
      "img id in: 21436\n",
      "img id out: 21436\n",
      "img id in: 21437\n",
      "img id out: 21437\n",
      "img id in: 21438\n",
      "img id out: 21438\n",
      "img id in: 21439\n",
      "img id out: 21439\n",
      "img id in: 21440\n",
      "img id out: 21440\n",
      "img id in: 21441\n",
      "img id out: 21441\n",
      "img id in: 21442\n",
      "img id out: 21442\n",
      "img id in: 21443\n",
      "img id out: 21443\n",
      "img id in: 21444\n",
      "img id out: 21444\n",
      "img id in: 21445\n",
      "img id out: 21445\n",
      "img id in: 21446\n",
      "img id out: 21446\n",
      "img id in: 21447\n",
      "img id out: 21447\n",
      "img id in: 21448\n",
      "img id out: 21448\n",
      "img id in: 21449\n",
      "img id out: 21449\n",
      "img id in: 21450\n",
      "img id out: 21450\n",
      "img id in: 21451\n",
      "img id out: 21451\n",
      "img id in: 21452\n",
      "img id out: 21452\n",
      "img id in: 21453\n",
      "img id out: 21453\n",
      "img id in: 21454\n",
      "img id out: 21454\n",
      "img id in: 21455\n",
      "img id out: 21455\n",
      "img id in: 21456\n",
      "img id out: 21456\n",
      "img id in: 21457\n",
      "img id out: 21457\n",
      "img id in: 21458\n",
      "img id out: 21458\n",
      "img id in: 21459\n",
      "img id out: 21459\n",
      "img id in: 21460\n",
      "img id out: 21460\n",
      "img id in: 21461\n",
      "img id out: 21461\n",
      "img id in: 21462\n",
      "img id out: 21462\n",
      "img id in: 21463\n",
      "img id out: 21463\n",
      "img id in: 21464\n",
      "img id out: 21464\n",
      "img id in: 21465\n",
      "img id out: 21465\n",
      "img id in: 21466\n",
      "img id out: 21466\n",
      "img id in: 21467\n",
      "img id out: 21467\n",
      "img id in: 21468\n",
      "img id out: 21468\n",
      "img id in: 21469\n",
      "img id out: 21469\n",
      "img id in: 21470\n",
      "img id out: 21470\n",
      "img id in: 21471\n",
      "img id out: 21471\n",
      "img id in: 21472\n",
      "img id out: 21472\n",
      "img id in: 21473\n",
      "img id out: 21473\n",
      "img id in: 21474\n",
      "img id out: 21474\n",
      "img id in: 21475\n",
      "img id out: 21475\n",
      "img id in: 21476\n",
      "img id out: 21476\n",
      "img id in: 21477\n",
      "img id out: 21477\n",
      "img id in: 21478\n",
      "img id out: 21478\n",
      "img id in: 21479\n",
      "img id out: 21479\n",
      "img id in: 21480\n",
      "img id out: 21480\n",
      "img id in: 21481\n",
      "img id out: 21481\n",
      "img id in: 21482\n",
      "img id out: 21482\n",
      "img id in: 21483\n",
      "img id out: 21483\n",
      "img id in: 21484\n",
      "img id out: 21484\n",
      "img id in: 21485\n",
      "img id out: 21485\n",
      "img id in: 21486\n",
      "img id out: 21486\n",
      "img id in: 21487\n",
      "img id out: 21487\n",
      "img id in: 21488\n",
      "img id out: 21488\n",
      "img id in: 21489\n",
      "img id out: 21489\n",
      "img id in: 21490\n",
      "img id out: 21490\n",
      "img id in: 21491\n",
      "img id out: 21491\n",
      "img id in: 21492\n",
      "img id out: 21492\n",
      "img id in: 21493\n",
      "img id out: 21493\n",
      "img id in: 21494\n",
      "img id out: 21494\n",
      "img id in: 21495\n",
      "img id out: 21495\n",
      "img id in: 21496\n",
      "img id out: 21496\n",
      "img id in: 21497\n",
      "img id out: 21497\n",
      "img id in: 21498\n",
      "img id out: 21498\n",
      "img id in: 21499\n",
      "img id out: 21499\n",
      "img id in: 21500\n",
      "img id out: 21500\n",
      "img id in: 21501\n",
      "img id out: 21501\n",
      "img id in: 21502\n",
      "img id out: 21502\n",
      "img id in: 21503\n",
      "img id out: 21503\n",
      "img id in: 21504\n",
      "img id out: 21504\n",
      "img id in: 21505\n",
      "img id out: 21505\n",
      "img id in: 21506\n",
      "img id out: 21506\n",
      "img id in: 21507\n",
      "img id out: 21507\n",
      "img id in: 21508\n",
      "img id out: 21508\n",
      "img id in: 21509\n",
      "img id out: 21509\n",
      "img id in: 21510\n",
      "img id out: 21510\n",
      "img id in: 21511\n",
      "img id out: 21511\n",
      "img id in: 21512\n",
      "img id out: 21512\n",
      "img id in: 21513\n",
      "img id out: 21513\n",
      "img id in: 21514\n",
      "img id out: 21514\n",
      "img id in: 21515\n",
      "img id out: 21515\n",
      "img id in: 21516\n",
      "img id out: 21516\n",
      "img id in: 21517\n",
      "img id out: 21517\n",
      "img id in: 21518\n",
      "img id out: 21518\n",
      "img id in: 21519\n",
      "img id out: 21519\n",
      "img id in: 21520\n",
      "img id out: 21520\n",
      "img id in: 21521\n",
      "img id out: 21521\n",
      "img id in: 21522\n",
      "img id out: 21522\n",
      "img id in: 21523\n",
      "img id out: 21523\n",
      "img id in: 21524\n",
      "img id out: 21524\n",
      "img id in: 21525\n",
      "img id out: 21525\n",
      "img id in: 21526\n",
      "img id out: 21526\n",
      "img id in: 21527\n",
      "img id out: 21527\n",
      "img id in: 21528\n",
      "img id out: 21528\n",
      "img id in: 21529\n",
      "img id out: 21529\n",
      "img id in: 21530\n",
      "img id out: 21530\n",
      "img id in: 21531\n",
      "img id out: 21531\n",
      "img id in: 21532\n",
      "img id out: 21532\n",
      "img id in: 21533\n",
      "img id out: 21533\n",
      "img id in: 21534\n",
      "img id out: 21534\n",
      "img id in: 21535\n",
      "img id out: 21535\n",
      "img id in: 21536\n",
      "img id out: 21536\n",
      "img id in: 21537\n",
      "img id out: 21537\n",
      "img id in: 21538\n",
      "img id out: 21538\n",
      "img id in: 21539\n",
      "img id out: 21539\n",
      "img id in: 21540\n",
      "img id out: 21540\n",
      "img id in: 21541\n",
      "img id out: 21541\n",
      "img id in: 21542\n",
      "img id out: 21542\n",
      "img id in: 21543\n",
      "img id out: 21543\n",
      "img id in: 21544\n",
      "img id out: 21544\n",
      "img id in: 21545\n",
      "img id out: 21545\n",
      "img id in: 21546\n",
      "img id out: 21546\n",
      "img id in: 21547\n",
      "img id out: 21547\n",
      "img id in: 21548\n",
      "img id out: 21548\n",
      "img id in: 21549\n",
      "img id out: 21549\n",
      "img id in: 21550\n",
      "img id out: 21550\n",
      "img id in: 21551\n",
      "img id out: 21551\n",
      "img id in: 21552\n",
      "img id out: 21552\n",
      "img id in: 21553\n",
      "img id out: 21553\n",
      "img id in: 21554\n",
      "img id out: 21554\n",
      "img id in: 21555\n",
      "img id out: 21555\n",
      "img id in: 21556\n",
      "img id out: 21556\n",
      "img id in: 21557\n",
      "img id out: 21557\n",
      "img id in: 21558\n",
      "img id out: 21558\n",
      "img id in: 21559\n",
      "img id out: 21559\n",
      "img id in: 21560\n",
      "img id out: 21560\n",
      "img id in: 21561\n",
      "img id out: 21561\n",
      "img id in: 21562\n",
      "img id out: 21562\n",
      "img id in: 21563\n",
      "img id out: 21563\n",
      "img id in: 21564\n",
      "img id out: 21564\n",
      "img id in: 21565\n",
      "img id out: 21565\n",
      "img id in: 21566\n",
      "img id out: 21566\n",
      "img id in: 21567\n",
      "img id out: 21567\n",
      "img id in: 21568\n",
      "img id out: 21568\n",
      "img id in: 21569\n",
      "img id out: 21569\n",
      "img id in: 21570\n",
      "img id out: 21570\n",
      "img id in: 21571\n",
      "img id out: 21571\n",
      "img id in: 21572\n",
      "img id out: 21572\n",
      "img id in: 21573\n",
      "img id out: 21573\n",
      "img id in: 21574\n",
      "img id out: 21574\n",
      "img id in: 21575\n",
      "img id out: 21575\n",
      "img id in: 21576\n",
      "img id out: 21576\n",
      "img id in: 21577\n",
      "img id out: 21577\n",
      "img id in: 21578\n",
      "img id out: 21578\n",
      "img id in: 21579\n",
      "img id out: 21579\n",
      "img id in: 21580\n",
      "img id out: 21580\n",
      "img id in: 21581\n",
      "img id out: 21581\n",
      "img id in: 21582\n",
      "img id out: 21582\n",
      "img id in: 21583\n",
      "img id out: 21583\n",
      "img id in: 21584\n",
      "img id out: 21584\n",
      "img id in: 21585\n",
      "img id out: 21585\n",
      "img id in: 21586\n",
      "img id out: 21586\n",
      "img id in: 21587\n",
      "img id out: 21587\n",
      "img id in: 21588\n",
      "img id out: 21588\n",
      "img id in: 21589\n",
      "img id out: 21589\n",
      "img id in: 21590\n",
      "img id out: 21590\n",
      "img id in: 21591\n",
      "img id out: 21591\n",
      "img id in: 21592\n",
      "img id out: 21592\n",
      "img id in: 21593\n",
      "img id out: 21593\n",
      "img id in: 21594\n",
      "img id out: 21594\n",
      "img id in: 21595\n",
      "img id out: 21595\n",
      "img id in: 21596\n",
      "img id out: 21596\n",
      "img id in: 21597\n",
      "img id out: 21597\n",
      "img id in: 21598\n",
      "img id out: 21598\n",
      "img id in: 21599\n",
      "img id out: 21599\n",
      "img id in: 21600\n",
      "img id out: 21600\n",
      "img id in: 21601\n",
      "img id out: 21601\n",
      "img id in: 21602\n",
      "img id out: 21602\n",
      "img id in: 21603\n",
      "img id out: 21603\n",
      "img id in: 21604\n",
      "img id out: 21604\n",
      "img id in: 21605\n",
      "img id out: 21605\n",
      "img id in: 21606\n",
      "img id out: 21606\n",
      "img id in: 21607\n",
      "img id out: 21607\n",
      "img id in: 21608\n",
      "img id out: 21608\n",
      "img id in: 21609\n",
      "img id out: 21609\n",
      "img id in: 21610\n",
      "img id out: 21610\n",
      "img id in: 21611\n",
      "img id out: 21611\n",
      "img id in: 21612\n",
      "img id out: 21612\n",
      "img id in: 21613\n",
      "img id out: 21613\n",
      "img id in: 21614\n",
      "img id out: 21614\n",
      "img id in: 21615\n",
      "img id out: 21615\n",
      "img id in: 21616\n",
      "img id out: 21616\n",
      "img id in: 21617\n",
      "img id out: 21617\n",
      "img id in: 21618\n",
      "img id out: 21618\n",
      "img id in: 21619\n",
      "img id out: 21619\n",
      "img id in: 21620\n",
      "img id out: 21620\n",
      "img id in: 21621\n",
      "img id out: 21621\n",
      "img id in: 21622\n",
      "img id out: 21622\n",
      "img id in: 21623\n",
      "img id out: 21623\n",
      "img id in: 21624\n",
      "img id out: 21624\n",
      "img id in: 21625\n",
      "img id out: 21625\n",
      "img id in: 21626\n",
      "img id out: 21626\n",
      "img id in: 21627\n",
      "img id out: 21627\n",
      "img id in: 21628\n",
      "img id out: 21628\n",
      "img id in: 21629\n",
      "img id out: 21629\n",
      "img id in: 21630\n",
      "img id out: 21630\n",
      "img id in: 21631\n",
      "img id out: 21631\n",
      "img id in: 21632\n",
      "img id out: 21632\n",
      "img id in: 21633\n",
      "img id out: 21633\n",
      "img id in: 21634\n",
      "img id out: 21634\n",
      "img id in: 21635\n",
      "img id out: 21635\n",
      "img id in: 21636\n",
      "img id out: 21636\n",
      "img id in: 21637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 21637\n",
      "img id in: 21638\n",
      "img id out: 21638\n",
      "img id in: 21639\n",
      "img id out: 21639\n",
      "img id in: 21640\n",
      "img id out: 21640\n",
      "img id in: 21641\n",
      "img id out: 21641\n",
      "img id in: 21642\n",
      "img id out: 21642\n",
      "img id in: 21643\n",
      "img id out: 21643\n",
      "img id in: 21644\n",
      "img id out: 21644\n",
      "img id in: 21645\n",
      "img id out: 21645\n",
      "img id in: 21646\n",
      "img id out: 21646\n",
      "img id in: 21647\n",
      "img id out: 21647\n",
      "img id in: 21648\n",
      "img id out: 21648\n",
      "img id in: 21649\n",
      "img id out: 21649\n",
      "img id in: 21650\n",
      "img id out: 21650\n",
      "img id in: 21651\n",
      "img id out: 21651\n",
      "img id in: 21652\n",
      "img id out: 21652\n",
      "img id in: 21653\n",
      "img id out: 21653\n",
      "img id in: 21654\n",
      "img id out: 21654\n",
      "img id in: 21655\n",
      "img id out: 21655\n",
      "img id in: 21656\n",
      "img id out: 21656\n",
      "img id in: 21657\n",
      "img id out: 21657\n",
      "img id in: 21658\n",
      "img id out: 21658\n",
      "img id in: 21659\n",
      "img id out: 21659\n",
      "img id in: 21660\n",
      "img id out: 21660\n",
      "img id in: 21661\n",
      "img id out: 21661\n",
      "img id in: 21662\n",
      "img id out: 21662\n",
      "img id in: 21663\n",
      "img id out: 21663\n",
      "img id in: 21664\n",
      "img id out: 21664\n",
      "img id in: 21665\n",
      "img id out: 21665\n",
      "img id in: 21666\n",
      "img id out: 21666\n",
      "img id in: 21667\n",
      "img id out: 21667\n",
      "img id in: 21668\n",
      "img id out: 21668\n",
      "img id in: 21669\n",
      "img id out: 21669\n",
      "img id in: 21670\n",
      "img id out: 21670\n",
      "img id in: 21671\n",
      "img id out: 21671\n",
      "img id in: 21672\n",
      "img id out: 21672\n",
      "img id in: 21673\n",
      "img id out: 21673\n",
      "img id in: 21674\n",
      "img id out: 21674\n",
      "img id in: 21675\n",
      "img id out: 21675\n",
      "img id in: 21676\n",
      "img id out: 21676\n",
      "img id in: 21677\n",
      "img id out: 21677\n",
      "img id in: 21678\n",
      "img id out: 21678\n",
      "img id in: 21679\n",
      "img id out: 21679\n",
      "img id in: 21680\n",
      "img id out: 21680\n",
      "img id in: 21681\n",
      "img id out: 21681\n",
      "img id in: 21682\n",
      "img id out: 21682\n",
      "img id in: 21683\n",
      "img id out: 21683\n",
      "img id in: 21684\n",
      "img id out: 21684\n",
      "img id in: 21685\n",
      "img id out: 21685\n",
      "img id in: 21686\n",
      "img id out: 21686\n",
      "img id in: 21687\n",
      "img id out: 21687\n",
      "img id in: 21688\n",
      "img id out: 21688\n",
      "img id in: 21689\n",
      "img id out: 21689\n",
      "img id in: 21690\n",
      "img id out: 21690\n",
      "img id in: 21691\n",
      "img id out: 21691\n",
      "img id in: 21692\n",
      "img id out: 21692\n",
      "img id in: 21693\n",
      "img id out: 21693\n",
      "img id in: 21694\n",
      "img id out: 21694\n",
      "img id in: 21695\n",
      "img id out: 21695\n",
      "img id in: 21696\n",
      "img id out: 21696\n",
      "img id in: 21697\n",
      "img id out: 21697\n",
      "img id in: 21698\n",
      "img id out: 21698\n",
      "img id in: 21699\n",
      "img id out: 21699\n",
      "img id in: 21700\n",
      "img id out: 21700\n",
      "img id in: 21701\n",
      "img id out: 21701\n",
      "img id in: 21702\n",
      "img id out: 21702\n",
      "img id in: 21703\n",
      "img id out: 21703\n",
      "img id in: 21704\n",
      "img id out: 21704\n",
      "img id in: 21705\n",
      "img id out: 21705\n",
      "img id in: 21706\n",
      "img id out: 21706\n",
      "img id in: 21707\n",
      "img id out: 21707\n",
      "img id in: 21708\n",
      "img id out: 21708\n",
      "img id in: 21709\n",
      "img id out: 21709\n",
      "img id in: 21710\n",
      "img id out: 21710\n",
      "img id in: 21711\n",
      "img id out: 21711\n",
      "img id in: 21712\n",
      "img id out: 21712\n",
      "img id in: 21713\n",
      "img id out: 21713\n",
      "img id in: 21714\n",
      "img id out: 21714\n",
      "img id in: 21715\n",
      "img id out: 21715\n",
      "img id in: 21716\n",
      "img id out: 21716\n",
      "img id in: 21717\n",
      "img id out: 21717\n",
      "img id in: 21718\n",
      "img id out: 21718\n",
      "img id in: 21719\n",
      "img id out: 21719\n",
      "img id in: 21720\n",
      "img id out: 21720\n",
      "img id in: 21721\n",
      "img id out: 21721\n",
      "img id in: 21722\n",
      "img id out: 21722\n",
      "img id in: 21723\n",
      "img id out: 21723\n",
      "img id in: 21724\n",
      "img id out: 21724\n",
      "img id in: 21725\n",
      "img id out: 21725\n",
      "img id in: 21726\n",
      "img id out: 21726\n",
      "img id in: 21727\n",
      "img id out: 21727\n",
      "img id in: 21728\n",
      "img id out: 21728\n",
      "img id in: 21729\n",
      "img id out: 21729\n",
      "img id in: 21730\n",
      "img id out: 21730\n",
      "img id in: 21731\n",
      "img id out: 21731\n",
      "img id in: 21732\n",
      "img id out: 21732\n",
      "img id in: 21733\n",
      "img id out: 21733\n",
      "img id in: 21734\n",
      "img id out: 21734\n",
      "img id in: 21735\n",
      "img id out: 21735\n",
      "img id in: 21736\n",
      "img id out: 21736\n",
      "img id in: 21737\n",
      "img id out: 21737\n",
      "img id in: 21738\n",
      "img id out: 21738\n",
      "img id in: 21739\n",
      "img id out: 21739\n",
      "img id in: 21740\n",
      "img id out: 21740\n",
      "img id in: 21741\n",
      "img id out: 21741\n",
      "img id in: 21742\n",
      "img id out: 21742\n",
      "img id in: 21743\n",
      "img id out: 21743\n",
      "img id in: 21744\n",
      "img id out: 21744\n",
      "img id in: 21745\n",
      "img id out: 21745\n",
      "img id in: 21746\n",
      "img id out: 21746\n",
      "img id in: 21747\n",
      "img id out: 21747\n",
      "img id in: 21748\n",
      "img id out: 21748\n",
      "img id in: 21749\n",
      "img id out: 21749\n",
      "img id in: 21750\n",
      "img id out: 21750\n",
      "img id in: 21751\n",
      "img id out: 21751\n",
      "img id in: 21752\n",
      "img id out: 21752\n",
      "img id in: 21753\n",
      "img id out: 21753\n",
      "img id in: 21754\n",
      "img id out: 21754\n",
      "img id in: 21755\n",
      "img id out: 21755\n",
      "img id in: 21756\n",
      "img id out: 21756\n",
      "img id in: 21757\n",
      "img id out: 21757\n",
      "img id in: 21758\n",
      "img id out: 21758\n",
      "img id in: 21759\n",
      "img id out: 21759\n",
      "img id in: 21760\n",
      "img id out: 21760\n",
      "img id in: 21761\n",
      "img id out: 21761\n",
      "img id in: 21762\n",
      "img id out: 21762\n",
      "img id in: 21763\n",
      "img id out: 21763\n",
      "img id in: 21764\n",
      "img id out: 21764\n",
      "img id in: 21765\n",
      "img id out: 21765\n",
      "img id in: 21766\n",
      "img id out: 21766\n",
      "img id in: 21767\n",
      "img id out: 21767\n",
      "img id in: 21768\n",
      "img id out: 21768\n",
      "img id in: 21769\n",
      "img id out: 21769\n",
      "img id in: 21770\n",
      "img id out: 21770\n",
      "img id in: 21771\n",
      "img id out: 21771\n",
      "img id in: 21772\n",
      "img id out: 21772\n",
      "img id in: 21773\n",
      "img id out: 21773\n",
      "img id in: 21774\n",
      "img id out: 21774\n",
      "img id in: 21775\n",
      "img id out: 21775\n",
      "img id in: 21776\n",
      "img id out: 21776\n",
      "img id in: 21777\n",
      "img id out: 21777\n",
      "img id in: 21778\n",
      "img id out: 21778\n",
      "img id in: 21779\n",
      "img id out: 21779\n",
      "img id in: 21780\n",
      "img id out: 21780\n",
      "img id in: 21781\n",
      "img id out: 21781\n",
      "img id in: 21782\n",
      "img id out: 21782\n",
      "img id in: 21783\n",
      "img id out: 21783\n",
      "img id in: 21784\n",
      "img id out: 21784\n",
      "img id in: 21785\n",
      "img id out: 21785\n",
      "img id in: 21786\n",
      "img id out: 21786\n",
      "img id in: 21787\n",
      "img id out: 21787\n",
      "img id in: 21788\n",
      "img id out: 21788\n",
      "img id in: 21789\n",
      "img id out: 21789\n",
      "img id in: 21790\n",
      "img id out: 21790\n",
      "img id in: 21791\n",
      "img id out: 21791\n",
      "img id in: 21792\n",
      "img id out: 21792\n",
      "img id in: 21793\n",
      "img id out: 21793\n",
      "img id in: 21794\n",
      "img id out: 21794\n",
      "img id in: 21795\n",
      "img id out: 21795\n",
      "img id in: 21796\n",
      "img id out: 21796\n",
      "img id in: 21797\n",
      "img id out: 21797\n",
      "img id in: 21798\n",
      "img id out: 21798\n",
      "img id in: 21799\n",
      "img id out: 21799\n",
      "img id in: 21800\n",
      "img id out: 21800\n",
      "img id in: 21801\n",
      "img id out: 21801\n",
      "img id in: 21802\n",
      "img id out: 21802\n",
      "img id in: 21803\n",
      "img id out: 21803\n",
      "img id in: 21804\n",
      "img id out: 21804\n",
      "img id in: 21805\n",
      "img id out: 21805\n",
      "img id in: 21806\n",
      "img id out: 21806\n",
      "img id in: 21807\n",
      "img id out: 21807\n",
      "img id in: 21808\n",
      "img id out: 21808\n",
      "img id in: 21809\n",
      "img id out: 21809\n",
      "img id in: 21810\n",
      "img id out: 21810\n",
      "img id in: 21811\n",
      "img id out: 21811\n",
      "img id in: 21812\n",
      "img id out: 21812\n",
      "img id in: 21813\n",
      "img id out: 21813\n",
      "img id in: 21814\n",
      "img id out: 21814\n",
      "img id in: 21815\n",
      "img id out: 21815\n",
      "img id in: 21816\n",
      "img id out: 21816\n",
      "img id in: 21817\n",
      "img id out: 21817\n",
      "img id in: 21818\n",
      "img id out: 21818\n",
      "img id in: 21819\n",
      "img id out: 21819\n",
      "img id in: 21820\n",
      "img id out: 21820\n",
      "img id in: 21821\n",
      "img id out: 21821\n",
      "img id in: 21822\n",
      "img id out: 21822\n",
      "img id in: 21823\n",
      "img id out: 21823\n",
      "img id in: 21824\n",
      "img id out: 21824\n",
      "img id in: 21825\n",
      "img id out: 21825\n",
      "img id in: 21826\n",
      "img id out: 21826\n",
      "img id in: 21827\n",
      "img id out: 21827\n",
      "img id in: 21828\n",
      "img id out: 21828\n",
      "img id in: 21829\n",
      "img id out: 21829\n",
      "img id in: 21830\n",
      "img id out: 21830\n",
      "img id in: 21831\n",
      "img id out: 21831\n",
      "img id in: 21832\n",
      "img id out: 21832\n",
      "img id in: 21833\n",
      "img id out: 21833\n",
      "img id in: 21834\n",
      "img id out: 21834\n",
      "img id in: 21835\n",
      "img id out: 21835\n",
      "img id in: 21836\n",
      "img id out: 21836\n",
      "img id in: 21837\n",
      "img id out: 21837\n",
      "img id in: 21838\n",
      "img id out: 21838\n",
      "img id in: 21839\n",
      "img id out: 21839\n",
      "img id in: 21840\n",
      "img id out: 21840\n",
      "img id in: 21841\n",
      "img id out: 21841\n",
      "img id in: 21842\n",
      "img id out: 21842\n",
      "img id in: 21843\n",
      "img id out: 21843\n",
      "img id in: 21844\n",
      "img id out: 21844\n",
      "img id in: 21845\n",
      "img id out: 21845\n",
      "img id in: 21846\n",
      "img id out: 21846\n",
      "img id in: 21847\n",
      "img id out: 21847\n",
      "img id in: 21848\n",
      "img id out: 21848\n",
      "img id in: 21849\n",
      "img id out: 21849\n",
      "img id in: 21850\n",
      "img id out: 21850\n",
      "img id in: 21851\n",
      "img id out: 21851\n",
      "img id in: 21852\n",
      "img id out: 21852\n",
      "img id in: 21853\n",
      "img id out: 21853\n",
      "img id in: 21854\n",
      "img id out: 21854\n",
      "img id in: 21855\n",
      "img id out: 21855\n",
      "img id in: 21856\n",
      "img id out: 21856\n",
      "img id in: 21857\n",
      "img id out: 21857\n",
      "img id in: 21858\n",
      "img id out: 21858\n",
      "img id in: 21859\n",
      "img id out: 21859\n",
      "img id in: 21860\n",
      "img id out: 21860\n",
      "img id in: 21861\n",
      "img id out: 21861\n",
      "img id in: 21862\n",
      "img id out: 21862\n",
      "img id in: 21863\n",
      "img id out: 21863\n",
      "img id in: 21864\n",
      "img id out: 21864\n",
      "img id in: 21865\n",
      "img id out: 21865\n",
      "img id in: 21866\n",
      "img id out: 21866\n",
      "img id in: 21867\n",
      "img id out: 21867\n",
      "img id in: 21868\n",
      "img id out: 21868\n",
      "img id in: 21869\n",
      "img id out: 21869\n",
      "img id in: 21870\n",
      "img id out: 21870\n",
      "img id in: 21871\n",
      "img id out: 21871\n",
      "img id in: 21872\n",
      "img id out: 21872\n",
      "img id in: 21873\n",
      "img id out: 21873\n",
      "img id in: 21874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 21874\n",
      "img id in: 21875\n",
      "img id out: 21875\n",
      "img id in: 21876\n",
      "img id out: 21876\n",
      "img id in: 21877\n",
      "img id out: 21877\n",
      "img id in: 21878\n",
      "img id out: 21878\n",
      "img id in: 21879\n",
      "img id out: 21879\n",
      "img id in: 21880\n",
      "img id out: 21880\n",
      "img id in: 21881\n",
      "img id out: 21881\n",
      "img id in: 21882\n",
      "img id out: 21882\n",
      "img id in: 21883\n",
      "img id out: 21883\n",
      "img id in: 21884\n",
      "img id out: 21884\n",
      "img id in: 21885\n",
      "img id out: 21885\n",
      "img id in: 21886\n",
      "img id out: 21886\n",
      "img id in: 21887\n",
      "img id out: 21887\n",
      "img id in: 21888\n",
      "img id out: 21888\n",
      "img id in: 21889\n",
      "img id out: 21889\n",
      "img id in: 21890\n",
      "img id out: 21890\n",
      "img id in: 21891\n",
      "img id out: 21891\n",
      "img id in: 21892\n",
      "img id out: 21892\n",
      "img id in: 21893\n",
      "img id out: 21893\n",
      "img id in: 21894\n",
      "img id out: 21894\n",
      "img id in: 21895\n",
      "img id out: 21895\n",
      "img id in: 21896\n",
      "img id out: 21896\n",
      "img id in: 21897\n",
      "img id out: 21897\n",
      "img id in: 21898\n",
      "img id out: 21898\n",
      "img id in: 21899\n",
      "img id out: 21899\n",
      "img id in: 21900\n",
      "img id out: 21900\n",
      "img id in: 21901\n",
      "img id out: 21901\n",
      "img id in: 21902\n",
      "img id out: 21902\n",
      "img id in: 21903\n",
      "img id out: 21903\n",
      "img id in: 21904\n",
      "img id out: 21904\n",
      "img id in: 21905\n",
      "img id out: 21905\n",
      "img id in: 21906\n",
      "img id out: 21906\n",
      "img id in: 21907\n",
      "img id out: 21907\n",
      "img id in: 21908\n",
      "img id out: 21908\n",
      "img id in: 21909\n",
      "img id out: 21909\n",
      "img id in: 21910\n",
      "img id out: 21910\n",
      "img id in: 21911\n",
      "img id out: 21911\n",
      "img id in: 21912\n",
      "img id out: 21912\n",
      "img id in: 21913\n",
      "img id out: 21913\n",
      "img id in: 21914\n",
      "img id out: 21914\n",
      "img id in: 21915\n",
      "img id out: 21915\n",
      "img id in: 21916\n",
      "img id out: 21916\n",
      "img id in: 21917\n",
      "img id out: 21917\n",
      "img id in: 21918\n",
      "img id out: 21918\n",
      "img id in: 21919\n",
      "img id out: 21919\n",
      "img id in: 21920\n",
      "img id out: 21920\n",
      "img id in: 21921\n",
      "img id out: 21921\n",
      "img id in: 21922\n",
      "img id out: 21922\n",
      "img id in: 21923\n",
      "img id out: 21923\n",
      "img id in: 21924\n",
      "img id out: 21924\n",
      "img id in: 21925\n",
      "img id out: 21925\n",
      "img id in: 21926\n",
      "img id out: 21926\n",
      "img id in: 21927\n",
      "img id out: 21927\n",
      "img id in: 21928\n",
      "img id out: 21928\n",
      "img id in: 21929\n",
      "img id out: 21929\n",
      "img id in: 21930\n",
      "img id out: 21930\n",
      "img id in: 21931\n",
      "img id out: 21931\n",
      "img id in: 21932\n",
      "img id out: 21932\n",
      "img id in: 21933\n",
      "img id out: 21933\n",
      "img id in: 21934\n",
      "img id out: 21934\n",
      "img id in: 21935\n",
      "img id out: 21935\n",
      "img id in: 21936\n",
      "img id out: 21936\n",
      "img id in: 21937\n",
      "img id out: 21937\n",
      "img id in: 21938\n",
      "img id out: 21938\n",
      "img id in: 21939\n",
      "img id out: 21939\n",
      "img id in: 21940\n",
      "img id out: 21940\n",
      "img id in: 21941\n",
      "img id out: 21941\n",
      "img id in: 21942\n",
      "img id out: 21942\n",
      "img id in: 21943\n",
      "img id out: 21943\n",
      "img id in: 21944\n",
      "img id out: 21944\n",
      "img id in: 21945\n",
      "img id out: 21945\n",
      "img id in: 21946\n",
      "img id out: 21946\n",
      "img id in: 21947\n",
      "img id out: 21947\n",
      "img id in: 21948\n",
      "img id out: 21948\n",
      "img id in: 21949\n",
      "img id out: 21949\n",
      "img id in: 21950\n",
      "img id out: 21950\n",
      "img id in: 21951\n",
      "img id out: 21951\n",
      "img id in: 21952\n",
      "img id out: 21952\n",
      "img id in: 21953\n",
      "img id out: 21953\n",
      "img id in: 21954\n",
      "img id out: 21954\n",
      "img id in: 21955\n",
      "img id out: 21955\n",
      "img id in: 21956\n",
      "img id out: 21956\n",
      "img id in: 21957\n",
      "img id out: 21957\n",
      "img id in: 21958\n",
      "img id out: 21958\n",
      "img id in: 21959\n",
      "img id out: 21959\n",
      "img id in: 21960\n",
      "img id out: 21960\n",
      "img id in: 21961\n",
      "img id out: 21961\n",
      "img id in: 21962\n",
      "img id out: 21962\n",
      "img id in: 21963\n",
      "img id out: 21963\n",
      "img id in: 21964\n",
      "img id out: 21964\n",
      "img id in: 21965\n",
      "img id out: 21965\n",
      "img id in: 21966\n",
      "img id out: 21966\n",
      "img id in: 21967\n",
      "img id out: 21967\n",
      "img id in: 21968\n",
      "img id out: 21968\n",
      "img id in: 21969\n",
      "img id out: 21969\n",
      "img id in: 21970\n",
      "img id out: 21970\n",
      "img id in: 21971\n",
      "img id out: 21971\n",
      "img id in: 21972\n",
      "img id out: 21972\n",
      "img id in: 21973\n",
      "img id out: 21973\n",
      "img id in: 21974\n",
      "img id out: 21974\n",
      "img id in: 21975\n",
      "img id out: 21975\n",
      "img id in: 21976\n",
      "img id out: 21976\n",
      "img id in: 21977\n",
      "img id out: 21977\n",
      "img id in: 21978\n",
      "img id out: 21978\n",
      "img id in: 21979\n",
      "img id out: 21979\n",
      "img id in: 21980\n",
      "img id out: 21980\n",
      "img id in: 21981\n",
      "img id out: 21981\n",
      "img id in: 21982\n",
      "img id out: 21982\n",
      "img id in: 21983\n",
      "img id out: 21983\n",
      "img id in: 21984\n",
      "img id out: 21984\n",
      "img id in: 21985\n",
      "img id out: 21985\n",
      "img id in: 21986\n",
      "img id out: 21986\n",
      "img id in: 21987\n",
      "img id out: 21987\n",
      "img id in: 21988\n",
      "img id out: 21988\n",
      "img id in: 21989\n",
      "img id out: 21989\n",
      "img id in: 21990\n",
      "img id out: 21990\n",
      "img id in: 21991\n",
      "img id out: 21991\n",
      "img id in: 21992\n",
      "img id out: 21992\n",
      "img id in: 21993\n",
      "img id out: 21993\n",
      "img id in: 21994\n",
      "img id out: 21994\n",
      "img id in: 21995\n",
      "img id out: 21995\n",
      "img id in: 21996\n",
      "img id out: 21996\n",
      "img id in: 21997\n",
      "img id out: 21997\n",
      "img id in: 21998\n",
      "img id out: 21998\n",
      "img id in: 21999\n",
      "img id out: 21999\n",
      "img id in: 22000\n",
      "img id out: 22000\n",
      "img id in: 22001\n",
      "img id out: 22001\n",
      "img id in: 22002\n",
      "img id out: 22002\n",
      "img id in: 22003\n",
      "img id out: 22003\n",
      "img id in: 22004\n",
      "img id out: 22004\n",
      "img id in: 22005\n",
      "img id out: 22005\n",
      "img id in: 22006\n",
      "img id out: 22006\n",
      "img id in: 22007\n",
      "img id out: 22007\n",
      "img id in: 22008\n",
      "img id out: 22008\n",
      "img id in: 22009\n",
      "img id out: 22009\n",
      "img id in: 22010\n",
      "img id out: 22010\n",
      "img id in: 22011\n",
      "img id out: 22011\n",
      "img id in: 22012\n",
      "img id out: 22012\n",
      "img id in: 22013\n",
      "img id out: 22013\n",
      "img id in: 22014\n",
      "img id out: 22014\n",
      "img id in: 22015\n",
      "img id out: 22015\n",
      "img id in: 22016\n",
      "img id out: 22016\n",
      "img id in: 22017\n",
      "img id out: 22017\n",
      "img id in: 22018\n",
      "img id out: 22018\n",
      "img id in: 22019\n",
      "img id out: 22019\n",
      "img id in: 22020\n",
      "img id out: 22020\n",
      "img id in: 22021\n",
      "img id out: 22021\n",
      "img id in: 22022\n",
      "img id out: 22022\n",
      "img id in: 22023\n",
      "img id out: 22023\n",
      "img id in: 22024\n",
      "img id out: 22024\n",
      "img id in: 22025\n",
      "img id out: 22025\n",
      "img id in: 22026\n",
      "img id out: 22026\n",
      "img id in: 22027\n",
      "img id out: 22027\n",
      "img id in: 22028\n",
      "img id out: 22028\n",
      "img id in: 22029\n",
      "img id out: 22029\n",
      "img id in: 22030\n",
      "img id out: 22030\n",
      "img id in: 22031\n",
      "img id out: 22031\n",
      "img id in: 22032\n",
      "img id out: 22032\n",
      "img id in: 22033\n",
      "img id out: 22033\n",
      "img id in: 22034\n",
      "img id out: 22034\n",
      "img id in: 22035\n",
      "img id out: 22035\n",
      "img id in: 22036\n",
      "img id out: 22036\n",
      "img id in: 22037\n",
      "img id out: 22037\n",
      "img id in: 22038\n",
      "img id out: 22038\n",
      "img id in: 22039\n",
      "img id out: 22039\n",
      "img id in: 22040\n",
      "img id out: 22040\n",
      "img id in: 22041\n",
      "img id out: 22041\n",
      "img id in: 22042\n",
      "img id out: 22042\n",
      "img id in: 22043\n",
      "img id out: 22043\n",
      "img id in: 22044\n",
      "img id out: 22044\n",
      "img id in: 22045\n",
      "img id out: 22045\n",
      "img id in: 22046\n",
      "img id out: 22046\n",
      "img id in: 22047\n",
      "img id out: 22047\n",
      "img id in: 22048\n",
      "img id out: 22048\n",
      "img id in: 22049\n",
      "img id out: 22049\n",
      "img id in: 22050\n",
      "img id out: 22050\n",
      "img id in: 22051\n",
      "img id out: 22051\n",
      "img id in: 22052\n",
      "img id out: 22052\n",
      "img id in: 22053\n",
      "img id out: 22053\n",
      "img id in: 22054\n",
      "img id out: 22054\n",
      "img id in: 22055\n",
      "img id out: 22055\n",
      "img id in: 22056\n",
      "img id out: 22056\n",
      "img id in: 22057\n",
      "img id out: 22057\n",
      "img id in: 22058\n",
      "img id out: 22058\n",
      "img id in: 22059\n",
      "img id out: 22059\n",
      "img id in: 22060\n",
      "img id out: 22060\n",
      "img id in: 22061\n",
      "img id out: 22061\n",
      "img id in: 22062\n",
      "img id out: 22062\n",
      "img id in: 22063\n",
      "img id out: 22063\n",
      "img id in: 22064\n",
      "img id out: 22064\n",
      "img id in: 22065\n",
      "img id out: 22065\n",
      "img id in: 22066\n",
      "img id out: 22066\n",
      "img id in: 22067\n",
      "img id out: 22067\n",
      "img id in: 22068\n",
      "img id out: 22068\n",
      "img id in: 22069\n",
      "img id out: 22069\n",
      "img id in: 22070\n",
      "img id out: 22070\n",
      "img id in: 22071\n",
      "img id out: 22071\n",
      "img id in: 22072\n",
      "img id out: 22072\n",
      "img id in: 22073\n",
      "img id out: 22073\n",
      "img id in: 22074\n",
      "img id out: 22074\n",
      "img id in: 22075\n",
      "img id out: 22075\n",
      "img id in: 22076\n",
      "img id out: 22076\n",
      "img id in: 22077\n",
      "img id out: 22077\n",
      "img id in: 22078\n",
      "img id out: 22078\n",
      "img id in: 22079\n",
      "img id out: 22079\n",
      "img id in: 22080\n",
      "img id out: 22080\n",
      "img id in: 22081\n",
      "img id out: 22081\n",
      "img id in: 22082\n",
      "img id out: 22082\n",
      "img id in: 22083\n",
      "img id out: 22083\n",
      "img id in: 22084\n",
      "img id out: 22084\n",
      "img id in: 22085\n",
      "img id out: 22085\n",
      "img id in: 22086\n",
      "img id out: 22086\n",
      "img id in: 22087\n",
      "img id out: 22087\n",
      "img id in: 22088\n",
      "img id out: 22088\n",
      "img id in: 22089\n",
      "img id out: 22089\n",
      "img id in: 22090\n",
      "img id out: 22090\n",
      "img id in: 22091\n",
      "img id out: 22091\n",
      "img id in: 22092\n",
      "img id out: 22092\n",
      "img id in: 22093\n",
      "img id out: 22093\n",
      "img id in: 22094\n",
      "img id out: 22094\n",
      "img id in: 22095\n",
      "img id out: 22095\n",
      "img id in: 22096\n",
      "img id out: 22096\n",
      "img id in: 22097\n",
      "img id out: 22097\n",
      "img id in: 22098\n",
      "img id out: 22098\n",
      "img id in: 22099\n",
      "img id out: 22099\n",
      "img id in: 22100\n",
      "img id out: 22100\n",
      "img id in: 22101\n",
      "img id out: 22101\n",
      "img id in: 22102\n",
      "img id out: 22102\n",
      "img id in: 22103\n",
      "img id out: 22103\n",
      "img id in: 22104\n",
      "img id out: 22104\n",
      "img id in: 22105\n",
      "img id out: 22105\n",
      "img id in: 22106\n",
      "img id out: 22106\n",
      "img id in: 22107\n",
      "img id out: 22107\n",
      "img id in: 22108\n",
      "img id out: 22108\n",
      "img id in: 22109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 22109\n",
      "img id in: 22110\n",
      "img id out: 22110\n",
      "img id in: 22111\n",
      "img id out: 22111\n",
      "img id in: 22112\n",
      "img id out: 22112\n",
      "img id in: 22113\n",
      "img id out: 22113\n",
      "img id in: 22114\n",
      "img id out: 22114\n",
      "img id in: 22115\n",
      "img id out: 22115\n",
      "img id in: 22116\n",
      "img id out: 22116\n",
      "img id in: 22117\n",
      "img id out: 22117\n",
      "img id in: 22118\n",
      "img id out: 22118\n",
      "img id in: 22119\n",
      "img id out: 22119\n",
      "img id in: 22120\n",
      "img id out: 22120\n",
      "img id in: 22121\n",
      "img id out: 22121\n",
      "img id in: 22122\n",
      "img id out: 22122\n",
      "img id in: 22123\n",
      "img id out: 22123\n",
      "img id in: 22124\n",
      "img id out: 22124\n",
      "img id in: 22125\n",
      "img id out: 22125\n",
      "img id in: 22126\n",
      "img id out: 22126\n",
      "img id in: 22127\n",
      "img id out: 22127\n",
      "img id in: 22128\n",
      "img id out: 22128\n",
      "img id in: 22129\n",
      "img id out: 22129\n",
      "img id in: 22130\n",
      "img id out: 22130\n",
      "img id in: 22131\n",
      "img id out: 22131\n",
      "img id in: 22132\n",
      "img id out: 22132\n",
      "img id in: 22133\n",
      "img id out: 22133\n",
      "img id in: 22134\n",
      "img id out: 22134\n",
      "img id in: 22135\n",
      "img id out: 22135\n",
      "img id in: 22136\n",
      "img id out: 22136\n",
      "img id in: 22137\n",
      "img id out: 22137\n",
      "img id in: 22138\n",
      "img id out: 22138\n",
      "img id in: 22139\n",
      "img id out: 22139\n",
      "img id in: 22140\n",
      "img id out: 22140\n",
      "img id in: 22141\n",
      "img id out: 22141\n",
      "img id in: 22142\n",
      "img id out: 22142\n",
      "img id in: 22143\n",
      "img id out: 22143\n",
      "img id in: 22144\n",
      "img id out: 22144\n",
      "img id in: 22145\n",
      "img id out: 22145\n",
      "img id in: 22146\n",
      "img id out: 22146\n",
      "img id in: 22147\n",
      "img id out: 22147\n",
      "img id in: 22148\n",
      "img id out: 22148\n",
      "img id in: 22149\n",
      "img id out: 22149\n",
      "img id in: 22150\n",
      "img id out: 22150\n",
      "img id in: 22151\n",
      "img id out: 22151\n",
      "img id in: 22152\n",
      "img id out: 22152\n",
      "img id in: 22153\n",
      "img id out: 22153\n",
      "img id in: 22154\n",
      "img id out: 22154\n",
      "img id in: 22155\n",
      "img id out: 22155\n",
      "img id in: 22156\n",
      "img id out: 22156\n",
      "img id in: 22157\n",
      "img id out: 22157\n",
      "img id in: 22158\n",
      "img id out: 22158\n",
      "img id in: 22159\n",
      "img id out: 22159\n",
      "img id in: 22160\n",
      "img id out: 22160\n",
      "img id in: 22161\n",
      "img id out: 22161\n",
      "img id in: 22162\n",
      "img id out: 22162\n",
      "img id in: 22163\n",
      "img id out: 22163\n",
      "img id in: 22164\n",
      "img id out: 22164\n",
      "img id in: 22165\n",
      "img id out: 22165\n",
      "img id in: 22166\n",
      "img id out: 22166\n",
      "img id in: 22167\n",
      "img id out: 22167\n",
      "img id in: 22168\n",
      "img id out: 22168\n",
      "img id in: 22169\n",
      "img id out: 22169\n",
      "img id in: 22170\n",
      "img id out: 22170\n",
      "img id in: 22171\n",
      "img id out: 22171\n",
      "img id in: 22172\n",
      "img id out: 22172\n",
      "img id in: 22173\n",
      "img id out: 22173\n",
      "img id in: 22174\n",
      "img id out: 22174\n",
      "img id in: 22175\n",
      "img id out: 22175\n",
      "img id in: 22176\n",
      "img id out: 22176\n",
      "img id in: 22177\n",
      "img id out: 22177\n",
      "img id in: 22178\n",
      "img id out: 22178\n",
      "img id in: 22179\n",
      "img id out: 22179\n",
      "img id in: 22180\n",
      "img id out: 22180\n",
      "img id in: 22181\n",
      "img id out: 22181\n",
      "img id in: 22182\n",
      "img id out: 22182\n",
      "img id in: 22183\n",
      "img id out: 22183\n",
      "img id in: 22184\n",
      "img id out: 22184\n",
      "img id in: 22185\n",
      "img id out: 22185\n",
      "img id in: 22186\n",
      "img id out: 22186\n",
      "img id in: 22187\n",
      "img id out: 22187\n",
      "img id in: 22188\n",
      "img id out: 22188\n",
      "img id in: 22189\n",
      "img id out: 22189\n",
      "img id in: 22190\n",
      "img id out: 22190\n",
      "img id in: 22191\n",
      "img id out: 22191\n",
      "img id in: 22192\n",
      "img id out: 22192\n",
      "img id in: 22193\n",
      "img id out: 22193\n",
      "img id in: 22194\n",
      "img id out: 22194\n",
      "img id in: 22195\n",
      "img id out: 22195\n",
      "img id in: 22196\n",
      "img id out: 22196\n",
      "img id in: 22197\n",
      "img id out: 22197\n",
      "img id in: 22198\n",
      "img id out: 22198\n",
      "img id in: 22199\n",
      "img id out: 22199\n",
      "img id in: 22200\n",
      "img id out: 22200\n",
      "img id in: 22201\n",
      "img id out: 22201\n",
      "img id in: 22202\n",
      "img id out: 22202\n",
      "img id in: 22203\n",
      "img id out: 22203\n",
      "img id in: 22204\n",
      "img id out: 22204\n",
      "img id in: 22205\n",
      "img id out: 22205\n",
      "img id in: 22206\n",
      "img id out: 22206\n",
      "img id in: 22207\n",
      "img id out: 22207\n",
      "img id in: 22208\n",
      "img id out: 22208\n",
      "img id in: 22209\n",
      "img id out: 22209\n",
      "img id in: 22210\n",
      "img id out: 22210\n",
      "img id in: 22211\n",
      "img id out: 22211\n",
      "img id in: 22212\n",
      "img id out: 22212\n",
      "img id in: 22213\n",
      "img id out: 22213\n",
      "img id in: 22214\n",
      "img id out: 22214\n",
      "img id in: 22215\n",
      "img id out: 22215\n",
      "img id in: 22216\n",
      "img id out: 22216\n",
      "img id in: 22217\n",
      "img id out: 22217\n",
      "img id in: 22218\n",
      "img id out: 22218\n",
      "img id in: 22219\n",
      "img id out: 22219\n",
      "img id in: 22220\n",
      "img id out: 22220\n",
      "img id in: 22221\n",
      "img id out: 22221\n",
      "img id in: 22222\n",
      "img id out: 22222\n",
      "img id in: 22223\n",
      "img id out: 22223\n",
      "img id in: 22224\n",
      "img id out: 22224\n",
      "img id in: 22225\n",
      "img id out: 22225\n",
      "img id in: 22226\n",
      "img id out: 22226\n",
      "img id in: 22227\n",
      "img id out: 22227\n",
      "img id in: 22228\n",
      "img id out: 22228\n",
      "img id in: 22229\n",
      "img id out: 22229\n",
      "img id in: 22230\n",
      "img id out: 22230\n",
      "img id in: 22231\n",
      "img id out: 22231\n",
      "img id in: 22232\n",
      "img id out: 22232\n",
      "img id in: 22233\n",
      "img id out: 22233\n",
      "img id in: 22234\n",
      "img id out: 22234\n",
      "img id in: 22235\n",
      "img id out: 22235\n",
      "img id in: 22236\n",
      "img id out: 22236\n",
      "img id in: 22237\n",
      "img id out: 22237\n",
      "img id in: 22238\n",
      "img id out: 22238\n",
      "img id in: 22239\n",
      "img id out: 22239\n",
      "img id in: 22240\n",
      "img id out: 22240\n",
      "img id in: 22241\n",
      "img id out: 22241\n",
      "img id in: 22242\n",
      "img id out: 22242\n",
      "img id in: 22243\n",
      "img id out: 22243\n",
      "img id in: 22244\n",
      "img id out: 22244\n",
      "img id in: 22245\n",
      "img id out: 22245\n",
      "img id in: 22246\n",
      "img id out: 22246\n",
      "img id in: 22247\n",
      "img id out: 22247\n",
      "img id in: 22248\n",
      "img id out: 22248\n",
      "img id in: 22249\n",
      "img id out: 22249\n",
      "img id in: 22250\n",
      "img id out: 22250\n",
      "img id in: 22251\n",
      "img id out: 22251\n",
      "img id in: 22252\n",
      "img id out: 22252\n",
      "img id in: 22253\n",
      "img id out: 22253\n",
      "img id in: 22254\n",
      "img id out: 22254\n",
      "img id in: 22255\n",
      "img id out: 22255\n",
      "img id in: 22256\n",
      "img id out: 22256\n",
      "img id in: 22257\n",
      "img id out: 22257\n",
      "img id in: 22258\n",
      "img id out: 22258\n",
      "img id in: 22259\n",
      "img id out: 22259\n",
      "img id in: 22260\n",
      "img id out: 22260\n",
      "img id in: 22261\n",
      "img id out: 22261\n",
      "img id in: 22262\n",
      "img id out: 22262\n",
      "img id in: 22263\n",
      "img id out: 22263\n",
      "img id in: 22264\n",
      "img id out: 22264\n",
      "img id in: 22265\n",
      "img id out: 22265\n",
      "img id in: 22266\n",
      "img id out: 22266\n",
      "img id in: 22267\n",
      "img id out: 22267\n",
      "img id in: 22268\n",
      "img id out: 22268\n",
      "img id in: 22269\n",
      "img id out: 22269\n",
      "img id in: 22270\n",
      "img id out: 22270\n",
      "img id in: 22271\n",
      "img id out: 22271\n",
      "img id in: 22272\n",
      "img id out: 22272\n",
      "img id in: 22273\n",
      "img id out: 22273\n",
      "img id in: 22274\n",
      "img id out: 22274\n",
      "img id in: 22275\n",
      "img id out: 22275\n",
      "img id in: 22276\n",
      "img id out: 22276\n",
      "img id in: 22277\n",
      "img id out: 22277\n",
      "img id in: 22278\n",
      "img id out: 22278\n",
      "img id in: 22279\n",
      "img id out: 22279\n",
      "img id in: 22280\n",
      "img id out: 22280\n",
      "img id in: 22281\n",
      "img id out: 22281\n",
      "img id in: 22282\n",
      "img id out: 22282\n",
      "img id in: 22283\n",
      "img id out: 22283\n",
      "img id in: 22284\n",
      "img id out: 22284\n",
      "img id in: 22285\n",
      "img id out: 22285\n",
      "img id in: 22286\n",
      "img id out: 22286\n",
      "img id in: 22287\n",
      "img id out: 22287\n",
      "img id in: 22288\n",
      "img id out: 22288\n",
      "img id in: 22289\n",
      "img id out: 22289\n",
      "img id in: 22290\n",
      "img id out: 22290\n",
      "img id in: 22291\n",
      "img id out: 22291\n",
      "img id in: 22292\n",
      "img id out: 22292\n",
      "img id in: 22293\n",
      "img id out: 22293\n",
      "img id in: 22294\n",
      "img id out: 22294\n",
      "img id in: 22295\n",
      "img id out: 22295\n",
      "img id in: 22296\n",
      "img id out: 22296\n",
      "img id in: 22297\n",
      "img id out: 22297\n",
      "img id in: 22298\n",
      "img id out: 22298\n",
      "img id in: 22299\n",
      "img id out: 22299\n",
      "img id in: 22300\n",
      "img id out: 22300\n",
      "img id in: 22301\n",
      "img id out: 22301\n",
      "img id in: 22302\n",
      "img id out: 22302\n",
      "img id in: 22303\n",
      "img id out: 22303\n",
      "img id in: 22304\n",
      "img id out: 22304\n",
      "img id in: 22305\n",
      "img id out: 22305\n",
      "img id in: 22306\n",
      "img id out: 22306\n",
      "img id in: 22307\n",
      "img id out: 22307\n",
      "img id in: 22308\n",
      "img id out: 22308\n",
      "img id in: 22309\n",
      "img id out: 22309\n",
      "img id in: 22310\n",
      "img id out: 22310\n",
      "img id in: 22311\n",
      "img id out: 22311\n",
      "img id in: 22312\n",
      "img id out: 22312\n",
      "img id in: 22313\n",
      "img id out: 22313\n",
      "img id in: 22314\n",
      "img id out: 22314\n",
      "img id in: 22315\n",
      "img id out: 22315\n",
      "img id in: 22316\n",
      "img id out: 22316\n",
      "img id in: 22317\n",
      "img id out: 22317\n",
      "img id in: 22318\n",
      "img id out: 22318\n",
      "img id in: 22319\n",
      "img id out: 22319\n",
      "img id in: 22320\n",
      "img id out: 22320\n",
      "img id in: 22321\n",
      "img id out: 22321\n",
      "img id in: 22322\n",
      "img id out: 22322\n",
      "img id in: 22323\n",
      "img id out: 22323\n",
      "img id in: 22324\n",
      "img id out: 22324\n",
      "img id in: 22325\n",
      "img id out: 22325\n",
      "img id in: 22326\n",
      "img id out: 22326\n",
      "img id in: 22327\n",
      "img id out: 22327\n",
      "img id in: 22328\n",
      "img id out: 22328\n",
      "img id in: 22329\n",
      "img id out: 22329\n",
      "img id in: 22330\n",
      "img id out: 22330\n",
      "img id in: 22331\n",
      "img id out: 22331\n",
      "img id in: 22332\n",
      "img id out: 22332\n",
      "img id in: 22333\n",
      "img id out: 22333\n",
      "img id in: 22334\n",
      "img id out: 22334\n",
      "img id in: 22335\n",
      "img id out: 22335\n",
      "img id in: 22336\n",
      "img id out: 22336\n",
      "img id in: 22337\n",
      "img id out: 22337\n",
      "img id in: 22338\n",
      "img id out: 22338\n",
      "img id in: 22339\n",
      "img id out: 22339\n",
      "img id in: 22340\n",
      "img id out: 22340\n",
      "img id in: 22341\n",
      "img id out: 22341\n",
      "img id in: 22342\n",
      "img id out: 22342\n",
      "img id in: 22343\n",
      "img id out: 22343\n",
      "img id in: 22344\n",
      "img id out: 22344\n",
      "img id in: 22345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 22345\n",
      "img id in: 22346\n",
      "img id out: 22346\n",
      "img id in: 22347\n",
      "img id out: 22347\n",
      "img id in: 22348\n",
      "img id out: 22348\n",
      "img id in: 22349\n",
      "img id out: 22349\n",
      "img id in: 22350\n",
      "img id out: 22350\n",
      "img id in: 22351\n",
      "img id out: 22351\n",
      "img id in: 22352\n",
      "img id out: 22352\n",
      "img id in: 22353\n",
      "img id out: 22353\n",
      "img id in: 22354\n",
      "img id out: 22354\n",
      "img id in: 22355\n",
      "img id out: 22355\n",
      "img id in: 22356\n",
      "img id out: 22356\n",
      "img id in: 22357\n",
      "img id out: 22357\n",
      "img id in: 22358\n",
      "img id out: 22358\n",
      "img id in: 22359\n",
      "img id out: 22359\n",
      "img id in: 22360\n",
      "img id out: 22360\n",
      "img id in: 22361\n",
      "img id out: 22361\n",
      "img id in: 22362\n",
      "img id out: 22362\n",
      "img id in: 22363\n",
      "img id out: 22363\n",
      "img id in: 22364\n",
      "img id out: 22364\n",
      "img id in: 22365\n",
      "img id out: 22365\n",
      "img id in: 22366\n",
      "img id out: 22366\n",
      "img id in: 22367\n",
      "img id out: 22367\n",
      "img id in: 22368\n",
      "img id out: 22368\n",
      "img id in: 22369\n",
      "img id out: 22369\n",
      "img id in: 22370\n",
      "img id out: 22370\n",
      "img id in: 22371\n",
      "img id out: 22371\n",
      "img id in: 22372\n",
      "img id out: 22372\n",
      "img id in: 22373\n",
      "img id out: 22373\n",
      "img id in: 22374\n",
      "img id out: 22374\n",
      "img id in: 22375\n",
      "img id out: 22375\n",
      "img id in: 22376\n",
      "img id out: 22376\n",
      "img id in: 22377\n",
      "img id out: 22377\n",
      "img id in: 22378\n",
      "img id out: 22378\n",
      "img id in: 22379\n",
      "img id out: 22379\n",
      "img id in: 22380\n",
      "img id out: 22380\n",
      "img id in: 22381\n",
      "img id out: 22381\n",
      "img id in: 22382\n",
      "img id out: 22382\n",
      "img id in: 22383\n",
      "img id out: 22383\n",
      "img id in: 22384\n",
      "img id out: 22384\n",
      "img id in: 22385\n",
      "img id out: 22385\n",
      "img id in: 22386\n",
      "img id out: 22386\n",
      "img id in: 22387\n",
      "img id out: 22387\n",
      "img id in: 22388\n",
      "img id out: 22388\n",
      "img id in: 22389\n",
      "img id out: 22389\n",
      "img id in: 22390\n",
      "img id out: 22390\n",
      "img id in: 22391\n",
      "img id out: 22391\n",
      "img id in: 22392\n",
      "img id out: 22392\n",
      "img id in: 22393\n",
      "img id out: 22393\n",
      "img id in: 22394\n",
      "img id out: 22394\n",
      "img id in: 22395\n",
      "img id out: 22395\n",
      "img id in: 22396\n",
      "img id out: 22396\n",
      "img id in: 22397\n",
      "img id out: 22397\n",
      "img id in: 22398\n",
      "img id out: 22398\n",
      "img id in: 22399\n",
      "img id out: 22399\n",
      "img id in: 22400\n",
      "img id out: 22400\n",
      "img id in: 22401\n",
      "img id out: 22401\n",
      "img id in: 22402\n",
      "img id out: 22402\n",
      "img id in: 22403\n",
      "img id out: 22403\n",
      "img id in: 22404\n",
      "img id out: 22404\n",
      "img id in: 22405\n",
      "img id out: 22405\n",
      "img id in: 22406\n",
      "img id out: 22406\n",
      "img id in: 22407\n",
      "img id out: 22407\n",
      "img id in: 22408\n",
      "img id out: 22408\n",
      "img id in: 22409\n",
      "img id out: 22409\n",
      "img id in: 22410\n",
      "img id out: 22410\n",
      "img id in: 22411\n",
      "img id out: 22411\n",
      "img id in: 22412\n",
      "img id out: 22412\n",
      "img id in: 22413\n",
      "img id out: 22413\n",
      "img id in: 22414\n",
      "img id out: 22414\n",
      "img id in: 22415\n",
      "img id out: 22415\n",
      "img id in: 22416\n",
      "img id out: 22416\n",
      "img id in: 22417\n",
      "img id out: 22417\n",
      "img id in: 22418\n",
      "img id out: 22418\n",
      "img id in: 22419\n",
      "img id out: 22419\n",
      "img id in: 22420\n",
      "img id out: 22420\n",
      "img id in: 22421\n",
      "img id out: 22421\n",
      "img id in: 22422\n",
      "img id out: 22422\n",
      "img id in: 22423\n",
      "img id out: 22423\n",
      "img id in: 22424\n",
      "img id out: 22424\n",
      "img id in: 22425\n",
      "img id out: 22425\n",
      "img id in: 22426\n",
      "img id out: 22426\n",
      "img id in: 22427\n",
      "img id out: 22427\n",
      "img id in: 22428\n",
      "img id out: 22428\n",
      "img id in: 22429\n",
      "img id out: 22429\n",
      "img id in: 22430\n",
      "img id out: 22430\n",
      "img id in: 22431\n",
      "img id out: 22431\n",
      "img id in: 22432\n",
      "img id out: 22432\n",
      "img id in: 22433\n",
      "img id out: 22433\n",
      "img id in: 22434\n",
      "img id out: 22434\n",
      "img id in: 22435\n",
      "img id out: 22435\n",
      "img id in: 22436\n",
      "img id out: 22436\n",
      "img id in: 22437\n",
      "img id out: 22437\n",
      "img id in: 22438\n",
      "img id out: 22438\n",
      "img id in: 22439\n",
      "img id out: 22439\n",
      "img id in: 22440\n",
      "img id out: 22440\n",
      "img id in: 22441\n",
      "img id out: 22441\n",
      "img id in: 22442\n",
      "img id out: 22442\n",
      "img id in: 22443\n",
      "img id out: 22443\n",
      "img id in: 22444\n",
      "img id out: 22444\n",
      "img id in: 22445\n",
      "img id out: 22445\n",
      "img id in: 22446\n",
      "img id out: 22446\n",
      "img id in: 22447\n",
      "img id out: 22447\n",
      "img id in: 22448\n",
      "img id out: 22448\n",
      "img id in: 22449\n",
      "img id out: 22449\n",
      "img id in: 22450\n",
      "img id out: 22450\n",
      "img id in: 22451\n",
      "img id out: 22451\n",
      "img id in: 22452\n",
      "img id out: 22452\n",
      "img id in: 22453\n",
      "img id out: 22453\n",
      "img id in: 22454\n",
      "img id out: 22454\n",
      "img id in: 22455\n",
      "img id out: 22455\n",
      "img id in: 22456\n",
      "img id out: 22456\n",
      "img id in: 22457\n",
      "img id out: 22457\n",
      "img id in: 22458\n",
      "img id out: 22458\n",
      "img id in: 22459\n",
      "img id out: 22459\n",
      "img id in: 22460\n",
      "img id out: 22460\n",
      "img id in: 22461\n",
      "img id out: 22461\n",
      "img id in: 22462\n",
      "img id out: 22462\n",
      "img id in: 22463\n",
      "img id out: 22463\n",
      "img id in: 22464\n",
      "img id out: 22464\n",
      "img id in: 22465\n",
      "img id out: 22465\n",
      "img id in: 22466\n",
      "img id out: 22466\n",
      "img id in: 22467\n",
      "img id out: 22467\n",
      "img id in: 22468\n",
      "img id out: 22468\n",
      "img id in: 22469\n",
      "img id out: 22469\n",
      "img id in: 22470\n",
      "img id out: 22470\n",
      "img id in: 22471\n",
      "img id out: 22471\n",
      "img id in: 22472\n",
      "img id out: 22472\n",
      "img id in: 22473\n",
      "img id out: 22473\n",
      "img id in: 22474\n",
      "img id out: 22474\n",
      "img id in: 22475\n",
      "img id out: 22475\n",
      "img id in: 22476\n",
      "img id out: 22476\n",
      "img id in: 22477\n",
      "img id out: 22477\n",
      "img id in: 22478\n",
      "img id out: 22478\n",
      "img id in: 22479\n",
      "img id out: 22479\n",
      "img id in: 22480\n",
      "img id out: 22480\n",
      "img id in: 22481\n",
      "img id out: 22481\n",
      "img id in: 22482\n",
      "img id out: 22482\n",
      "img id in: 22483\n",
      "img id out: 22483\n",
      "img id in: 22484\n",
      "img id out: 22484\n",
      "img id in: 22485\n",
      "img id out: 22485\n",
      "img id in: 22486\n",
      "img id out: 22486\n",
      "img id in: 22487\n",
      "img id out: 22487\n",
      "img id in: 22488\n",
      "img id out: 22488\n",
      "img id in: 22489\n",
      "img id out: 22489\n",
      "img id in: 22490\n",
      "img id out: 22490\n",
      "img id in: 22491\n",
      "img id out: 22491\n",
      "img id in: 22492\n",
      "img id out: 22492\n",
      "img id in: 22493\n",
      "img id out: 22493\n",
      "img id in: 22494\n",
      "img id out: 22494\n",
      "img id in: 22495\n",
      "img id out: 22495\n",
      "img id in: 22496\n",
      "img id out: 22496\n",
      "img id in: 22497\n",
      "img id out: 22497\n",
      "img id in: 22498\n",
      "img id out: 22498\n",
      "img id in: 22499\n",
      "img id out: 22499\n",
      "img id in: 22500\n",
      "img id out: 22500\n",
      "img id in: 22501\n",
      "img id out: 22501\n",
      "img id in: 22502\n",
      "img id out: 22502\n",
      "img id in: 22503\n",
      "img id out: 22503\n",
      "img id in: 22504\n",
      "img id out: 22504\n",
      "img id in: 22505\n",
      "img id out: 22505\n",
      "img id in: 22506\n",
      "img id out: 22506\n",
      "img id in: 22507\n",
      "img id out: 22507\n",
      "img id in: 22508\n",
      "img id out: 22508\n",
      "img id in: 22509\n",
      "img id out: 22509\n",
      "img id in: 22510\n",
      "img id out: 22510\n",
      "img id in: 22511\n",
      "img id out: 22511\n",
      "img id in: 22512\n",
      "img id out: 22512\n",
      "img id in: 22513\n",
      "img id out: 22513\n",
      "img id in: 22514\n",
      "img id out: 22514\n",
      "img id in: 22515\n",
      "img id out: 22515\n",
      "img id in: 22516\n",
      "img id out: 22516\n",
      "img id in: 22517\n",
      "img id out: 22517\n",
      "img id in: 22518\n",
      "img id out: 22518\n",
      "img id in: 22519\n",
      "img id out: 22519\n",
      "img id in: 22520\n",
      "img id out: 22520\n",
      "img id in: 22521\n",
      "img id out: 22521\n",
      "img id in: 22522\n",
      "img id out: 22522\n",
      "img id in: 22523\n",
      "img id out: 22523\n",
      "img id in: 22524\n",
      "img id out: 22524\n",
      "img id in: 22525\n",
      "img id out: 22525\n",
      "img id in: 22526\n",
      "img id out: 22526\n",
      "img id in: 22527\n",
      "img id out: 22527\n",
      "img id in: 22528\n",
      "img id out: 22528\n",
      "img id in: 22529\n",
      "img id out: 22529\n",
      "img id in: 22530\n",
      "img id out: 22530\n",
      "img id in: 22531\n",
      "img id out: 22531\n",
      "img id in: 22532\n",
      "img id out: 22532\n",
      "img id in: 22533\n",
      "img id out: 22533\n",
      "img id in: 22534\n",
      "img id out: 22534\n",
      "img id in: 22535\n",
      "img id out: 22535\n",
      "img id in: 22536\n",
      "img id out: 22536\n",
      "img id in: 22537\n",
      "img id out: 22537\n",
      "img id in: 22538\n",
      "img id out: 22538\n",
      "img id in: 22539\n",
      "img id out: 22539\n",
      "img id in: 22540\n",
      "img id out: 22540\n",
      "img id in: 22541\n",
      "img id out: 22541\n",
      "img id in: 22542\n",
      "img id out: 22542\n",
      "img id in: 22543\n",
      "img id out: 22543\n",
      "img id in: 22544\n",
      "img id out: 22544\n",
      "img id in: 22545\n",
      "img id out: 22545\n",
      "img id in: 22546\n",
      "img id out: 22546\n",
      "img id in: 22547\n",
      "img id out: 22547\n",
      "img id in: 22548\n",
      "img id out: 22548\n",
      "img id in: 22549\n",
      "img id out: 22549\n",
      "img id in: 22550\n",
      "img id out: 22550\n",
      "img id in: 22551\n",
      "img id out: 22551\n",
      "img id in: 22552\n",
      "img id out: 22552\n",
      "img id in: 22553\n",
      "img id out: 22553\n",
      "img id in: 22554\n",
      "img id out: 22554\n",
      "img id in: 22555\n",
      "img id out: 22555\n",
      "img id in: 22556\n",
      "img id out: 22556\n",
      "img id in: 22557\n",
      "img id out: 22557\n",
      "img id in: 22558\n",
      "img id out: 22558\n",
      "img id in: 22559\n",
      "img id out: 22559\n",
      "img id in: 22560\n",
      "img id out: 22560\n",
      "img id in: 22561\n",
      "img id out: 22561\n",
      "img id in: 22562\n",
      "img id out: 22562\n",
      "img id in: 22563\n",
      "img id out: 22563\n",
      "img id in: 22564\n",
      "img id out: 22564\n",
      "img id in: 22565\n",
      "img id out: 22565\n",
      "img id in: 22566\n",
      "img id out: 22566\n",
      "img id in: 22567\n",
      "img id out: 22567\n",
      "img id in: 22568\n",
      "img id out: 22568\n",
      "img id in: 22569\n",
      "img id out: 22569\n",
      "img id in: 22570\n",
      "img id out: 22570\n",
      "img id in: 22571\n",
      "img id out: 22571\n",
      "img id in: 22572\n",
      "img id out: 22572\n",
      "img id in: 22573\n",
      "img id out: 22573\n",
      "img id in: 22574\n",
      "img id out: 22574\n",
      "img id in: 22575\n",
      "img id out: 22575\n",
      "img id in: 22576\n",
      "img id out: 22576\n",
      "img id in: 22577\n",
      "img id out: 22577\n",
      "img id in: 22578\n",
      "img id out: 22578\n",
      "img id in: 22579\n",
      "img id out: 22579\n",
      "img id in: 22580\n",
      "img id out: 22580\n",
      "img id in: 22581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 22581\n",
      "img id in: 22582\n",
      "img id out: 22582\n",
      "img id in: 22583\n",
      "img id out: 22583\n",
      "img id in: 22584\n",
      "img id out: 22584\n",
      "img id in: 22585\n",
      "img id out: 22585\n",
      "img id in: 22586\n",
      "img id out: 22586\n",
      "img id in: 22587\n",
      "img id out: 22587\n",
      "img id in: 22588\n",
      "img id out: 22588\n",
      "img id in: 22589\n",
      "img id out: 22589\n",
      "img id in: 22590\n",
      "img id out: 22590\n",
      "img id in: 22591\n",
      "img id out: 22591\n",
      "img id in: 22592\n",
      "img id out: 22592\n",
      "img id in: 22593\n",
      "img id out: 22593\n",
      "img id in: 22594\n",
      "img id out: 22594\n",
      "img id in: 22595\n",
      "img id out: 22595\n",
      "img id in: 22596\n",
      "img id out: 22596\n",
      "img id in: 22597\n",
      "img id out: 22597\n",
      "img id in: 22598\n",
      "img id out: 22598\n",
      "img id in: 22599\n",
      "img id out: 22599\n",
      "img id in: 22600\n",
      "img id out: 22600\n",
      "img id in: 22601\n",
      "img id out: 22601\n",
      "img id in: 22602\n",
      "img id out: 22602\n",
      "img id in: 22603\n",
      "img id out: 22603\n",
      "img id in: 22604\n",
      "img id out: 22604\n",
      "img id in: 22605\n",
      "img id out: 22605\n",
      "img id in: 22606\n",
      "img id out: 22606\n",
      "img id in: 22607\n",
      "img id out: 22607\n",
      "img id in: 22608\n",
      "img id out: 22608\n",
      "img id in: 22609\n",
      "img id out: 22609\n",
      "img id in: 22610\n",
      "img id out: 22610\n",
      "img id in: 22611\n",
      "img id out: 22611\n",
      "img id in: 22612\n",
      "img id out: 22612\n",
      "img id in: 22613\n",
      "img id out: 22613\n",
      "img id in: 22614\n",
      "img id out: 22614\n",
      "img id in: 22615\n",
      "img id out: 22615\n",
      "img id in: 22616\n",
      "img id out: 22616\n",
      "img id in: 22617\n",
      "img id out: 22617\n",
      "img id in: 22618\n",
      "img id out: 22618\n",
      "img id in: 22619\n",
      "img id out: 22619\n",
      "img id in: 22620\n",
      "img id out: 22620\n",
      "img id in: 22621\n",
      "img id out: 22621\n",
      "img id in: 22622\n",
      "img id out: 22622\n",
      "img id in: 22623\n",
      "img id out: 22623\n",
      "img id in: 22624\n",
      "img id out: 22624\n",
      "img id in: 22625\n",
      "img id out: 22625\n",
      "img id in: 22626\n",
      "img id out: 22626\n",
      "img id in: 22627\n",
      "img id out: 22627\n",
      "img id in: 22628\n",
      "img id out: 22628\n",
      "img id in: 22629\n",
      "img id out: 22629\n",
      "img id in: 22630\n",
      "img id out: 22630\n",
      "img id in: 22631\n",
      "img id out: 22631\n",
      "img id in: 22632\n",
      "img id out: 22632\n",
      "img id in: 22633\n",
      "img id out: 22633\n",
      "img id in: 22634\n",
      "img id out: 22634\n",
      "img id in: 22635\n",
      "img id out: 22635\n",
      "img id in: 22636\n",
      "img id out: 22636\n",
      "img id in: 22637\n",
      "img id out: 22637\n",
      "img id in: 22638\n",
      "img id out: 22638\n",
      "img id in: 22639\n",
      "img id out: 22639\n",
      "img id in: 22640\n",
      "img id out: 22640\n",
      "img id in: 22641\n",
      "img id out: 22641\n",
      "img id in: 22642\n",
      "img id out: 22642\n",
      "img id in: 22643\n",
      "img id out: 22643\n",
      "img id in: 22644\n",
      "img id out: 22644\n",
      "img id in: 22645\n",
      "img id out: 22645\n",
      "img id in: 22646\n",
      "img id out: 22646\n",
      "img id in: 22647\n",
      "img id out: 22647\n",
      "img id in: 22648\n",
      "img id out: 22648\n",
      "img id in: 22649\n",
      "img id out: 22649\n",
      "img id in: 22650\n",
      "img id out: 22650\n",
      "img id in: 22651\n",
      "img id out: 22651\n",
      "img id in: 22652\n",
      "img id out: 22652\n",
      "img id in: 22653\n",
      "img id out: 22653\n",
      "img id in: 22654\n",
      "img id out: 22654\n",
      "img id in: 22655\n",
      "img id out: 22655\n",
      "img id in: 22656\n",
      "img id out: 22656\n",
      "img id in: 22657\n",
      "img id out: 22657\n",
      "img id in: 22658\n",
      "img id out: 22658\n",
      "img id in: 22659\n",
      "img id out: 22659\n",
      "img id in: 22660\n",
      "img id out: 22660\n",
      "img id in: 22661\n",
      "img id out: 22661\n",
      "img id in: 22662\n",
      "img id out: 22662\n",
      "img id in: 22663\n",
      "img id out: 22663\n",
      "img id in: 22664\n",
      "img id out: 22664\n",
      "img id in: 22665\n",
      "img id out: 22665\n",
      "img id in: 22666\n",
      "img id out: 22666\n",
      "img id in: 22667\n",
      "img id out: 22667\n",
      "img id in: 22668\n",
      "img id out: 22668\n",
      "img id in: 22669\n",
      "img id out: 22669\n",
      "img id in: 22670\n",
      "img id out: 22670\n",
      "img id in: 22671\n",
      "img id out: 22671\n",
      "img id in: 22672\n",
      "img id out: 22672\n",
      "img id in: 22673\n",
      "img id out: 22673\n",
      "img id in: 22674\n",
      "img id out: 22674\n",
      "img id in: 22675\n",
      "img id out: 22675\n",
      "img id in: 22676\n",
      "img id out: 22676\n",
      "img id in: 22677\n",
      "img id out: 22677\n",
      "img id in: 22678\n",
      "img id out: 22678\n",
      "img id in: 22679\n",
      "img id out: 22679\n",
      "img id in: 22680\n",
      "img id out: 22680\n",
      "img id in: 22681\n",
      "img id out: 22681\n",
      "img id in: 22682\n",
      "img id out: 22682\n",
      "img id in: 22683\n",
      "img id out: 22683\n",
      "img id in: 22684\n",
      "img id out: 22684\n",
      "img id in: 22685\n",
      "img id out: 22685\n",
      "img id in: 22686\n",
      "img id out: 22686\n",
      "img id in: 22687\n",
      "img id out: 22687\n",
      "img id in: 22688\n",
      "img id out: 22688\n",
      "img id in: 22689\n",
      "img id out: 22689\n",
      "img id in: 22690\n",
      "img id out: 22690\n",
      "img id in: 22691\n",
      "img id out: 22691\n",
      "img id in: 22692\n",
      "img id out: 22692\n",
      "img id in: 22693\n",
      "img id out: 22693\n",
      "img id in: 22694\n",
      "img id out: 22694\n",
      "img id in: 22695\n",
      "img id out: 22695\n",
      "img id in: 22696\n",
      "img id out: 22696\n",
      "img id in: 22697\n",
      "img id out: 22697\n",
      "img id in: 22698\n",
      "img id out: 22698\n",
      "img id in: 22699\n",
      "img id out: 22699\n",
      "img id in: 22700\n",
      "img id out: 22700\n",
      "img id in: 22701\n",
      "img id out: 22701\n",
      "img id in: 22702\n",
      "img id out: 22702\n",
      "img id in: 22703\n",
      "img id out: 22703\n",
      "img id in: 22704\n",
      "img id out: 22704\n",
      "img id in: 22705\n",
      "img id out: 22705\n",
      "img id in: 22706\n",
      "img id out: 22706\n",
      "img id in: 22707\n",
      "img id out: 22707\n",
      "img id in: 22708\n",
      "img id out: 22708\n",
      "img id in: 22709\n",
      "img id out: 22709\n",
      "img id in: 22710\n",
      "img id out: 22710\n",
      "img id in: 22711\n",
      "img id out: 22711\n",
      "img id in: 22712\n",
      "img id out: 22712\n",
      "img id in: 22713\n",
      "img id out: 22713\n",
      "img id in: 22714\n",
      "img id out: 22714\n",
      "img id in: 22715\n",
      "img id out: 22715\n",
      "img id in: 22716\n",
      "img id out: 22716\n",
      "img id in: 22717\n",
      "img id out: 22717\n",
      "img id in: 22718\n",
      "img id out: 22718\n",
      "img id in: 22719\n",
      "img id out: 22719\n",
      "img id in: 22720\n",
      "img id out: 22720\n",
      "img id in: 22721\n",
      "img id out: 22721\n",
      "img id in: 22722\n",
      "img id out: 22722\n",
      "img id in: 22723\n",
      "img id out: 22723\n",
      "img id in: 22724\n",
      "img id out: 22724\n",
      "img id in: 22725\n",
      "img id out: 22725\n",
      "img id in: 22726\n",
      "img id out: 22726\n",
      "img id in: 22727\n",
      "img id out: 22727\n",
      "img id in: 22728\n",
      "img id out: 22728\n",
      "img id in: 22729\n",
      "img id out: 22729\n",
      "img id in: 22730\n",
      "img id out: 22730\n",
      "img id in: 22731\n",
      "img id out: 22731\n",
      "img id in: 22732\n",
      "img id out: 22732\n",
      "img id in: 22733\n",
      "img id out: 22733\n",
      "img id in: 22734\n",
      "img id out: 22734\n",
      "img id in: 22735\n",
      "img id out: 22735\n",
      "img id in: 22736\n",
      "img id out: 22736\n",
      "img id in: 22737\n",
      "img id out: 22737\n",
      "img id in: 22738\n",
      "img id out: 22738\n",
      "img id in: 22739\n",
      "img id out: 22739\n",
      "img id in: 22740\n",
      "img id out: 22740\n",
      "img id in: 22741\n",
      "img id out: 22741\n",
      "img id in: 22742\n",
      "img id out: 22742\n",
      "img id in: 22743\n",
      "img id out: 22743\n",
      "img id in: 22744\n",
      "img id out: 22744\n",
      "img id in: 22745\n",
      "img id out: 22745\n",
      "img id in: 22746\n",
      "img id out: 22746\n",
      "img id in: 22747\n",
      "img id out: 22747\n",
      "img id in: 22748\n",
      "img id out: 22748\n",
      "img id in: 22749\n",
      "img id out: 22749\n",
      "img id in: 22750\n",
      "img id out: 22750\n",
      "img id in: 22751\n",
      "img id out: 22751\n",
      "img id in: 22752\n",
      "img id out: 22752\n",
      "img id in: 22753\n",
      "img id out: 22753\n",
      "img id in: 22754\n",
      "img id out: 22754\n",
      "img id in: 22755\n",
      "img id out: 22755\n",
      "img id in: 22756\n",
      "img id out: 22756\n",
      "img id in: 22757\n",
      "img id out: 22757\n",
      "img id in: 22758\n",
      "img id out: 22758\n",
      "img id in: 22759\n",
      "img id out: 22759\n",
      "img id in: 22760\n",
      "img id out: 22760\n",
      "img id in: 22761\n",
      "img id out: 22761\n",
      "img id in: 22762\n",
      "img id out: 22762\n",
      "img id in: 22763\n",
      "img id out: 22763\n",
      "img id in: 22764\n",
      "img id out: 22764\n",
      "img id in: 22765\n",
      "img id out: 22765\n",
      "img id in: 22766\n",
      "img id out: 22766\n",
      "img id in: 22767\n",
      "img id out: 22767\n",
      "img id in: 22768\n",
      "img id out: 22768\n",
      "img id in: 22769\n",
      "img id out: 22769\n",
      "img id in: 22770\n",
      "img id out: 22770\n",
      "img id in: 22771\n",
      "img id out: 22771\n",
      "img id in: 22772\n",
      "img id out: 22772\n",
      "img id in: 22773\n",
      "img id out: 22773\n",
      "img id in: 22774\n",
      "img id out: 22774\n",
      "img id in: 22775\n",
      "img id out: 22775\n",
      "img id in: 22776\n",
      "img id out: 22776\n",
      "img id in: 22777\n",
      "img id out: 22777\n",
      "img id in: 22778\n",
      "img id out: 22778\n",
      "img id in: 22779\n",
      "img id out: 22779\n",
      "img id in: 22780\n",
      "img id out: 22780\n",
      "img id in: 22781\n",
      "img id out: 22781\n",
      "img id in: 22782\n",
      "img id out: 22782\n",
      "img id in: 22783\n",
      "img id out: 22783\n",
      "img id in: 22784\n",
      "img id out: 22784\n",
      "img id in: 22785\n",
      "img id out: 22785\n",
      "img id in: 22786\n",
      "img id out: 22786\n",
      "img id in: 22787\n",
      "img id out: 22787\n",
      "img id in: 22788\n",
      "img id out: 22788\n",
      "img id in: 22789\n",
      "img id out: 22789\n",
      "img id in: 22790\n",
      "img id out: 22790\n",
      "img id in: 22791\n",
      "img id out: 22791\n",
      "img id in: 22792\n",
      "img id out: 22792\n",
      "img id in: 22793\n",
      "img id out: 22793\n",
      "img id in: 22794\n",
      "img id out: 22794\n",
      "img id in: 22795\n",
      "img id out: 22795\n",
      "img id in: 22796\n",
      "img id out: 22796\n",
      "img id in: 22797\n",
      "img id out: 22797\n",
      "img id in: 22798\n",
      "img id out: 22798\n",
      "img id in: 22799\n",
      "img id out: 22799\n",
      "img id in: 22800\n",
      "img id out: 22800\n",
      "img id in: 22801\n",
      "img id out: 22801\n",
      "img id in: 22802\n",
      "img id out: 22802\n",
      "img id in: 22803\n",
      "img id out: 22803\n",
      "img id in: 22804\n",
      "img id out: 22804\n",
      "img id in: 22805\n",
      "img id out: 22805\n",
      "img id in: 22806\n",
      "img id out: 22806\n",
      "img id in: 22807\n",
      "img id out: 22807\n",
      "img id in: 22808\n",
      "img id out: 22808\n",
      "img id in: 22809\n",
      "img id out: 22809\n",
      "img id in: 22810\n",
      "img id out: 22810\n",
      "img id in: 22811\n",
      "img id out: 22811\n",
      "img id in: 22812\n",
      "img id out: 22812\n",
      "img id in: 22813\n",
      "img id out: 22813\n",
      "img id in: 22814\n",
      "img id out: 22814\n",
      "img id in: 22815\n",
      "img id out: 22815\n",
      "img id in: 22816\n",
      "img id out: 22816\n",
      "img id in: 22817\n",
      "img id out: 22817\n",
      "img id in: 22818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 22818\n",
      "img id in: 22819\n",
      "img id out: 22819\n",
      "img id in: 22820\n",
      "img id out: 22820\n",
      "img id in: 22821\n",
      "img id out: 22821\n",
      "img id in: 22822\n",
      "img id out: 22822\n",
      "img id in: 22823\n",
      "img id out: 22823\n",
      "img id in: 22824\n",
      "img id out: 22824\n",
      "img id in: 22825\n",
      "img id out: 22825\n",
      "img id in: 22826\n",
      "img id out: 22826\n",
      "img id in: 22827\n",
      "img id out: 22827\n",
      "img id in: 22828\n",
      "img id out: 22828\n",
      "img id in: 22829\n",
      "img id out: 22829\n",
      "img id in: 22830\n",
      "img id out: 22830\n",
      "img id in: 22831\n",
      "img id out: 22831\n",
      "img id in: 22832\n",
      "img id out: 22832\n",
      "img id in: 22833\n",
      "img id out: 22833\n",
      "img id in: 22834\n",
      "img id out: 22834\n",
      "img id in: 22835\n",
      "img id out: 22835\n",
      "img id in: 22836\n",
      "img id out: 22836\n",
      "img id in: 22837\n",
      "img id out: 22837\n",
      "img id in: 22838\n",
      "img id out: 22838\n",
      "img id in: 22839\n",
      "img id out: 22839\n",
      "img id in: 22840\n",
      "img id out: 22840\n",
      "img id in: 22841\n",
      "img id out: 22841\n",
      "img id in: 22842\n",
      "img id out: 22842\n",
      "img id in: 22843\n",
      "img id out: 22843\n",
      "img id in: 22844\n",
      "img id out: 22844\n",
      "img id in: 22845\n",
      "img id out: 22845\n",
      "img id in: 22846\n",
      "img id out: 22846\n",
      "img id in: 22847\n",
      "img id out: 22847\n",
      "img id in: 22848\n",
      "img id out: 22848\n",
      "img id in: 22849\n",
      "img id out: 22849\n",
      "img id in: 22850\n",
      "img id out: 22850\n",
      "img id in: 22851\n",
      "img id out: 22851\n",
      "img id in: 22852\n",
      "img id out: 22852\n",
      "img id in: 22853\n",
      "img id out: 22853\n",
      "img id in: 22854\n",
      "img id out: 22854\n",
      "img id in: 22855\n",
      "img id out: 22855\n",
      "img id in: 22856\n",
      "img id out: 22856\n",
      "img id in: 22857\n",
      "img id out: 22857\n",
      "img id in: 22858\n",
      "img id out: 22858\n",
      "img id in: 22859\n",
      "img id out: 22859\n",
      "img id in: 22860\n",
      "img id out: 22860\n",
      "img id in: 22861\n",
      "img id out: 22861\n",
      "img id in: 22862\n",
      "img id out: 22862\n",
      "img id in: 22863\n",
      "img id out: 22863\n",
      "img id in: 22864\n",
      "img id out: 22864\n",
      "img id in: 22865\n",
      "img id out: 22865\n",
      "img id in: 22866\n",
      "img id out: 22866\n",
      "img id in: 22867\n",
      "img id out: 22867\n",
      "img id in: 22868\n",
      "img id out: 22868\n",
      "img id in: 22869\n",
      "img id out: 22869\n",
      "img id in: 22870\n",
      "img id out: 22870\n",
      "img id in: 22871\n",
      "img id out: 22871\n",
      "img id in: 22872\n",
      "img id out: 22872\n",
      "img id in: 22873\n",
      "img id out: 22873\n",
      "img id in: 22874\n",
      "img id out: 22874\n",
      "img id in: 22875\n",
      "img id out: 22875\n",
      "img id in: 22876\n",
      "img id out: 22876\n",
      "img id in: 22877\n",
      "img id out: 22877\n",
      "img id in: 22878\n",
      "img id out: 22878\n",
      "img id in: 22879\n",
      "img id out: 22879\n",
      "img id in: 22880\n",
      "img id out: 22880\n",
      "img id in: 22881\n",
      "img id out: 22881\n",
      "img id in: 22882\n",
      "img id out: 22882\n",
      "img id in: 22883\n",
      "img id out: 22883\n",
      "img id in: 22884\n",
      "img id out: 22884\n",
      "img id in: 22885\n",
      "img id out: 22885\n",
      "img id in: 22886\n",
      "img id out: 22886\n",
      "img id in: 22887\n",
      "img id out: 22887\n",
      "img id in: 22888\n",
      "img id out: 22888\n",
      "img id in: 22889\n",
      "img id out: 22889\n",
      "img id in: 22890\n",
      "img id out: 22890\n",
      "img id in: 22891\n",
      "img id out: 22891\n",
      "img id in: 22892\n",
      "img id out: 22892\n",
      "img id in: 22893\n",
      "img id out: 22893\n",
      "img id in: 22894\n",
      "img id out: 22894\n",
      "img id in: 22895\n",
      "img id out: 22895\n",
      "img id in: 22896\n",
      "img id out: 22896\n",
      "img id in: 22897\n",
      "img id out: 22897\n",
      "img id in: 22898\n",
      "img id out: 22898\n",
      "img id in: 22899\n",
      "img id out: 22899\n",
      "img id in: 22900\n",
      "img id out: 22900\n",
      "img id in: 22901\n",
      "img id out: 22901\n",
      "img id in: 22902\n",
      "img id out: 22902\n",
      "img id in: 22903\n",
      "img id out: 22903\n",
      "img id in: 22904\n",
      "img id out: 22904\n",
      "img id in: 22905\n",
      "img id out: 22905\n",
      "img id in: 22906\n",
      "img id out: 22906\n",
      "img id in: 22907\n",
      "img id out: 22907\n",
      "img id in: 22908\n",
      "img id out: 22908\n",
      "img id in: 22909\n",
      "img id out: 22909\n",
      "img id in: 22910\n",
      "img id out: 22910\n",
      "img id in: 22911\n",
      "img id out: 22911\n",
      "img id in: 22912\n",
      "img id out: 22912\n",
      "img id in: 22913\n",
      "img id out: 22913\n",
      "img id in: 22914\n",
      "img id out: 22914\n",
      "img id in: 22915\n",
      "img id out: 22915\n",
      "img id in: 22916\n",
      "img id out: 22916\n",
      "img id in: 22917\n",
      "img id out: 22917\n",
      "img id in: 22918\n",
      "img id out: 22918\n",
      "img id in: 22919\n",
      "img id out: 22919\n",
      "img id in: 22920\n",
      "img id out: 22920\n",
      "img id in: 22921\n",
      "img id out: 22921\n",
      "img id in: 22922\n",
      "img id out: 22922\n",
      "img id in: 22923\n",
      "img id out: 22923\n",
      "img id in: 22924\n",
      "img id out: 22924\n",
      "img id in: 22925\n",
      "img id out: 22925\n",
      "img id in: 22926\n",
      "img id out: 22926\n",
      "img id in: 22927\n",
      "img id out: 22927\n",
      "img id in: 22928\n",
      "img id out: 22928\n",
      "img id in: 22929\n",
      "img id out: 22929\n",
      "img id in: 22930\n",
      "img id out: 22930\n",
      "img id in: 22931\n",
      "img id out: 22931\n",
      "img id in: 22932\n",
      "img id out: 22932\n",
      "img id in: 22933\n",
      "img id out: 22933\n",
      "img id in: 22934\n",
      "img id out: 22934\n",
      "img id in: 22935\n",
      "img id out: 22935\n",
      "img id in: 22936\n",
      "img id out: 22936\n",
      "img id in: 22937\n",
      "img id out: 22937\n",
      "img id in: 22938\n",
      "img id out: 22938\n",
      "img id in: 22939\n",
      "img id out: 22939\n",
      "img id in: 22940\n",
      "img id out: 22940\n",
      "img id in: 22941\n",
      "img id out: 22941\n",
      "img id in: 22942\n",
      "img id out: 22942\n",
      "img id in: 22943\n",
      "img id out: 22943\n",
      "img id in: 22944\n",
      "img id out: 22944\n",
      "img id in: 22945\n",
      "img id out: 22945\n",
      "img id in: 22946\n",
      "img id out: 22946\n",
      "img id in: 22947\n",
      "img id out: 22947\n",
      "img id in: 22948\n",
      "img id out: 22948\n",
      "img id in: 22949\n",
      "img id out: 22949\n",
      "img id in: 22950\n",
      "img id out: 22950\n",
      "img id in: 22951\n",
      "img id out: 22951\n",
      "img id in: 22952\n",
      "img id out: 22952\n",
      "img id in: 22953\n",
      "img id out: 22953\n",
      "img id in: 22954\n",
      "img id out: 22954\n",
      "img id in: 22955\n",
      "img id out: 22955\n",
      "img id in: 22956\n",
      "img id out: 22956\n",
      "img id in: 22957\n",
      "img id out: 22957\n",
      "img id in: 22958\n",
      "img id out: 22958\n",
      "img id in: 22959\n",
      "img id out: 22959\n",
      "img id in: 22960\n",
      "img id out: 22960\n",
      "img id in: 22961\n",
      "img id out: 22961\n",
      "img id in: 22962\n",
      "img id out: 22962\n",
      "img id in: 22963\n",
      "img id out: 22963\n",
      "img id in: 22964\n",
      "img id out: 22964\n",
      "img id in: 22965\n",
      "img id out: 22965\n",
      "img id in: 22966\n",
      "img id out: 22966\n",
      "img id in: 22967\n",
      "img id out: 22967\n",
      "img id in: 22968\n",
      "img id out: 22968\n",
      "img id in: 22969\n",
      "img id out: 22969\n",
      "img id in: 22970\n",
      "img id out: 22970\n",
      "img id in: 22971\n",
      "img id out: 22971\n",
      "img id in: 22972\n",
      "img id out: 22972\n",
      "img id in: 22973\n",
      "img id out: 22973\n",
      "img id in: 22974\n",
      "img id out: 22974\n",
      "img id in: 22975\n",
      "img id out: 22975\n",
      "img id in: 22976\n",
      "img id out: 22976\n",
      "img id in: 22977\n",
      "img id out: 22977\n",
      "img id in: 22978\n",
      "img id out: 22978\n",
      "img id in: 22979\n",
      "img id out: 22979\n",
      "img id in: 22980\n",
      "img id out: 22980\n",
      "img id in: 22981\n",
      "img id out: 22981\n",
      "img id in: 22982\n",
      "img id out: 22982\n",
      "img id in: 22983\n",
      "img id out: 22983\n",
      "img id in: 22984\n",
      "img id out: 22984\n",
      "img id in: 22985\n",
      "img id out: 22985\n",
      "img id in: 22986\n",
      "img id out: 22986\n",
      "img id in: 22987\n",
      "img id out: 22987\n",
      "img id in: 22988\n",
      "img id out: 22988\n",
      "img id in: 22989\n",
      "img id out: 22989\n",
      "img id in: 22990\n",
      "img id out: 22990\n",
      "img id in: 22991\n",
      "img id out: 22991\n",
      "img id in: 22992\n",
      "img id out: 22992\n",
      "img id in: 22993\n",
      "img id out: 22993\n",
      "img id in: 22994\n",
      "img id out: 22994\n",
      "img id in: 22995\n",
      "img id out: 22995\n",
      "img id in: 22996\n",
      "img id out: 22996\n",
      "img id in: 22997\n",
      "img id out: 22997\n",
      "img id in: 22998\n",
      "img id out: 22998\n",
      "img id in: 22999\n",
      "img id out: 22999\n",
      "img id in: 23000\n",
      "img id out: 23000\n",
      "img id in: 23001\n",
      "img id out: 23001\n",
      "img id in: 23002\n",
      "img id out: 23002\n",
      "img id in: 23003\n",
      "img id out: 23003\n",
      "img id in: 23004\n",
      "img id out: 23004\n",
      "img id in: 23005\n",
      "img id out: 23005\n",
      "img id in: 23006\n",
      "img id out: 23006\n",
      "img id in: 23007\n",
      "img id out: 23007\n",
      "img id in: 23008\n",
      "img id out: 23008\n",
      "img id in: 23009\n",
      "img id out: 23009\n",
      "img id in: 23010\n",
      "img id out: 23010\n",
      "img id in: 23011\n",
      "img id out: 23011\n",
      "img id in: 23012\n",
      "img id out: 23012\n",
      "img id in: 23013\n",
      "img id out: 23013\n",
      "img id in: 23014\n",
      "img id out: 23014\n",
      "img id in: 23015\n",
      "img id out: 23015\n",
      "img id in: 23016\n",
      "img id out: 23016\n",
      "img id in: 23017\n",
      "img id out: 23017\n",
      "img id in: 23018\n",
      "img id out: 23018\n",
      "img id in: 23019\n",
      "img id out: 23019\n",
      "img id in: 23020\n",
      "img id out: 23020\n",
      "img id in: 23021\n",
      "img id out: 23021\n",
      "img id in: 23022\n",
      "img id out: 23022\n",
      "img id in: 23023\n",
      "img id out: 23023\n",
      "img id in: 23024\n",
      "img id out: 23024\n",
      "img id in: 23025\n",
      "img id out: 23025\n",
      "img id in: 23026\n",
      "img id out: 23026\n",
      "img id in: 23027\n",
      "img id out: 23027\n",
      "img id in: 23028\n",
      "img id out: 23028\n",
      "img id in: 23029\n",
      "img id out: 23029\n",
      "img id in: 23030\n",
      "img id out: 23030\n",
      "img id in: 23031\n",
      "img id out: 23031\n",
      "img id in: 23032\n",
      "img id out: 23032\n",
      "img id in: 23033\n",
      "img id out: 23033\n",
      "img id in: 23034\n",
      "img id out: 23034\n",
      "img id in: 23035\n",
      "img id out: 23035\n",
      "img id in: 23036\n",
      "img id out: 23036\n",
      "img id in: 23037\n",
      "img id out: 23037\n",
      "img id in: 23038\n",
      "img id out: 23038\n",
      "img id in: 23039\n",
      "img id out: 23039\n",
      "img id in: 23040\n",
      "img id out: 23040\n",
      "img id in: 23041\n",
      "img id out: 23041\n",
      "img id in: 23042\n",
      "img id out: 23042\n",
      "img id in: 23043\n",
      "img id out: 23043\n",
      "img id in: 23044\n",
      "img id out: 23044\n",
      "img id in: 23045\n",
      "img id out: 23045\n",
      "img id in: 23046\n",
      "img id out: 23046\n",
      "img id in: 23047\n",
      "img id out: 23047\n",
      "img id in: 23048\n",
      "img id out: 23048\n",
      "img id in: 23049\n",
      "img id out: 23049\n",
      "img id in: 23050\n",
      "img id out: 23050\n",
      "img id in: 23051\n",
      "img id out: 23051\n",
      "img id in: 23052\n",
      "img id out: 23052\n",
      "img id in: 23053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 23053\n",
      "img id in: 23054\n",
      "img id out: 23054\n",
      "img id in: 23055\n",
      "img id out: 23055\n",
      "img id in: 23056\n",
      "img id out: 23056\n",
      "img id in: 23057\n",
      "img id out: 23057\n",
      "img id in: 23058\n",
      "img id out: 23058\n",
      "img id in: 23059\n",
      "img id out: 23059\n",
      "img id in: 23060\n",
      "img id out: 23060\n",
      "img id in: 23061\n",
      "img id out: 23061\n",
      "img id in: 23062\n",
      "img id out: 23062\n",
      "img id in: 23063\n",
      "img id out: 23063\n",
      "img id in: 23064\n",
      "img id out: 23064\n",
      "img id in: 23065\n",
      "img id out: 23065\n",
      "img id in: 23066\n",
      "img id out: 23066\n",
      "img id in: 23067\n",
      "img id out: 23067\n",
      "img id in: 23068\n",
      "img id out: 23068\n",
      "img id in: 23069\n",
      "img id out: 23069\n",
      "img id in: 23070\n",
      "img id out: 23070\n",
      "img id in: 23071\n",
      "img id out: 23071\n",
      "img id in: 23072\n",
      "img id out: 23072\n",
      "img id in: 23073\n",
      "img id out: 23073\n",
      "img id in: 23074\n",
      "img id out: 23074\n",
      "img id in: 23075\n",
      "img id out: 23075\n",
      "img id in: 23076\n",
      "img id out: 23076\n",
      "img id in: 23077\n",
      "img id out: 23077\n",
      "img id in: 23078\n",
      "img id out: 23078\n",
      "img id in: 23079\n",
      "img id out: 23079\n",
      "img id in: 23080\n",
      "img id out: 23080\n",
      "img id in: 23081\n",
      "img id out: 23081\n",
      "img id in: 23082\n",
      "img id out: 23082\n",
      "img id in: 23083\n",
      "img id out: 23083\n",
      "img id in: 23084\n",
      "img id out: 23084\n",
      "img id in: 23085\n",
      "img id out: 23085\n",
      "img id in: 23086\n",
      "img id out: 23086\n",
      "img id in: 23087\n",
      "img id out: 23087\n",
      "img id in: 23088\n",
      "img id out: 23088\n",
      "img id in: 23089\n",
      "img id out: 23089\n",
      "img id in: 23090\n",
      "img id out: 23090\n",
      "img id in: 23091\n",
      "img id out: 23091\n",
      "img id in: 23092\n",
      "img id out: 23092\n",
      "img id in: 23093\n",
      "img id out: 23093\n",
      "img id in: 23094\n",
      "img id out: 23094\n",
      "img id in: 23095\n",
      "img id out: 23095\n",
      "img id in: 23096\n",
      "img id out: 23096\n",
      "img id in: 23097\n",
      "img id out: 23097\n",
      "img id in: 23098\n",
      "img id out: 23098\n",
      "img id in: 23099\n",
      "img id out: 23099\n",
      "img id in: 23100\n",
      "img id out: 23100\n",
      "img id in: 23101\n",
      "img id out: 23101\n",
      "img id in: 23102\n",
      "img id out: 23102\n",
      "img id in: 23103\n",
      "img id out: 23103\n",
      "img id in: 23104\n",
      "img id out: 23104\n",
      "img id in: 23105\n",
      "img id out: 23105\n",
      "img id in: 23106\n",
      "img id out: 23106\n",
      "img id in: 23107\n",
      "img id out: 23107\n",
      "img id in: 23108\n",
      "img id out: 23108\n",
      "img id in: 23109\n",
      "img id out: 23109\n",
      "img id in: 23110\n",
      "img id out: 23110\n",
      "img id in: 23111\n",
      "img id out: 23111\n",
      "img id in: 23112\n",
      "img id out: 23112\n",
      "img id in: 23113\n",
      "img id out: 23113\n",
      "img id in: 23114\n",
      "img id out: 23114\n",
      "img id in: 23115\n",
      "img id out: 23115\n",
      "img id in: 23116\n",
      "img id out: 23116\n",
      "img id in: 23117\n",
      "img id out: 23117\n",
      "img id in: 23118\n",
      "img id out: 23118\n",
      "img id in: 23119\n",
      "img id out: 23119\n",
      "img id in: 23120\n",
      "img id out: 23120\n",
      "img id in: 23121\n",
      "img id out: 23121\n",
      "img id in: 23122\n",
      "img id out: 23122\n",
      "img id in: 23123\n",
      "img id out: 23123\n",
      "img id in: 23124\n",
      "img id out: 23124\n",
      "img id in: 23125\n",
      "img id out: 23125\n",
      "img id in: 23126\n",
      "img id out: 23126\n",
      "img id in: 23127\n",
      "img id out: 23127\n",
      "img id in: 23128\n",
      "img id out: 23128\n",
      "img id in: 23129\n",
      "img id out: 23129\n",
      "img id in: 23130\n",
      "img id out: 23130\n",
      "img id in: 23131\n",
      "img id out: 23131\n",
      "img id in: 23132\n",
      "img id out: 23132\n",
      "img id in: 23133\n",
      "img id out: 23133\n",
      "img id in: 23134\n",
      "img id out: 23134\n",
      "img id in: 23135\n",
      "img id out: 23135\n",
      "img id in: 23136\n",
      "img id out: 23136\n",
      "img id in: 23137\n",
      "img id out: 23137\n",
      "img id in: 23138\n",
      "img id out: 23138\n",
      "img id in: 23139\n",
      "img id out: 23139\n",
      "img id in: 23140\n",
      "img id out: 23140\n",
      "img id in: 23141\n",
      "img id out: 23141\n",
      "img id in: 23142\n",
      "img id out: 23142\n",
      "img id in: 23143\n",
      "img id out: 23143\n",
      "img id in: 23144\n",
      "img id out: 23144\n",
      "img id in: 23145\n",
      "img id out: 23145\n",
      "img id in: 23146\n",
      "img id out: 23146\n",
      "img id in: 23147\n",
      "img id out: 23147\n",
      "img id in: 23148\n",
      "img id out: 23148\n",
      "img id in: 23149\n",
      "img id out: 23149\n",
      "img id in: 23150\n",
      "img id out: 23150\n",
      "img id in: 23151\n",
      "img id out: 23151\n",
      "img id in: 23152\n",
      "img id out: 23152\n",
      "img id in: 23153\n",
      "img id out: 23153\n",
      "img id in: 23154\n",
      "img id out: 23154\n",
      "img id in: 23155\n",
      "img id out: 23155\n",
      "img id in: 23156\n",
      "img id out: 23156\n",
      "img id in: 23157\n",
      "img id out: 23157\n",
      "img id in: 23158\n",
      "img id out: 23158\n",
      "img id in: 23159\n",
      "img id out: 23159\n",
      "img id in: 23160\n",
      "img id out: 23160\n",
      "img id in: 23161\n",
      "img id out: 23161\n",
      "img id in: 23162\n",
      "img id out: 23162\n",
      "img id in: 23163\n",
      "img id out: 23163\n",
      "img id in: 23164\n",
      "img id out: 23164\n",
      "img id in: 23165\n",
      "img id out: 23165\n",
      "img id in: 23166\n",
      "img id out: 23166\n",
      "img id in: 23167\n",
      "img id out: 23167\n",
      "img id in: 23168\n",
      "img id out: 23168\n",
      "img id in: 23169\n",
      "img id out: 23169\n",
      "img id in: 23170\n",
      "img id out: 23170\n",
      "img id in: 23171\n",
      "img id out: 23171\n",
      "img id in: 23172\n",
      "img id out: 23172\n",
      "img id in: 23173\n",
      "img id out: 23173\n",
      "img id in: 23174\n",
      "img id out: 23174\n",
      "img id in: 23175\n",
      "img id out: 23175\n",
      "img id in: 23176\n",
      "img id out: 23176\n",
      "img id in: 23177\n",
      "img id out: 23177\n",
      "img id in: 23178\n",
      "img id out: 23178\n",
      "img id in: 23179\n",
      "img id out: 23179\n",
      "img id in: 23180\n",
      "img id out: 23180\n",
      "img id in: 23181\n",
      "img id out: 23181\n",
      "img id in: 23182\n",
      "img id out: 23182\n",
      "img id in: 23183\n",
      "img id out: 23183\n",
      "img id in: 23184\n",
      "img id out: 23184\n",
      "img id in: 23185\n",
      "img id out: 23185\n",
      "img id in: 23186\n",
      "img id out: 23186\n",
      "img id in: 23187\n",
      "img id out: 23187\n",
      "img id in: 23188\n",
      "img id out: 23188\n",
      "img id in: 23189\n",
      "img id out: 23189\n",
      "img id in: 23190\n",
      "img id out: 23190\n",
      "img id in: 23191\n",
      "img id out: 23191\n",
      "img id in: 23192\n",
      "img id out: 23192\n",
      "img id in: 23193\n",
      "img id out: 23193\n",
      "img id in: 23194\n",
      "img id out: 23194\n",
      "img id in: 23195\n",
      "img id out: 23195\n",
      "img id in: 23196\n",
      "img id out: 23196\n",
      "img id in: 23197\n",
      "img id out: 23197\n",
      "img id in: 23198\n",
      "img id out: 23198\n",
      "img id in: 23199\n",
      "img id out: 23199\n",
      "img id in: 23200\n",
      "img id out: 23200\n",
      "img id in: 23201\n",
      "img id out: 23201\n",
      "img id in: 23202\n",
      "img id out: 23202\n",
      "img id in: 23203\n",
      "img id out: 23203\n",
      "img id in: 23204\n",
      "img id out: 23204\n",
      "img id in: 23205\n",
      "img id out: 23205\n",
      "img id in: 23206\n",
      "img id out: 23206\n",
      "img id in: 23207\n",
      "img id out: 23207\n",
      "img id in: 23208\n",
      "img id out: 23208\n",
      "img id in: 23209\n",
      "img id out: 23209\n",
      "img id in: 23210\n",
      "img id out: 23210\n",
      "img id in: 23211\n",
      "img id out: 23211\n",
      "img id in: 23212\n",
      "img id out: 23212\n",
      "img id in: 23213\n",
      "img id out: 23213\n",
      "img id in: 23214\n",
      "img id out: 23214\n",
      "img id in: 23215\n",
      "img id out: 23215\n",
      "img id in: 23216\n",
      "img id out: 23216\n",
      "img id in: 23217\n",
      "img id out: 23217\n",
      "img id in: 23218\n",
      "img id out: 23218\n",
      "img id in: 23219\n",
      "img id out: 23219\n",
      "img id in: 23220\n",
      "img id out: 23220\n",
      "img id in: 23221\n",
      "img id out: 23221\n",
      "img id in: 23222\n",
      "img id out: 23222\n",
      "img id in: 23223\n",
      "img id out: 23223\n",
      "img id in: 23224\n",
      "img id out: 23224\n",
      "img id in: 23225\n",
      "img id out: 23225\n",
      "img id in: 23226\n",
      "img id out: 23226\n",
      "img id in: 23227\n",
      "img id out: 23227\n",
      "img id in: 23228\n",
      "img id out: 23228\n",
      "img id in: 23229\n",
      "img id out: 23229\n",
      "img id in: 23230\n",
      "img id out: 23230\n",
      "img id in: 23231\n",
      "img id out: 23231\n",
      "img id in: 23232\n",
      "img id out: 23232\n",
      "img id in: 23233\n",
      "img id out: 23233\n",
      "img id in: 23234\n",
      "img id out: 23234\n",
      "img id in: 23235\n",
      "img id out: 23235\n",
      "img id in: 23236\n",
      "img id out: 23236\n",
      "img id in: 23237\n",
      "img id out: 23237\n",
      "img id in: 23238\n",
      "img id out: 23238\n",
      "img id in: 23239\n",
      "img id out: 23239\n",
      "img id in: 23240\n",
      "img id out: 23240\n",
      "img id in: 23241\n",
      "img id out: 23241\n",
      "img id in: 23242\n",
      "img id out: 23242\n",
      "img id in: 23243\n",
      "img id out: 23243\n",
      "img id in: 23244\n",
      "img id out: 23244\n",
      "img id in: 23245\n",
      "img id out: 23245\n",
      "img id in: 23246\n",
      "img id out: 23246\n",
      "img id in: 23247\n",
      "img id out: 23247\n",
      "img id in: 23248\n",
      "img id out: 23248\n",
      "img id in: 23249\n",
      "img id out: 23249\n",
      "img id in: 23250\n",
      "img id out: 23250\n",
      "img id in: 23251\n",
      "img id out: 23251\n",
      "img id in: 23252\n",
      "img id out: 23252\n",
      "img id in: 23253\n",
      "img id out: 23253\n",
      "img id in: 23254\n",
      "img id out: 23254\n",
      "img id in: 23255\n",
      "img id out: 23255\n",
      "img id in: 23256\n",
      "img id out: 23256\n",
      "img id in: 23257\n",
      "img id out: 23257\n",
      "img id in: 23258\n",
      "img id out: 23258\n",
      "img id in: 23259\n",
      "img id out: 23259\n",
      "img id in: 23260\n",
      "img id out: 23260\n",
      "img id in: 23261\n",
      "img id out: 23261\n",
      "img id in: 23262\n",
      "img id out: 23262\n",
      "img id in: 23263\n",
      "img id out: 23263\n",
      "img id in: 23264\n",
      "img id out: 23264\n",
      "img id in: 23265\n",
      "img id out: 23265\n",
      "img id in: 23266\n",
      "img id out: 23266\n",
      "img id in: 23267\n",
      "img id out: 23267\n",
      "img id in: 23268\n",
      "img id out: 23268\n",
      "img id in: 23269\n",
      "img id out: 23269\n",
      "img id in: 23270\n",
      "img id out: 23270\n",
      "img id in: 23271\n",
      "img id out: 23271\n",
      "img id in: 23272\n",
      "img id out: 23272\n",
      "img id in: 23273\n",
      "img id out: 23273\n",
      "img id in: 23274\n",
      "img id out: 23274\n",
      "img id in: 23275\n",
      "img id out: 23275\n",
      "img id in: 23276\n",
      "img id out: 23276\n",
      "img id in: 23277\n",
      "img id out: 23277\n",
      "img id in: 23278\n",
      "img id out: 23278\n",
      "img id in: 23279\n",
      "img id out: 23279\n",
      "img id in: 23280\n",
      "img id out: 23280\n",
      "img id in: 23281\n",
      "img id out: 23281\n",
      "img id in: 23282\n",
      "img id out: 23282\n",
      "img id in: 23283\n",
      "img id out: 23283\n",
      "img id in: 23284\n",
      "img id out: 23284\n",
      "img id in: 23285\n",
      "img id out: 23285\n",
      "img id in: 23286\n",
      "img id out: 23286\n",
      "img id in: 23287\n",
      "img id out: 23287\n",
      "img id in: 23288\n",
      "img id out: 23288\n",
      "img id in: 23289\n",
      "img id out: 23289\n",
      "img id in: 23290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 23290\n",
      "img id in: 23291\n",
      "img id out: 23291\n",
      "img id in: 23292\n",
      "img id out: 23292\n",
      "img id in: 23293\n",
      "img id out: 23293\n",
      "img id in: 23294\n",
      "img id out: 23294\n",
      "img id in: 23295\n",
      "img id out: 23295\n",
      "img id in: 23296\n",
      "img id out: 23296\n",
      "img id in: 23297\n",
      "img id out: 23297\n",
      "img id in: 23298\n",
      "img id out: 23298\n",
      "img id in: 23299\n",
      "img id out: 23299\n",
      "img id in: 23300\n",
      "img id out: 23300\n",
      "img id in: 23301\n",
      "img id out: 23301\n",
      "img id in: 23302\n",
      "img id out: 23302\n",
      "img id in: 23303\n",
      "img id out: 23303\n",
      "img id in: 23304\n",
      "img id out: 23304\n",
      "img id in: 23305\n",
      "img id out: 23305\n",
      "img id in: 23306\n",
      "img id out: 23306\n",
      "img id in: 23307\n",
      "img id out: 23307\n",
      "img id in: 23308\n",
      "img id out: 23308\n",
      "img id in: 23309\n",
      "img id out: 23309\n",
      "img id in: 23310\n",
      "img id out: 23310\n",
      "img id in: 23311\n",
      "img id out: 23311\n",
      "img id in: 23312\n",
      "img id out: 23312\n",
      "img id in: 23313\n",
      "img id out: 23313\n",
      "img id in: 23314\n",
      "img id out: 23314\n",
      "img id in: 23315\n",
      "img id out: 23315\n",
      "img id in: 23316\n",
      "img id out: 23316\n",
      "img id in: 23317\n",
      "img id out: 23317\n",
      "img id in: 23318\n",
      "img id out: 23318\n",
      "img id in: 23319\n",
      "img id out: 23319\n",
      "img id in: 23320\n",
      "img id out: 23320\n",
      "img id in: 23321\n",
      "img id out: 23321\n",
      "img id in: 23322\n",
      "img id out: 23322\n",
      "img id in: 23323\n",
      "img id out: 23323\n",
      "img id in: 23324\n",
      "img id out: 23324\n",
      "img id in: 23325\n",
      "img id out: 23325\n",
      "img id in: 23326\n",
      "img id out: 23326\n",
      "img id in: 23327\n",
      "img id out: 23327\n",
      "img id in: 23328\n",
      "img id out: 23328\n",
      "img id in: 23329\n",
      "img id out: 23329\n",
      "img id in: 23330\n",
      "img id out: 23330\n",
      "img id in: 23331\n",
      "img id out: 23331\n",
      "img id in: 23332\n",
      "img id out: 23332\n",
      "img id in: 23333\n",
      "img id out: 23333\n",
      "img id in: 23334\n",
      "img id out: 23334\n",
      "img id in: 23335\n",
      "img id out: 23335\n",
      "img id in: 23336\n",
      "img id out: 23336\n",
      "img id in: 23337\n",
      "img id out: 23337\n",
      "img id in: 23338\n",
      "img id out: 23338\n",
      "img id in: 23339\n",
      "img id out: 23339\n",
      "img id in: 23340\n",
      "img id out: 23340\n",
      "img id in: 23341\n",
      "img id out: 23341\n",
      "img id in: 23342\n",
      "img id out: 23342\n",
      "img id in: 23343\n",
      "img id out: 23343\n",
      "img id in: 23344\n",
      "img id out: 23344\n",
      "img id in: 23345\n",
      "img id out: 23345\n",
      "img id in: 23346\n",
      "img id out: 23346\n",
      "img id in: 23347\n",
      "img id out: 23347\n",
      "img id in: 23348\n",
      "img id out: 23348\n",
      "img id in: 23349\n",
      "img id out: 23349\n",
      "img id in: 23350\n",
      "img id out: 23350\n",
      "img id in: 23351\n",
      "img id out: 23351\n",
      "img id in: 23352\n",
      "img id out: 23352\n",
      "img id in: 23353\n",
      "img id out: 23353\n",
      "img id in: 23354\n",
      "img id out: 23354\n",
      "img id in: 23355\n",
      "img id out: 23355\n",
      "img id in: 23356\n",
      "img id out: 23356\n",
      "img id in: 23357\n",
      "img id out: 23357\n",
      "img id in: 23358\n",
      "img id out: 23358\n",
      "img id in: 23359\n",
      "img id out: 23359\n",
      "img id in: 23360\n",
      "img id out: 23360\n",
      "img id in: 23361\n",
      "img id out: 23361\n",
      "img id in: 23362\n",
      "img id out: 23362\n",
      "img id in: 23363\n",
      "img id out: 23363\n",
      "img id in: 23364\n",
      "img id out: 23364\n",
      "img id in: 23365\n",
      "img id out: 23365\n",
      "img id in: 23366\n",
      "img id out: 23366\n",
      "img id in: 23367\n",
      "img id out: 23367\n",
      "img id in: 23368\n",
      "img id out: 23368\n",
      "img id in: 23369\n",
      "img id out: 23369\n",
      "img id in: 23370\n",
      "img id out: 23370\n",
      "img id in: 23371\n",
      "img id out: 23371\n",
      "img id in: 23372\n",
      "img id out: 23372\n",
      "img id in: 23373\n",
      "img id out: 23373\n",
      "img id in: 23374\n",
      "img id out: 23374\n",
      "img id in: 23375\n",
      "img id out: 23375\n",
      "img id in: 23376\n",
      "img id out: 23376\n",
      "img id in: 23377\n",
      "img id out: 23377\n",
      "img id in: 23378\n",
      "img id out: 23378\n",
      "img id in: 23379\n",
      "img id out: 23379\n",
      "img id in: 23380\n",
      "img id out: 23380\n",
      "img id in: 23381\n",
      "img id out: 23381\n",
      "img id in: 23382\n",
      "img id out: 23382\n",
      "img id in: 23383\n",
      "img id out: 23383\n",
      "img id in: 23384\n",
      "img id out: 23384\n",
      "img id in: 23385\n",
      "img id out: 23385\n",
      "img id in: 23386\n",
      "img id out: 23386\n",
      "img id in: 23387\n",
      "img id out: 23387\n",
      "img id in: 23388\n",
      "img id out: 23388\n",
      "img id in: 23389\n",
      "img id out: 23389\n",
      "img id in: 23390\n",
      "img id out: 23390\n",
      "img id in: 23391\n",
      "img id out: 23391\n",
      "img id in: 23392\n",
      "img id out: 23392\n",
      "img id in: 23393\n",
      "img id out: 23393\n",
      "img id in: 23394\n",
      "img id out: 23394\n",
      "img id in: 23395\n",
      "img id out: 23395\n",
      "img id in: 23396\n",
      "img id out: 23396\n",
      "img id in: 23397\n",
      "img id out: 23397\n",
      "img id in: 23398\n",
      "img id out: 23398\n",
      "img id in: 23399\n",
      "img id out: 23399\n",
      "img id in: 23400\n",
      "img id out: 23400\n",
      "img id in: 23401\n",
      "img id out: 23401\n",
      "img id in: 23402\n",
      "img id out: 23402\n",
      "img id in: 23403\n",
      "img id out: 23403\n",
      "img id in: 23404\n",
      "img id out: 23404\n",
      "img id in: 23405\n",
      "img id out: 23405\n",
      "img id in: 23406\n",
      "img id out: 23406\n",
      "img id in: 23407\n",
      "img id out: 23407\n",
      "img id in: 23408\n",
      "img id out: 23408\n",
      "img id in: 23409\n",
      "img id out: 23409\n",
      "img id in: 23410\n",
      "img id out: 23410\n",
      "img id in: 23411\n",
      "img id out: 23411\n",
      "img id in: 23412\n",
      "img id out: 23412\n",
      "img id in: 23413\n",
      "img id out: 23413\n",
      "img id in: 23414\n",
      "img id out: 23414\n",
      "img id in: 23415\n",
      "img id out: 23415\n",
      "img id in: 23416\n",
      "img id out: 23416\n",
      "img id in: 23417\n",
      "img id out: 23417\n",
      "img id in: 23418\n",
      "img id out: 23418\n",
      "img id in: 23419\n",
      "img id out: 23419\n",
      "img id in: 23420\n",
      "img id out: 23420\n",
      "img id in: 23421\n",
      "img id out: 23421\n",
      "img id in: 23422\n",
      "img id out: 23422\n",
      "img id in: 23423\n",
      "img id out: 23423\n",
      "img id in: 23424\n",
      "img id out: 23424\n",
      "img id in: 23425\n",
      "img id out: 23425\n",
      "img id in: 23426\n",
      "img id out: 23426\n",
      "img id in: 23427\n",
      "img id out: 23427\n",
      "img id in: 23428\n",
      "img id out: 23428\n",
      "img id in: 23429\n",
      "img id out: 23429\n",
      "img id in: 23430\n",
      "img id out: 23430\n",
      "img id in: 23431\n",
      "img id out: 23431\n",
      "img id in: 23432\n",
      "img id out: 23432\n",
      "img id in: 23433\n",
      "img id out: 23433\n",
      "img id in: 23434\n",
      "img id out: 23434\n",
      "img id in: 23435\n",
      "img id out: 23435\n",
      "img id in: 23436\n",
      "img id out: 23436\n",
      "img id in: 23437\n",
      "img id out: 23437\n",
      "img id in: 23438\n",
      "img id out: 23438\n",
      "img id in: 23439\n",
      "img id out: 23439\n",
      "img id in: 23440\n",
      "img id out: 23440\n",
      "img id in: 23441\n",
      "img id out: 23441\n",
      "img id in: 23442\n",
      "img id out: 23442\n",
      "img id in: 23443\n",
      "img id out: 23443\n",
      "img id in: 23444\n",
      "img id out: 23444\n",
      "img id in: 23445\n",
      "img id out: 23445\n",
      "img id in: 23446\n",
      "img id out: 23446\n",
      "img id in: 23447\n",
      "img id out: 23447\n",
      "img id in: 23448\n",
      "img id out: 23448\n",
      "img id in: 23449\n",
      "img id out: 23449\n",
      "img id in: 23450\n",
      "img id out: 23450\n",
      "img id in: 23451\n",
      "img id out: 23451\n",
      "img id in: 23452\n",
      "img id out: 23452\n",
      "img id in: 23453\n",
      "img id out: 23453\n",
      "img id in: 23454\n",
      "img id out: 23454\n",
      "img id in: 23455\n",
      "img id out: 23455\n",
      "img id in: 23456\n",
      "img id out: 23456\n",
      "img id in: 23457\n",
      "img id out: 23457\n",
      "img id in: 23458\n",
      "img id out: 23458\n",
      "img id in: 23459\n",
      "img id out: 23459\n",
      "img id in: 23460\n",
      "img id out: 23460\n",
      "img id in: 23461\n",
      "img id out: 23461\n",
      "img id in: 23462\n",
      "img id out: 23462\n",
      "img id in: 23463\n",
      "img id out: 23463\n",
      "img id in: 23464\n",
      "img id out: 23464\n",
      "img id in: 23465\n",
      "img id out: 23465\n",
      "img id in: 23466\n",
      "img id out: 23466\n",
      "img id in: 23467\n",
      "img id out: 23467\n",
      "img id in: 23468\n",
      "img id out: 23468\n",
      "img id in: 23469\n",
      "img id out: 23469\n",
      "img id in: 23470\n",
      "img id out: 23470\n",
      "img id in: 23471\n",
      "img id out: 23471\n",
      "img id in: 23472\n",
      "img id out: 23472\n",
      "img id in: 23473\n",
      "img id out: 23473\n",
      "img id in: 23474\n",
      "img id out: 23474\n",
      "img id in: 23475\n",
      "img id out: 23475\n",
      "img id in: 23476\n",
      "img id out: 23476\n",
      "img id in: 23477\n",
      "img id out: 23477\n",
      "img id in: 23478\n",
      "img id out: 23478\n",
      "img id in: 23479\n",
      "img id out: 23479\n",
      "img id in: 23480\n",
      "img id out: 23480\n",
      "img id in: 23481\n",
      "img id out: 23481\n",
      "img id in: 23482\n",
      "img id out: 23482\n",
      "img id in: 23483\n",
      "img id out: 23483\n",
      "img id in: 23484\n",
      "img id out: 23484\n",
      "img id in: 23485\n",
      "img id out: 23485\n",
      "img id in: 23486\n",
      "img id out: 23486\n",
      "img id in: 23487\n",
      "img id out: 23487\n",
      "img id in: 23488\n",
      "img id out: 23488\n",
      "img id in: 23489\n",
      "img id out: 23489\n",
      "img id in: 23490\n",
      "img id out: 23490\n",
      "img id in: 23491\n",
      "img id out: 23491\n",
      "img id in: 23492\n",
      "img id out: 23492\n",
      "img id in: 23493\n",
      "img id out: 23493\n",
      "img id in: 23494\n",
      "img id out: 23494\n",
      "img id in: 23495\n",
      "img id out: 23495\n",
      "img id in: 23496\n",
      "img id out: 23496\n",
      "img id in: 23497\n",
      "img id out: 23497\n",
      "img id in: 23498\n",
      "img id out: 23498\n",
      "img id in: 23499\n",
      "img id out: 23499\n",
      "img id in: 23500\n",
      "img id out: 23500\n",
      "img id in: 23501\n",
      "img id out: 23501\n",
      "img id in: 23502\n",
      "img id out: 23502\n",
      "img id in: 23503\n",
      "img id out: 23503\n",
      "img id in: 23504\n",
      "img id out: 23504\n",
      "img id in: 23505\n",
      "img id out: 23505\n",
      "img id in: 23506\n",
      "img id out: 23506\n",
      "img id in: 23507\n",
      "img id out: 23507\n",
      "img id in: 23508\n",
      "img id out: 23508\n",
      "img id in: 23509\n",
      "img id out: 23509\n",
      "img id in: 23510\n",
      "img id out: 23510\n",
      "img id in: 23511\n",
      "img id out: 23511\n",
      "img id in: 23512\n",
      "img id out: 23512\n",
      "img id in: 23513\n",
      "img id out: 23513\n",
      "img id in: 23514\n",
      "img id out: 23514\n",
      "img id in: 23515\n",
      "img id out: 23515\n",
      "img id in: 23516\n",
      "img id out: 23516\n",
      "img id in: 23517\n",
      "img id out: 23517\n",
      "img id in: 23518\n",
      "img id out: 23518\n",
      "img id in: 23519\n",
      "img id out: 23519\n",
      "img id in: 23520\n",
      "img id out: 23520\n",
      "img id in: 23521\n",
      "img id out: 23521\n",
      "img id in: 23522\n",
      "img id out: 23522\n",
      "img id in: 23523\n",
      "img id out: 23523\n",
      "img id in: 23524\n",
      "img id out: 23524\n",
      "img id in: 23525\n",
      "img id out: 23525\n",
      "img id in: 23526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 23526\n",
      "img id in: 23527\n",
      "img id out: 23527\n",
      "img id in: 23528\n",
      "img id out: 23528\n",
      "img id in: 23529\n",
      "img id out: 23529\n",
      "img id in: 23530\n",
      "img id out: 23530\n",
      "img id in: 23531\n",
      "img id out: 23531\n",
      "img id in: 23532\n",
      "img id out: 23532\n",
      "img id in: 23533\n",
      "img id out: 23533\n",
      "img id in: 23534\n",
      "img id out: 23534\n",
      "img id in: 23535\n",
      "img id out: 23535\n",
      "img id in: 23536\n",
      "img id out: 23536\n",
      "img id in: 23537\n",
      "img id out: 23537\n",
      "img id in: 23538\n",
      "img id out: 23538\n",
      "img id in: 23539\n",
      "img id out: 23539\n",
      "img id in: 23540\n",
      "img id out: 23540\n",
      "img id in: 23541\n",
      "img id out: 23541\n",
      "img id in: 23542\n",
      "img id out: 23542\n",
      "img id in: 23543\n",
      "img id out: 23543\n",
      "img id in: 23544\n",
      "img id out: 23544\n",
      "img id in: 23545\n",
      "img id out: 23545\n",
      "img id in: 23546\n",
      "img id out: 23546\n",
      "img id in: 23547\n",
      "img id out: 23547\n",
      "img id in: 23548\n",
      "img id out: 23548\n",
      "img id in: 23549\n",
      "img id out: 23549\n",
      "img id in: 23550\n",
      "img id out: 23550\n",
      "img id in: 23551\n",
      "img id out: 23551\n",
      "img id in: 23552\n",
      "img id out: 23552\n",
      "img id in: 23553\n",
      "img id out: 23553\n",
      "img id in: 23554\n",
      "img id out: 23554\n",
      "img id in: 23555\n",
      "img id out: 23555\n",
      "img id in: 23556\n",
      "img id out: 23556\n",
      "img id in: 23557\n",
      "img id out: 23557\n",
      "img id in: 23558\n",
      "img id out: 23558\n",
      "img id in: 23559\n",
      "img id out: 23559\n",
      "img id in: 23560\n",
      "img id out: 23560\n",
      "img id in: 23561\n",
      "img id out: 23561\n",
      "img id in: 23562\n",
      "img id out: 23562\n",
      "img id in: 23563\n",
      "img id out: 23563\n",
      "img id in: 23564\n",
      "img id out: 23564\n",
      "img id in: 23565\n",
      "img id out: 23565\n",
      "img id in: 23566\n",
      "img id out: 23566\n",
      "img id in: 23567\n",
      "img id out: 23567\n",
      "img id in: 23568\n",
      "img id out: 23568\n",
      "img id in: 23569\n",
      "img id out: 23569\n",
      "img id in: 23570\n",
      "img id out: 23570\n",
      "img id in: 23571\n",
      "img id out: 23571\n",
      "img id in: 23572\n",
      "img id out: 23572\n",
      "img id in: 23573\n",
      "img id out: 23573\n",
      "img id in: 23574\n",
      "img id out: 23574\n",
      "img id in: 23575\n",
      "img id out: 23575\n",
      "img id in: 23576\n",
      "img id out: 23576\n",
      "img id in: 23577\n",
      "img id out: 23577\n",
      "img id in: 23578\n",
      "img id out: 23578\n",
      "img id in: 23579\n",
      "img id out: 23579\n",
      "img id in: 23580\n",
      "img id out: 23580\n",
      "img id in: 23581\n",
      "img id out: 23581\n",
      "img id in: 23582\n",
      "img id out: 23582\n",
      "img id in: 23583\n",
      "img id out: 23583\n",
      "img id in: 23584\n",
      "img id out: 23584\n",
      "img id in: 23585\n",
      "img id out: 23585\n",
      "img id in: 23586\n",
      "img id out: 23586\n",
      "img id in: 23587\n",
      "img id out: 23587\n",
      "img id in: 23588\n",
      "img id out: 23588\n",
      "img id in: 23589\n",
      "img id out: 23589\n",
      "img id in: 23590\n",
      "img id out: 23590\n",
      "img id in: 23591\n",
      "img id out: 23591\n",
      "img id in: 23592\n",
      "img id out: 23592\n",
      "img id in: 23593\n",
      "img id out: 23593\n",
      "img id in: 23594\n",
      "img id out: 23594\n",
      "img id in: 23595\n",
      "img id out: 23595\n",
      "img id in: 23596\n",
      "img id out: 23596\n",
      "img id in: 23597\n",
      "img id out: 23597\n",
      "img id in: 23598\n",
      "img id out: 23598\n",
      "img id in: 23599\n",
      "img id out: 23599\n",
      "img id in: 23600\n",
      "img id out: 23600\n",
      "img id in: 23601\n",
      "img id out: 23601\n",
      "img id in: 23602\n",
      "img id out: 23602\n",
      "img id in: 23603\n",
      "img id out: 23603\n",
      "img id in: 23604\n",
      "img id out: 23604\n",
      "img id in: 23605\n",
      "img id out: 23605\n",
      "img id in: 23606\n",
      "img id out: 23606\n",
      "img id in: 23607\n",
      "img id out: 23607\n",
      "img id in: 23608\n",
      "img id out: 23608\n",
      "img id in: 23609\n",
      "img id out: 23609\n",
      "img id in: 23610\n",
      "img id out: 23610\n",
      "img id in: 23611\n",
      "img id out: 23611\n",
      "img id in: 23612\n",
      "img id out: 23612\n",
      "img id in: 23613\n",
      "img id out: 23613\n",
      "img id in: 23614\n",
      "img id out: 23614\n",
      "img id in: 23615\n",
      "img id out: 23615\n",
      "img id in: 23616\n",
      "img id out: 23616\n",
      "img id in: 23617\n",
      "img id out: 23617\n",
      "img id in: 23618\n",
      "img id out: 23618\n",
      "img id in: 23619\n",
      "img id out: 23619\n",
      "img id in: 23620\n",
      "img id out: 23620\n",
      "img id in: 23621\n",
      "img id out: 23621\n",
      "img id in: 23622\n",
      "img id out: 23622\n",
      "img id in: 23623\n",
      "img id out: 23623\n",
      "img id in: 23624\n",
      "img id out: 23624\n",
      "img id in: 23625\n",
      "img id out: 23625\n",
      "img id in: 23626\n",
      "img id out: 23626\n",
      "img id in: 23627\n",
      "img id out: 23627\n",
      "img id in: 23628\n",
      "img id out: 23628\n",
      "img id in: 23629\n",
      "img id out: 23629\n",
      "img id in: 23630\n",
      "img id out: 23630\n",
      "img id in: 23631\n",
      "img id out: 23631\n",
      "img id in: 23632\n",
      "img id out: 23632\n",
      "img id in: 23633\n",
      "img id out: 23633\n",
      "img id in: 23634\n",
      "img id out: 23634\n",
      "img id in: 23635\n",
      "img id out: 23635\n",
      "img id in: 23636\n",
      "img id out: 23636\n",
      "img id in: 23637\n",
      "img id out: 23637\n",
      "img id in: 23638\n",
      "img id out: 23638\n",
      "img id in: 23639\n",
      "img id out: 23639\n",
      "img id in: 23640\n",
      "img id out: 23640\n",
      "img id in: 23641\n",
      "img id out: 23641\n",
      "img id in: 23642\n",
      "img id out: 23642\n",
      "img id in: 23643\n",
      "img id out: 23643\n",
      "img id in: 23644\n",
      "img id out: 23644\n",
      "img id in: 23645\n",
      "img id out: 23645\n",
      "img id in: 23646\n",
      "img id out: 23646\n",
      "img id in: 23647\n",
      "img id out: 23647\n",
      "img id in: 23648\n",
      "img id out: 23648\n",
      "img id in: 23649\n",
      "img id out: 23649\n",
      "img id in: 23650\n",
      "img id out: 23650\n",
      "img id in: 23651\n",
      "img id out: 23651\n",
      "img id in: 23652\n",
      "img id out: 23652\n",
      "img id in: 23653\n",
      "img id out: 23653\n",
      "img id in: 23654\n",
      "img id out: 23654\n",
      "img id in: 23655\n",
      "img id out: 23655\n",
      "img id in: 23656\n",
      "img id out: 23656\n",
      "img id in: 23657\n",
      "img id out: 23657\n",
      "img id in: 23658\n",
      "img id out: 23658\n",
      "img id in: 23659\n",
      "img id out: 23659\n",
      "img id in: 23660\n",
      "img id out: 23660\n",
      "img id in: 23661\n",
      "img id out: 23661\n",
      "img id in: 23662\n",
      "img id out: 23662\n",
      "img id in: 23663\n",
      "img id out: 23663\n",
      "img id in: 23664\n",
      "img id out: 23664\n",
      "img id in: 23665\n",
      "img id out: 23665\n",
      "img id in: 23666\n",
      "img id out: 23666\n",
      "img id in: 23667\n",
      "img id out: 23667\n",
      "img id in: 23668\n",
      "img id out: 23668\n",
      "img id in: 23669\n",
      "img id out: 23669\n",
      "img id in: 23670\n",
      "img id out: 23670\n",
      "img id in: 23671\n",
      "img id out: 23671\n",
      "img id in: 23672\n",
      "img id out: 23672\n",
      "img id in: 23673\n",
      "img id out: 23673\n",
      "img id in: 23674\n",
      "img id out: 23674\n",
      "img id in: 23675\n",
      "img id out: 23675\n",
      "img id in: 23676\n",
      "img id out: 23676\n",
      "img id in: 23677\n",
      "img id out: 23677\n",
      "img id in: 23678\n",
      "img id out: 23678\n",
      "img id in: 23679\n",
      "img id out: 23679\n",
      "img id in: 23680\n",
      "img id out: 23680\n",
      "img id in: 23681\n",
      "img id out: 23681\n",
      "img id in: 23682\n",
      "img id out: 23682\n",
      "img id in: 23683\n",
      "img id out: 23683\n",
      "img id in: 23684\n",
      "img id out: 23684\n",
      "img id in: 23685\n",
      "img id out: 23685\n",
      "img id in: 23686\n",
      "img id out: 23686\n",
      "img id in: 23687\n",
      "img id out: 23687\n",
      "img id in: 23688\n",
      "img id out: 23688\n",
      "img id in: 23689\n",
      "img id out: 23689\n",
      "img id in: 23690\n",
      "img id out: 23690\n",
      "img id in: 23691\n",
      "img id out: 23691\n",
      "img id in: 23692\n",
      "img id out: 23692\n",
      "img id in: 23693\n",
      "img id out: 23693\n",
      "img id in: 23694\n",
      "img id out: 23694\n",
      "img id in: 23695\n",
      "img id out: 23695\n",
      "img id in: 23696\n",
      "img id out: 23696\n",
      "img id in: 23697\n",
      "img id out: 23697\n",
      "img id in: 23698\n",
      "img id out: 23698\n",
      "img id in: 23699\n",
      "img id out: 23699\n",
      "img id in: 23700\n",
      "img id out: 23700\n",
      "img id in: 23701\n",
      "img id out: 23701\n",
      "img id in: 23702\n",
      "img id out: 23702\n",
      "img id in: 23703\n",
      "img id out: 23703\n",
      "img id in: 23704\n",
      "img id out: 23704\n",
      "img id in: 23705\n",
      "img id out: 23705\n",
      "img id in: 23706\n",
      "img id out: 23706\n",
      "img id in: 23707\n",
      "img id out: 23707\n",
      "img id in: 23708\n",
      "img id out: 23708\n",
      "img id in: 23709\n",
      "img id out: 23709\n",
      "img id in: 23710\n",
      "img id out: 23710\n",
      "img id in: 23711\n",
      "img id out: 23711\n",
      "img id in: 23712\n",
      "img id out: 23712\n",
      "img id in: 23713\n",
      "img id out: 23713\n",
      "img id in: 23714\n",
      "img id out: 23714\n",
      "img id in: 23715\n",
      "img id out: 23715\n",
      "img id in: 23716\n",
      "img id out: 23716\n",
      "img id in: 23717\n",
      "img id out: 23717\n",
      "img id in: 23718\n",
      "img id out: 23718\n",
      "img id in: 23719\n",
      "img id out: 23719\n",
      "img id in: 23720\n",
      "img id out: 23720\n",
      "img id in: 23721\n",
      "img id out: 23721\n",
      "img id in: 23722\n",
      "img id out: 23722\n",
      "img id in: 23723\n",
      "img id out: 23723\n",
      "img id in: 23724\n",
      "img id out: 23724\n",
      "img id in: 23725\n",
      "img id out: 23725\n",
      "img id in: 23726\n",
      "img id out: 23726\n",
      "img id in: 23727\n",
      "img id out: 23727\n",
      "img id in: 23728\n",
      "img id out: 23728\n",
      "img id in: 23729\n",
      "img id out: 23729\n",
      "img id in: 23730\n",
      "img id out: 23730\n",
      "img id in: 23731\n",
      "img id out: 23731\n",
      "img id in: 23732\n",
      "img id out: 23732\n",
      "img id in: 23733\n",
      "img id out: 23733\n",
      "img id in: 23734\n",
      "img id out: 23734\n",
      "img id in: 23735\n",
      "img id out: 23735\n",
      "img id in: 23736\n",
      "img id out: 23736\n",
      "img id in: 23737\n",
      "img id out: 23737\n",
      "img id in: 23738\n",
      "img id out: 23738\n",
      "img id in: 23739\n",
      "img id out: 23739\n",
      "img id in: 23740\n",
      "img id out: 23740\n",
      "img id in: 23741\n",
      "img id out: 23741\n",
      "img id in: 23742\n",
      "img id out: 23742\n",
      "img id in: 23743\n",
      "img id out: 23743\n",
      "img id in: 23744\n",
      "img id out: 23744\n",
      "img id in: 23745\n",
      "img id out: 23745\n",
      "img id in: 23746\n",
      "img id out: 23746\n",
      "img id in: 23747\n",
      "img id out: 23747\n",
      "img id in: 23748\n",
      "img id out: 23748\n",
      "img id in: 23749\n",
      "img id out: 23749\n",
      "img id in: 23750\n",
      "img id out: 23750\n",
      "img id in: 23751\n",
      "img id out: 23751\n",
      "img id in: 23752\n",
      "img id out: 23752\n",
      "img id in: 23753\n",
      "img id out: 23753\n",
      "img id in: 23754\n",
      "img id out: 23754\n",
      "img id in: 23755\n",
      "img id out: 23755\n",
      "img id in: 23756\n",
      "img id out: 23756\n",
      "img id in: 23757\n",
      "img id out: 23757\n",
      "img id in: 23758\n",
      "img id out: 23758\n",
      "img id in: 23759\n",
      "img id out: 23759\n",
      "img id in: 23760\n",
      "img id out: 23760\n",
      "img id in: 23761\n",
      "img id out: 23761\n",
      "img id in: 23762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 23762\n",
      "img id in: 23763\n",
      "img id out: 23763\n",
      "img id in: 23764\n",
      "img id out: 23764\n",
      "img id in: 23765\n",
      "img id out: 23765\n",
      "img id in: 23766\n",
      "img id out: 23766\n",
      "img id in: 23767\n",
      "img id out: 23767\n",
      "img id in: 23768\n",
      "img id out: 23768\n",
      "img id in: 23769\n",
      "img id out: 23769\n",
      "img id in: 23770\n",
      "img id out: 23770\n",
      "img id in: 23771\n",
      "img id out: 23771\n",
      "img id in: 23772\n",
      "img id out: 23772\n",
      "img id in: 23773\n",
      "img id out: 23773\n",
      "img id in: 23774\n",
      "img id out: 23774\n",
      "img id in: 23775\n",
      "img id out: 23775\n",
      "img id in: 23776\n",
      "img id out: 23776\n",
      "img id in: 23777\n",
      "img id out: 23777\n",
      "img id in: 23778\n",
      "img id out: 23778\n",
      "img id in: 23779\n",
      "img id out: 23779\n",
      "img id in: 23780\n",
      "img id out: 23780\n",
      "img id in: 23781\n",
      "img id out: 23781\n",
      "img id in: 23782\n",
      "img id out: 23782\n",
      "img id in: 23783\n",
      "img id out: 23783\n",
      "img id in: 23784\n",
      "img id out: 23784\n",
      "img id in: 23785\n",
      "img id out: 23785\n",
      "img id in: 23786\n",
      "img id out: 23786\n",
      "img id in: 23787\n",
      "img id out: 23787\n",
      "img id in: 23788\n",
      "img id out: 23788\n",
      "img id in: 23789\n",
      "img id out: 23789\n",
      "img id in: 23790\n",
      "img id out: 23790\n",
      "img id in: 23791\n",
      "img id out: 23791\n",
      "img id in: 23792\n",
      "img id out: 23792\n",
      "img id in: 23793\n",
      "img id out: 23793\n",
      "img id in: 23794\n",
      "img id out: 23794\n",
      "img id in: 23795\n",
      "img id out: 23795\n",
      "img id in: 23796\n",
      "img id out: 23796\n",
      "img id in: 23797\n",
      "img id out: 23797\n",
      "img id in: 23798\n",
      "img id out: 23798\n",
      "img id in: 23799\n",
      "img id out: 23799\n",
      "img id in: 23800\n",
      "img id out: 23800\n",
      "img id in: 23801\n",
      "img id out: 23801\n",
      "img id in: 23802\n",
      "img id out: 23802\n",
      "img id in: 23803\n",
      "img id out: 23803\n",
      "img id in: 23804\n",
      "img id out: 23804\n",
      "img id in: 23805\n",
      "img id out: 23805\n",
      "img id in: 23806\n",
      "img id out: 23806\n",
      "img id in: 23807\n",
      "img id out: 23807\n",
      "img id in: 23808\n",
      "img id out: 23808\n",
      "img id in: 23809\n",
      "img id out: 23809\n",
      "img id in: 23810\n",
      "img id out: 23810\n",
      "img id in: 23811\n",
      "img id out: 23811\n",
      "img id in: 23812\n",
      "img id out: 23812\n",
      "img id in: 23813\n",
      "img id out: 23813\n",
      "img id in: 23814\n",
      "img id out: 23814\n",
      "img id in: 23815\n",
      "img id out: 23815\n",
      "img id in: 23816\n",
      "img id out: 23816\n",
      "img id in: 23817\n",
      "img id out: 23817\n",
      "img id in: 23818\n",
      "img id out: 23818\n",
      "img id in: 23819\n",
      "img id out: 23819\n",
      "img id in: 23820\n",
      "img id out: 23820\n",
      "img id in: 23821\n",
      "img id out: 23821\n",
      "img id in: 23822\n",
      "img id out: 23822\n",
      "img id in: 23823\n",
      "img id out: 23823\n",
      "img id in: 23824\n",
      "img id out: 23824\n",
      "img id in: 23825\n",
      "img id out: 23825\n",
      "img id in: 23826\n",
      "img id out: 23826\n",
      "img id in: 23827\n",
      "img id out: 23827\n",
      "img id in: 23828\n",
      "img id out: 23828\n",
      "img id in: 23829\n",
      "img id out: 23829\n",
      "img id in: 23830\n",
      "img id out: 23830\n",
      "img id in: 23831\n",
      "img id out: 23831\n",
      "img id in: 23832\n",
      "img id out: 23832\n",
      "img id in: 23833\n",
      "img id out: 23833\n",
      "img id in: 23834\n",
      "img id out: 23834\n",
      "img id in: 23835\n",
      "img id out: 23835\n",
      "img id in: 23836\n",
      "img id out: 23836\n",
      "img id in: 23837\n",
      "img id out: 23837\n",
      "img id in: 23838\n",
      "img id out: 23838\n",
      "img id in: 23839\n",
      "img id out: 23839\n",
      "img id in: 23840\n",
      "img id out: 23840\n",
      "img id in: 23841\n",
      "img id out: 23841\n",
      "img id in: 23842\n",
      "img id out: 23842\n",
      "img id in: 23843\n",
      "img id out: 23843\n",
      "img id in: 23844\n",
      "img id out: 23844\n",
      "img id in: 23845\n",
      "img id out: 23845\n",
      "img id in: 23846\n",
      "img id out: 23846\n",
      "img id in: 23847\n",
      "img id out: 23847\n",
      "img id in: 23848\n",
      "img id out: 23848\n",
      "img id in: 23849\n",
      "img id out: 23849\n",
      "img id in: 23850\n",
      "img id out: 23850\n",
      "img id in: 23851\n",
      "img id out: 23851\n",
      "img id in: 23852\n",
      "img id out: 23852\n",
      "img id in: 23853\n",
      "img id out: 23853\n",
      "img id in: 23854\n",
      "img id out: 23854\n",
      "img id in: 23855\n",
      "img id out: 23855\n",
      "img id in: 23856\n",
      "img id out: 23856\n",
      "img id in: 23857\n",
      "img id out: 23857\n",
      "img id in: 23858\n",
      "img id out: 23858\n",
      "img id in: 23859\n",
      "img id out: 23859\n",
      "img id in: 23860\n",
      "img id out: 23860\n",
      "img id in: 23861\n",
      "img id out: 23861\n",
      "img id in: 23862\n",
      "img id out: 23862\n",
      "img id in: 23863\n",
      "img id out: 23863\n",
      "img id in: 23864\n",
      "img id out: 23864\n",
      "img id in: 23865\n",
      "img id out: 23865\n",
      "img id in: 23866\n",
      "img id out: 23866\n",
      "img id in: 23867\n",
      "img id out: 23867\n",
      "img id in: 23868\n",
      "img id out: 23868\n",
      "img id in: 23869\n",
      "img id out: 23869\n",
      "img id in: 23870\n",
      "img id out: 23870\n",
      "img id in: 23871\n",
      "img id out: 23871\n",
      "img id in: 23872\n",
      "img id out: 23872\n",
      "img id in: 23873\n",
      "img id out: 23873\n",
      "img id in: 23874\n",
      "img id out: 23874\n",
      "img id in: 23875\n",
      "img id out: 23875\n",
      "img id in: 23876\n",
      "img id out: 23876\n",
      "img id in: 23877\n",
      "img id out: 23877\n",
      "img id in: 23878\n",
      "img id out: 23878\n",
      "img id in: 23879\n",
      "img id out: 23879\n",
      "img id in: 23880\n",
      "img id out: 23880\n",
      "img id in: 23881\n",
      "img id out: 23881\n",
      "img id in: 23882\n",
      "img id out: 23882\n",
      "img id in: 23883\n",
      "img id out: 23883\n",
      "img id in: 23884\n",
      "img id out: 23884\n",
      "img id in: 23885\n",
      "img id out: 23885\n",
      "img id in: 23886\n",
      "img id out: 23886\n",
      "img id in: 23887\n",
      "img id out: 23887\n",
      "img id in: 23888\n",
      "img id out: 23888\n",
      "img id in: 23889\n",
      "img id out: 23889\n",
      "img id in: 23890\n",
      "img id out: 23890\n",
      "img id in: 23891\n",
      "img id out: 23891\n",
      "img id in: 23892\n",
      "img id out: 23892\n",
      "img id in: 23893\n",
      "img id out: 23893\n",
      "img id in: 23894\n",
      "img id out: 23894\n",
      "img id in: 23895\n",
      "img id out: 23895\n",
      "img id in: 23896\n",
      "img id out: 23896\n",
      "img id in: 23897\n",
      "img id out: 23897\n",
      "img id in: 23898\n",
      "img id out: 23898\n",
      "img id in: 23899\n",
      "img id out: 23899\n",
      "img id in: 23900\n",
      "img id out: 23900\n",
      "img id in: 23901\n",
      "img id out: 23901\n",
      "img id in: 23902\n",
      "img id out: 23902\n",
      "img id in: 23903\n",
      "img id out: 23903\n",
      "img id in: 23904\n",
      "img id out: 23904\n",
      "img id in: 23905\n",
      "img id out: 23905\n",
      "img id in: 23906\n",
      "img id out: 23906\n",
      "img id in: 23907\n",
      "img id out: 23907\n",
      "img id in: 23908\n",
      "img id out: 23908\n",
      "img id in: 23909\n",
      "img id out: 23909\n",
      "img id in: 23910\n",
      "img id out: 23910\n",
      "img id in: 23911\n",
      "img id out: 23911\n",
      "img id in: 23912\n",
      "img id out: 23912\n",
      "img id in: 23913\n",
      "img id out: 23913\n",
      "img id in: 23914\n",
      "img id out: 23914\n",
      "img id in: 23915\n",
      "img id out: 23915\n",
      "img id in: 23916\n",
      "img id out: 23916\n",
      "img id in: 23917\n",
      "img id out: 23917\n",
      "img id in: 23918\n",
      "img id out: 23918\n",
      "img id in: 23919\n",
      "img id out: 23919\n",
      "img id in: 23920\n",
      "img id out: 23920\n",
      "img id in: 23921\n",
      "img id out: 23921\n",
      "img id in: 23922\n",
      "img id out: 23922\n",
      "img id in: 23923\n",
      "img id out: 23923\n",
      "img id in: 23924\n",
      "img id out: 23924\n",
      "img id in: 23925\n",
      "img id out: 23925\n",
      "img id in: 23926\n",
      "img id out: 23926\n",
      "img id in: 23927\n",
      "img id out: 23927\n",
      "img id in: 23928\n",
      "img id out: 23928\n",
      "img id in: 23929\n",
      "img id out: 23929\n",
      "img id in: 23930\n",
      "img id out: 23930\n",
      "img id in: 23931\n",
      "img id out: 23931\n",
      "img id in: 23932\n",
      "img id out: 23932\n",
      "img id in: 23933\n",
      "img id out: 23933\n",
      "img id in: 23934\n",
      "img id out: 23934\n",
      "img id in: 23935\n",
      "img id out: 23935\n",
      "img id in: 23936\n",
      "img id out: 23936\n",
      "img id in: 23937\n",
      "img id out: 23937\n",
      "img id in: 23938\n",
      "img id out: 23938\n",
      "img id in: 23939\n",
      "img id out: 23939\n",
      "img id in: 23940\n",
      "img id out: 23940\n",
      "img id in: 23941\n",
      "img id out: 23941\n",
      "img id in: 23942\n",
      "img id out: 23942\n",
      "img id in: 23943\n",
      "img id out: 23943\n",
      "img id in: 23944\n",
      "img id out: 23944\n",
      "img id in: 23945\n",
      "img id out: 23945\n",
      "img id in: 23946\n",
      "img id out: 23946\n",
      "img id in: 23947\n",
      "img id out: 23947\n",
      "img id in: 23948\n",
      "img id out: 23948\n",
      "img id in: 23949\n",
      "img id out: 23949\n",
      "img id in: 23950\n",
      "img id out: 23950\n",
      "img id in: 23951\n",
      "img id out: 23951\n",
      "img id in: 23952\n",
      "img id out: 23952\n",
      "img id in: 23953\n",
      "img id out: 23953\n",
      "img id in: 23954\n",
      "img id out: 23954\n",
      "img id in: 23955\n",
      "img id out: 23955\n",
      "img id in: 23956\n",
      "img id out: 23956\n",
      "img id in: 23957\n",
      "img id out: 23957\n",
      "img id in: 23958\n",
      "img id out: 23958\n",
      "img id in: 23959\n",
      "img id out: 23959\n",
      "img id in: 23960\n",
      "img id out: 23960\n",
      "img id in: 23961\n",
      "img id out: 23961\n",
      "img id in: 23962\n",
      "img id out: 23962\n",
      "img id in: 23963\n",
      "img id out: 23963\n",
      "img id in: 23964\n",
      "img id out: 23964\n",
      "img id in: 23965\n",
      "img id out: 23965\n",
      "img id in: 23966\n",
      "img id out: 23966\n",
      "img id in: 23967\n",
      "img id out: 23967\n",
      "img id in: 23968\n",
      "img id out: 23968\n",
      "img id in: 23969\n",
      "img id out: 23969\n",
      "img id in: 23970\n",
      "img id out: 23970\n",
      "img id in: 23971\n",
      "img id out: 23971\n",
      "img id in: 23972\n",
      "img id out: 23972\n",
      "img id in: 23973\n",
      "img id out: 23973\n",
      "img id in: 23974\n",
      "img id out: 23974\n",
      "img id in: 23975\n",
      "img id out: 23975\n",
      "img id in: 23976\n",
      "img id out: 23976\n",
      "img id in: 23977\n",
      "img id out: 23977\n",
      "img id in: 23978\n",
      "img id out: 23978\n",
      "img id in: 23979\n",
      "img id out: 23979\n",
      "img id in: 23980\n",
      "img id out: 23980\n",
      "img id in: 23981\n",
      "img id out: 23981\n",
      "img id in: 23982\n",
      "img id out: 23982\n",
      "img id in: 23983\n",
      "img id out: 23983\n",
      "img id in: 23984\n",
      "img id out: 23984\n",
      "img id in: 23985\n",
      "img id out: 23985\n",
      "img id in: 23986\n",
      "img id out: 23986\n",
      "img id in: 23987\n",
      "img id out: 23987\n",
      "img id in: 23988\n",
      "img id out: 23988\n",
      "img id in: 23989\n",
      "img id out: 23989\n",
      "img id in: 23990\n",
      "img id out: 23990\n",
      "img id in: 23991\n",
      "img id out: 23991\n",
      "img id in: 23992\n",
      "img id out: 23992\n",
      "img id in: 23993\n",
      "img id out: 23993\n",
      "img id in: 23994\n",
      "img id out: 23994\n",
      "img id in: 23995\n",
      "img id out: 23995\n",
      "img id in: 23996\n",
      "img id out: 23996\n",
      "img id in: 23997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 23997\n",
      "img id in: 23998\n",
      "img id out: 23998\n",
      "img id in: 23999\n",
      "img id out: 23999\n",
      "img id in: 24000\n",
      "img id out: 24000\n",
      "img id in: 24001\n",
      "img id out: 24001\n",
      "img id in: 24002\n",
      "img id out: 24002\n",
      "img id in: 24003\n",
      "img id out: 24003\n",
      "img id in: 24004\n",
      "img id out: 24004\n",
      "img id in: 24005\n",
      "img id out: 24005\n",
      "img id in: 24006\n",
      "img id out: 24006\n",
      "img id in: 24007\n",
      "img id out: 24007\n",
      "img id in: 24008\n",
      "img id out: 24008\n",
      "img id in: 24009\n",
      "img id out: 24009\n",
      "img id in: 24010\n",
      "img id out: 24010\n",
      "img id in: 24011\n",
      "img id out: 24011\n",
      "img id in: 24012\n",
      "img id out: 24012\n",
      "img id in: 24013\n",
      "img id out: 24013\n",
      "img id in: 24014\n",
      "img id out: 24014\n",
      "img id in: 24015\n",
      "img id out: 24015\n",
      "img id in: 24016\n",
      "img id out: 24016\n",
      "img id in: 24017\n",
      "img id out: 24017\n",
      "img id in: 24018\n",
      "img id out: 24018\n",
      "img id in: 24019\n",
      "img id out: 24019\n",
      "img id in: 24020\n",
      "img id out: 24020\n",
      "img id in: 24021\n",
      "img id out: 24021\n",
      "img id in: 24022\n",
      "img id out: 24022\n",
      "img id in: 24023\n",
      "img id out: 24023\n",
      "img id in: 24024\n",
      "img id out: 24024\n",
      "img id in: 24025\n",
      "img id out: 24025\n",
      "img id in: 24026\n",
      "img id out: 24026\n",
      "img id in: 24027\n",
      "img id out: 24027\n",
      "img id in: 24028\n",
      "img id out: 24028\n",
      "img id in: 24029\n",
      "img id out: 24029\n",
      "img id in: 24030\n",
      "img id out: 24030\n",
      "img id in: 24031\n",
      "img id out: 24031\n",
      "img id in: 24032\n",
      "img id out: 24032\n",
      "img id in: 24033\n",
      "img id out: 24033\n",
      "img id in: 24034\n",
      "img id out: 24034\n",
      "img id in: 24035\n",
      "img id out: 24035\n",
      "img id in: 24036\n",
      "img id out: 24036\n",
      "img id in: 24037\n",
      "img id out: 24037\n",
      "img id in: 24038\n",
      "img id out: 24038\n",
      "img id in: 24039\n",
      "img id out: 24039\n",
      "img id in: 24040\n",
      "img id out: 24040\n",
      "img id in: 24041\n",
      "img id out: 24041\n",
      "img id in: 24042\n",
      "img id out: 24042\n",
      "img id in: 24043\n",
      "img id out: 24043\n",
      "img id in: 24044\n",
      "img id out: 24044\n",
      "img id in: 24045\n",
      "img id out: 24045\n",
      "img id in: 24046\n",
      "img id out: 24046\n",
      "img id in: 24047\n",
      "img id out: 24047\n",
      "img id in: 24048\n",
      "img id out: 24048\n",
      "img id in: 24049\n",
      "img id out: 24049\n",
      "img id in: 24050\n",
      "img id out: 24050\n",
      "img id in: 24051\n",
      "img id out: 24051\n",
      "img id in: 24052\n",
      "img id out: 24052\n",
      "img id in: 24053\n",
      "img id out: 24053\n",
      "img id in: 24054\n",
      "img id out: 24054\n",
      "img id in: 24055\n",
      "img id out: 24055\n",
      "img id in: 24056\n",
      "img id out: 24056\n",
      "img id in: 24057\n",
      "img id out: 24057\n",
      "img id in: 24058\n",
      "img id out: 24058\n",
      "img id in: 24059\n",
      "img id out: 24059\n",
      "img id in: 24060\n",
      "img id out: 24060\n",
      "img id in: 24061\n",
      "img id out: 24061\n",
      "img id in: 24062\n",
      "img id out: 24062\n",
      "img id in: 24063\n",
      "img id out: 24063\n",
      "img id in: 24064\n",
      "img id out: 24064\n",
      "img id in: 24065\n",
      "img id out: 24065\n",
      "img id in: 24066\n",
      "img id out: 24066\n",
      "img id in: 24067\n",
      "img id out: 24067\n",
      "img id in: 24068\n",
      "img id out: 24068\n",
      "img id in: 24069\n",
      "img id out: 24069\n",
      "img id in: 24070\n",
      "img id out: 24070\n",
      "img id in: 24071\n",
      "img id out: 24071\n",
      "img id in: 24072\n",
      "img id out: 24072\n",
      "img id in: 24073\n",
      "img id out: 24073\n",
      "img id in: 24074\n",
      "img id out: 24074\n",
      "img id in: 24075\n",
      "img id out: 24075\n",
      "img id in: 24076\n",
      "img id out: 24076\n",
      "img id in: 24077\n",
      "img id out: 24077\n",
      "img id in: 24078\n",
      "img id out: 24078\n",
      "img id in: 24079\n",
      "img id out: 24079\n",
      "img id in: 24080\n",
      "img id out: 24080\n",
      "img id in: 24081\n",
      "img id out: 24081\n",
      "img id in: 24082\n",
      "img id out: 24082\n",
      "img id in: 24083\n",
      "img id out: 24083\n",
      "img id in: 24084\n",
      "img id out: 24084\n",
      "img id in: 24085\n",
      "img id out: 24085\n",
      "img id in: 24086\n",
      "img id out: 24086\n",
      "img id in: 24087\n",
      "img id out: 24087\n",
      "img id in: 24088\n",
      "img id out: 24088\n",
      "img id in: 24089\n",
      "img id out: 24089\n",
      "img id in: 24090\n",
      "img id out: 24090\n",
      "img id in: 24091\n",
      "img id out: 24091\n",
      "img id in: 24092\n",
      "img id out: 24092\n",
      "img id in: 24093\n",
      "img id out: 24093\n",
      "img id in: 24094\n",
      "img id out: 24094\n",
      "img id in: 24095\n",
      "img id out: 24095\n",
      "img id in: 24096\n",
      "img id out: 24096\n",
      "img id in: 24097\n",
      "img id out: 24097\n",
      "img id in: 24098\n",
      "img id out: 24098\n",
      "img id in: 24099\n",
      "img id out: 24099\n",
      "img id in: 24100\n",
      "img id out: 24100\n",
      "img id in: 24101\n",
      "img id out: 24101\n",
      "img id in: 24102\n",
      "img id out: 24102\n",
      "img id in: 24103\n",
      "img id out: 24103\n",
      "img id in: 24104\n",
      "img id out: 24104\n",
      "img id in: 24105\n",
      "img id out: 24105\n",
      "img id in: 24106\n",
      "img id out: 24106\n",
      "img id in: 24107\n",
      "img id out: 24107\n",
      "img id in: 24108\n",
      "img id out: 24108\n",
      "img id in: 24109\n",
      "img id out: 24109\n",
      "img id in: 24110\n",
      "img id out: 24110\n",
      "img id in: 24111\n",
      "img id out: 24111\n",
      "img id in: 24112\n",
      "img id out: 24112\n",
      "img id in: 24113\n",
      "img id out: 24113\n",
      "img id in: 24114\n",
      "img id out: 24114\n",
      "img id in: 24115\n",
      "img id out: 24115\n",
      "img id in: 24116\n",
      "img id out: 24116\n",
      "img id in: 24117\n",
      "img id out: 24117\n",
      "img id in: 24118\n",
      "img id out: 24118\n",
      "img id in: 24119\n",
      "img id out: 24119\n",
      "img id in: 24120\n",
      "img id out: 24120\n",
      "img id in: 24121\n",
      "img id out: 24121\n",
      "img id in: 24122\n",
      "img id out: 24122\n",
      "img id in: 24123\n",
      "img id out: 24123\n",
      "img id in: 24124\n",
      "img id out: 24124\n",
      "img id in: 24125\n",
      "img id out: 24125\n",
      "img id in: 24126\n",
      "img id out: 24126\n",
      "img id in: 24127\n",
      "img id out: 24127\n",
      "img id in: 24128\n",
      "img id out: 24128\n",
      "img id in: 24129\n",
      "img id out: 24129\n",
      "img id in: 24130\n",
      "img id out: 24130\n",
      "img id in: 24131\n",
      "img id out: 24131\n",
      "img id in: 24132\n",
      "img id out: 24132\n",
      "img id in: 24133\n",
      "img id out: 24133\n",
      "img id in: 24134\n",
      "img id out: 24134\n",
      "img id in: 24135\n",
      "img id out: 24135\n",
      "img id in: 24136\n",
      "img id out: 24136\n",
      "img id in: 24137\n",
      "img id out: 24137\n",
      "img id in: 24138\n",
      "img id out: 24138\n",
      "img id in: 24139\n",
      "img id out: 24139\n",
      "img id in: 24140\n",
      "img id out: 24140\n",
      "img id in: 24141\n",
      "img id out: 24141\n",
      "img id in: 24142\n",
      "img id out: 24142\n",
      "img id in: 24143\n",
      "img id out: 24143\n",
      "img id in: 24144\n",
      "img id out: 24144\n",
      "img id in: 24145\n",
      "img id out: 24145\n",
      "img id in: 24146\n",
      "img id out: 24146\n",
      "img id in: 24147\n",
      "img id out: 24147\n",
      "img id in: 24148\n",
      "img id out: 24148\n",
      "img id in: 24149\n",
      "img id out: 24149\n",
      "img id in: 24150\n",
      "img id out: 24150\n",
      "img id in: 24151\n",
      "img id out: 24151\n",
      "img id in: 24152\n",
      "img id out: 24152\n",
      "img id in: 24153\n",
      "img id out: 24153\n",
      "img id in: 24154\n",
      "img id out: 24154\n",
      "img id in: 24155\n",
      "img id out: 24155\n",
      "img id in: 24156\n",
      "img id out: 24156\n",
      "img id in: 24157\n",
      "img id out: 24157\n",
      "img id in: 24158\n",
      "img id out: 24158\n",
      "img id in: 24159\n",
      "img id out: 24159\n",
      "img id in: 24160\n",
      "img id out: 24160\n",
      "img id in: 24161\n",
      "img id out: 24161\n",
      "img id in: 24162\n",
      "img id out: 24162\n",
      "img id in: 24163\n",
      "img id out: 24163\n",
      "img id in: 24164\n",
      "img id out: 24164\n",
      "img id in: 24165\n",
      "img id out: 24165\n",
      "img id in: 24166\n",
      "img id out: 24166\n",
      "img id in: 24167\n",
      "img id out: 24167\n",
      "img id in: 24168\n",
      "img id out: 24168\n",
      "img id in: 24169\n",
      "img id out: 24169\n",
      "img id in: 24170\n",
      "img id out: 24170\n",
      "img id in: 24171\n",
      "img id out: 24171\n",
      "img id in: 24172\n",
      "img id out: 24172\n",
      "img id in: 24173\n",
      "img id out: 24173\n",
      "img id in: 24174\n",
      "img id out: 24174\n",
      "img id in: 24175\n",
      "img id out: 24175\n",
      "img id in: 24176\n",
      "img id out: 24176\n",
      "img id in: 24177\n",
      "img id out: 24177\n",
      "img id in: 24178\n",
      "img id out: 24178\n",
      "img id in: 24179\n",
      "img id out: 24179\n",
      "img id in: 24180\n",
      "img id out: 24180\n",
      "img id in: 24181\n",
      "img id out: 24181\n",
      "img id in: 24182\n",
      "img id out: 24182\n",
      "img id in: 24183\n",
      "img id out: 24183\n",
      "img id in: 24184\n",
      "img id out: 24184\n",
      "img id in: 24185\n",
      "img id out: 24185\n",
      "img id in: 24186\n",
      "img id out: 24186\n",
      "img id in: 24187\n",
      "img id out: 24187\n",
      "img id in: 24188\n",
      "img id out: 24188\n",
      "img id in: 24189\n",
      "img id out: 24189\n",
      "img id in: 24190\n",
      "img id out: 24190\n",
      "img id in: 24191\n",
      "img id out: 24191\n",
      "img id in: 24192\n",
      "img id out: 24192\n",
      "img id in: 24193\n",
      "img id out: 24193\n",
      "img id in: 24194\n",
      "img id out: 24194\n",
      "img id in: 24195\n",
      "img id out: 24195\n",
      "img id in: 24196\n",
      "img id out: 24196\n",
      "img id in: 24197\n",
      "img id out: 24197\n",
      "img id in: 24198\n",
      "img id out: 24198\n",
      "img id in: 24199\n",
      "img id out: 24199\n",
      "img id in: 24200\n",
      "img id out: 24200\n",
      "img id in: 24201\n",
      "img id out: 24201\n",
      "img id in: 24202\n",
      "img id out: 24202\n",
      "img id in: 24203\n",
      "img id out: 24203\n",
      "img id in: 24204\n",
      "img id out: 24204\n",
      "img id in: 24205\n",
      "img id out: 24205\n",
      "img id in: 24206\n",
      "img id out: 24206\n",
      "img id in: 24207\n",
      "img id out: 24207\n",
      "img id in: 24208\n",
      "img id out: 24208\n",
      "img id in: 24209\n",
      "img id out: 24209\n",
      "img id in: 24210\n",
      "img id out: 24210\n",
      "img id in: 24211\n",
      "img id out: 24211\n",
      "img id in: 24212\n",
      "img id out: 24212\n",
      "img id in: 24213\n",
      "img id out: 24213\n",
      "img id in: 24214\n",
      "img id out: 24214\n",
      "img id in: 24215\n",
      "img id out: 24215\n",
      "img id in: 24216\n",
      "img id out: 24216\n",
      "img id in: 24217\n",
      "img id out: 24217\n",
      "img id in: 24218\n",
      "img id out: 24218\n",
      "img id in: 24219\n",
      "img id out: 24219\n",
      "img id in: 24220\n",
      "img id out: 24220\n",
      "img id in: 24221\n",
      "img id out: 24221\n",
      "img id in: 24222\n",
      "img id out: 24222\n",
      "img id in: 24223\n",
      "img id out: 24223\n",
      "img id in: 24224\n",
      "img id out: 24224\n",
      "img id in: 24225\n",
      "img id out: 24225\n",
      "img id in: 24226\n",
      "img id out: 24226\n",
      "img id in: 24227\n",
      "img id out: 24227\n",
      "img id in: 24228\n",
      "img id out: 24228\n",
      "img id in: 24229\n",
      "img id out: 24229\n",
      "img id in: 24230\n",
      "img id out: 24230\n",
      "img id in: 24231\n",
      "img id out: 24231\n",
      "img id in: 24232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 24232\n",
      "img id in: 24233\n",
      "img id out: 24233\n",
      "img id in: 24234\n",
      "img id out: 24234\n",
      "img id in: 24235\n",
      "img id out: 24235\n",
      "img id in: 24236\n",
      "img id out: 24236\n",
      "img id in: 24237\n",
      "img id out: 24237\n",
      "img id in: 24238\n",
      "img id out: 24238\n",
      "img id in: 24239\n",
      "img id out: 24239\n",
      "img id in: 24240\n",
      "img id out: 24240\n",
      "img id in: 24241\n",
      "img id out: 24241\n",
      "img id in: 24242\n",
      "img id out: 24242\n",
      "img id in: 24243\n",
      "img id out: 24243\n",
      "img id in: 24244\n",
      "img id out: 24244\n",
      "img id in: 24245\n",
      "img id out: 24245\n",
      "img id in: 24246\n",
      "img id out: 24246\n",
      "img id in: 24247\n",
      "img id out: 24247\n",
      "img id in: 24248\n",
      "img id out: 24248\n",
      "img id in: 24249\n",
      "img id out: 24249\n",
      "img id in: 24250\n",
      "img id out: 24250\n",
      "img id in: 24251\n",
      "img id out: 24251\n",
      "img id in: 24252\n",
      "img id out: 24252\n",
      "img id in: 24253\n",
      "img id out: 24253\n",
      "img id in: 24254\n",
      "img id out: 24254\n",
      "img id in: 24255\n",
      "img id out: 24255\n",
      "img id in: 24256\n",
      "img id out: 24256\n",
      "img id in: 24257\n",
      "img id out: 24257\n",
      "img id in: 24258\n",
      "img id out: 24258\n",
      "img id in: 24259\n",
      "img id out: 24259\n",
      "img id in: 24260\n",
      "img id out: 24260\n",
      "img id in: 24261\n",
      "img id out: 24261\n",
      "img id in: 24262\n",
      "img id out: 24262\n",
      "img id in: 24263\n",
      "img id out: 24263\n",
      "img id in: 24264\n",
      "img id out: 24264\n",
      "img id in: 24265\n",
      "img id out: 24265\n",
      "img id in: 24266\n",
      "img id out: 24266\n",
      "img id in: 24267\n",
      "img id out: 24267\n",
      "img id in: 24268\n",
      "img id out: 24268\n",
      "img id in: 24269\n",
      "img id out: 24269\n",
      "img id in: 24270\n",
      "img id out: 24270\n",
      "img id in: 24271\n",
      "img id out: 24271\n",
      "img id in: 24272\n",
      "img id out: 24272\n",
      "img id in: 24273\n",
      "img id out: 24273\n",
      "img id in: 24274\n",
      "img id out: 24274\n",
      "img id in: 24275\n",
      "img id out: 24275\n",
      "img id in: 24276\n",
      "img id out: 24276\n",
      "img id in: 24277\n",
      "img id out: 24277\n",
      "img id in: 24278\n",
      "img id out: 24278\n",
      "img id in: 24279\n",
      "img id out: 24279\n",
      "img id in: 24280\n",
      "img id out: 24280\n",
      "img id in: 24281\n",
      "img id out: 24281\n",
      "img id in: 24282\n",
      "img id out: 24282\n",
      "img id in: 24283\n",
      "img id out: 24283\n",
      "img id in: 24284\n",
      "img id out: 24284\n",
      "img id in: 24285\n",
      "img id out: 24285\n",
      "img id in: 24286\n",
      "img id out: 24286\n",
      "img id in: 24287\n",
      "img id out: 24287\n",
      "img id in: 24288\n",
      "img id out: 24288\n",
      "img id in: 24289\n",
      "img id out: 24289\n",
      "img id in: 24290\n",
      "img id out: 24290\n",
      "img id in: 24291\n",
      "img id out: 24291\n",
      "img id in: 24292\n",
      "img id out: 24292\n",
      "img id in: 24293\n",
      "img id out: 24293\n",
      "img id in: 24294\n",
      "img id out: 24294\n",
      "img id in: 24295\n",
      "img id out: 24295\n",
      "img id in: 24296\n",
      "img id out: 24296\n",
      "img id in: 24297\n",
      "img id out: 24297\n",
      "img id in: 24298\n",
      "img id out: 24298\n",
      "img id in: 24299\n",
      "img id out: 24299\n",
      "img id in: 24300\n",
      "img id out: 24300\n",
      "img id in: 24301\n",
      "img id out: 24301\n",
      "img id in: 24302\n",
      "img id out: 24302\n",
      "img id in: 24303\n",
      "img id out: 24303\n",
      "img id in: 24304\n",
      "img id out: 24304\n",
      "img id in: 24305\n",
      "img id out: 24305\n",
      "img id in: 24306\n",
      "img id out: 24306\n",
      "img id in: 24307\n",
      "img id out: 24307\n",
      "img id in: 24308\n",
      "img id out: 24308\n",
      "img id in: 24309\n",
      "img id out: 24309\n",
      "img id in: 24310\n",
      "img id out: 24310\n",
      "img id in: 24311\n",
      "img id out: 24311\n",
      "img id in: 24312\n",
      "img id out: 24312\n",
      "img id in: 24313\n",
      "img id out: 24313\n",
      "img id in: 24314\n",
      "img id out: 24314\n",
      "img id in: 24315\n",
      "img id out: 24315\n",
      "img id in: 24316\n",
      "img id out: 24316\n",
      "img id in: 24317\n",
      "img id out: 24317\n",
      "img id in: 24318\n",
      "img id out: 24318\n",
      "img id in: 24319\n",
      "img id out: 24319\n",
      "img id in: 24320\n",
      "img id out: 24320\n",
      "img id in: 24321\n",
      "img id out: 24321\n",
      "img id in: 24322\n",
      "img id out: 24322\n",
      "img id in: 24323\n",
      "img id out: 24323\n",
      "img id in: 24324\n",
      "img id out: 24324\n",
      "img id in: 24325\n",
      "img id out: 24325\n",
      "img id in: 24326\n",
      "img id out: 24326\n",
      "img id in: 24327\n",
      "img id out: 24327\n",
      "img id in: 24328\n",
      "img id out: 24328\n",
      "img id in: 24329\n",
      "img id out: 24329\n",
      "img id in: 24330\n",
      "img id out: 24330\n",
      "img id in: 24331\n",
      "img id out: 24331\n",
      "img id in: 24332\n",
      "img id out: 24332\n",
      "img id in: 24333\n",
      "img id out: 24333\n",
      "img id in: 24334\n",
      "img id out: 24334\n",
      "img id in: 24335\n",
      "img id out: 24335\n",
      "img id in: 24336\n",
      "img id out: 24336\n",
      "img id in: 24337\n",
      "img id out: 24337\n",
      "img id in: 24338\n",
      "img id out: 24338\n",
      "img id in: 24339\n",
      "img id out: 24339\n",
      "img id in: 24340\n",
      "img id out: 24340\n",
      "img id in: 24341\n",
      "img id out: 24341\n",
      "img id in: 24342\n",
      "img id out: 24342\n",
      "img id in: 24343\n",
      "img id out: 24343\n",
      "img id in: 24344\n",
      "img id out: 24344\n",
      "img id in: 24345\n",
      "img id out: 24345\n",
      "img id in: 24346\n",
      "img id out: 24346\n",
      "img id in: 24347\n",
      "img id out: 24347\n",
      "img id in: 24348\n",
      "img id out: 24348\n",
      "img id in: 24349\n",
      "img id out: 24349\n",
      "img id in: 24350\n",
      "img id out: 24350\n",
      "img id in: 24351\n",
      "img id out: 24351\n",
      "img id in: 24352\n",
      "img id out: 24352\n",
      "img id in: 24353\n",
      "img id out: 24353\n",
      "img id in: 24354\n",
      "img id out: 24354\n",
      "img id in: 24355\n",
      "img id out: 24355\n",
      "img id in: 24356\n",
      "img id out: 24356\n",
      "img id in: 24357\n",
      "img id out: 24357\n",
      "img id in: 24358\n",
      "img id out: 24358\n",
      "img id in: 24359\n",
      "img id out: 24359\n",
      "img id in: 24360\n",
      "img id out: 24360\n",
      "img id in: 24361\n",
      "img id out: 24361\n",
      "img id in: 24362\n",
      "img id out: 24362\n",
      "img id in: 24363\n",
      "img id out: 24363\n",
      "img id in: 24364\n",
      "img id out: 24364\n",
      "img id in: 24365\n",
      "img id out: 24365\n",
      "img id in: 24366\n",
      "img id out: 24366\n",
      "img id in: 24367\n",
      "img id out: 24367\n",
      "img id in: 24368\n",
      "img id out: 24368\n",
      "img id in: 24369\n",
      "img id out: 24369\n",
      "img id in: 24370\n",
      "img id out: 24370\n",
      "img id in: 24371\n",
      "img id out: 24371\n",
      "img id in: 24372\n",
      "img id out: 24372\n",
      "img id in: 24373\n",
      "img id out: 24373\n",
      "img id in: 24374\n",
      "img id out: 24374\n",
      "img id in: 24375\n",
      "img id out: 24375\n",
      "img id in: 24376\n",
      "img id out: 24376\n",
      "img id in: 24377\n",
      "img id out: 24377\n",
      "img id in: 24378\n",
      "img id out: 24378\n",
      "img id in: 24379\n",
      "img id out: 24379\n",
      "img id in: 24380\n",
      "img id out: 24380\n",
      "img id in: 24381\n",
      "img id out: 24381\n",
      "img id in: 24382\n",
      "img id out: 24382\n",
      "img id in: 24383\n",
      "img id out: 24383\n",
      "img id in: 24384\n",
      "img id out: 24384\n",
      "img id in: 24385\n",
      "img id out: 24385\n",
      "img id in: 24386\n",
      "img id out: 24386\n",
      "img id in: 24387\n",
      "img id out: 24387\n",
      "img id in: 24388\n",
      "img id out: 24388\n",
      "img id in: 24389\n",
      "img id out: 24389\n",
      "img id in: 24390\n",
      "img id out: 24390\n",
      "img id in: 24391\n",
      "img id out: 24391\n",
      "img id in: 24392\n",
      "img id out: 24392\n",
      "img id in: 24393\n",
      "img id out: 24393\n",
      "img id in: 24394\n",
      "img id out: 24394\n",
      "img id in: 24395\n",
      "img id out: 24395\n",
      "img id in: 24396\n",
      "img id out: 24396\n",
      "img id in: 24397\n",
      "img id out: 24397\n",
      "img id in: 24398\n",
      "img id out: 24398\n",
      "img id in: 24399\n",
      "img id out: 24399\n",
      "img id in: 24400\n",
      "img id out: 24400\n",
      "img id in: 24401\n",
      "img id out: 24401\n",
      "img id in: 24402\n",
      "img id out: 24402\n",
      "img id in: 24403\n",
      "img id out: 24403\n",
      "img id in: 24404\n",
      "img id out: 24404\n",
      "img id in: 24405\n",
      "img id out: 24405\n",
      "img id in: 24406\n",
      "img id out: 24406\n",
      "img id in: 24407\n",
      "img id out: 24407\n",
      "img id in: 24408\n",
      "img id out: 24408\n",
      "img id in: 24409\n",
      "img id out: 24409\n",
      "img id in: 24410\n",
      "img id out: 24410\n",
      "img id in: 24411\n",
      "img id out: 24411\n",
      "img id in: 24412\n",
      "img id out: 24412\n",
      "img id in: 24413\n",
      "img id out: 24413\n",
      "img id in: 24414\n",
      "img id out: 24414\n",
      "img id in: 24415\n",
      "img id out: 24415\n",
      "img id in: 24416\n",
      "img id out: 24416\n",
      "img id in: 24417\n",
      "img id out: 24417\n",
      "img id in: 24418\n",
      "img id out: 24418\n",
      "img id in: 24419\n",
      "img id out: 24419\n",
      "img id in: 24420\n",
      "img id out: 24420\n",
      "img id in: 24421\n",
      "img id out: 24421\n",
      "img id in: 24422\n",
      "img id out: 24422\n",
      "img id in: 24423\n",
      "img id out: 24423\n",
      "img id in: 24424\n",
      "img id out: 24424\n",
      "img id in: 24425\n",
      "img id out: 24425\n",
      "img id in: 24426\n",
      "img id out: 24426\n",
      "img id in: 24427\n",
      "img id out: 24427\n",
      "img id in: 24428\n",
      "img id out: 24428\n",
      "img id in: 24429\n",
      "img id out: 24429\n",
      "img id in: 24430\n",
      "img id out: 24430\n",
      "img id in: 24431\n",
      "img id out: 24431\n",
      "img id in: 24432\n",
      "img id out: 24432\n",
      "img id in: 24433\n",
      "img id out: 24433\n",
      "img id in: 24434\n",
      "img id out: 24434\n",
      "img id in: 24435\n",
      "img id out: 24435\n",
      "img id in: 24436\n",
      "img id out: 24436\n",
      "img id in: 24437\n",
      "img id out: 24437\n",
      "img id in: 24438\n",
      "img id out: 24438\n",
      "img id in: 24439\n",
      "img id out: 24439\n",
      "img id in: 24440\n",
      "img id out: 24440\n",
      "img id in: 24441\n",
      "img id out: 24441\n",
      "img id in: 24442\n",
      "img id out: 24442\n",
      "img id in: 24443\n",
      "img id out: 24443\n",
      "img id in: 24444\n",
      "img id out: 24444\n",
      "img id in: 24445\n",
      "img id out: 24445\n",
      "img id in: 24446\n",
      "img id out: 24446\n",
      "img id in: 24447\n",
      "img id out: 24447\n",
      "img id in: 24448\n",
      "img id out: 24448\n",
      "img id in: 24449\n",
      "img id out: 24449\n",
      "img id in: 24450\n",
      "img id out: 24450\n",
      "img id in: 24451\n",
      "img id out: 24451\n",
      "img id in: 24452\n",
      "img id out: 24452\n",
      "img id in: 24453\n",
      "img id out: 24453\n",
      "img id in: 24454\n",
      "img id out: 24454\n",
      "img id in: 24455\n",
      "img id out: 24455\n",
      "img id in: 24456\n",
      "img id out: 24456\n",
      "img id in: 24457\n",
      "img id out: 24457\n",
      "img id in: 24458\n",
      "img id out: 24458\n",
      "img id in: 24459\n",
      "img id out: 24459\n",
      "img id in: 24460\n",
      "img id out: 24460\n",
      "img id in: 24461\n",
      "img id out: 24461\n",
      "img id in: 24462\n",
      "img id out: 24462\n",
      "img id in: 24463\n",
      "img id out: 24463\n",
      "img id in: 24464\n",
      "img id out: 24464\n",
      "img id in: 24465\n",
      "img id out: 24465\n",
      "img id in: 24466\n",
      "img id out: 24466\n",
      "img id in: 24467\n",
      "img id out: 24467\n",
      "img id in: 24468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 24468\n",
      "img id in: 24469\n",
      "img id out: 24469\n",
      "img id in: 24470\n",
      "img id out: 24470\n",
      "img id in: 24471\n",
      "img id out: 24471\n",
      "img id in: 24472\n",
      "img id out: 24472\n",
      "img id in: 24473\n",
      "img id out: 24473\n",
      "img id in: 24474\n",
      "img id out: 24474\n",
      "img id in: 24475\n",
      "img id out: 24475\n",
      "img id in: 24476\n",
      "img id out: 24476\n",
      "img id in: 24477\n",
      "img id out: 24477\n",
      "img id in: 24478\n",
      "img id out: 24478\n",
      "img id in: 24479\n",
      "img id out: 24479\n",
      "img id in: 24480\n",
      "img id out: 24480\n",
      "img id in: 24481\n",
      "img id out: 24481\n",
      "img id in: 24482\n",
      "img id out: 24482\n",
      "img id in: 24483\n",
      "img id out: 24483\n",
      "img id in: 24484\n",
      "img id out: 24484\n",
      "img id in: 24485\n",
      "img id out: 24485\n",
      "img id in: 24486\n",
      "img id out: 24486\n",
      "img id in: 24487\n",
      "img id out: 24487\n",
      "img id in: 24488\n",
      "img id out: 24488\n",
      "img id in: 24489\n",
      "img id out: 24489\n",
      "img id in: 24490\n",
      "img id out: 24490\n",
      "img id in: 24491\n",
      "img id out: 24491\n",
      "img id in: 24492\n",
      "img id out: 24492\n",
      "img id in: 24493\n",
      "img id out: 24493\n",
      "img id in: 24494\n",
      "img id out: 24494\n",
      "img id in: 24495\n",
      "img id out: 24495\n",
      "img id in: 24496\n",
      "img id out: 24496\n",
      "img id in: 24497\n",
      "img id out: 24497\n",
      "img id in: 24498\n",
      "img id out: 24498\n",
      "img id in: 24499\n",
      "img id out: 24499\n",
      "img id in: 24500\n",
      "img id out: 24500\n",
      "img id in: 24501\n",
      "img id out: 24501\n",
      "img id in: 24502\n",
      "img id out: 24502\n",
      "img id in: 24503\n",
      "img id out: 24503\n",
      "img id in: 24504\n",
      "img id out: 24504\n",
      "img id in: 24505\n",
      "img id out: 24505\n",
      "img id in: 24506\n",
      "img id out: 24506\n",
      "img id in: 24507\n",
      "img id out: 24507\n",
      "img id in: 24508\n",
      "img id out: 24508\n",
      "img id in: 24509\n",
      "img id out: 24509\n",
      "img id in: 24510\n",
      "img id out: 24510\n",
      "img id in: 24511\n",
      "img id out: 24511\n",
      "img id in: 24512\n",
      "img id out: 24512\n",
      "img id in: 24513\n",
      "img id out: 24513\n",
      "img id in: 24514\n",
      "img id out: 24514\n",
      "img id in: 24515\n",
      "img id out: 24515\n",
      "img id in: 24516\n",
      "img id out: 24516\n",
      "img id in: 24517\n",
      "img id out: 24517\n",
      "img id in: 24518\n",
      "img id out: 24518\n",
      "img id in: 24519\n",
      "img id out: 24519\n",
      "img id in: 24520\n",
      "img id out: 24520\n",
      "img id in: 24521\n",
      "img id out: 24521\n",
      "img id in: 24522\n",
      "img id out: 24522\n",
      "img id in: 24523\n",
      "img id out: 24523\n",
      "img id in: 24524\n",
      "img id out: 24524\n",
      "img id in: 24525\n",
      "img id out: 24525\n",
      "img id in: 24526\n",
      "img id out: 24526\n",
      "img id in: 24527\n",
      "img id out: 24527\n",
      "img id in: 24528\n",
      "img id out: 24528\n",
      "img id in: 24529\n",
      "img id out: 24529\n",
      "img id in: 24530\n",
      "img id out: 24530\n",
      "img id in: 24531\n",
      "img id out: 24531\n",
      "img id in: 24532\n",
      "img id out: 24532\n",
      "img id in: 24533\n",
      "img id out: 24533\n",
      "img id in: 24534\n",
      "img id out: 24534\n",
      "img id in: 24535\n",
      "img id out: 24535\n",
      "img id in: 24536\n",
      "img id out: 24536\n",
      "img id in: 24537\n",
      "img id out: 24537\n",
      "img id in: 24538\n",
      "img id out: 24538\n",
      "img id in: 24539\n",
      "img id out: 24539\n",
      "img id in: 24540\n",
      "img id out: 24540\n",
      "img id in: 24541\n",
      "img id out: 24541\n",
      "img id in: 24542\n",
      "img id out: 24542\n",
      "img id in: 24543\n",
      "img id out: 24543\n",
      "img id in: 24544\n",
      "img id out: 24544\n",
      "img id in: 24545\n",
      "img id out: 24545\n",
      "img id in: 24546\n",
      "img id out: 24546\n",
      "img id in: 24547\n",
      "img id out: 24547\n",
      "img id in: 24548\n",
      "img id out: 24548\n",
      "img id in: 24549\n",
      "img id out: 24549\n",
      "img id in: 24550\n",
      "img id out: 24550\n",
      "img id in: 24551\n",
      "img id out: 24551\n",
      "img id in: 24552\n",
      "img id out: 24552\n",
      "img id in: 24553\n",
      "img id out: 24553\n",
      "img id in: 24554\n",
      "img id out: 24554\n",
      "img id in: 24555\n",
      "img id out: 24555\n",
      "img id in: 24556\n",
      "img id out: 24556\n",
      "img id in: 24557\n",
      "img id out: 24557\n",
      "img id in: 24558\n",
      "img id out: 24558\n",
      "img id in: 24559\n",
      "img id out: 24559\n",
      "img id in: 24560\n",
      "img id out: 24560\n",
      "img id in: 24561\n",
      "img id out: 24561\n",
      "img id in: 24562\n",
      "img id out: 24562\n",
      "img id in: 24563\n",
      "img id out: 24563\n",
      "img id in: 24564\n",
      "img id out: 24564\n",
      "img id in: 24565\n",
      "img id out: 24565\n",
      "img id in: 24566\n",
      "img id out: 24566\n",
      "img id in: 24567\n",
      "img id out: 24567\n",
      "img id in: 24568\n",
      "img id out: 24568\n",
      "img id in: 24569\n",
      "img id out: 24569\n",
      "img id in: 24570\n",
      "img id out: 24570\n",
      "img id in: 24571\n",
      "img id out: 24571\n",
      "img id in: 24572\n",
      "img id out: 24572\n",
      "img id in: 24573\n",
      "img id out: 24573\n",
      "img id in: 24574\n",
      "img id out: 24574\n",
      "img id in: 24575\n",
      "img id out: 24575\n",
      "img id in: 24576\n",
      "img id out: 24576\n",
      "img id in: 24577\n",
      "img id out: 24577\n",
      "img id in: 24578\n",
      "img id out: 24578\n",
      "img id in: 24579\n",
      "img id out: 24579\n",
      "img id in: 24580\n",
      "img id out: 24580\n",
      "img id in: 24581\n",
      "img id out: 24581\n",
      "img id in: 24582\n",
      "img id out: 24582\n",
      "img id in: 24583\n",
      "img id out: 24583\n",
      "img id in: 24584\n",
      "img id out: 24584\n",
      "img id in: 24585\n",
      "img id out: 24585\n",
      "img id in: 24586\n",
      "img id out: 24586\n",
      "img id in: 24587\n",
      "img id out: 24587\n",
      "img id in: 24588\n",
      "img id out: 24588\n",
      "img id in: 24589\n",
      "img id out: 24589\n",
      "img id in: 24590\n",
      "img id out: 24590\n",
      "img id in: 24591\n",
      "img id out: 24591\n",
      "img id in: 24592\n",
      "img id out: 24592\n",
      "img id in: 24593\n",
      "img id out: 24593\n",
      "img id in: 24594\n",
      "img id out: 24594\n",
      "img id in: 24595\n",
      "img id out: 24595\n",
      "img id in: 24596\n",
      "img id out: 24596\n",
      "img id in: 24597\n",
      "img id out: 24597\n",
      "img id in: 24598\n",
      "img id out: 24598\n",
      "img id in: 24599\n",
      "img id out: 24599\n",
      "img id in: 24600\n",
      "img id out: 24600\n",
      "img id in: 24601\n",
      "img id out: 24601\n",
      "img id in: 24602\n",
      "img id out: 24602\n",
      "img id in: 24603\n",
      "img id out: 24603\n",
      "img id in: 24604\n",
      "img id out: 24604\n",
      "img id in: 24605\n",
      "img id out: 24605\n",
      "img id in: 24606\n",
      "img id out: 24606\n",
      "img id in: 24607\n",
      "img id out: 24607\n",
      "img id in: 24608\n",
      "img id out: 24608\n",
      "img id in: 24609\n",
      "img id out: 24609\n",
      "img id in: 24610\n",
      "img id out: 24610\n",
      "img id in: 24611\n",
      "img id out: 24611\n",
      "img id in: 24612\n",
      "img id out: 24612\n",
      "img id in: 24613\n",
      "img id out: 24613\n",
      "img id in: 24614\n",
      "img id out: 24614\n",
      "img id in: 24615\n",
      "img id out: 24615\n",
      "img id in: 24616\n",
      "img id out: 24616\n",
      "img id in: 24617\n",
      "img id out: 24617\n",
      "img id in: 24618\n",
      "img id out: 24618\n",
      "img id in: 24619\n",
      "img id out: 24619\n",
      "img id in: 24620\n",
      "img id out: 24620\n",
      "img id in: 24621\n",
      "img id out: 24621\n",
      "img id in: 24622\n",
      "img id out: 24622\n",
      "img id in: 24623\n",
      "img id out: 24623\n",
      "img id in: 24624\n",
      "img id out: 24624\n",
      "img id in: 24625\n",
      "img id out: 24625\n",
      "img id in: 24626\n",
      "img id out: 24626\n",
      "img id in: 24627\n",
      "img id out: 24627\n",
      "img id in: 24628\n",
      "img id out: 24628\n",
      "img id in: 24629\n",
      "img id out: 24629\n",
      "img id in: 24630\n",
      "img id out: 24630\n",
      "img id in: 24631\n",
      "img id out: 24631\n",
      "img id in: 24632\n",
      "img id out: 24632\n",
      "img id in: 24633\n",
      "img id out: 24633\n",
      "img id in: 24634\n",
      "img id out: 24634\n",
      "img id in: 24635\n",
      "img id out: 24635\n",
      "img id in: 24636\n",
      "img id out: 24636\n",
      "img id in: 24637\n",
      "img id out: 24637\n",
      "img id in: 24638\n",
      "img id out: 24638\n",
      "img id in: 24639\n",
      "img id out: 24639\n",
      "img id in: 24640\n",
      "img id out: 24640\n",
      "img id in: 24641\n",
      "img id out: 24641\n",
      "img id in: 24642\n",
      "img id out: 24642\n",
      "img id in: 24643\n",
      "img id out: 24643\n",
      "img id in: 24644\n",
      "img id out: 24644\n",
      "img id in: 24645\n",
      "img id out: 24645\n",
      "img id in: 24646\n",
      "img id out: 24646\n",
      "img id in: 24647\n",
      "img id out: 24647\n",
      "img id in: 24648\n",
      "img id out: 24648\n",
      "img id in: 24649\n",
      "img id out: 24649\n",
      "img id in: 24650\n",
      "img id out: 24650\n",
      "img id in: 24651\n",
      "img id out: 24651\n",
      "img id in: 24652\n",
      "img id out: 24652\n",
      "img id in: 24653\n",
      "img id out: 24653\n",
      "img id in: 24654\n",
      "img id out: 24654\n",
      "img id in: 24655\n",
      "img id out: 24655\n",
      "img id in: 24656\n",
      "img id out: 24656\n",
      "img id in: 24657\n",
      "img id out: 24657\n",
      "img id in: 24658\n",
      "img id out: 24658\n",
      "img id in: 24659\n",
      "img id out: 24659\n",
      "img id in: 24660\n",
      "img id out: 24660\n",
      "img id in: 24661\n",
      "img id out: 24661\n",
      "img id in: 24662\n",
      "img id out: 24662\n",
      "img id in: 24663\n",
      "img id out: 24663\n",
      "img id in: 24664\n",
      "img id out: 24664\n",
      "img id in: 24665\n",
      "img id out: 24665\n",
      "img id in: 24666\n",
      "img id out: 24666\n",
      "img id in: 24667\n",
      "img id out: 24667\n",
      "img id in: 24668\n",
      "img id out: 24668\n",
      "img id in: 24669\n",
      "img id out: 24669\n",
      "img id in: 24670\n",
      "img id out: 24670\n",
      "img id in: 24671\n",
      "img id out: 24671\n",
      "img id in: 24672\n",
      "img id out: 24672\n",
      "img id in: 24673\n",
      "img id out: 24673\n",
      "img id in: 24674\n",
      "img id out: 24674\n",
      "img id in: 24675\n",
      "img id out: 24675\n",
      "img id in: 24676\n",
      "img id out: 24676\n",
      "img id in: 24677\n",
      "img id out: 24677\n",
      "img id in: 24678\n",
      "img id out: 24678\n",
      "img id in: 24679\n",
      "img id out: 24679\n",
      "img id in: 24680\n",
      "img id out: 24680\n",
      "img id in: 24681\n",
      "img id out: 24681\n",
      "img id in: 24682\n",
      "img id out: 24682\n",
      "img id in: 24683\n",
      "img id out: 24683\n",
      "img id in: 24684\n",
      "img id out: 24684\n",
      "img id in: 24685\n",
      "img id out: 24685\n",
      "img id in: 24686\n",
      "img id out: 24686\n",
      "img id in: 24687\n",
      "img id out: 24687\n",
      "img id in: 24688\n",
      "img id out: 24688\n",
      "img id in: 24689\n",
      "img id out: 24689\n",
      "img id in: 24690\n",
      "img id out: 24690\n",
      "img id in: 24691\n",
      "img id out: 24691\n",
      "img id in: 24692\n",
      "img id out: 24692\n",
      "img id in: 24693\n",
      "img id out: 24693\n",
      "img id in: 24694\n",
      "img id out: 24694\n",
      "img id in: 24695\n",
      "img id out: 24695\n",
      "img id in: 24696\n",
      "img id out: 24696\n",
      "img id in: 24697\n",
      "img id out: 24697\n",
      "img id in: 24698\n",
      "img id out: 24698\n",
      "img id in: 24699\n",
      "img id out: 24699\n",
      "img id in: 24700\n",
      "img id out: 24700\n",
      "img id in: 24701\n",
      "img id out: 24701\n",
      "img id in: 24702\n",
      "img id out: 24702\n",
      "img id in: 24703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 24703\n",
      "img id in: 24704\n",
      "img id out: 24704\n",
      "img id in: 24705\n",
      "img id out: 24705\n",
      "img id in: 24706\n",
      "img id out: 24706\n",
      "img id in: 24707\n",
      "img id out: 24707\n",
      "img id in: 24708\n",
      "img id out: 24708\n",
      "img id in: 24709\n",
      "img id out: 24709\n",
      "img id in: 24710\n",
      "img id out: 24710\n",
      "img id in: 24711\n",
      "img id out: 24711\n",
      "img id in: 24712\n",
      "img id out: 24712\n",
      "img id in: 24713\n",
      "img id out: 24713\n",
      "img id in: 24714\n",
      "img id out: 24714\n",
      "img id in: 24715\n",
      "img id out: 24715\n",
      "img id in: 24716\n",
      "img id out: 24716\n",
      "img id in: 24717\n",
      "img id out: 24717\n",
      "img id in: 24718\n",
      "img id out: 24718\n",
      "img id in: 24719\n",
      "img id out: 24719\n",
      "img id in: 24720\n",
      "img id out: 24720\n",
      "img id in: 24721\n",
      "img id out: 24721\n",
      "img id in: 24722\n",
      "img id out: 24722\n",
      "img id in: 24723\n",
      "img id out: 24723\n",
      "img id in: 24724\n",
      "img id out: 24724\n",
      "img id in: 24725\n",
      "img id out: 24725\n",
      "img id in: 24726\n",
      "img id out: 24726\n",
      "img id in: 24727\n",
      "img id out: 24727\n",
      "img id in: 24728\n",
      "img id out: 24728\n",
      "img id in: 24729\n",
      "img id out: 24729\n",
      "img id in: 24730\n",
      "img id out: 24730\n",
      "img id in: 24731\n",
      "img id out: 24731\n",
      "img id in: 24732\n",
      "img id out: 24732\n",
      "img id in: 24733\n",
      "img id out: 24733\n",
      "img id in: 24734\n",
      "img id out: 24734\n",
      "img id in: 24735\n",
      "img id out: 24735\n",
      "img id in: 24736\n",
      "img id out: 24736\n",
      "img id in: 24737\n",
      "img id out: 24737\n",
      "img id in: 24738\n",
      "img id out: 24738\n",
      "img id in: 24739\n",
      "img id out: 24739\n",
      "img id in: 24740\n",
      "img id out: 24740\n",
      "img id in: 24741\n",
      "img id out: 24741\n",
      "img id in: 24742\n",
      "img id out: 24742\n",
      "img id in: 24743\n",
      "img id out: 24743\n",
      "img id in: 24744\n",
      "img id out: 24744\n",
      "img id in: 24745\n",
      "img id out: 24745\n",
      "img id in: 24746\n",
      "img id out: 24746\n",
      "img id in: 24747\n",
      "img id out: 24747\n",
      "img id in: 24748\n",
      "img id out: 24748\n",
      "img id in: 24749\n",
      "img id out: 24749\n",
      "img id in: 24750\n",
      "img id out: 24750\n",
      "img id in: 24751\n",
      "img id out: 24751\n",
      "img id in: 24752\n",
      "img id out: 24752\n",
      "img id in: 24753\n",
      "img id out: 24753\n",
      "img id in: 24754\n",
      "img id out: 24754\n",
      "img id in: 24755\n",
      "img id out: 24755\n",
      "img id in: 24756\n",
      "img id out: 24756\n",
      "img id in: 24757\n",
      "img id out: 24757\n",
      "img id in: 24758\n",
      "img id out: 24758\n",
      "img id in: 24759\n",
      "img id out: 24759\n",
      "img id in: 24760\n",
      "img id out: 24760\n",
      "img id in: 24761\n",
      "img id out: 24761\n",
      "img id in: 24762\n",
      "img id out: 24762\n",
      "img id in: 24763\n",
      "img id out: 24763\n",
      "img id in: 24764\n",
      "img id out: 24764\n",
      "img id in: 24765\n",
      "img id out: 24765\n",
      "img id in: 24766\n",
      "img id out: 24766\n",
      "img id in: 24767\n",
      "img id out: 24767\n",
      "img id in: 24768\n",
      "img id out: 24768\n",
      "img id in: 24769\n",
      "img id out: 24769\n",
      "img id in: 24770\n",
      "img id out: 24770\n",
      "img id in: 24771\n",
      "img id out: 24771\n",
      "img id in: 24772\n",
      "img id out: 24772\n",
      "img id in: 24773\n",
      "img id out: 24773\n",
      "img id in: 24774\n",
      "img id out: 24774\n",
      "img id in: 24775\n",
      "img id out: 24775\n",
      "img id in: 24776\n",
      "img id out: 24776\n",
      "img id in: 24777\n",
      "img id out: 24777\n",
      "img id in: 24778\n",
      "img id out: 24778\n",
      "img id in: 24779\n",
      "img id out: 24779\n",
      "img id in: 24780\n",
      "img id out: 24780\n",
      "img id in: 24781\n",
      "img id out: 24781\n",
      "img id in: 24782\n",
      "img id out: 24782\n",
      "img id in: 24783\n",
      "img id out: 24783\n",
      "img id in: 24784\n",
      "img id out: 24784\n",
      "img id in: 24785\n",
      "img id out: 24785\n",
      "img id in: 24786\n",
      "img id out: 24786\n",
      "img id in: 24787\n",
      "img id out: 24787\n",
      "img id in: 24788\n",
      "img id out: 24788\n",
      "img id in: 24789\n",
      "img id out: 24789\n",
      "img id in: 24790\n",
      "img id out: 24790\n",
      "img id in: 24791\n",
      "img id out: 24791\n",
      "img id in: 24792\n",
      "img id out: 24792\n",
      "img id in: 24793\n",
      "img id out: 24793\n",
      "img id in: 24794\n",
      "img id out: 24794\n",
      "img id in: 24795\n",
      "img id out: 24795\n",
      "img id in: 24796\n",
      "img id out: 24796\n",
      "img id in: 24797\n",
      "img id out: 24797\n",
      "img id in: 24798\n",
      "img id out: 24798\n",
      "img id in: 24799\n",
      "img id out: 24799\n",
      "img id in: 24800\n",
      "img id out: 24800\n",
      "img id in: 24801\n",
      "img id out: 24801\n",
      "img id in: 24802\n",
      "img id out: 24802\n",
      "img id in: 24803\n",
      "img id out: 24803\n",
      "img id in: 24804\n",
      "img id out: 24804\n",
      "img id in: 24805\n",
      "img id out: 24805\n",
      "img id in: 24806\n",
      "img id out: 24806\n",
      "img id in: 24807\n",
      "img id out: 24807\n",
      "img id in: 24808\n",
      "img id out: 24808\n",
      "img id in: 24809\n",
      "img id out: 24809\n",
      "img id in: 24810\n",
      "img id out: 24810\n",
      "img id in: 24811\n",
      "img id out: 24811\n",
      "img id in: 24812\n",
      "img id out: 24812\n",
      "img id in: 24813\n",
      "img id out: 24813\n",
      "img id in: 24814\n",
      "img id out: 24814\n",
      "img id in: 24815\n",
      "img id out: 24815\n",
      "img id in: 24816\n",
      "img id out: 24816\n",
      "img id in: 24817\n",
      "img id out: 24817\n",
      "img id in: 24818\n",
      "img id out: 24818\n",
      "img id in: 24819\n",
      "img id out: 24819\n",
      "img id in: 24820\n",
      "img id out: 24820\n",
      "img id in: 24821\n",
      "img id out: 24821\n",
      "img id in: 24822\n",
      "img id out: 24822\n",
      "img id in: 24823\n",
      "img id out: 24823\n",
      "img id in: 24824\n",
      "img id out: 24824\n",
      "img id in: 24825\n",
      "img id out: 24825\n",
      "img id in: 24826\n",
      "img id out: 24826\n",
      "img id in: 24827\n",
      "img id out: 24827\n",
      "img id in: 24828\n",
      "img id out: 24828\n",
      "img id in: 24829\n",
      "img id out: 24829\n",
      "img id in: 24830\n",
      "img id out: 24830\n",
      "img id in: 24831\n",
      "img id out: 24831\n",
      "img id in: 24832\n",
      "img id out: 24832\n",
      "img id in: 24833\n",
      "img id out: 24833\n",
      "img id in: 24834\n",
      "img id out: 24834\n",
      "img id in: 24835\n",
      "img id out: 24835\n",
      "img id in: 24836\n",
      "img id out: 24836\n",
      "img id in: 24837\n",
      "img id out: 24837\n",
      "img id in: 24838\n",
      "img id out: 24838\n",
      "img id in: 24839\n",
      "img id out: 24839\n",
      "img id in: 24840\n",
      "img id out: 24840\n",
      "img id in: 24841\n",
      "img id out: 24841\n",
      "img id in: 24842\n",
      "img id out: 24842\n",
      "img id in: 24843\n",
      "img id out: 24843\n",
      "img id in: 24844\n",
      "img id out: 24844\n",
      "img id in: 24845\n",
      "img id out: 24845\n",
      "img id in: 24846\n",
      "img id out: 24846\n",
      "img id in: 24847\n",
      "img id out: 24847\n",
      "img id in: 24848\n",
      "img id out: 24848\n",
      "img id in: 24849\n",
      "img id out: 24849\n",
      "img id in: 24850\n",
      "img id out: 24850\n",
      "img id in: 24851\n",
      "img id out: 24851\n",
      "img id in: 24852\n",
      "img id out: 24852\n",
      "img id in: 24853\n",
      "img id out: 24853\n",
      "img id in: 24854\n",
      "img id out: 24854\n",
      "img id in: 24855\n",
      "img id out: 24855\n",
      "img id in: 24856\n",
      "img id out: 24856\n",
      "img id in: 24857\n",
      "img id out: 24857\n",
      "img id in: 24858\n",
      "img id out: 24858\n",
      "img id in: 24859\n",
      "img id out: 24859\n",
      "img id in: 24860\n",
      "img id out: 24860\n",
      "img id in: 24861\n",
      "img id out: 24861\n",
      "img id in: 24862\n",
      "img id out: 24862\n",
      "img id in: 24863\n",
      "img id out: 24863\n",
      "img id in: 24864\n",
      "img id out: 24864\n",
      "img id in: 24865\n",
      "img id out: 24865\n",
      "img id in: 24866\n",
      "img id out: 24866\n",
      "img id in: 24867\n",
      "img id out: 24867\n",
      "img id in: 24868\n",
      "img id out: 24868\n",
      "img id in: 24869\n",
      "img id out: 24869\n",
      "img id in: 24870\n",
      "img id out: 24870\n",
      "img id in: 24871\n",
      "img id out: 24871\n",
      "img id in: 24872\n",
      "img id out: 24872\n",
      "img id in: 24873\n",
      "img id out: 24873\n",
      "img id in: 24874\n",
      "img id out: 24874\n",
      "img id in: 24875\n",
      "img id out: 24875\n",
      "img id in: 24876\n",
      "img id out: 24876\n",
      "img id in: 24877\n",
      "img id out: 24877\n",
      "img id in: 24878\n",
      "img id out: 24878\n",
      "img id in: 24879\n",
      "img id out: 24879\n",
      "img id in: 24880\n",
      "img id out: 24880\n",
      "img id in: 24881\n",
      "img id out: 24881\n",
      "img id in: 24882\n",
      "img id out: 24882\n",
      "img id in: 24883\n",
      "img id out: 24883\n",
      "img id in: 24884\n",
      "img id out: 24884\n",
      "img id in: 24885\n",
      "img id out: 24885\n",
      "img id in: 24886\n",
      "img id out: 24886\n",
      "img id in: 24887\n",
      "img id out: 24887\n",
      "img id in: 24888\n",
      "img id out: 24888\n",
      "img id in: 24889\n",
      "img id out: 24889\n",
      "img id in: 24890\n",
      "img id out: 24890\n",
      "img id in: 24891\n",
      "img id out: 24891\n",
      "img id in: 24892\n",
      "img id out: 24892\n",
      "img id in: 24893\n",
      "img id out: 24893\n",
      "img id in: 24894\n",
      "img id out: 24894\n",
      "img id in: 24895\n",
      "img id out: 24895\n",
      "img id in: 24896\n",
      "img id out: 24896\n",
      "img id in: 24897\n",
      "img id out: 24897\n",
      "img id in: 24898\n",
      "img id out: 24898\n",
      "img id in: 24899\n",
      "img id out: 24899\n",
      "img id in: 24900\n",
      "img id out: 24900\n",
      "img id in: 24901\n",
      "img id out: 24901\n",
      "img id in: 24902\n",
      "img id out: 24902\n",
      "img id in: 24903\n",
      "img id out: 24903\n",
      "img id in: 24904\n",
      "img id out: 24904\n",
      "img id in: 24905\n",
      "img id out: 24905\n",
      "img id in: 24906\n",
      "img id out: 24906\n",
      "img id in: 24907\n",
      "img id out: 24907\n",
      "img id in: 24908\n",
      "img id out: 24908\n",
      "img id in: 24909\n",
      "img id out: 24909\n",
      "img id in: 24910\n",
      "img id out: 24910\n",
      "img id in: 24911\n",
      "img id out: 24911\n",
      "img id in: 24912\n",
      "img id out: 24912\n",
      "img id in: 24913\n",
      "img id out: 24913\n",
      "img id in: 24914\n",
      "img id out: 24914\n",
      "img id in: 24915\n",
      "img id out: 24915\n",
      "img id in: 24916\n",
      "img id out: 24916\n",
      "img id in: 24917\n",
      "img id out: 24917\n",
      "img id in: 24918\n",
      "img id out: 24918\n",
      "img id in: 24919\n",
      "img id out: 24919\n",
      "img id in: 24920\n",
      "img id out: 24920\n",
      "img id in: 24921\n",
      "img id out: 24921\n",
      "img id in: 24922\n",
      "img id out: 24922\n",
      "img id in: 24923\n",
      "img id out: 24923\n",
      "img id in: 24924\n",
      "img id out: 24924\n",
      "img id in: 24925\n",
      "img id out: 24925\n",
      "img id in: 24926\n",
      "img id out: 24926\n",
      "img id in: 24927\n",
      "img id out: 24927\n",
      "img id in: 24928\n",
      "img id out: 24928\n",
      "img id in: 24929\n",
      "img id out: 24929\n",
      "img id in: 24930\n",
      "img id out: 24930\n",
      "img id in: 24931\n",
      "img id out: 24931\n",
      "img id in: 24932\n",
      "img id out: 24932\n",
      "img id in: 24933\n",
      "img id out: 24933\n",
      "img id in: 24934\n",
      "img id out: 24934\n",
      "img id in: 24935\n",
      "img id out: 24935\n",
      "img id in: 24936\n",
      "img id out: 24936\n",
      "img id in: 24937\n",
      "img id out: 24937\n",
      "img id in: 24938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 24938\n",
      "img id in: 24939\n",
      "img id out: 24939\n",
      "img id in: 24940\n",
      "img id out: 24940\n",
      "img id in: 24941\n",
      "img id out: 24941\n",
      "img id in: 24942\n",
      "img id out: 24942\n",
      "img id in: 24943\n",
      "img id out: 24943\n",
      "img id in: 24944\n",
      "img id out: 24944\n",
      "img id in: 24945\n",
      "img id out: 24945\n",
      "img id in: 24946\n",
      "img id out: 24946\n",
      "img id in: 24947\n",
      "img id out: 24947\n",
      "img id in: 24948\n",
      "img id out: 24948\n",
      "img id in: 24949\n",
      "img id out: 24949\n",
      "img id in: 24950\n",
      "img id out: 24950\n",
      "img id in: 24951\n",
      "img id out: 24951\n",
      "img id in: 24952\n",
      "img id out: 24952\n",
      "img id in: 24953\n",
      "img id out: 24953\n",
      "img id in: 24954\n",
      "img id out: 24954\n",
      "img id in: 24955\n",
      "img id out: 24955\n",
      "img id in: 24956\n",
      "img id out: 24956\n",
      "img id in: 24957\n",
      "img id out: 24957\n",
      "img id in: 24958\n",
      "img id out: 24958\n",
      "img id in: 24959\n",
      "img id out: 24959\n",
      "img id in: 24960\n",
      "img id out: 24960\n",
      "img id in: 24961\n",
      "img id out: 24961\n",
      "img id in: 24962\n",
      "img id out: 24962\n",
      "img id in: 24963\n",
      "img id out: 24963\n",
      "img id in: 24964\n",
      "img id out: 24964\n",
      "img id in: 24965\n",
      "img id out: 24965\n",
      "img id in: 24966\n",
      "img id out: 24966\n",
      "img id in: 24967\n",
      "img id out: 24967\n",
      "img id in: 24968\n",
      "img id out: 24968\n",
      "img id in: 24969\n",
      "img id out: 24969\n",
      "img id in: 24970\n",
      "img id out: 24970\n",
      "img id in: 24971\n",
      "img id out: 24971\n",
      "img id in: 24972\n",
      "img id out: 24972\n",
      "img id in: 24973\n",
      "img id out: 24973\n",
      "img id in: 24974\n",
      "img id out: 24974\n",
      "img id in: 24975\n",
      "img id out: 24975\n",
      "img id in: 24976\n",
      "img id out: 24976\n",
      "img id in: 24977\n",
      "img id out: 24977\n",
      "img id in: 24978\n",
      "img id out: 24978\n",
      "img id in: 24979\n",
      "img id out: 24979\n",
      "img id in: 24980\n",
      "img id out: 24980\n",
      "img id in: 24981\n",
      "img id out: 24981\n",
      "img id in: 24982\n",
      "img id out: 24982\n",
      "img id in: 24983\n",
      "img id out: 24983\n",
      "img id in: 24984\n",
      "img id out: 24984\n",
      "img id in: 24985\n",
      "img id out: 24985\n",
      "img id in: 24986\n",
      "img id out: 24986\n",
      "img id in: 24987\n",
      "img id out: 24987\n",
      "img id in: 24988\n",
      "img id out: 24988\n",
      "img id in: 24989\n",
      "img id out: 24989\n",
      "img id in: 24990\n",
      "img id out: 24990\n",
      "img id in: 24991\n",
      "img id out: 24991\n",
      "img id in: 24992\n",
      "img id out: 24992\n",
      "img id in: 24993\n",
      "img id out: 24993\n",
      "img id in: 24994\n",
      "img id out: 24994\n",
      "img id in: 24995\n",
      "img id out: 24995\n",
      "img id in: 24996\n",
      "img id out: 24996\n",
      "img id in: 24997\n",
      "img id out: 24997\n",
      "img id in: 24998\n",
      "img id out: 24998\n",
      "img id in: 24999\n",
      "img id out: 24999\n",
      "img id in: 25000\n",
      "img id out: 25000\n",
      "img id in: 25001\n",
      "img id out: 25001\n",
      "img id in: 25002\n",
      "img id out: 25002\n",
      "img id in: 25003\n",
      "img id out: 25003\n",
      "img id in: 25004\n",
      "img id out: 25004\n",
      "img id in: 25005\n",
      "img id out: 25005\n",
      "img id in: 25006\n",
      "img id out: 25006\n",
      "img id in: 25007\n",
      "img id out: 25007\n",
      "img id in: 25008\n",
      "img id out: 25008\n",
      "img id in: 25009\n",
      "img id out: 25009\n",
      "img id in: 25010\n",
      "img id out: 25010\n",
      "img id in: 25011\n",
      "img id out: 25011\n",
      "img id in: 25012\n",
      "img id out: 25012\n",
      "img id in: 25013\n",
      "img id out: 25013\n",
      "img id in: 25014\n",
      "img id out: 25014\n",
      "img id in: 25015\n",
      "img id out: 25015\n",
      "img id in: 25016\n",
      "img id out: 25016\n",
      "img id in: 25017\n",
      "img id out: 25017\n",
      "img id in: 25018\n",
      "img id out: 25018\n",
      "img id in: 25019\n",
      "img id out: 25019\n",
      "img id in: 25020\n",
      "img id out: 25020\n",
      "img id in: 25021\n",
      "img id out: 25021\n",
      "img id in: 25022\n",
      "img id out: 25022\n",
      "img id in: 25023\n",
      "img id out: 25023\n",
      "img id in: 25024\n",
      "img id out: 25024\n",
      "img id in: 25025\n",
      "img id out: 25025\n",
      "img id in: 25026\n",
      "img id out: 25026\n",
      "img id in: 25027\n",
      "img id out: 25027\n",
      "img id in: 25028\n",
      "img id out: 25028\n",
      "img id in: 25029\n",
      "img id out: 25029\n",
      "img id in: 25030\n",
      "img id out: 25030\n",
      "img id in: 25031\n",
      "img id out: 25031\n",
      "img id in: 25032\n",
      "img id out: 25032\n",
      "img id in: 25033\n",
      "img id out: 25033\n",
      "img id in: 25034\n",
      "img id out: 25034\n",
      "img id in: 25035\n",
      "img id out: 25035\n",
      "img id in: 25036\n",
      "img id out: 25036\n",
      "img id in: 25037\n",
      "img id out: 25037\n",
      "img id in: 25038\n",
      "img id out: 25038\n",
      "img id in: 25039\n",
      "img id out: 25039\n",
      "img id in: 25040\n",
      "img id out: 25040\n",
      "img id in: 25041\n",
      "img id out: 25041\n",
      "img id in: 25042\n",
      "img id out: 25042\n",
      "img id in: 25043\n",
      "img id out: 25043\n",
      "img id in: 25044\n",
      "img id out: 25044\n",
      "img id in: 25045\n",
      "img id out: 25045\n",
      "img id in: 25046\n",
      "img id out: 25046\n",
      "img id in: 25047\n",
      "img id out: 25047\n",
      "img id in: 25048\n",
      "img id out: 25048\n",
      "img id in: 25049\n",
      "img id out: 25049\n",
      "img id in: 25050\n",
      "img id out: 25050\n",
      "img id in: 25051\n",
      "img id out: 25051\n",
      "img id in: 25052\n",
      "img id out: 25052\n",
      "img id in: 25053\n",
      "img id out: 25053\n",
      "img id in: 25054\n",
      "img id out: 25054\n",
      "img id in: 25055\n",
      "img id out: 25055\n",
      "img id in: 25056\n",
      "img id out: 25056\n",
      "img id in: 25057\n",
      "img id out: 25057\n",
      "img id in: 25058\n",
      "img id out: 25058\n",
      "img id in: 25059\n",
      "img id out: 25059\n",
      "img id in: 25060\n",
      "img id out: 25060\n",
      "img id in: 25061\n",
      "img id out: 25061\n",
      "img id in: 25062\n",
      "img id out: 25062\n",
      "img id in: 25063\n",
      "img id out: 25063\n",
      "img id in: 25064\n",
      "img id out: 25064\n",
      "img id in: 25065\n",
      "img id out: 25065\n",
      "img id in: 25066\n",
      "img id out: 25066\n",
      "img id in: 25067\n",
      "img id out: 25067\n",
      "img id in: 25068\n",
      "img id out: 25068\n",
      "img id in: 25069\n",
      "img id out: 25069\n",
      "img id in: 25070\n",
      "img id out: 25070\n",
      "img id in: 25071\n",
      "img id out: 25071\n",
      "img id in: 25072\n",
      "img id out: 25072\n",
      "img id in: 25073\n",
      "img id out: 25073\n",
      "img id in: 25074\n",
      "img id out: 25074\n",
      "img id in: 25075\n",
      "img id out: 25075\n",
      "img id in: 25076\n",
      "img id out: 25076\n",
      "img id in: 25077\n",
      "img id out: 25077\n",
      "img id in: 25078\n",
      "img id out: 25078\n",
      "img id in: 25079\n",
      "img id out: 25079\n",
      "img id in: 25080\n",
      "img id out: 25080\n",
      "img id in: 25081\n",
      "img id out: 25081\n",
      "img id in: 25082\n",
      "img id out: 25082\n",
      "img id in: 25083\n",
      "img id out: 25083\n",
      "img id in: 25084\n",
      "img id out: 25084\n",
      "img id in: 25085\n",
      "img id out: 25085\n",
      "img id in: 25086\n",
      "img id out: 25086\n",
      "img id in: 25087\n",
      "img id out: 25087\n",
      "img id in: 25088\n",
      "img id out: 25088\n",
      "img id in: 25089\n",
      "img id out: 25089\n",
      "img id in: 25090\n",
      "img id out: 25090\n",
      "img id in: 25091\n",
      "img id out: 25091\n",
      "img id in: 25092\n",
      "img id out: 25092\n",
      "img id in: 25093\n",
      "img id out: 25093\n",
      "img id in: 25094\n",
      "img id out: 25094\n",
      "img id in: 25095\n",
      "img id out: 25095\n",
      "img id in: 25096\n",
      "img id out: 25096\n",
      "img id in: 25097\n",
      "img id out: 25097\n",
      "img id in: 25098\n",
      "img id out: 25098\n",
      "img id in: 25099\n",
      "img id out: 25099\n",
      "img id in: 25100\n",
      "img id out: 25100\n",
      "img id in: 25101\n",
      "img id out: 25101\n",
      "img id in: 25102\n",
      "img id out: 25102\n",
      "img id in: 25103\n",
      "img id out: 25103\n",
      "img id in: 25104\n",
      "img id out: 25104\n",
      "img id in: 25105\n",
      "img id out: 25105\n",
      "img id in: 25106\n",
      "img id out: 25106\n",
      "img id in: 25107\n",
      "img id out: 25107\n",
      "img id in: 25108\n",
      "img id out: 25108\n",
      "img id in: 25109\n",
      "img id out: 25109\n",
      "img id in: 25110\n",
      "img id out: 25110\n",
      "img id in: 25111\n",
      "img id out: 25111\n",
      "img id in: 25112\n",
      "img id out: 25112\n",
      "img id in: 25113\n",
      "img id out: 25113\n",
      "img id in: 25114\n",
      "img id out: 25114\n",
      "img id in: 25115\n",
      "img id out: 25115\n",
      "img id in: 25116\n",
      "img id out: 25116\n",
      "img id in: 25117\n",
      "img id out: 25117\n",
      "img id in: 25118\n",
      "img id out: 25118\n",
      "img id in: 25119\n",
      "img id out: 25119\n",
      "img id in: 25120\n",
      "img id out: 25120\n",
      "img id in: 25121\n",
      "img id out: 25121\n",
      "img id in: 25122\n",
      "img id out: 25122\n",
      "img id in: 25123\n",
      "img id out: 25123\n",
      "img id in: 25124\n",
      "img id out: 25124\n",
      "img id in: 25125\n",
      "img id out: 25125\n",
      "img id in: 25126\n",
      "img id out: 25126\n",
      "img id in: 25127\n",
      "img id out: 25127\n",
      "img id in: 25128\n",
      "img id out: 25128\n",
      "img id in: 25129\n",
      "img id out: 25129\n",
      "img id in: 25130\n",
      "img id out: 25130\n",
      "img id in: 25131\n",
      "img id out: 25131\n",
      "img id in: 25132\n",
      "img id out: 25132\n",
      "img id in: 25133\n",
      "img id out: 25133\n",
      "img id in: 25134\n",
      "img id out: 25134\n",
      "img id in: 25135\n",
      "img id out: 25135\n",
      "img id in: 25136\n",
      "img id out: 25136\n",
      "img id in: 25137\n",
      "img id out: 25137\n",
      "img id in: 25138\n",
      "img id out: 25138\n",
      "img id in: 25139\n",
      "img id out: 25139\n",
      "img id in: 25140\n",
      "img id out: 25140\n",
      "img id in: 25141\n",
      "img id out: 25141\n",
      "img id in: 25142\n",
      "img id out: 25142\n",
      "img id in: 25143\n",
      "img id out: 25143\n",
      "img id in: 25144\n",
      "img id out: 25144\n",
      "img id in: 25145\n",
      "img id out: 25145\n",
      "img id in: 25146\n",
      "img id out: 25146\n",
      "img id in: 25147\n",
      "img id out: 25147\n",
      "img id in: 25148\n",
      "img id out: 25148\n",
      "img id in: 25149\n",
      "img id out: 25149\n",
      "img id in: 25150\n",
      "img id out: 25150\n",
      "img id in: 25151\n",
      "img id out: 25151\n",
      "img id in: 25152\n",
      "img id out: 25152\n",
      "img id in: 25153\n",
      "img id out: 25153\n",
      "img id in: 25154\n",
      "img id out: 25154\n",
      "img id in: 25155\n",
      "img id out: 25155\n",
      "img id in: 25156\n",
      "img id out: 25156\n",
      "img id in: 25157\n",
      "img id out: 25157\n",
      "img id in: 25158\n",
      "img id out: 25158\n",
      "img id in: 25159\n",
      "img id out: 25159\n",
      "img id in: 25160\n",
      "img id out: 25160\n",
      "img id in: 25161\n",
      "img id out: 25161\n",
      "img id in: 25162\n",
      "img id out: 25162\n",
      "img id in: 25163\n",
      "img id out: 25163\n",
      "img id in: 25164\n",
      "img id out: 25164\n",
      "img id in: 25165\n",
      "img id out: 25165\n",
      "img id in: 25166\n",
      "img id out: 25166\n",
      "img id in: 25167\n",
      "img id out: 25167\n",
      "img id in: 25168\n",
      "img id out: 25168\n",
      "img id in: 25169\n",
      "img id out: 25169\n",
      "img id in: 25170\n",
      "img id out: 25170\n",
      "img id in: 25171\n",
      "img id out: 25171\n",
      "img id in: 25172\n",
      "img id out: 25172\n",
      "img id in: 25173\n",
      "img id out: 25173\n",
      "img id in: 25174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 25174\n",
      "img id in: 25175\n",
      "img id out: 25175\n",
      "img id in: 25176\n",
      "img id out: 25176\n",
      "img id in: 25177\n",
      "img id out: 25177\n",
      "img id in: 25178\n",
      "img id out: 25178\n",
      "img id in: 25179\n",
      "img id out: 25179\n",
      "img id in: 25180\n",
      "img id out: 25180\n",
      "img id in: 25181\n",
      "img id out: 25181\n",
      "img id in: 25182\n",
      "img id out: 25182\n",
      "img id in: 25183\n",
      "img id out: 25183\n",
      "img id in: 25184\n",
      "img id out: 25184\n",
      "img id in: 25185\n",
      "img id out: 25185\n",
      "img id in: 25186\n",
      "img id out: 25186\n",
      "img id in: 25187\n",
      "img id out: 25187\n",
      "img id in: 25188\n",
      "img id out: 25188\n",
      "img id in: 25189\n",
      "img id out: 25189\n",
      "img id in: 25190\n",
      "img id out: 25190\n",
      "img id in: 25191\n",
      "img id out: 25191\n",
      "img id in: 25192\n",
      "img id out: 25192\n",
      "img id in: 25193\n",
      "img id out: 25193\n",
      "img id in: 25194\n",
      "img id out: 25194\n",
      "img id in: 25195\n",
      "img id out: 25195\n",
      "img id in: 25196\n",
      "img id out: 25196\n",
      "img id in: 25197\n",
      "img id out: 25197\n",
      "img id in: 25198\n",
      "img id out: 25198\n",
      "img id in: 25199\n",
      "img id out: 25199\n",
      "img id in: 25200\n",
      "img id out: 25200\n",
      "img id in: 25201\n",
      "img id out: 25201\n",
      "img id in: 25202\n",
      "img id out: 25202\n",
      "img id in: 25203\n",
      "img id out: 25203\n",
      "img id in: 25204\n",
      "img id out: 25204\n",
      "img id in: 25205\n",
      "img id out: 25205\n",
      "img id in: 25206\n",
      "img id out: 25206\n",
      "img id in: 25207\n",
      "img id out: 25207\n",
      "img id in: 25208\n",
      "img id out: 25208\n",
      "img id in: 25209\n",
      "img id out: 25209\n",
      "img id in: 25210\n",
      "img id out: 25210\n",
      "img id in: 25211\n",
      "img id out: 25211\n",
      "img id in: 25212\n",
      "img id out: 25212\n",
      "img id in: 25213\n",
      "img id out: 25213\n",
      "img id in: 25214\n",
      "img id out: 25214\n",
      "img id in: 25215\n",
      "img id out: 25215\n",
      "img id in: 25216\n",
      "img id out: 25216\n",
      "img id in: 25217\n",
      "img id out: 25217\n",
      "img id in: 25218\n",
      "img id out: 25218\n",
      "img id in: 25219\n",
      "img id out: 25219\n",
      "img id in: 25220\n",
      "img id out: 25220\n",
      "img id in: 25221\n",
      "img id out: 25221\n",
      "img id in: 25222\n",
      "img id out: 25222\n",
      "img id in: 25223\n",
      "img id out: 25223\n",
      "img id in: 25224\n",
      "img id out: 25224\n",
      "img id in: 25225\n",
      "img id out: 25225\n",
      "img id in: 25226\n",
      "img id out: 25226\n",
      "img id in: 25227\n",
      "img id out: 25227\n",
      "img id in: 25228\n",
      "img id out: 25228\n",
      "img id in: 25229\n",
      "img id out: 25229\n",
      "img id in: 25230\n",
      "img id out: 25230\n",
      "img id in: 25231\n",
      "img id out: 25231\n",
      "img id in: 25232\n",
      "img id out: 25232\n",
      "img id in: 25233\n",
      "img id out: 25233\n",
      "img id in: 25234\n",
      "img id out: 25234\n",
      "img id in: 25235\n",
      "img id out: 25235\n",
      "img id in: 25236\n",
      "img id out: 25236\n",
      "img id in: 25237\n",
      "img id out: 25237\n",
      "img id in: 25238\n",
      "img id out: 25238\n",
      "img id in: 25239\n",
      "img id out: 25239\n",
      "img id in: 25240\n",
      "img id out: 25240\n",
      "img id in: 25241\n",
      "img id out: 25241\n",
      "img id in: 25242\n",
      "img id out: 25242\n",
      "img id in: 25243\n",
      "img id out: 25243\n",
      "img id in: 25244\n",
      "img id out: 25244\n",
      "img id in: 25245\n",
      "img id out: 25245\n",
      "img id in: 25246\n",
      "img id out: 25246\n",
      "img id in: 25247\n",
      "img id out: 25247\n",
      "img id in: 25248\n",
      "img id out: 25248\n",
      "img id in: 25249\n",
      "img id out: 25249\n",
      "img id in: 25250\n",
      "img id out: 25250\n",
      "img id in: 25251\n",
      "img id out: 25251\n",
      "img id in: 25252\n",
      "img id out: 25252\n",
      "img id in: 25253\n",
      "img id out: 25253\n",
      "img id in: 25254\n",
      "img id out: 25254\n",
      "img id in: 25255\n",
      "img id out: 25255\n",
      "img id in: 25256\n",
      "img id out: 25256\n",
      "img id in: 25257\n",
      "img id out: 25257\n",
      "img id in: 25258\n",
      "img id out: 25258\n",
      "img id in: 25259\n",
      "img id out: 25259\n",
      "img id in: 25260\n",
      "img id out: 25260\n",
      "img id in: 25261\n",
      "img id out: 25261\n",
      "img id in: 25262\n",
      "img id out: 25262\n",
      "img id in: 25263\n",
      "img id out: 25263\n",
      "img id in: 25264\n",
      "img id out: 25264\n",
      "img id in: 25265\n",
      "img id out: 25265\n",
      "img id in: 25266\n",
      "img id out: 25266\n",
      "img id in: 25267\n",
      "img id out: 25267\n",
      "img id in: 25268\n",
      "img id out: 25268\n",
      "img id in: 25269\n",
      "img id out: 25269\n",
      "img id in: 25270\n",
      "img id out: 25270\n",
      "img id in: 25271\n",
      "img id out: 25271\n",
      "img id in: 25272\n",
      "img id out: 25272\n",
      "img id in: 25273\n",
      "img id out: 25273\n",
      "img id in: 25274\n",
      "img id out: 25274\n",
      "img id in: 25275\n",
      "img id out: 25275\n",
      "img id in: 25276\n",
      "img id out: 25276\n",
      "img id in: 25277\n",
      "img id out: 25277\n",
      "img id in: 25278\n",
      "img id out: 25278\n",
      "img id in: 25279\n",
      "img id out: 25279\n",
      "img id in: 25280\n",
      "img id out: 25280\n",
      "img id in: 25281\n",
      "img id out: 25281\n",
      "img id in: 25282\n",
      "img id out: 25282\n",
      "img id in: 25283\n",
      "img id out: 25283\n",
      "img id in: 25284\n",
      "img id out: 25284\n",
      "img id in: 25285\n",
      "img id out: 25285\n",
      "img id in: 25286\n",
      "img id out: 25286\n",
      "img id in: 25287\n",
      "img id out: 25287\n",
      "img id in: 25288\n",
      "img id out: 25288\n",
      "img id in: 25289\n",
      "img id out: 25289\n",
      "img id in: 25290\n",
      "img id out: 25290\n",
      "img id in: 25291\n",
      "img id out: 25291\n",
      "img id in: 25292\n",
      "img id out: 25292\n",
      "img id in: 25293\n",
      "img id out: 25293\n",
      "img id in: 25294\n",
      "img id out: 25294\n",
      "img id in: 25295\n",
      "img id out: 25295\n",
      "img id in: 25296\n",
      "img id out: 25296\n",
      "img id in: 25297\n",
      "img id out: 25297\n",
      "img id in: 25298\n",
      "img id out: 25298\n",
      "img id in: 25299\n",
      "img id out: 25299\n",
      "img id in: 25300\n",
      "img id out: 25300\n",
      "img id in: 25301\n",
      "img id out: 25301\n",
      "img id in: 25302\n",
      "img id out: 25302\n",
      "img id in: 25303\n",
      "img id out: 25303\n",
      "img id in: 25304\n",
      "img id out: 25304\n",
      "img id in: 25305\n",
      "img id out: 25305\n",
      "img id in: 25306\n",
      "img id out: 25306\n",
      "img id in: 25307\n",
      "img id out: 25307\n",
      "img id in: 25308\n",
      "img id out: 25308\n",
      "img id in: 25309\n",
      "img id out: 25309\n",
      "img id in: 25310\n",
      "img id out: 25310\n",
      "img id in: 25311\n",
      "img id out: 25311\n",
      "img id in: 25312\n",
      "img id out: 25312\n",
      "img id in: 25313\n",
      "img id out: 25313\n",
      "img id in: 25314\n",
      "img id out: 25314\n",
      "img id in: 25315\n",
      "img id out: 25315\n",
      "img id in: 25316\n",
      "img id out: 25316\n",
      "img id in: 25317\n",
      "img id out: 25317\n",
      "img id in: 25318\n",
      "img id out: 25318\n",
      "img id in: 25319\n",
      "img id out: 25319\n",
      "img id in: 25320\n",
      "img id out: 25320\n",
      "img id in: 25321\n",
      "img id out: 25321\n",
      "img id in: 25322\n",
      "img id out: 25322\n",
      "img id in: 25323\n",
      "img id out: 25323\n",
      "img id in: 25324\n",
      "img id out: 25324\n",
      "img id in: 25325\n",
      "img id out: 25325\n",
      "img id in: 25326\n",
      "img id out: 25326\n",
      "img id in: 25327\n",
      "img id out: 25327\n",
      "img id in: 25328\n",
      "img id out: 25328\n",
      "img id in: 25329\n",
      "img id out: 25329\n",
      "img id in: 25330\n",
      "img id out: 25330\n",
      "img id in: 25331\n",
      "img id out: 25331\n",
      "img id in: 25332\n",
      "img id out: 25332\n",
      "img id in: 25333\n",
      "img id out: 25333\n",
      "img id in: 25334\n",
      "img id out: 25334\n",
      "img id in: 25335\n",
      "img id out: 25335\n",
      "img id in: 25336\n",
      "img id out: 25336\n",
      "img id in: 25337\n",
      "img id out: 25337\n",
      "img id in: 25338\n",
      "img id out: 25338\n",
      "img id in: 25339\n",
      "img id out: 25339\n",
      "img id in: 25340\n",
      "img id out: 25340\n",
      "img id in: 25341\n",
      "img id out: 25341\n",
      "img id in: 25342\n",
      "img id out: 25342\n",
      "img id in: 25343\n",
      "img id out: 25343\n",
      "img id in: 25344\n",
      "img id out: 25344\n",
      "img id in: 25345\n",
      "img id out: 25345\n",
      "img id in: 25346\n",
      "img id out: 25346\n",
      "img id in: 25347\n",
      "img id out: 25347\n",
      "img id in: 25348\n",
      "img id out: 25348\n",
      "img id in: 25349\n",
      "img id out: 25349\n",
      "img id in: 25350\n",
      "img id out: 25350\n",
      "img id in: 25351\n",
      "img id out: 25351\n",
      "img id in: 25352\n",
      "img id out: 25352\n",
      "img id in: 25353\n",
      "img id out: 25353\n",
      "img id in: 25354\n",
      "img id out: 25354\n",
      "img id in: 25355\n",
      "img id out: 25355\n",
      "img id in: 25356\n",
      "img id out: 25356\n",
      "img id in: 25357\n",
      "img id out: 25357\n",
      "img id in: 25358\n",
      "img id out: 25358\n",
      "img id in: 25359\n",
      "img id out: 25359\n",
      "img id in: 25360\n",
      "img id out: 25360\n",
      "img id in: 25361\n",
      "img id out: 25361\n",
      "img id in: 25362\n",
      "img id out: 25362\n",
      "img id in: 25363\n",
      "img id out: 25363\n",
      "img id in: 25364\n",
      "img id out: 25364\n",
      "img id in: 25365\n",
      "img id out: 25365\n",
      "img id in: 25366\n",
      "img id out: 25366\n",
      "img id in: 25367\n",
      "img id out: 25367\n",
      "img id in: 25368\n",
      "img id out: 25368\n",
      "img id in: 25369\n",
      "img id out: 25369\n",
      "img id in: 25370\n",
      "img id out: 25370\n",
      "img id in: 25371\n",
      "img id out: 25371\n",
      "img id in: 25372\n",
      "img id out: 25372\n",
      "img id in: 25373\n",
      "img id out: 25373\n",
      "img id in: 25374\n",
      "img id out: 25374\n",
      "img id in: 25375\n",
      "img id out: 25375\n",
      "img id in: 25376\n",
      "img id out: 25376\n",
      "img id in: 25377\n",
      "img id out: 25377\n",
      "img id in: 25378\n",
      "img id out: 25378\n",
      "img id in: 25379\n",
      "img id out: 25379\n",
      "img id in: 25380\n",
      "img id out: 25380\n",
      "img id in: 25381\n",
      "img id out: 25381\n",
      "img id in: 25382\n",
      "img id out: 25382\n",
      "img id in: 25383\n",
      "img id out: 25383\n",
      "img id in: 25384\n",
      "img id out: 25384\n",
      "img id in: 25385\n",
      "img id out: 25385\n",
      "img id in: 25386\n",
      "img id out: 25386\n",
      "img id in: 25387\n",
      "img id out: 25387\n",
      "img id in: 25388\n",
      "img id out: 25388\n",
      "img id in: 25389\n",
      "img id out: 25389\n",
      "img id in: 25390\n",
      "img id out: 25390\n",
      "img id in: 25391\n",
      "img id out: 25391\n",
      "img id in: 25392\n",
      "img id out: 25392\n",
      "img id in: 25393\n",
      "img id out: 25393\n",
      "img id in: 25394\n",
      "img id out: 25394\n",
      "img id in: 25395\n",
      "img id out: 25395\n",
      "img id in: 25396\n",
      "img id out: 25396\n",
      "img id in: 25397\n",
      "img id out: 25397\n",
      "img id in: 25398\n",
      "img id out: 25398\n",
      "img id in: 25399\n",
      "img id out: 25399\n",
      "img id in: 25400\n",
      "img id out: 25400\n",
      "img id in: 25401\n",
      "img id out: 25401\n",
      "img id in: 25402\n",
      "img id out: 25402\n",
      "img id in: 25403\n",
      "img id out: 25403\n",
      "img id in: 25404\n",
      "img id out: 25404\n",
      "img id in: 25405\n",
      "img id out: 25405\n",
      "img id in: 25406\n",
      "img id out: 25406\n",
      "img id in: 25407\n",
      "img id out: 25407\n",
      "img id in: 25408\n",
      "img id out: 25408\n",
      "img id in: 25409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 25409\n",
      "img id in: 25410\n",
      "img id out: 25410\n",
      "img id in: 25411\n",
      "img id out: 25411\n",
      "img id in: 25412\n",
      "img id out: 25412\n",
      "img id in: 25413\n",
      "img id out: 25413\n",
      "img id in: 25414\n",
      "img id out: 25414\n",
      "img id in: 25415\n",
      "img id out: 25415\n",
      "img id in: 25416\n",
      "img id out: 25416\n",
      "img id in: 25417\n",
      "img id out: 25417\n",
      "img id in: 25418\n",
      "img id out: 25418\n",
      "img id in: 25419\n",
      "img id out: 25419\n",
      "img id in: 25420\n",
      "img id out: 25420\n",
      "img id in: 25421\n",
      "img id out: 25421\n",
      "img id in: 25422\n",
      "img id out: 25422\n",
      "img id in: 25423\n",
      "img id out: 25423\n",
      "img id in: 25424\n",
      "img id out: 25424\n",
      "img id in: 25425\n",
      "img id out: 25425\n",
      "img id in: 25426\n",
      "img id out: 25426\n",
      "img id in: 25427\n",
      "img id out: 25427\n",
      "img id in: 25428\n",
      "img id out: 25428\n",
      "img id in: 25429\n",
      "img id out: 25429\n",
      "img id in: 25430\n",
      "img id out: 25430\n",
      "img id in: 25431\n",
      "img id out: 25431\n",
      "img id in: 25432\n",
      "img id out: 25432\n",
      "img id in: 25433\n",
      "img id out: 25433\n",
      "img id in: 25434\n",
      "img id out: 25434\n",
      "img id in: 25435\n",
      "img id out: 25435\n",
      "img id in: 25436\n",
      "img id out: 25436\n",
      "img id in: 25437\n",
      "img id out: 25437\n",
      "img id in: 25438\n",
      "img id out: 25438\n",
      "img id in: 25439\n",
      "img id out: 25439\n",
      "img id in: 25440\n",
      "img id out: 25440\n",
      "img id in: 25441\n",
      "img id out: 25441\n",
      "img id in: 25442\n",
      "img id out: 25442\n",
      "img id in: 25443\n",
      "img id out: 25443\n",
      "img id in: 25444\n",
      "img id out: 25444\n",
      "img id in: 25445\n",
      "img id out: 25445\n",
      "img id in: 25446\n",
      "img id out: 25446\n",
      "img id in: 25447\n",
      "img id out: 25447\n",
      "img id in: 25448\n",
      "img id out: 25448\n",
      "img id in: 25449\n",
      "img id out: 25449\n",
      "img id in: 25450\n",
      "img id out: 25450\n",
      "img id in: 25451\n",
      "img id out: 25451\n",
      "img id in: 25452\n",
      "img id out: 25452\n",
      "img id in: 25453\n",
      "img id out: 25453\n",
      "img id in: 25454\n",
      "img id out: 25454\n",
      "img id in: 25455\n",
      "img id out: 25455\n",
      "img id in: 25456\n",
      "img id out: 25456\n",
      "img id in: 25457\n",
      "img id out: 25457\n",
      "img id in: 25458\n",
      "img id out: 25458\n",
      "img id in: 25459\n",
      "img id out: 25459\n",
      "img id in: 25460\n",
      "img id out: 25460\n",
      "img id in: 25461\n",
      "img id out: 25461\n",
      "img id in: 25462\n",
      "img id out: 25462\n",
      "img id in: 25463\n",
      "img id out: 25463\n",
      "img id in: 25464\n",
      "img id out: 25464\n",
      "img id in: 25465\n",
      "img id out: 25465\n",
      "img id in: 25466\n",
      "img id out: 25466\n",
      "img id in: 25467\n",
      "img id out: 25467\n",
      "img id in: 25468\n",
      "img id out: 25468\n",
      "img id in: 25469\n",
      "img id out: 25469\n",
      "img id in: 25470\n",
      "img id out: 25470\n",
      "img id in: 25471\n",
      "img id out: 25471\n",
      "img id in: 25472\n",
      "img id out: 25472\n",
      "img id in: 25473\n",
      "img id out: 25473\n",
      "img id in: 25474\n",
      "img id out: 25474\n",
      "img id in: 25475\n",
      "img id out: 25475\n",
      "img id in: 25476\n",
      "img id out: 25476\n",
      "img id in: 25477\n",
      "img id out: 25477\n",
      "img id in: 25478\n",
      "img id out: 25478\n",
      "img id in: 25479\n",
      "img id out: 25479\n",
      "img id in: 25480\n",
      "img id out: 25480\n",
      "img id in: 25481\n",
      "img id out: 25481\n",
      "img id in: 25482\n",
      "img id out: 25482\n",
      "img id in: 25483\n",
      "img id out: 25483\n",
      "img id in: 25484\n",
      "img id out: 25484\n",
      "img id in: 25485\n",
      "img id out: 25485\n",
      "img id in: 25486\n",
      "img id out: 25486\n",
      "img id in: 25487\n",
      "img id out: 25487\n",
      "img id in: 25488\n",
      "img id out: 25488\n",
      "img id in: 25489\n",
      "img id out: 25489\n",
      "img id in: 25490\n",
      "img id out: 25490\n",
      "img id in: 25491\n",
      "img id out: 25491\n",
      "img id in: 25492\n",
      "img id out: 25492\n",
      "img id in: 25493\n",
      "img id out: 25493\n",
      "img id in: 25494\n",
      "img id out: 25494\n",
      "img id in: 25495\n",
      "img id out: 25495\n",
      "img id in: 25496\n",
      "img id out: 25496\n",
      "img id in: 25497\n",
      "img id out: 25497\n",
      "img id in: 25498\n",
      "img id out: 25498\n",
      "img id in: 25499\n",
      "img id out: 25499\n",
      "img id in: 25500\n",
      "img id out: 25500\n",
      "img id in: 25501\n",
      "img id out: 25501\n",
      "img id in: 25502\n",
      "img id out: 25502\n",
      "img id in: 25503\n",
      "img id out: 25503\n",
      "img id in: 25504\n",
      "img id out: 25504\n",
      "img id in: 25505\n",
      "img id out: 25505\n",
      "img id in: 25506\n",
      "img id out: 25506\n",
      "img id in: 25507\n",
      "img id out: 25507\n",
      "img id in: 25508\n",
      "img id out: 25508\n",
      "img id in: 25509\n",
      "img id out: 25509\n",
      "img id in: 25510\n",
      "img id out: 25510\n",
      "img id in: 25511\n",
      "img id out: 25511\n",
      "img id in: 25512\n",
      "img id out: 25512\n",
      "img id in: 25513\n",
      "img id out: 25513\n",
      "img id in: 25514\n",
      "img id out: 25514\n",
      "img id in: 25515\n",
      "img id out: 25515\n",
      "img id in: 25516\n",
      "img id out: 25516\n",
      "img id in: 25517\n",
      "img id out: 25517\n",
      "img id in: 25518\n",
      "img id out: 25518\n",
      "img id in: 25519\n",
      "img id out: 25519\n",
      "img id in: 25520\n",
      "img id out: 25520\n",
      "img id in: 25521\n",
      "img id out: 25521\n",
      "img id in: 25522\n",
      "img id out: 25522\n",
      "img id in: 25523\n",
      "img id out: 25523\n",
      "img id in: 25524\n",
      "img id out: 25524\n",
      "img id in: 25525\n",
      "img id out: 25525\n",
      "img id in: 25526\n",
      "img id out: 25526\n",
      "img id in: 25527\n",
      "img id out: 25527\n",
      "img id in: 25528\n",
      "img id out: 25528\n",
      "img id in: 25529\n",
      "img id out: 25529\n",
      "img id in: 25530\n",
      "img id out: 25530\n",
      "img id in: 25531\n",
      "img id out: 25531\n",
      "img id in: 25532\n",
      "img id out: 25532\n",
      "img id in: 25533\n",
      "img id out: 25533\n",
      "img id in: 25534\n",
      "img id out: 25534\n",
      "img id in: 25535\n",
      "img id out: 25535\n",
      "img id in: 25536\n",
      "img id out: 25536\n",
      "img id in: 25537\n",
      "img id out: 25537\n",
      "img id in: 25538\n",
      "img id out: 25538\n",
      "img id in: 25539\n",
      "img id out: 25539\n",
      "img id in: 25540\n",
      "img id out: 25540\n",
      "img id in: 25541\n",
      "img id out: 25541\n",
      "img id in: 25542\n",
      "img id out: 25542\n",
      "img id in: 25543\n",
      "img id out: 25543\n",
      "img id in: 25544\n",
      "img id out: 25544\n",
      "img id in: 25545\n",
      "img id out: 25545\n",
      "img id in: 25546\n",
      "img id out: 25546\n",
      "img id in: 25547\n",
      "img id out: 25547\n",
      "img id in: 25548\n",
      "img id out: 25548\n",
      "img id in: 25549\n",
      "img id out: 25549\n",
      "img id in: 25550\n",
      "img id out: 25550\n",
      "img id in: 25551\n",
      "img id out: 25551\n",
      "img id in: 25552\n",
      "img id out: 25552\n",
      "img id in: 25553\n",
      "img id out: 25553\n",
      "img id in: 25554\n",
      "img id out: 25554\n",
      "img id in: 25555\n",
      "img id out: 25555\n",
      "img id in: 25556\n",
      "img id out: 25556\n",
      "img id in: 25557\n",
      "img id out: 25557\n",
      "img id in: 25558\n",
      "img id out: 25558\n",
      "img id in: 25559\n",
      "img id out: 25559\n",
      "img id in: 25560\n",
      "img id out: 25560\n",
      "img id in: 25561\n",
      "img id out: 25561\n",
      "img id in: 25562\n",
      "img id out: 25562\n",
      "img id in: 25563\n",
      "img id out: 25563\n",
      "img id in: 25564\n",
      "img id out: 25564\n",
      "img id in: 25565\n",
      "img id out: 25565\n",
      "img id in: 25566\n",
      "img id out: 25566\n",
      "img id in: 25567\n",
      "img id out: 25567\n",
      "img id in: 25568\n",
      "img id out: 25568\n",
      "img id in: 25569\n",
      "img id out: 25569\n",
      "img id in: 25570\n",
      "img id out: 25570\n",
      "img id in: 25571\n",
      "img id out: 25571\n",
      "img id in: 25572\n",
      "img id out: 25572\n",
      "img id in: 25573\n",
      "img id out: 25573\n",
      "img id in: 25574\n",
      "img id out: 25574\n",
      "img id in: 25575\n",
      "img id out: 25575\n",
      "img id in: 25576\n",
      "img id out: 25576\n",
      "img id in: 25577\n",
      "img id out: 25577\n",
      "img id in: 25578\n",
      "img id out: 25578\n",
      "img id in: 25579\n",
      "img id out: 25579\n",
      "img id in: 25580\n",
      "img id out: 25580\n",
      "img id in: 25581\n",
      "img id out: 25581\n",
      "img id in: 25582\n",
      "img id out: 25582\n",
      "img id in: 25583\n",
      "img id out: 25583\n",
      "img id in: 25584\n",
      "img id out: 25584\n",
      "img id in: 25585\n",
      "img id out: 25585\n",
      "img id in: 25586\n",
      "img id out: 25586\n",
      "img id in: 25587\n",
      "img id out: 25587\n",
      "img id in: 25588\n",
      "img id out: 25588\n",
      "img id in: 25589\n",
      "img id out: 25589\n",
      "img id in: 25590\n",
      "img id out: 25590\n",
      "img id in: 25591\n",
      "img id out: 25591\n",
      "img id in: 25592\n",
      "img id out: 25592\n",
      "img id in: 25593\n",
      "img id out: 25593\n",
      "img id in: 25594\n",
      "img id out: 25594\n",
      "img id in: 25595\n",
      "img id out: 25595\n",
      "img id in: 25596\n",
      "img id out: 25596\n",
      "img id in: 25597\n",
      "img id out: 25597\n",
      "img id in: 25598\n",
      "img id out: 25598\n",
      "img id in: 25599\n",
      "img id out: 25599\n",
      "img id in: 25600\n",
      "img id out: 25600\n",
      "img id in: 25601\n",
      "img id out: 25601\n",
      "img id in: 25602\n",
      "img id out: 25602\n",
      "img id in: 25603\n",
      "img id out: 25603\n",
      "img id in: 25604\n",
      "img id out: 25604\n",
      "img id in: 25605\n",
      "img id out: 25605\n",
      "img id in: 25606\n",
      "img id out: 25606\n",
      "img id in: 25607\n",
      "img id out: 25607\n",
      "img id in: 25608\n",
      "img id out: 25608\n",
      "img id in: 25609\n",
      "img id out: 25609\n",
      "img id in: 25610\n",
      "img id out: 25610\n",
      "img id in: 25611\n",
      "img id out: 25611\n",
      "img id in: 25612\n",
      "img id out: 25612\n",
      "img id in: 25613\n",
      "img id out: 25613\n",
      "img id in: 25614\n",
      "img id out: 25614\n",
      "img id in: 25615\n",
      "img id out: 25615\n",
      "img id in: 25616\n",
      "img id out: 25616\n",
      "img id in: 25617\n",
      "img id out: 25617\n",
      "img id in: 25618\n",
      "img id out: 25618\n",
      "img id in: 25619\n",
      "img id out: 25619\n",
      "img id in: 25620\n",
      "img id out: 25620\n",
      "img id in: 25621\n",
      "img id out: 25621\n",
      "img id in: 25622\n",
      "img id out: 25622\n",
      "img id in: 25623\n",
      "img id out: 25623\n",
      "img id in: 25624\n",
      "img id out: 25624\n",
      "img id in: 25625\n",
      "img id out: 25625\n",
      "img id in: 25626\n",
      "img id out: 25626\n",
      "img id in: 25627\n",
      "img id out: 25627\n",
      "img id in: 25628\n",
      "img id out: 25628\n",
      "img id in: 25629\n",
      "img id out: 25629\n",
      "img id in: 25630\n",
      "img id out: 25630\n",
      "img id in: 25631\n",
      "img id out: 25631\n",
      "img id in: 25632\n",
      "img id out: 25632\n",
      "img id in: 25633\n",
      "img id out: 25633\n",
      "img id in: 25634\n",
      "img id out: 25634\n",
      "img id in: 25635\n",
      "img id out: 25635\n",
      "img id in: 25636\n",
      "img id out: 25636\n",
      "img id in: 25637\n",
      "img id out: 25637\n",
      "img id in: 25638\n",
      "img id out: 25638\n",
      "img id in: 25639\n",
      "img id out: 25639\n",
      "img id in: 25640\n",
      "img id out: 25640\n",
      "img id in: 25641\n",
      "img id out: 25641\n",
      "img id in: 25642\n",
      "img id out: 25642\n",
      "img id in: 25643\n",
      "img id out: 25643\n",
      "img id in: 25644\n",
      "img id out: 25644\n",
      "img id in: 25645\n",
      "img id out: 25645\n",
      "img id in: 25646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 25646\n",
      "img id in: 25647\n",
      "img id out: 25647\n",
      "img id in: 25648\n",
      "img id out: 25648\n",
      "img id in: 25649\n",
      "img id out: 25649\n",
      "img id in: 25650\n",
      "img id out: 25650\n",
      "img id in: 25651\n",
      "img id out: 25651\n",
      "img id in: 25652\n",
      "img id out: 25652\n",
      "img id in: 25653\n",
      "img id out: 25653\n",
      "img id in: 25654\n",
      "img id out: 25654\n",
      "img id in: 25655\n",
      "img id out: 25655\n",
      "img id in: 25656\n",
      "img id out: 25656\n",
      "img id in: 25657\n",
      "img id out: 25657\n",
      "img id in: 25658\n",
      "img id out: 25658\n",
      "img id in: 25659\n",
      "img id out: 25659\n",
      "img id in: 25660\n",
      "img id out: 25660\n",
      "img id in: 25661\n",
      "img id out: 25661\n",
      "img id in: 25662\n",
      "img id out: 25662\n",
      "img id in: 25663\n",
      "img id out: 25663\n",
      "img id in: 25664\n",
      "img id out: 25664\n",
      "img id in: 25665\n",
      "img id out: 25665\n",
      "img id in: 25666\n",
      "img id out: 25666\n",
      "img id in: 25667\n",
      "img id out: 25667\n",
      "img id in: 25668\n",
      "img id out: 25668\n",
      "img id in: 25669\n",
      "img id out: 25669\n",
      "img id in: 25670\n",
      "img id out: 25670\n",
      "img id in: 25671\n",
      "img id out: 25671\n",
      "img id in: 25672\n",
      "img id out: 25672\n",
      "img id in: 25673\n",
      "img id out: 25673\n",
      "img id in: 25674\n",
      "img id out: 25674\n",
      "img id in: 25675\n",
      "img id out: 25675\n",
      "img id in: 25676\n",
      "img id out: 25676\n",
      "img id in: 25677\n",
      "img id out: 25677\n",
      "img id in: 25678\n",
      "img id out: 25678\n",
      "img id in: 25679\n",
      "img id out: 25679\n",
      "img id in: 25680\n",
      "img id out: 25680\n",
      "img id in: 25681\n",
      "img id out: 25681\n",
      "img id in: 25682\n",
      "img id out: 25682\n",
      "img id in: 25683\n",
      "img id out: 25683\n",
      "img id in: 25684\n",
      "img id out: 25684\n",
      "img id in: 25685\n",
      "img id out: 25685\n",
      "img id in: 25686\n",
      "img id out: 25686\n",
      "img id in: 25687\n",
      "img id out: 25687\n",
      "img id in: 25688\n",
      "img id out: 25688\n",
      "img id in: 25689\n",
      "img id out: 25689\n",
      "img id in: 25690\n",
      "img id out: 25690\n",
      "img id in: 25691\n",
      "img id out: 25691\n",
      "img id in: 25692\n",
      "img id out: 25692\n",
      "img id in: 25693\n",
      "img id out: 25693\n",
      "img id in: 25694\n",
      "img id out: 25694\n",
      "img id in: 25695\n",
      "img id out: 25695\n",
      "img id in: 25696\n",
      "img id out: 25696\n",
      "img id in: 25697\n",
      "img id out: 25697\n",
      "img id in: 25698\n",
      "img id out: 25698\n",
      "img id in: 25699\n",
      "img id out: 25699\n",
      "img id in: 25700\n",
      "img id out: 25700\n",
      "img id in: 25701\n",
      "img id out: 25701\n",
      "img id in: 25702\n",
      "img id out: 25702\n",
      "img id in: 25703\n",
      "img id out: 25703\n",
      "img id in: 25704\n",
      "img id out: 25704\n",
      "img id in: 25705\n",
      "img id out: 25705\n",
      "img id in: 25706\n",
      "img id out: 25706\n",
      "img id in: 25707\n",
      "img id out: 25707\n",
      "img id in: 25708\n",
      "img id out: 25708\n",
      "img id in: 25709\n",
      "img id out: 25709\n",
      "img id in: 25710\n",
      "img id out: 25710\n",
      "img id in: 25711\n",
      "img id out: 25711\n",
      "img id in: 25712\n",
      "img id out: 25712\n",
      "img id in: 25713\n",
      "img id out: 25713\n",
      "img id in: 25714\n",
      "img id out: 25714\n",
      "img id in: 25715\n",
      "img id out: 25715\n",
      "img id in: 25716\n",
      "img id out: 25716\n",
      "img id in: 25717\n",
      "img id out: 25717\n",
      "img id in: 25718\n",
      "img id out: 25718\n",
      "img id in: 25719\n",
      "img id out: 25719\n",
      "img id in: 25720\n",
      "img id out: 25720\n",
      "img id in: 25721\n",
      "img id out: 25721\n",
      "img id in: 25722\n",
      "img id out: 25722\n",
      "img id in: 25723\n",
      "img id out: 25723\n",
      "img id in: 25724\n",
      "img id out: 25724\n",
      "img id in: 25725\n",
      "img id out: 25725\n",
      "img id in: 25726\n",
      "img id out: 25726\n",
      "img id in: 25727\n",
      "img id out: 25727\n",
      "img id in: 25728\n",
      "img id out: 25728\n",
      "img id in: 25729\n",
      "img id out: 25729\n",
      "img id in: 25730\n",
      "img id out: 25730\n",
      "img id in: 25731\n",
      "img id out: 25731\n",
      "img id in: 25732\n",
      "img id out: 25732\n",
      "img id in: 25733\n",
      "img id out: 25733\n",
      "img id in: 25734\n",
      "img id out: 25734\n",
      "img id in: 25735\n",
      "img id out: 25735\n",
      "img id in: 25736\n",
      "img id out: 25736\n",
      "img id in: 25737\n",
      "img id out: 25737\n",
      "img id in: 25738\n",
      "img id out: 25738\n",
      "img id in: 25739\n",
      "img id out: 25739\n",
      "img id in: 25740\n",
      "img id out: 25740\n",
      "img id in: 25741\n",
      "img id out: 25741\n",
      "img id in: 25742\n",
      "img id out: 25742\n",
      "img id in: 25743\n",
      "img id out: 25743\n",
      "img id in: 25744\n",
      "img id out: 25744\n",
      "img id in: 25745\n",
      "img id out: 25745\n",
      "img id in: 25746\n",
      "img id out: 25746\n",
      "img id in: 25747\n",
      "img id out: 25747\n",
      "img id in: 25748\n",
      "img id out: 25748\n",
      "img id in: 25749\n",
      "img id out: 25749\n",
      "img id in: 25750\n",
      "img id out: 25750\n",
      "img id in: 25751\n",
      "img id out: 25751\n",
      "img id in: 25752\n",
      "img id out: 25752\n",
      "img id in: 25753\n",
      "img id out: 25753\n",
      "img id in: 25754\n",
      "img id out: 25754\n",
      "img id in: 25755\n",
      "img id out: 25755\n",
      "img id in: 25756\n",
      "img id out: 25756\n",
      "img id in: 25757\n",
      "img id out: 25757\n",
      "img id in: 25758\n",
      "img id out: 25758\n",
      "img id in: 25759\n",
      "img id out: 25759\n",
      "img id in: 25760\n",
      "img id out: 25760\n",
      "img id in: 25761\n",
      "img id out: 25761\n",
      "img id in: 25762\n",
      "img id out: 25762\n",
      "img id in: 25763\n",
      "img id out: 25763\n",
      "img id in: 25764\n",
      "img id out: 25764\n",
      "img id in: 25765\n",
      "img id out: 25765\n",
      "img id in: 25766\n",
      "img id out: 25766\n",
      "img id in: 25767\n",
      "img id out: 25767\n",
      "img id in: 25768\n",
      "img id out: 25768\n",
      "img id in: 25769\n",
      "img id out: 25769\n",
      "img id in: 25770\n",
      "img id out: 25770\n",
      "img id in: 25771\n",
      "img id out: 25771\n",
      "img id in: 25772\n",
      "img id out: 25772\n",
      "img id in: 25773\n",
      "img id out: 25773\n",
      "img id in: 25774\n",
      "img id out: 25774\n",
      "img id in: 25775\n",
      "img id out: 25775\n",
      "img id in: 25776\n",
      "img id out: 25776\n",
      "img id in: 25777\n",
      "img id out: 25777\n",
      "img id in: 25778\n",
      "img id out: 25778\n",
      "img id in: 25779\n",
      "img id out: 25779\n",
      "img id in: 25780\n",
      "img id out: 25780\n",
      "img id in: 25781\n",
      "img id out: 25781\n",
      "img id in: 25782\n",
      "img id out: 25782\n",
      "img id in: 25783\n",
      "img id out: 25783\n",
      "img id in: 25784\n",
      "img id out: 25784\n",
      "img id in: 25785\n",
      "img id out: 25785\n",
      "img id in: 25786\n",
      "img id out: 25786\n",
      "img id in: 25787\n",
      "img id out: 25787\n",
      "img id in: 25788\n",
      "img id out: 25788\n",
      "img id in: 25789\n",
      "img id out: 25789\n",
      "img id in: 25790\n",
      "img id out: 25790\n",
      "img id in: 25791\n",
      "img id out: 25791\n",
      "img id in: 25792\n",
      "img id out: 25792\n",
      "img id in: 25793\n",
      "img id out: 25793\n",
      "img id in: 25794\n",
      "img id out: 25794\n",
      "img id in: 25795\n",
      "img id out: 25795\n",
      "img id in: 25796\n",
      "img id out: 25796\n",
      "img id in: 25797\n",
      "img id out: 25797\n",
      "img id in: 25798\n",
      "img id out: 25798\n",
      "img id in: 25799\n",
      "img id out: 25799\n",
      "img id in: 25800\n",
      "img id out: 25800\n",
      "img id in: 25801\n",
      "img id out: 25801\n",
      "img id in: 25802\n",
      "img id out: 25802\n",
      "img id in: 25803\n",
      "img id out: 25803\n",
      "img id in: 25804\n",
      "img id out: 25804\n",
      "img id in: 25805\n",
      "img id out: 25805\n",
      "img id in: 25806\n",
      "img id out: 25806\n",
      "img id in: 25807\n",
      "img id out: 25807\n",
      "img id in: 25808\n",
      "img id out: 25808\n",
      "img id in: 25809\n",
      "img id out: 25809\n",
      "img id in: 25810\n",
      "img id out: 25810\n",
      "img id in: 25811\n",
      "img id out: 25811\n",
      "img id in: 25812\n",
      "img id out: 25812\n",
      "img id in: 25813\n",
      "img id out: 25813\n",
      "img id in: 25814\n",
      "img id out: 25814\n",
      "img id in: 25815\n",
      "img id out: 25815\n",
      "img id in: 25816\n",
      "img id out: 25816\n",
      "img id in: 25817\n",
      "img id out: 25817\n",
      "img id in: 25818\n",
      "img id out: 25818\n",
      "img id in: 25819\n",
      "img id out: 25819\n",
      "img id in: 25820\n",
      "img id out: 25820\n",
      "img id in: 25821\n",
      "img id out: 25821\n",
      "img id in: 25822\n",
      "img id out: 25822\n",
      "img id in: 25823\n",
      "img id out: 25823\n",
      "img id in: 25824\n",
      "img id out: 25824\n",
      "img id in: 25825\n",
      "img id out: 25825\n",
      "img id in: 25826\n",
      "img id out: 25826\n",
      "img id in: 25827\n",
      "img id out: 25827\n",
      "img id in: 25828\n",
      "img id out: 25828\n",
      "img id in: 25829\n",
      "img id out: 25829\n",
      "img id in: 25830\n",
      "img id out: 25830\n",
      "img id in: 25831\n",
      "img id out: 25831\n",
      "img id in: 25832\n",
      "img id out: 25832\n",
      "img id in: 25833\n",
      "img id out: 25833\n",
      "img id in: 25834\n",
      "img id out: 25834\n",
      "img id in: 25835\n",
      "img id out: 25835\n",
      "img id in: 25836\n",
      "img id out: 25836\n",
      "img id in: 25837\n",
      "img id out: 25837\n",
      "img id in: 25838\n",
      "img id out: 25838\n",
      "img id in: 25839\n",
      "img id out: 25839\n",
      "img id in: 25840\n",
      "img id out: 25840\n",
      "img id in: 25841\n",
      "img id out: 25841\n",
      "img id in: 25842\n",
      "img id out: 25842\n",
      "img id in: 25843\n",
      "img id out: 25843\n",
      "img id in: 25844\n",
      "img id out: 25844\n",
      "img id in: 25845\n",
      "img id out: 25845\n",
      "img id in: 25846\n",
      "img id out: 25846\n",
      "img id in: 25847\n",
      "img id out: 25847\n",
      "img id in: 25848\n",
      "img id out: 25848\n",
      "img id in: 25849\n",
      "img id out: 25849\n",
      "img id in: 25850\n",
      "img id out: 25850\n",
      "img id in: 25851\n",
      "img id out: 25851\n",
      "img id in: 25852\n",
      "img id out: 25852\n",
      "img id in: 25853\n",
      "img id out: 25853\n",
      "img id in: 25854\n",
      "img id out: 25854\n",
      "img id in: 25855\n",
      "img id out: 25855\n",
      "img id in: 25856\n",
      "img id out: 25856\n",
      "img id in: 25857\n",
      "img id out: 25857\n",
      "img id in: 25858\n",
      "img id out: 25858\n",
      "img id in: 25859\n",
      "img id out: 25859\n",
      "img id in: 25860\n",
      "img id out: 25860\n",
      "img id in: 25861\n",
      "img id out: 25861\n",
      "img id in: 25862\n",
      "img id out: 25862\n",
      "img id in: 25863\n",
      "img id out: 25863\n",
      "img id in: 25864\n",
      "img id out: 25864\n",
      "img id in: 25865\n",
      "img id out: 25865\n",
      "img id in: 25866\n",
      "img id out: 25866\n",
      "img id in: 25867\n",
      "img id out: 25867\n",
      "img id in: 25868\n",
      "img id out: 25868\n",
      "img id in: 25869\n",
      "img id out: 25869\n",
      "img id in: 25870\n",
      "img id out: 25870\n",
      "img id in: 25871\n",
      "img id out: 25871\n",
      "img id in: 25872\n",
      "img id out: 25872\n",
      "img id in: 25873\n",
      "img id out: 25873\n",
      "img id in: 25874\n",
      "img id out: 25874\n",
      "img id in: 25875\n",
      "img id out: 25875\n",
      "img id in: 25876\n",
      "img id out: 25876\n",
      "img id in: 25877\n",
      "img id out: 25877\n",
      "img id in: 25878\n",
      "img id out: 25878\n",
      "img id in: 25879\n",
      "img id out: 25879\n",
      "img id in: 25880\n",
      "img id out: 25880\n",
      "img id in: 25881\n",
      "img id out: 25881\n",
      "img id in: 25882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 25882\n",
      "img id in: 25883\n",
      "img id out: 25883\n",
      "img id in: 25884\n",
      "img id out: 25884\n",
      "img id in: 25885\n",
      "img id out: 25885\n",
      "img id in: 25886\n",
      "img id out: 25886\n",
      "img id in: 25887\n",
      "img id out: 25887\n",
      "img id in: 25888\n",
      "img id out: 25888\n",
      "img id in: 25889\n",
      "img id out: 25889\n",
      "img id in: 25890\n",
      "img id out: 25890\n",
      "img id in: 25891\n",
      "img id out: 25891\n",
      "img id in: 25892\n",
      "img id out: 25892\n",
      "img id in: 25893\n",
      "img id out: 25893\n",
      "img id in: 25894\n",
      "img id out: 25894\n",
      "img id in: 25895\n",
      "img id out: 25895\n",
      "img id in: 25896\n",
      "img id out: 25896\n",
      "img id in: 25897\n",
      "img id out: 25897\n",
      "img id in: 25898\n",
      "img id out: 25898\n",
      "img id in: 25899\n",
      "img id out: 25899\n",
      "img id in: 25900\n",
      "img id out: 25900\n",
      "img id in: 25901\n",
      "img id out: 25901\n",
      "img id in: 25902\n",
      "img id out: 25902\n",
      "img id in: 25903\n",
      "img id out: 25903\n",
      "img id in: 25904\n",
      "img id out: 25904\n",
      "img id in: 25905\n",
      "img id out: 25905\n",
      "img id in: 25906\n",
      "img id out: 25906\n",
      "img id in: 25907\n",
      "img id out: 25907\n",
      "img id in: 25908\n",
      "img id out: 25908\n",
      "img id in: 25909\n",
      "img id out: 25909\n",
      "img id in: 25910\n",
      "img id out: 25910\n",
      "img id in: 25911\n",
      "img id out: 25911\n",
      "img id in: 25912\n",
      "img id out: 25912\n",
      "img id in: 25913\n",
      "img id out: 25913\n",
      "img id in: 25914\n",
      "img id out: 25914\n",
      "img id in: 25915\n",
      "img id out: 25915\n",
      "img id in: 25916\n",
      "img id out: 25916\n",
      "img id in: 25917\n",
      "img id out: 25917\n",
      "img id in: 25918\n",
      "img id out: 25918\n",
      "img id in: 25919\n",
      "img id out: 25919\n",
      "img id in: 25920\n",
      "img id out: 25920\n",
      "img id in: 25921\n",
      "img id out: 25921\n",
      "img id in: 25922\n",
      "img id out: 25922\n",
      "img id in: 25923\n",
      "img id out: 25923\n",
      "img id in: 25924\n",
      "img id out: 25924\n",
      "img id in: 25925\n",
      "img id out: 25925\n",
      "img id in: 25926\n",
      "img id out: 25926\n",
      "img id in: 25927\n",
      "img id out: 25927\n",
      "img id in: 25928\n",
      "img id out: 25928\n",
      "img id in: 25929\n",
      "img id out: 25929\n",
      "img id in: 25930\n",
      "img id out: 25930\n",
      "img id in: 25931\n",
      "img id out: 25931\n",
      "img id in: 25932\n",
      "img id out: 25932\n",
      "img id in: 25933\n",
      "img id out: 25933\n",
      "img id in: 25934\n",
      "img id out: 25934\n",
      "img id in: 25935\n",
      "img id out: 25935\n",
      "img id in: 25936\n",
      "img id out: 25936\n",
      "img id in: 25937\n",
      "img id out: 25937\n",
      "img id in: 25938\n",
      "img id out: 25938\n",
      "img id in: 25939\n",
      "img id out: 25939\n",
      "img id in: 25940\n",
      "img id out: 25940\n",
      "img id in: 25941\n",
      "img id out: 25941\n",
      "img id in: 25942\n",
      "img id out: 25942\n",
      "img id in: 25943\n",
      "img id out: 25943\n",
      "img id in: 25944\n",
      "img id out: 25944\n",
      "img id in: 25945\n",
      "img id out: 25945\n",
      "img id in: 25946\n",
      "img id out: 25946\n",
      "img id in: 25947\n",
      "img id out: 25947\n",
      "img id in: 25948\n",
      "img id out: 25948\n",
      "img id in: 25949\n",
      "img id out: 25949\n",
      "img id in: 25950\n",
      "img id out: 25950\n",
      "img id in: 25951\n",
      "img id out: 25951\n",
      "img id in: 25952\n",
      "img id out: 25952\n",
      "img id in: 25953\n",
      "img id out: 25953\n",
      "img id in: 25954\n",
      "img id out: 25954\n",
      "img id in: 25955\n",
      "img id out: 25955\n",
      "img id in: 25956\n",
      "img id out: 25956\n",
      "img id in: 25957\n",
      "img id out: 25957\n",
      "img id in: 25958\n",
      "img id out: 25958\n",
      "img id in: 25959\n",
      "img id out: 25959\n",
      "img id in: 25960\n",
      "img id out: 25960\n",
      "img id in: 25961\n",
      "img id out: 25961\n",
      "img id in: 25962\n",
      "img id out: 25962\n",
      "img id in: 25963\n",
      "img id out: 25963\n",
      "img id in: 25964\n",
      "img id out: 25964\n",
      "img id in: 25965\n",
      "img id out: 25965\n",
      "img id in: 25966\n",
      "img id out: 25966\n",
      "img id in: 25967\n",
      "img id out: 25967\n",
      "img id in: 25968\n",
      "img id out: 25968\n",
      "img id in: 25969\n",
      "img id out: 25969\n",
      "img id in: 25970\n",
      "img id out: 25970\n",
      "img id in: 25971\n",
      "img id out: 25971\n",
      "img id in: 25972\n",
      "img id out: 25972\n",
      "img id in: 25973\n",
      "img id out: 25973\n",
      "img id in: 25974\n",
      "img id out: 25974\n",
      "img id in: 25975\n",
      "img id out: 25975\n",
      "img id in: 25976\n",
      "img id out: 25976\n",
      "img id in: 25977\n",
      "img id out: 25977\n",
      "img id in: 25978\n",
      "img id out: 25978\n",
      "img id in: 25979\n",
      "img id out: 25979\n",
      "img id in: 25980\n",
      "img id out: 25980\n",
      "img id in: 25981\n",
      "img id out: 25981\n",
      "img id in: 25982\n",
      "img id out: 25982\n",
      "img id in: 25983\n",
      "img id out: 25983\n",
      "img id in: 25984\n",
      "img id out: 25984\n",
      "img id in: 25985\n",
      "img id out: 25985\n",
      "img id in: 25986\n",
      "img id out: 25986\n",
      "img id in: 25987\n",
      "img id out: 25987\n",
      "img id in: 25988\n",
      "img id out: 25988\n",
      "img id in: 25989\n",
      "img id out: 25989\n",
      "img id in: 25990\n",
      "img id out: 25990\n",
      "img id in: 25991\n",
      "img id out: 25991\n",
      "img id in: 25992\n",
      "img id out: 25992\n",
      "img id in: 25993\n",
      "img id out: 25993\n",
      "img id in: 25994\n",
      "img id out: 25994\n",
      "img id in: 25995\n",
      "img id out: 25995\n",
      "img id in: 25996\n",
      "img id out: 25996\n",
      "img id in: 25997\n",
      "img id out: 25997\n",
      "img id in: 25998\n",
      "img id out: 25998\n",
      "img id in: 25999\n",
      "img id out: 25999\n",
      "img id in: 26000\n",
      "img id out: 26000\n",
      "img id in: 26001\n",
      "img id out: 26001\n",
      "img id in: 26002\n",
      "img id out: 26002\n",
      "img id in: 26003\n",
      "img id out: 26003\n",
      "img id in: 26004\n",
      "img id out: 26004\n",
      "img id in: 26005\n",
      "img id out: 26005\n",
      "img id in: 26006\n",
      "img id out: 26006\n",
      "img id in: 26007\n",
      "img id out: 26007\n",
      "img id in: 26008\n",
      "img id out: 26008\n",
      "img id in: 26009\n",
      "img id out: 26009\n",
      "img id in: 26010\n",
      "img id out: 26010\n",
      "img id in: 26011\n",
      "img id out: 26011\n",
      "img id in: 26012\n",
      "img id out: 26012\n",
      "img id in: 26013\n",
      "img id out: 26013\n",
      "img id in: 26014\n",
      "img id out: 26014\n",
      "img id in: 26015\n",
      "img id out: 26015\n",
      "img id in: 26016\n",
      "img id out: 26016\n",
      "img id in: 26017\n",
      "img id out: 26017\n",
      "img id in: 26018\n",
      "img id out: 26018\n",
      "img id in: 26019\n",
      "img id out: 26019\n",
      "img id in: 26020\n",
      "img id out: 26020\n",
      "img id in: 26021\n",
      "img id out: 26021\n",
      "img id in: 26022\n",
      "img id out: 26022\n",
      "img id in: 26023\n",
      "img id out: 26023\n",
      "img id in: 26024\n",
      "img id out: 26024\n",
      "img id in: 26025\n",
      "img id out: 26025\n",
      "img id in: 26026\n",
      "img id out: 26026\n",
      "img id in: 26027\n",
      "img id out: 26027\n",
      "img id in: 26028\n",
      "img id out: 26028\n",
      "img id in: 26029\n",
      "img id out: 26029\n",
      "img id in: 26030\n",
      "img id out: 26030\n",
      "img id in: 26031\n",
      "img id out: 26031\n",
      "img id in: 26032\n",
      "img id out: 26032\n",
      "img id in: 26033\n",
      "img id out: 26033\n",
      "img id in: 26034\n",
      "img id out: 26034\n",
      "img id in: 26035\n",
      "img id out: 26035\n",
      "img id in: 26036\n",
      "img id out: 26036\n",
      "img id in: 26037\n",
      "img id out: 26037\n",
      "img id in: 26038\n",
      "img id out: 26038\n",
      "img id in: 26039\n",
      "img id out: 26039\n",
      "img id in: 26040\n",
      "img id out: 26040\n",
      "img id in: 26041\n",
      "img id out: 26041\n",
      "img id in: 26042\n",
      "img id out: 26042\n",
      "img id in: 26043\n",
      "img id out: 26043\n",
      "img id in: 26044\n",
      "img id out: 26044\n",
      "img id in: 26045\n",
      "img id out: 26045\n",
      "img id in: 26046\n",
      "img id out: 26046\n",
      "img id in: 26047\n",
      "img id out: 26047\n",
      "img id in: 26048\n",
      "img id out: 26048\n",
      "img id in: 26049\n",
      "img id out: 26049\n",
      "img id in: 26050\n",
      "img id out: 26050\n",
      "img id in: 26051\n",
      "img id out: 26051\n",
      "img id in: 26052\n",
      "img id out: 26052\n",
      "img id in: 26053\n",
      "img id out: 26053\n",
      "img id in: 26054\n",
      "img id out: 26054\n",
      "img id in: 26055\n",
      "img id out: 26055\n",
      "img id in: 26056\n",
      "img id out: 26056\n",
      "img id in: 26057\n",
      "img id out: 26057\n",
      "img id in: 26058\n",
      "img id out: 26058\n",
      "img id in: 26059\n",
      "img id out: 26059\n",
      "img id in: 26060\n",
      "img id out: 26060\n",
      "img id in: 26061\n",
      "img id out: 26061\n",
      "img id in: 26062\n",
      "img id out: 26062\n",
      "img id in: 26063\n",
      "img id out: 26063\n",
      "img id in: 26064\n",
      "img id out: 26064\n",
      "img id in: 26065\n",
      "img id out: 26065\n",
      "img id in: 26066\n",
      "img id out: 26066\n",
      "img id in: 26067\n",
      "img id out: 26067\n",
      "img id in: 26068\n",
      "img id out: 26068\n",
      "img id in: 26069\n",
      "img id out: 26069\n",
      "img id in: 26070\n",
      "img id out: 26070\n",
      "img id in: 26071\n",
      "img id out: 26071\n",
      "img id in: 26072\n",
      "img id out: 26072\n",
      "img id in: 26073\n",
      "img id out: 26073\n",
      "img id in: 26074\n",
      "img id out: 26074\n",
      "img id in: 26075\n",
      "img id out: 26075\n",
      "img id in: 26076\n",
      "img id out: 26076\n",
      "img id in: 26077\n",
      "img id out: 26077\n",
      "img id in: 26078\n",
      "img id out: 26078\n",
      "img id in: 26079\n",
      "img id out: 26079\n",
      "img id in: 26080\n",
      "img id out: 26080\n",
      "img id in: 26081\n",
      "img id out: 26081\n",
      "img id in: 26082\n",
      "img id out: 26082\n",
      "img id in: 26083\n",
      "img id out: 26083\n",
      "img id in: 26084\n",
      "img id out: 26084\n",
      "img id in: 26085\n",
      "img id out: 26085\n",
      "img id in: 26086\n",
      "img id out: 26086\n",
      "img id in: 26087\n",
      "img id out: 26087\n",
      "img id in: 26088\n",
      "img id out: 26088\n",
      "img id in: 26089\n",
      "img id out: 26089\n",
      "img id in: 26090\n",
      "img id out: 26090\n",
      "img id in: 26091\n",
      "img id out: 26091\n",
      "img id in: 26092\n",
      "img id out: 26092\n",
      "img id in: 26093\n",
      "img id out: 26093\n",
      "img id in: 26094\n",
      "img id out: 26094\n",
      "img id in: 26095\n",
      "img id out: 26095\n",
      "img id in: 26096\n",
      "img id out: 26096\n",
      "img id in: 26097\n",
      "img id out: 26097\n",
      "img id in: 26098\n",
      "img id out: 26098\n",
      "img id in: 26099\n",
      "img id out: 26099\n",
      "img id in: 26100\n",
      "img id out: 26100\n",
      "img id in: 26101\n",
      "img id out: 26101\n",
      "img id in: 26102\n",
      "img id out: 26102\n",
      "img id in: 26103\n",
      "img id out: 26103\n",
      "img id in: 26104\n",
      "img id out: 26104\n",
      "img id in: 26105\n",
      "img id out: 26105\n",
      "img id in: 26106\n",
      "img id out: 26106\n",
      "img id in: 26107\n",
      "img id out: 26107\n",
      "img id in: 26108\n",
      "img id out: 26108\n",
      "img id in: 26109\n",
      "img id out: 26109\n",
      "img id in: 26110\n",
      "img id out: 26110\n",
      "img id in: 26111\n",
      "img id out: 26111\n",
      "img id in: 26112\n",
      "img id out: 26112\n",
      "img id in: 26113\n",
      "img id out: 26113\n",
      "img id in: 26114\n",
      "img id out: 26114\n",
      "img id in: 26115\n",
      "img id out: 26115\n",
      "img id in: 26116\n",
      "img id out: 26116\n",
      "img id in: 26117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 26117\n",
      "img id in: 26118\n",
      "img id out: 26118\n",
      "img id in: 26119\n",
      "img id out: 26119\n",
      "img id in: 26120\n",
      "img id out: 26120\n",
      "img id in: 26121\n",
      "img id out: 26121\n",
      "img id in: 26122\n",
      "img id out: 26122\n",
      "img id in: 26123\n",
      "img id out: 26123\n",
      "img id in: 26124\n",
      "img id out: 26124\n",
      "img id in: 26125\n",
      "img id out: 26125\n",
      "img id in: 26126\n",
      "img id out: 26126\n",
      "img id in: 26127\n",
      "img id out: 26127\n",
      "img id in: 26128\n",
      "img id out: 26128\n",
      "img id in: 26129\n",
      "img id out: 26129\n",
      "img id in: 26130\n",
      "img id out: 26130\n",
      "img id in: 26131\n",
      "img id out: 26131\n",
      "img id in: 26132\n",
      "img id out: 26132\n",
      "img id in: 26133\n",
      "img id out: 26133\n",
      "img id in: 26134\n",
      "img id out: 26134\n",
      "img id in: 26135\n",
      "img id out: 26135\n",
      "img id in: 26136\n",
      "img id out: 26136\n",
      "img id in: 26137\n",
      "img id out: 26137\n",
      "img id in: 26138\n",
      "img id out: 26138\n",
      "img id in: 26139\n",
      "img id out: 26139\n",
      "img id in: 26140\n",
      "img id out: 26140\n",
      "img id in: 26141\n",
      "img id out: 26141\n",
      "img id in: 26142\n",
      "img id out: 26142\n",
      "img id in: 26143\n",
      "img id out: 26143\n",
      "img id in: 26144\n",
      "img id out: 26144\n",
      "img id in: 26145\n",
      "img id out: 26145\n",
      "img id in: 26146\n",
      "img id out: 26146\n",
      "img id in: 26147\n",
      "img id out: 26147\n",
      "img id in: 26148\n",
      "img id out: 26148\n",
      "img id in: 26149\n",
      "img id out: 26149\n",
      "img id in: 26150\n",
      "img id out: 26150\n",
      "img id in: 26151\n",
      "img id out: 26151\n",
      "img id in: 26152\n",
      "img id out: 26152\n",
      "img id in: 26153\n",
      "img id out: 26153\n",
      "img id in: 26154\n",
      "img id out: 26154\n",
      "img id in: 26155\n",
      "img id out: 26155\n",
      "img id in: 26156\n",
      "img id out: 26156\n",
      "img id in: 26157\n",
      "img id out: 26157\n",
      "img id in: 26158\n",
      "img id out: 26158\n",
      "img id in: 26159\n",
      "img id out: 26159\n",
      "img id in: 26160\n",
      "img id out: 26160\n",
      "img id in: 26161\n",
      "img id out: 26161\n",
      "img id in: 26162\n",
      "img id out: 26162\n",
      "img id in: 26163\n",
      "img id out: 26163\n",
      "img id in: 26164\n",
      "img id out: 26164\n",
      "img id in: 26165\n",
      "img id out: 26165\n",
      "img id in: 26166\n",
      "img id out: 26166\n",
      "img id in: 26167\n",
      "img id out: 26167\n",
      "img id in: 26168\n",
      "img id out: 26168\n",
      "img id in: 26169\n",
      "img id out: 26169\n",
      "img id in: 26170\n",
      "img id out: 26170\n",
      "img id in: 26171\n",
      "img id out: 26171\n",
      "img id in: 26172\n",
      "img id out: 26172\n",
      "img id in: 26173\n",
      "img id out: 26173\n",
      "img id in: 26174\n",
      "img id out: 26174\n",
      "img id in: 26175\n",
      "img id out: 26175\n",
      "img id in: 26176\n",
      "img id out: 26176\n",
      "img id in: 26177\n",
      "img id out: 26177\n",
      "img id in: 26178\n",
      "img id out: 26178\n",
      "img id in: 26179\n",
      "img id out: 26179\n",
      "img id in: 26180\n",
      "img id out: 26180\n",
      "img id in: 26181\n",
      "img id out: 26181\n",
      "img id in: 26182\n",
      "img id out: 26182\n",
      "img id in: 26183\n",
      "img id out: 26183\n",
      "img id in: 26184\n",
      "img id out: 26184\n",
      "img id in: 26185\n",
      "img id out: 26185\n",
      "img id in: 26186\n",
      "img id out: 26186\n",
      "img id in: 26187\n",
      "img id out: 26187\n",
      "img id in: 26188\n",
      "img id out: 26188\n",
      "img id in: 26189\n",
      "img id out: 26189\n",
      "img id in: 26190\n",
      "img id out: 26190\n",
      "img id in: 26191\n",
      "img id out: 26191\n",
      "img id in: 26192\n",
      "img id out: 26192\n",
      "img id in: 26193\n",
      "img id out: 26193\n",
      "img id in: 26194\n",
      "img id out: 26194\n",
      "img id in: 26195\n",
      "img id out: 26195\n",
      "img id in: 26196\n",
      "img id out: 26196\n",
      "img id in: 26197\n",
      "img id out: 26197\n",
      "img id in: 26198\n",
      "img id out: 26198\n",
      "img id in: 26199\n",
      "img id out: 26199\n",
      "img id in: 26200\n",
      "img id out: 26200\n",
      "img id in: 26201\n",
      "img id out: 26201\n",
      "img id in: 26202\n",
      "img id out: 26202\n",
      "img id in: 26203\n",
      "img id out: 26203\n",
      "img id in: 26204\n",
      "img id out: 26204\n",
      "img id in: 26205\n",
      "img id out: 26205\n",
      "img id in: 26206\n",
      "img id out: 26206\n",
      "img id in: 26207\n",
      "img id out: 26207\n",
      "img id in: 26208\n",
      "img id out: 26208\n",
      "img id in: 26209\n",
      "img id out: 26209\n",
      "img id in: 26210\n",
      "img id out: 26210\n",
      "img id in: 26211\n",
      "img id out: 26211\n",
      "img id in: 26212\n",
      "img id out: 26212\n",
      "img id in: 26213\n",
      "img id out: 26213\n",
      "img id in: 26214\n",
      "img id out: 26214\n",
      "img id in: 26215\n",
      "img id out: 26215\n",
      "img id in: 26216\n",
      "img id out: 26216\n",
      "img id in: 26217\n",
      "img id out: 26217\n",
      "img id in: 26218\n",
      "img id out: 26218\n",
      "img id in: 26219\n",
      "img id out: 26219\n",
      "img id in: 26220\n",
      "img id out: 26220\n",
      "img id in: 26221\n",
      "img id out: 26221\n",
      "img id in: 26222\n",
      "img id out: 26222\n",
      "img id in: 26223\n",
      "img id out: 26223\n",
      "img id in: 26224\n",
      "img id out: 26224\n",
      "img id in: 26225\n",
      "img id out: 26225\n",
      "img id in: 26226\n",
      "img id out: 26226\n",
      "img id in: 26227\n",
      "img id out: 26227\n",
      "img id in: 26228\n",
      "img id out: 26228\n",
      "img id in: 26229\n",
      "img id out: 26229\n",
      "img id in: 26230\n",
      "img id out: 26230\n",
      "img id in: 26231\n",
      "img id out: 26231\n",
      "img id in: 26232\n",
      "img id out: 26232\n",
      "img id in: 26233\n",
      "img id out: 26233\n",
      "img id in: 26234\n",
      "img id out: 26234\n",
      "img id in: 26235\n",
      "img id out: 26235\n",
      "img id in: 26236\n",
      "img id out: 26236\n",
      "img id in: 26237\n",
      "img id out: 26237\n",
      "img id in: 26238\n",
      "img id out: 26238\n",
      "img id in: 26239\n",
      "img id out: 26239\n",
      "img id in: 26240\n",
      "img id out: 26240\n",
      "img id in: 26241\n",
      "img id out: 26241\n",
      "img id in: 26242\n",
      "img id out: 26242\n",
      "img id in: 26243\n",
      "img id out: 26243\n",
      "img id in: 26244\n",
      "img id out: 26244\n",
      "img id in: 26245\n",
      "img id out: 26245\n",
      "img id in: 26246\n",
      "img id out: 26246\n",
      "img id in: 26247\n",
      "img id out: 26247\n",
      "img id in: 26248\n",
      "img id out: 26248\n",
      "img id in: 26249\n",
      "img id out: 26249\n",
      "img id in: 26250\n",
      "img id out: 26250\n",
      "img id in: 26251\n",
      "img id out: 26251\n",
      "img id in: 26252\n",
      "img id out: 26252\n",
      "img id in: 26253\n",
      "img id out: 26253\n",
      "img id in: 26254\n",
      "img id out: 26254\n",
      "img id in: 26255\n",
      "img id out: 26255\n",
      "img id in: 26256\n",
      "img id out: 26256\n",
      "img id in: 26257\n",
      "img id out: 26257\n",
      "img id in: 26258\n",
      "img id out: 26258\n",
      "img id in: 26259\n",
      "img id out: 26259\n",
      "img id in: 26260\n",
      "img id out: 26260\n",
      "img id in: 26261\n",
      "img id out: 26261\n",
      "img id in: 26262\n",
      "img id out: 26262\n",
      "img id in: 26263\n",
      "img id out: 26263\n",
      "img id in: 26264\n",
      "img id out: 26264\n",
      "img id in: 26265\n",
      "img id out: 26265\n",
      "img id in: 26266\n",
      "img id out: 26266\n",
      "img id in: 26267\n",
      "img id out: 26267\n",
      "img id in: 26268\n",
      "img id out: 26268\n",
      "img id in: 26269\n",
      "img id out: 26269\n",
      "img id in: 26270\n",
      "img id out: 26270\n",
      "img id in: 26271\n",
      "img id out: 26271\n",
      "img id in: 26272\n",
      "img id out: 26272\n",
      "img id in: 26273\n",
      "img id out: 26273\n",
      "img id in: 26274\n",
      "img id out: 26274\n",
      "img id in: 26275\n",
      "img id out: 26275\n",
      "img id in: 26276\n",
      "img id out: 26276\n",
      "img id in: 26277\n",
      "img id out: 26277\n",
      "img id in: 26278\n",
      "img id out: 26278\n",
      "img id in: 26279\n",
      "img id out: 26279\n",
      "img id in: 26280\n",
      "img id out: 26280\n",
      "img id in: 26281\n",
      "img id out: 26281\n",
      "img id in: 26282\n",
      "img id out: 26282\n",
      "img id in: 26283\n",
      "img id out: 26283\n",
      "img id in: 26284\n",
      "img id out: 26284\n",
      "img id in: 26285\n",
      "img id out: 26285\n",
      "img id in: 26286\n",
      "img id out: 26286\n",
      "img id in: 26287\n",
      "img id out: 26287\n",
      "img id in: 26288\n",
      "img id out: 26288\n",
      "img id in: 26289\n",
      "img id out: 26289\n",
      "img id in: 26290\n",
      "img id out: 26290\n",
      "img id in: 26291\n",
      "img id out: 26291\n",
      "img id in: 26292\n",
      "img id out: 26292\n",
      "img id in: 26293\n",
      "img id out: 26293\n",
      "img id in: 26294\n",
      "img id out: 26294\n",
      "img id in: 26295\n",
      "img id out: 26295\n",
      "img id in: 26296\n",
      "img id out: 26296\n",
      "img id in: 26297\n",
      "img id out: 26297\n",
      "img id in: 26298\n",
      "img id out: 26298\n",
      "img id in: 26299\n",
      "img id out: 26299\n",
      "img id in: 26300\n",
      "img id out: 26300\n",
      "img id in: 26301\n",
      "img id out: 26301\n",
      "img id in: 26302\n",
      "img id out: 26302\n",
      "img id in: 26303\n",
      "img id out: 26303\n",
      "img id in: 26304\n",
      "img id out: 26304\n",
      "img id in: 26305\n",
      "img id out: 26305\n",
      "img id in: 26306\n",
      "img id out: 26306\n",
      "img id in: 26307\n",
      "img id out: 26307\n",
      "img id in: 26308\n",
      "img id out: 26308\n",
      "img id in: 26309\n",
      "img id out: 26309\n",
      "img id in: 26310\n",
      "img id out: 26310\n",
      "img id in: 26311\n",
      "img id out: 26311\n",
      "img id in: 26312\n",
      "img id out: 26312\n",
      "img id in: 26313\n",
      "img id out: 26313\n",
      "img id in: 26314\n",
      "img id out: 26314\n",
      "img id in: 26315\n",
      "img id out: 26315\n",
      "img id in: 26316\n",
      "img id out: 26316\n",
      "img id in: 26317\n",
      "img id out: 26317\n",
      "img id in: 26318\n",
      "img id out: 26318\n",
      "img id in: 26319\n",
      "img id out: 26319\n",
      "img id in: 26320\n",
      "img id out: 26320\n",
      "img id in: 26321\n",
      "img id out: 26321\n",
      "img id in: 26322\n",
      "img id out: 26322\n",
      "img id in: 26323\n",
      "img id out: 26323\n",
      "img id in: 26324\n",
      "img id out: 26324\n",
      "img id in: 26325\n",
      "img id out: 26325\n",
      "img id in: 26326\n",
      "img id out: 26326\n",
      "img id in: 26327\n",
      "img id out: 26327\n",
      "img id in: 26328\n",
      "img id out: 26328\n",
      "img id in: 26329\n",
      "img id out: 26329\n",
      "img id in: 26330\n",
      "img id out: 26330\n",
      "img id in: 26331\n",
      "img id out: 26331\n",
      "img id in: 26332\n",
      "img id out: 26332\n",
      "img id in: 26333\n",
      "img id out: 26333\n",
      "img id in: 26334\n",
      "img id out: 26334\n",
      "img id in: 26335\n",
      "img id out: 26335\n",
      "img id in: 26336\n",
      "img id out: 26336\n",
      "img id in: 26337\n",
      "img id out: 26337\n",
      "img id in: 26338\n",
      "img id out: 26338\n",
      "img id in: 26339\n",
      "img id out: 26339\n",
      "img id in: 26340\n",
      "img id out: 26340\n",
      "img id in: 26341\n",
      "img id out: 26341\n",
      "img id in: 26342\n",
      "img id out: 26342\n",
      "img id in: 26343\n",
      "img id out: 26343\n",
      "img id in: 26344\n",
      "img id out: 26344\n",
      "img id in: 26345\n",
      "img id out: 26345\n",
      "img id in: 26346\n",
      "img id out: 26346\n",
      "img id in: 26347\n",
      "img id out: 26347\n",
      "img id in: 26348\n",
      "img id out: 26348\n",
      "img id in: 26349\n",
      "img id out: 26349\n",
      "img id in: 26350\n",
      "img id out: 26350\n",
      "img id in: 26351\n",
      "img id out: 26351\n",
      "img id in: 26352\n",
      "img id out: 26352\n",
      "img id in: 26353\n",
      "img id out: 26353\n",
      "img id in: 26354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img id out: 26354\n",
      "img id in: 26355\n",
      "img id out: 26355\n",
      "img id in: 26356\n",
      "img id out: 26356\n",
      "img id in: 26357\n",
      "img id out: 26357\n",
      "img id in: 26358\n",
      "img id out: 26358\n",
      "img id in: 26359\n",
      "img id out: 26359\n",
      "img id in: 26360\n",
      "img id out: 26360\n",
      "img id in: 26361\n",
      "img id out: 26361\n",
      "img id in: 26362\n",
      "img id out: 26362\n",
      "img id in: 26363\n",
      "img id out: 26363\n",
      "img id in: 26364\n",
      "img id out: 26364\n",
      "img id in: 26365\n",
      "img id out: 26365\n",
      "img id in: 26366\n",
      "img id out: 26366\n",
      "img id in: 26367\n",
      "img id out: 26367\n",
      "img id in: 26368\n",
      "img id out: 26368\n",
      "img id in: 26369\n",
      "img id out: 26369\n",
      "img id in: 26370\n",
      "img id out: 26370\n",
      "img id in: 26371\n",
      "img id out: 26371\n",
      "img id in: 26372\n",
      "img id out: 26372\n",
      "img id in: 26373\n",
      "img id out: 26373\n",
      "img id in: 26374\n",
      "img id out: 26374\n",
      "img id in: 26375\n",
      "img id out: 26375\n",
      "img id in: 26376\n",
      "img id out: 26376\n",
      "img id in: 26377\n",
      "img id out: 26377\n",
      "img id in: 26378\n",
      "img id out: 26378\n",
      "img id in: 26379\n",
      "img id out: 26379\n",
      "img id in: 26380\n",
      "img id out: 26380\n",
      "img id in: 26381\n",
      "img id out: 26381\n",
      "img id in: 26382\n",
      "img id out: 26382\n",
      "img id in: 26383\n",
      "img id out: 26383\n",
      "img id in: 26384\n",
      "img id out: 26384\n",
      "img id in: 26385\n",
      "img id out: 26385\n",
      "img id in: 26386\n",
      "img id out: 26386\n",
      "img id in: 26387\n",
      "img id out: 26387\n",
      "img id in: 26388\n",
      "img id out: 26388\n",
      "img id in: 26389\n",
      "img id out: 26389\n",
      "img id in: 26390\n",
      "img id out: 26390\n",
      "img id in: 26391\n",
      "img id out: 26391\n",
      "img id in: 26392\n",
      "img id out: 26392\n",
      "img id in: 26393\n",
      "img id out: 26393\n",
      "img id in: 26394\n",
      "img id out: 26394\n",
      "img id in: 26395\n",
      "img id out: 26395\n",
      "img id in: 26396\n",
      "img id out: 26396\n",
      "img id in: 26397\n",
      "img id out: 26397\n",
      "img id in: 26398\n",
      "img id out: 26398\n",
      "img id in: 26399\n",
      "img id out: 26399\n",
      "img id in: 26400\n",
      "img id out: 26400\n",
      "img id in: 26401\n",
      "img id out: 26401\n",
      "img id in: 26402\n",
      "img id out: 26402\n",
      "img id in: 26403\n",
      "img id out: 26403\n",
      "img id in: 26404\n",
      "img id out: 26404\n",
      "img id in: 26405\n",
      "img id out: 26405\n",
      "img id in: 26406\n",
      "img id out: 26406\n",
      "img id in: 26407\n",
      "img id out: 26407\n",
      "img id in: 26408\n",
      "img id out: 26408\n",
      "img id in: 26409\n",
      "img id out: 26409\n",
      "img id in: 26410\n",
      "img id out: 26410\n",
      "img id in: 26411\n",
      "img id out: 26411\n",
      "img id in: 26412\n",
      "img id out: 26412\n",
      "img id in: 26413\n",
      "img id out: 26413\n",
      "img id in: 26414\n",
      "img id out: 26414\n",
      "img id in: 26415\n",
      "img id out: 26415\n",
      "img id in: 26416\n",
      "img id out: 26416\n",
      "img id in: 26417\n",
      "img id out: 26417\n",
      "img id in: 26418\n",
      "img id out: 26418\n",
      "img id in: 26419\n",
      "img id out: 26419\n",
      "img id in: 26420\n",
      "img id out: 26420\n",
      "img id in: 26421\n",
      "img id out: 26421\n",
      "img id in: 26422\n",
      "img id out: 26422\n",
      "img id in: 26423\n",
      "img id out: 26423\n",
      "img id in: 26424\n",
      "img id out: 26424\n",
      "img id in: 26425\n",
      "img id out: 26425\n",
      "img id in: 26426\n",
      "img id out: 26426\n",
      "img id in: 26427\n",
      "img id out: 26427\n",
      "img id in: 26428\n",
      "img id out: 26428\n",
      "img id in: 26429\n",
      "img id out: 26429\n",
      "img id in: 26430\n",
      "img id out: 26430\n",
      "img id in: 26431\n",
      "img id out: 26431\n",
      "img id in: 26432\n",
      "img id out: 26432\n",
      "img id in: 26433\n",
      "img id out: 26433\n",
      "img id in: 26434\n",
      "img id out: 26434\n",
      "img id in: 26435\n",
      "img id out: 26435\n",
      "img id in: 26436\n",
      "img id out: 26436\n",
      "img id in: 26437\n",
      "img id out: 26437\n",
      "img id in: 26438\n",
      "img id out: 26438\n",
      "img id in: 26439\n",
      "img id out: 26439\n",
      "img id in: 26440\n",
      "img id out: 26440\n",
      "img id in: 26441\n",
      "img id out: 26441\n",
      "img id in: 26442\n",
      "img id out: 26442\n",
      "img id in: 26443\n",
      "img id out: 26443\n",
      "img id in: 26444\n",
      "img id out: 26444\n",
      "img id in: 26445\n",
      "img id out: 26445\n",
      "2020-06-08 07:55:49,963 maskrcnn_benchmark.inference INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9995\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.5908;   R @ 50: 0.6548;   R @ 100: 0.6723;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6731; ngR @ 50: 0.8181; ngR @ 100: 0.8882;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0133;  zR @ 50: 0.0385;  zR @ 100: 0.0580;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1281;  mR @ 50: 0.1631;  mR @ 100: 0.1764;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1563) (across:0.0000) (against:0.0000) (along:0.0092) (and:0.0118) (at:0.3054) (attached to:0.0024) (behind:0.5860) (belonging to:0.0000) (between:0.0069) (carrying:0.3453) (covered in:0.0943) (covering:0.0013) (eating:0.3226) (flying in:0.0000) (for:0.0811) (from:0.0000) (growing on:0.0000) (hanging from:0.0531) (has:0.7991) (holding:0.6764) (in:0.3879) (in front of:0.1597) (laying on:0.0090) (looking at:0.0894) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4176) (of:0.6643) (on:0.8025) (on back of:0.0000) (over:0.0997) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3350) (says:0.0000) (sitting on:0.2706) (standing on:0.0241) (to:0.0000) (under:0.4054) (using:0.1390) (walking in:0.0000) (walking on:0.1151) (watching:0.3467) (wearing:0.9708) (wears:0.0000) (with:0.1303) \n",
      "SGG eval:   A @ 20: 0.6897;   A @ 50: 0.6925;   A @ 100: 0.6925;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10027 --nproc_per_node=8 tools/relation_test_net.py \\\n",
    "--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \\\n",
    "TEST.IMS_PER_BATCH 8 DTYPE \"float16\" \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/motif-precls-exmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Ex2 : (SGCls, Causal, TDE, SUM Fusion, MOTIFS Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!  python -m torch.distributed.launch --master_port 10026 --nproc_per_node=2 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none \n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\  \n",
    "SOLVER.IMS_PER_BATCH 12 TEST.IMS_PER_BATCH 2 DTYPE \"float16\" \\ \n",
    "SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\ \n",
    "GLOVE_DIR /home/kaihua/glove \n",
    "MODEL.PRETRAINED_DETECTOR_CKPT /home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth \n",
    "OUTPUT_DIR /home/kaihua/checkpoints/causal-motifs-sgcls-exmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_port 10028 --nproc_per_node=1 tools/relation_test_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" MODEL.ROI_RELATION_HEAD.USE_GT_BOX True MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs  TEST.IMS_PER_BATCH 1 DTYPE \"float16\" GLOVE_DIR /home/kaihua/glove MODEL.PRETRAINED_DETECTOR_CKPT /home/kaihua/checkpoints/causal-motifs-sgcls-exmp OUTPUT_DIR /home/kaihua/checkpoints/causal-motifs-sgcls-exmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "## sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-09T09:26:12.898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-09 09:26:23,637 maskrcnn_benchmark INFO: Using 8 GPUs\n",
      "2020-06-09 09:26:23,637 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE'], skip_test=False)\n",
      "2020-06-09 09:26:23,637 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-09 09:26:28,506 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n",
      "2020-06-09 09:26:28,507 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml\n",
      "2020-06-09 09:26:28,507 maskrcnn_benchmark INFO: \n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MAX_SIZE_TEST: 1000\n",
      "MODEL:\n",
      "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
      "  WEIGHT: \"catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\"\n",
      "  BACKBONE:\n",
      "    CONV_BODY: \"R-101-FPN\" # VGG-16\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    STRIDE_IN_1X1: False\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RELATION_ON: True\n",
      "  ATTRIBUTE_ON: False\n",
      "  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false\n",
      "  RPN:\n",
      "    USE_FPN: True\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    RPN_MID_CHANNEL: 256\n",
      "  ROI_HEADS:\n",
      "    USE_FPN: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "  ROI_BOX_HEAD:\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA\n",
      "    MLP_HEAD_DIM: 4096\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight\n",
      "    POS_WEIGHT: 50.0\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA\n",
      "    MAX_ATTRIBUTES: 10             \n",
      "    ATTRIBUTE_BGFG_SAMPLE: True    \n",
      "    ATTRIBUTE_BGFG_RATIO: 3        \n",
      "  ROI_RELATION_HEAD:\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing\n",
      "    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain \"to the left of\" & \"to the right of\")\n",
      "    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    FEATURE_EXTRACTOR: \"RelationFeatureExtractor\"\n",
      "    #################### Select Relationship Model ####################\n",
      "    #PREDICTOR: \"MotifPredictor\"\n",
      "    #PREDICTOR: \"VCTreePredictor\"\n",
      "    #PREDICTOR: \"TransformerPredictor\"\n",
      "    PREDICTOR: \"CausalAnalysisPredictor\"\n",
      "    ################# Parameters for Motif Predictor ##################\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    ############# Parameters for Causal Unbias Predictor ##############\n",
      "    ### Implementation for paper \"Unbiased Scene Graph Generation from Biased Training\"\n",
      "    CAUSAL:\n",
      "      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'\n",
      "      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         \n",
      "      SEPARATE_SPATIAL: False         # separate spatial in union feature\n",
      "      CONTEXT_LAYER: \"motifs\"         # candicates: motifs, vctree, vtranse\n",
      "      SPATIAL_FOR_VISION: True\n",
      "      EFFECT_ANALYSIS: True\n",
      "    ############### Parameters for Transformer Predictor ##############\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      NUM_HEAD: 8\n",
      "      KEY_DIM: 64\n",
      "      VAL_DIM: 64\n",
      "      INNER_DIM: 2048 \n",
      "DATASETS:\n",
      "  TRAIN: (\"VG_stanford_filtered_with_attribute_train\",)\n",
      "  VAL: (\"VG_stanford_filtered_with_attribute_val\",)\n",
      "  TEST: (\"VG_stanford_filtered_with_attribute_test\",)\n",
      "DATALOADER:\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "SOLVER:\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  BASE_LR: 0.01\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  MOMENTUM: 0.9\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  STEPS: (10000, 16000)\n",
      "  MAX_ITER: 40000\n",
      "  VAL_PERIOD: 2000\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    # the following paramters are only used for WarmupReduceLROnPlateau\n",
      "    TYPE: \"WarmupReduceLROnPlateau\"    # WarmupMultiStepLR, WarmupReduceLROnPlateau\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "OUTPUT_DIR: './output/relation_baseline'\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  RELATION:\n",
      "    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem\n",
      "    REQUIRE_OVERLAP: False\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "\n",
      "2020-06-09 09:26:28,510 maskrcnn_benchmark INFO: Running with config:\n",
      "AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: TDE\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 64\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 8\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-09 09:26:28,510 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 09:26:28,545 maskrcnn_benchmark INFO: #################### prepare training ####################\n",
      "2020-06-09 09:26:31,832 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:26:31,832 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6925.71it/s]\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7169.99it/s]\n",
      " 97%|█████████████████████████████████▉ | 54441/56224 [00:07<00:00, 6402.23it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7084.15it/s]\n",
      "2020-06-09 09:26:59,213 maskrcnn_benchmark.data.build INFO: finish\n",
      "2020-06-09 09:26:59,213 maskrcnn_benchmark.data.build INFO: Save data statistics to: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-09 09:26:59,213 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      " 96%|█████████████████████████████████▋ | 54056/56224 [00:07<00:00, 6250.88it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7129.52it/s]\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7180.18it/s]\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7128.10it/s]\n",
      " 98%|██████████████████████████████████▍| 55303/56224 [00:08<00:00, 5896.24it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 98%|██████████████████████████████████▍| 55323/56224 [00:07<00:00, 6088.23it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      " 99%|██████████████████████████████████▊| 55897/56224 [00:08<00:00, 5725.72it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 99%|██████████████████████████████████▊| 55938/56224 [00:07<00:00, 5956.35it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6881.60it/s]\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7162.89it/s]\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ __background__ -> __background__ \n",
      "\n",
      "fail on __background__\n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-09 09:27:00,505 maskrcnn_benchmark INFO: #################### end model construction ####################\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ __background__ -> __background__ \n",
      "\n",
      "fail on __background__fail on __background__\n",
      "\n",
      "2020-06-09 09:27:01,166 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "2020-06-09 09:27:01,194 maskrcnn_benchmark INFO: #################### end distributed ####################\n",
      "2020-06-09 09:27:01,196 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-09 09:27:02,104 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-09 09:27:02,105 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.\n",
      "2020-06-09 09:27:02,105 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)\n",
      "2020-06-09 09:27:02,167 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\n",
      "2020-06-09 09:27:02,168 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)\n",
      "2020-06-09 09:27:02,169 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)\n",
      "2020-06-09 09:27:02,170 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)\n",
      "2020-06-09 09:27:02,171 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-09 09:27:02,530 maskrcnn_benchmark INFO: #################### end load checkpointer ####################\n",
      "2020-06-09 09:27:02,531 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-09 09:27:05,309 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/labels.json\n",
      "2020-06-09 09:27:06,520 maskrcnn_benchmark INFO: #################### end dataloader ####################\n",
      "2020-06-09 09:27:06,521 maskrcnn_benchmark INFO: Validate before training\n",
      "2020-06-09 09:27:06,529 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.85it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.84it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.84it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.81it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.84it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.84it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.85it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.81it/s]\n",
      "2020-06-09 09:28:38,354 maskrcnn_benchmark INFO: Total run time: 0:01:31.824018 (0.1469184295654297 s / img per device, on 8 devices)\n",
      "2020-06-09 09:28:38,354 maskrcnn_benchmark INFO: Model inference time: 0:01:09.704013 (0.11152642021179199 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.39s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 09:29:45,520 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.0033;   R @ 50: 0.0049;   R @ 100: 0.0061;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.0069; ngR @ 50: 0.0196; ngR @ 100: 0.0440;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0044;  zR @ 50: 0.0044;  zR @ 100: 0.0095;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.0053;  mR @ 50: 0.0093;  mR @ 100: 0.0111;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.0108) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0000) (attached to:0.0000) (behind:0.0000) (belonging to:0.0000) (between:0.0962) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.0294) (holding:0.0067) (in:0.0000) (in front of:0.0235) (laying on:0.0000) (looking at:0.1739) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0000) (of:0.0016) (on:0.0014) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0159) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0000) (standing on:0.0909) (to:0.0694) (under:0.0000) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.0000) (wears:0.0000) (with:0.0004) \n",
      "SGG eval:   A @ 20: 0.0073;   A @ 50: 0.0075;   A @ 100: 0.0075;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 09:29:46,288 maskrcnn_benchmark INFO: Start training\n",
      "2020-06-09 09:29:48,285 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------\n",
      "2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: inf, (torch.Size([51]))\n",
      "2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: inf, (torch.Size([51, 4096]))\n",
      "2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: inf, (torch.Size([51]))\n",
      "2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 64594.83203, (torch.Size([4096, 512]))\n",
      "2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 20386.34180, (torch.Size([512, 32]))\n",
      "2020-06-09 09:29:48,295 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 18794.22852, (torch.Size([4096]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 6352.29395, (torch.Size([512]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 670.18872, (torch.Size([22801, 51]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 20.33342, (torch.Size([4096, 4096]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 18.43250, (torch.Size([4096, 12544]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 3.79290, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.63481, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 1.09265, (torch.Size([51, 4096]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.64679, (torch.Size([4096, 1024]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.63362, (torch.Size([512, 1024]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.49527, (torch.Size([4096, 4096]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.35582, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.30655, (torch.Size([2048, 4808]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.30343, (torch.Size([2048, 4808]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.24282, (torch.Size([4096, 12544]))\n",
      "2020-06-09 09:29:48,296 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.24256, (torch.Size([512]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.21975, (torch.Size([4096]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.17784, (torch.Size([256]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.09924, (torch.Size([4096]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.09058, (torch.Size([256]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.07593, (torch.Size([128]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.06794, (torch.Size([512, 1024]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.05310, (torch.Size([2048, 512]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.05284, (torch.Size([2048, 512]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.03785, (torch.Size([4096]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.03560, (torch.Size([2048, 4424]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.03413, (torch.Size([2048, 4424]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.03335, (torch.Size([256]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.03174, (torch.Size([256]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.03166, (torch.Size([2048]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.03166, (torch.Size([2048]))\n",
      "2020-06-09 09:29:48,297 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.03132, (torch.Size([2048]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.03132, (torch.Size([2048]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02829, (torch.Size([128]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02815, (torch.Size([1024, 512]))\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.02707, (torch.Size([128]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.02595, (torch.Size([512]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.02407, (torch.Size([1024]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01344, (torch.Size([4096]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00597, (torch.Size([2048, 512]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00583, (torch.Size([2048, 512]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00356, (torch.Size([2048]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00356, (torch.Size([2048]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00341, (torch.Size([2048]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00341, (torch.Size([2048]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00318, (torch.Size([4096]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00247, (torch.Size([151, 200]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00179, (torch.Size([128, 32]))\n",
      "2020-06-09 09:29:48,298 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00102, (torch.Size([32, 9]))\n",
      "2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00070, (torch.Size([128]))\n",
      "2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00032, (torch.Size([32]))\n",
      "2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00028, (torch.Size([151, 200]))\n",
      "2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00018, (torch.Size([32]))\n",
      "2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 09:29:48,299 maskrcnn_benchmark INFO: -------------------------------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "2020-06-09 09:33:37,089 maskrcnn_benchmark INFO: eta: 12:45:29  iter: 200  loss: 0.8979 (1.3697)  auxiliary_ctx: 0.1836 (0.3939)  auxiliary_frq: 0.2057 (0.2092)  auxiliary_vis: 0.1858 (0.3753)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2993 (0.3914)  time: 1.1446 (1.1540)  data: 0.0206 (0.0298)  lr: 0.293248  max mem: 6061\n",
      "2020-06-09 09:37:27,522 maskrcnn_benchmark INFO: eta: 12:41:02  iter: 400  loss: 0.8389 (1.1123)  auxiliary_ctx: 0.1693 (0.2835)  auxiliary_frq: 0.2078 (0.2088)  auxiliary_vis: 0.1844 (0.2821)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2740 (0.3380)  time: 1.1383 (1.1531)  data: 0.0164 (0.0266)  lr: 0.523648  max mem: 6061\n",
      "2020-06-09 09:41:17,401 maskrcnn_benchmark INFO: eta: 12:36:23  iter: 600  loss: 0.7891 (1.0206)  auxiliary_ctx: 0.1521 (0.2443)  auxiliary_frq: 0.2033 (0.2083)  auxiliary_vis: 0.1752 (0.2506)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2570 (0.3174)  time: 1.1465 (1.1519)  data: 0.0238 (0.0242)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 09:45:07,793 maskrcnn_benchmark INFO: eta: 12:32:33  iter: 800  loss: 0.8228 (0.9693)  auxiliary_ctx: 0.1638 (0.2236)  auxiliary_frq: 0.2094 (0.2077)  auxiliary_vis: 0.1862 (0.2333)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2641 (0.3047)  time: 1.1481 (1.1519)  data: 0.0242 (0.0238)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 09:48:57,311 maskrcnn_benchmark INFO: eta: 12:28:09  iter: 1000  loss: 0.7759 (0.9363)  auxiliary_ctx: 0.1501 (0.2104)  auxiliary_frq: 0.2010 (0.2073)  auxiliary_vis: 0.1678 (0.2225)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2548 (0.2961)  time: 1.1420 (1.1510)  data: 0.0249 (0.0238)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 09:52:47,557 maskrcnn_benchmark INFO: eta: 12:24:20  iter: 1200  loss: 0.7592 (0.9119)  auxiliary_ctx: 0.1472 (0.2011)  auxiliary_frq: 0.1994 (0.2068)  auxiliary_vis: 0.1682 (0.2145)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2431 (0.2894)  time: 1.1584 (1.1511)  data: 0.0236 (0.0234)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 09:56:37,402 maskrcnn_benchmark INFO: eta: 12:20:20  iter: 1400  loss: 0.7770 (0.8927)  auxiliary_ctx: 0.1502 (0.1941)  auxiliary_frq: 0.2048 (0.2061)  auxiliary_vis: 0.1760 (0.2086)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2451 (0.2840)  time: 1.1412 (1.1508)  data: 0.0246 (0.0232)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:00:27,095 maskrcnn_benchmark INFO: eta: 12:16:19  iter: 1600  loss: 0.7829 (0.8790)  auxiliary_ctx: 0.1508 (0.1889)  auxiliary_frq: 0.2019 (0.2056)  auxiliary_vis: 0.1708 (0.2042)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2479 (0.2802)  time: 1.1467 (1.1505)  data: 0.0243 (0.0232)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:04:17,544 maskrcnn_benchmark INFO: eta: 12:12:36  iter: 1800  loss: 0.7965 (0.8682)  auxiliary_ctx: 0.1487 (0.1849)  auxiliary_frq: 0.2032 (0.2053)  auxiliary_vis: 0.1767 (0.2008)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2481 (0.2772)  time: 1.1528 (1.1507)  data: 0.0233 (0.0230)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:08:06,939 maskrcnn_benchmark INFO: eta: 12:08:32  iter: 2000  loss: 0.7567 (0.8587)  auxiliary_ctx: 0.1514 (0.1816)  auxiliary_frq: 0.1990 (0.2049)  auxiliary_vis: 0.1675 (0.1978)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2437 (0.2744)  time: 1.1437 (1.1503)  data: 0.0248 (0.0230)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:08:06,942 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0002000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 10:08:09,217 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 10:08:09,243 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.90it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "2020-06-09 10:09:39,769 maskrcnn_benchmark INFO: Total run time: 0:01:30.525655 (0.14484104766845704 s / img per device, on 8 devices)\n",
      "2020-06-09 10:09:39,769 maskrcnn_benchmark INFO: Model inference time: 0:01:10.113488 (0.11218158073425293 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.72s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.32s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 10:11:10,741 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2329;   R @ 50: 0.3147;   R @ 100: 0.3624;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2876; ngR @ 50: 0.4438; ngR @ 100: 0.5837;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.1022;  zR @ 50: 0.1422;  zR @ 100: 0.1793;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1512;  mR @ 50: 0.2033;  mR @ 100: 0.2300;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.3151) (across:0.0000) (against:0.0000) (along:0.2308) (and:0.0000) (at:0.6978) (attached to:0.0000) (behind:0.5724) (belonging to:0.0000) (between:0.0000) (carrying:0.6711) (covered in:0.0714) (covering:0.0000) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.2132) (has:0.5954) (holding:0.3415) (in:0.3653) (in front of:0.4913) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0412) (of:0.6082) (on:0.1933) (on back of:0.0000) (over:0.0305) (painted on:0.0000) (parked on:0.9616) (part of:0.0000) (playing:0.0000) (riding:0.9464) (says:0.0000) (sitting on:0.5319) (standing on:0.0562) (to:0.0000) (under:0.1437) (using:0.0000) (walking in:0.0000) (walking on:0.9337) (watching:0.5098) (wearing:0.9401) (wears:0.0000) (with:0.2767) \n",
      "SGG eval:   A @ 20: 0.4054;   A @ 50: 0.4079;   A @ 100: 0.4079;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 10:11:11,506 maskrcnn_benchmark INFO: Validation Result: 0.3624\n",
      "2020-06-09 10:15:00,990 maskrcnn_benchmark INFO: eta: 12:57:23  iter: 2200  loss: 0.7729 (0.8499)  auxiliary_ctx: 0.1487 (0.1786)  auxiliary_frq: 0.2021 (0.2044)  auxiliary_vis: 0.1699 (0.1952)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2474 (0.2717)  time: 1.1451 (1.2340)  data: 0.0238 (0.1070)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:18:51,159 maskrcnn_benchmark INFO: eta: 12:48:56  iter: 2400  loss: 0.7678 (0.8423)  auxiliary_ctx: 0.1457 (0.1760)  auxiliary_frq: 0.2013 (0.2039)  auxiliary_vis: 0.1731 (0.1929)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2450 (0.2695)  time: 1.1449 (1.2270)  data: 0.0250 (0.1001)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:22:41,490 maskrcnn_benchmark INFO: eta: 12:41:14  iter: 2600  loss: 0.7512 (0.8364)  auxiliary_ctx: 0.1443 (0.1740)  auxiliary_frq: 0.1975 (0.2035)  auxiliary_vis: 0.1660 (0.1911)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2488 (0.2678)  time: 1.1495 (1.2212)  data: 0.0247 (0.0943)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:26:31,920 maskrcnn_benchmark INFO: eta: 12:34:06  iter: 2800  loss: 0.7614 (0.8304)  auxiliary_ctx: 0.1424 (0.1720)  auxiliary_frq: 0.1995 (0.2030)  auxiliary_vis: 0.1683 (0.1893)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2417 (0.2660)  time: 1.1445 (1.2163)  data: 0.0221 (0.0892)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:30:21,992 maskrcnn_benchmark INFO: eta: 12:27:20  iter: 3000  loss: 0.7557 (0.8253)  auxiliary_ctx: 0.1470 (0.1704)  auxiliary_frq: 0.1963 (0.2027)  auxiliary_vis: 0.1664 (0.1878)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2431 (0.2645)  time: 1.1455 (1.2119)  data: 0.0205 (0.0848)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:34:12,914 maskrcnn_benchmark INFO: eta: 12:21:06  iter: 3200  loss: 0.7645 (0.8209)  auxiliary_ctx: 0.1449 (0.1690)  auxiliary_frq: 0.1987 (0.2023)  auxiliary_vis: 0.1656 (0.1865)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2380 (0.2632)  time: 1.1521 (1.2083)  data: 0.0245 (0.0810)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:38:03,538 maskrcnn_benchmark INFO: eta: 12:15:05  iter: 3400  loss: 0.7488 (0.8167)  auxiliary_ctx: 0.1460 (0.1677)  auxiliary_frq: 0.1983 (0.2019)  auxiliary_vis: 0.1641 (0.1852)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2445 (0.2620)  time: 1.1426 (1.2051)  data: 0.0199 (0.0775)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:41:53,377 maskrcnn_benchmark INFO: eta: 12:09:11  iter: 3600  loss: 0.7680 (0.8133)  auxiliary_ctx: 0.1514 (0.1666)  auxiliary_frq: 0.1975 (0.2016)  auxiliary_vis: 0.1690 (0.1842)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2502 (0.2610)  time: 1.1425 (1.2020)  data: 0.0159 (0.0744)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:45:43,133 maskrcnn_benchmark INFO: eta: 12:03:29  iter: 3800  loss: 0.7026 (0.8101)  auxiliary_ctx: 0.1378 (0.1656)  auxiliary_frq: 0.1886 (0.2013)  auxiliary_vis: 0.1559 (0.1832)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2254 (0.2600)  time: 1.1455 (1.1992)  data: 0.0182 (0.0716)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:49:33,316 maskrcnn_benchmark INFO: ---Total norm 0.25203 clip coef 19.83860-----------------\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.13293, (torch.Size([4096, 12544]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.09491, (torch.Size([51, 4096]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.08744, (torch.Size([4096, 12544]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.08035, (torch.Size([4096, 4096]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.07343, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06540, (torch.Size([4096, 4096]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05465, (torch.Size([51, 4096]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04717, (torch.Size([4096, 1024]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03975, (torch.Size([2048, 4808]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03738, (torch.Size([2048, 4808]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02796, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02765, (torch.Size([512, 1024]))\n",
      "2020-06-09 10:49:33,326 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02396, (torch.Size([1024, 512]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02367, (torch.Size([51]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02287, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02159, (torch.Size([512, 32]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01877, (torch.Size([4096, 512]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01271, (torch.Size([256]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00929, (torch.Size([151, 200]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00879, (torch.Size([128]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00874, (torch.Size([51]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00854, (torch.Size([4096]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00808, (torch.Size([2048, 512]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00660, (torch.Size([256]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00642, (torch.Size([22801, 51]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00628, (torch.Size([2048, 512]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00623, (torch.Size([4096]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00622, (torch.Size([512]))\n",
      "2020-06-09 10:49:33,327 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00493, (torch.Size([512]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00440, (torch.Size([128]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00425, (torch.Size([4096]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00355, (torch.Size([128]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00273, (torch.Size([1024]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00248, (torch.Size([256]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00233, (torch.Size([2048]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00233, (torch.Size([2048]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00209, (torch.Size([2048]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00209, (torch.Size([2048]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00199, (torch.Size([4096]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00151, (torch.Size([4096]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00122, (torch.Size([2048, 4424]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00097, (torch.Size([2048, 4424]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00074, (torch.Size([256]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00058, (torch.Size([512, 1024]))\n",
      "2020-06-09 10:49:33,328 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00046, (torch.Size([4096]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00031, (torch.Size([512]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00009, (torch.Size([2048, 512]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00007, (torch.Size([2048, 512]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00007, (torch.Size([2048]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00007, (torch.Size([2048]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00007, (torch.Size([2048]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00007, (torch.Size([2048]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00002, (torch.Size([128, 32]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00002, (torch.Size([151, 200]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00002, (torch.Size([128]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 10:49:33,329 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-09 10:49:33,332 maskrcnn_benchmark INFO: eta: 11:58:03  iter: 4000  loss: 0.7685 (0.8071)  auxiliary_ctx: 0.1495 (0.1646)  auxiliary_frq: 0.1987 (0.2010)  auxiliary_vis: 0.1682 (0.1823)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2363 (0.2591)  time: 1.1499 (1.1968)  data: 0.0204 (0.0691)  lr: 0.640000  max mem: 6124\n",
      "2020-06-09 10:49:33,335 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0004000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 10:49:35,780 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 10:49:35,813 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.90it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.90it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:28<00:00,  7.08it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.90it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.90it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.90it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.90it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.90it/s]\n",
      "2020-06-09 10:51:04,088 maskrcnn_benchmark INFO: Total run time: 0:01:28.274763 (0.14123962020874023 s / img per device, on 8 devices)\n",
      "2020-06-09 10:51:04,088 maskrcnn_benchmark INFO: Model inference time: 0:01:09.485233 (0.11117637252807618 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n"
     ]
    }
   ],
   "source": [
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10025 --nproc_per_node=8 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE \\\n",
    "SOLVER.IMS_PER_BATCH 64 TEST.IMS_PER_BATCH 8 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 40000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-09T11:13:29.081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-09 11:13:47,066 maskrcnn_benchmark INFO: Using 8 GPUs\n",
      "2020-06-09 11:13:47,066 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE'], skip_test=False)\n",
      "2020-06-09 11:13:47,066 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-09 11:13:52,029 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n",
      "2020-06-09 11:13:52,030 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml\n",
      "2020-06-09 11:13:52,030 maskrcnn_benchmark INFO: \n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MAX_SIZE_TEST: 1000\n",
      "MODEL:\n",
      "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
      "  WEIGHT: \"catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\"\n",
      "  BACKBONE:\n",
      "    CONV_BODY: \"R-101-FPN\" # VGG-16\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    STRIDE_IN_1X1: False\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RELATION_ON: True\n",
      "  ATTRIBUTE_ON: False\n",
      "  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false\n",
      "  RPN:\n",
      "    USE_FPN: True\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    RPN_MID_CHANNEL: 256\n",
      "  ROI_HEADS:\n",
      "    USE_FPN: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "  ROI_BOX_HEAD:\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA\n",
      "    MLP_HEAD_DIM: 4096\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight\n",
      "    POS_WEIGHT: 50.0\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA\n",
      "    MAX_ATTRIBUTES: 10             \n",
      "    ATTRIBUTE_BGFG_SAMPLE: True    \n",
      "    ATTRIBUTE_BGFG_RATIO: 3        \n",
      "  ROI_RELATION_HEAD:\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing\n",
      "    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain \"to the left of\" & \"to the right of\")\n",
      "    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    FEATURE_EXTRACTOR: \"RelationFeatureExtractor\"\n",
      "    #################### Select Relationship Model ####################\n",
      "    #PREDICTOR: \"MotifPredictor\"\n",
      "    #PREDICTOR: \"VCTreePredictor\"\n",
      "    #PREDICTOR: \"TransformerPredictor\"\n",
      "    PREDICTOR: \"CausalAnalysisPredictor\"\n",
      "    ################# Parameters for Motif Predictor ##################\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    ############# Parameters for Causal Unbias Predictor ##############\n",
      "    ### Implementation for paper \"Unbiased Scene Graph Generation from Biased Training\"\n",
      "    CAUSAL:\n",
      "      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'\n",
      "      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         \n",
      "      SEPARATE_SPATIAL: False         # separate spatial in union feature\n",
      "      CONTEXT_LAYER: \"motifs\"         # candicates: motifs, vctree, vtranse\n",
      "      SPATIAL_FOR_VISION: True\n",
      "      EFFECT_ANALYSIS: True\n",
      "    ############### Parameters for Transformer Predictor ##############\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      NUM_HEAD: 8\n",
      "      KEY_DIM: 64\n",
      "      VAL_DIM: 64\n",
      "      INNER_DIM: 2048 \n",
      "DATASETS:\n",
      "  TRAIN: (\"VG_stanford_filtered_with_attribute_train\",)\n",
      "  VAL: (\"VG_stanford_filtered_with_attribute_val\",)\n",
      "  TEST: (\"VG_stanford_filtered_with_attribute_test\",)\n",
      "DATALOADER:\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "SOLVER:\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  BASE_LR: 0.01\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  MOMENTUM: 0.9\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  STEPS: (10000, 16000)\n",
      "  MAX_ITER: 40000\n",
      "  VAL_PERIOD: 2000\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    # the following paramters are only used for WarmupReduceLROnPlateau\n",
      "    TYPE: \"WarmupReduceLROnPlateau\"    # WarmupMultiStepLR, WarmupReduceLROnPlateau\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "OUTPUT_DIR: './output/relation_baseline'\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  RELATION:\n",
      "    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem\n",
      "    REQUIRE_OVERLAP: False\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "\n",
      "2020-06-09 11:13:52,033 maskrcnn_benchmark INFO: Running with config:\n",
      "AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: TDE\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 64\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 8\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-09 11:13:52,034 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 11:13:52,070 maskrcnn_benchmark INFO: #################### prepare training ####################\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "2020-06-09 11:13:55,367 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:13:55,367 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2020-06-09 11:13:55,368 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-09 11:13:55,368 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "__background__ -> __background__ fail on __background__\n",
      "\n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-09 11:13:56,581 maskrcnn_benchmark INFO: #################### end model construction ####################\n",
      "2020-06-09 11:13:57,386 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "2020-06-09 11:13:57,419 maskrcnn_benchmark INFO: #################### end distributed ####################\n",
      "2020-06-09 11:13:57,420 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0004000.pth\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-09 11:13:59,579 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0004000.pth\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-09 11:14:00,283 maskrcnn_benchmark INFO: #################### end load checkpointer ####################\n",
      "2020-06-09 11:14:00,283 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-09 11:14:02,971 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/labels.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 11:14:04,196 maskrcnn_benchmark INFO: #################### end dataloader ####################\n",
      "2020-06-09 11:14:04,197 maskrcnn_benchmark INFO: Validate before training\n",
      "2020-06-09 11:14:04,199 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.72it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.66it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.72it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "2020-06-09 11:15:37,025 maskrcnn_benchmark INFO: Total run time: 0:01:32.825702 (0.14852112312316895 s / img per device, on 8 devices)\n",
      "2020-06-09 11:15:37,025 maskrcnn_benchmark INFO: Model inference time: 0:01:11.770481 (0.1148327693939209 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 11:17:09,780 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2520;   R @ 50: 0.3401;   R @ 100: 0.3961;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2968; ngR @ 50: 0.4558; ngR @ 100: 0.5902;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.1000;  zR @ 50: 0.1363;  zR @ 100: 0.1807;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1690;  mR @ 50: 0.2244;  mR @ 100: 0.2559;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2155) (across:0.0000) (against:0.0000) (along:0.7821) (and:0.0000) (at:0.7892) (attached to:0.0000) (behind:0.5517) (belonging to:0.0000) (between:0.0000) (carrying:0.7281) (covered in:0.4048) (covering:0.1878) (eating:0.8571) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.1287) (has:0.5993) (holding:0.2415) (in:0.3543) (in front of:0.4943) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0657) (of:0.5745) (on:0.2635) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.7753) (part of:0.0000) (playing:0.0000) (riding:0.9286) (says:0.0000) (sitting on:0.5016) (standing on:0.1087) (to:0.0000) (under:0.2075) (using:0.1923) (walking in:0.0000) (walking on:0.9622) (watching:0.5686) (wearing:0.9707) (wears:0.0000) (with:0.2232) \n",
      "SGG eval:   A @ 20: 0.4751;   A @ 50: 0.4794;   A @ 100: 0.4794;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 11:17:10,580 maskrcnn_benchmark INFO: Start training\n",
      "2020-06-09 11:17:12,890 maskrcnn_benchmark INFO: ---Total norm 0.21389 clip coef 23.37625-----------------\n",
      "2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.10699, (torch.Size([4096, 12544]))\n",
      "2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.10371, (torch.Size([51, 4096]))\n",
      "2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06745, (torch.Size([4096, 4096]))\n",
      "2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.06372, (torch.Size([4096, 12544]))\n",
      "2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.06253, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.04697, (torch.Size([4096, 4096]))\n",
      "2020-06-09 11:17:12,900 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.04320, (torch.Size([51, 4096]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03704, (torch.Size([4096, 1024]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.02884, (torch.Size([2048, 4808]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.02719, (torch.Size([2048, 4808]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02711, (torch.Size([51]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02602, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02378, (torch.Size([512, 1024]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02034, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01859, (torch.Size([1024, 512]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01754, (torch.Size([512, 32]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01513, (torch.Size([4096, 512]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01452, (torch.Size([256]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00907, (torch.Size([128]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00730, (torch.Size([4096]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00698, (torch.Size([151, 200]))\n",
      "2020-06-09 11:17:12,901 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00682, (torch.Size([4096]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00626, (torch.Size([512]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00579, (torch.Size([256]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00570, (torch.Size([51]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00552, (torch.Size([2048, 512]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00529, (torch.Size([22801, 51]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00513, (torch.Size([2048, 512]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00413, (torch.Size([512]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00388, (torch.Size([1024]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00366, (torch.Size([4096]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00357, (torch.Size([128]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00300, (torch.Size([128]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00247, (torch.Size([2048]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00247, (torch.Size([2048]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00236, (torch.Size([256]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00229, (torch.Size([2048]))\n",
      "2020-06-09 11:17:12,902 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00229, (torch.Size([2048]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00205, (torch.Size([4096]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00129, (torch.Size([4096]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00123, (torch.Size([512, 1024]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00095, (torch.Size([2048, 4424]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00086, (torch.Size([2048, 4424]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00076, (torch.Size([256]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00069, (torch.Size([512]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00040, (torch.Size([4096]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00020, (torch.Size([2048, 512]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00015, (torch.Size([2048]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00015, (torch.Size([2048]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00014, (torch.Size([2048]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00014, (torch.Size([2048]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00014, (torch.Size([2048, 512]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00004, (torch.Size([128]))\n",
      "2020-06-09 11:17:12,903 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00001, (torch.Size([151, 200]))\n",
      "2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))\n",
      "2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))\n",
      "2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 11:17:12,904 maskrcnn_benchmark INFO: -------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 11:21:04,667 maskrcnn_benchmark INFO: eta: 11:38:21  iter: 4200  loss: 0.7182 (0.7445)  auxiliary_ctx: 0.1454 (0.1461)  auxiliary_frq: 0.1881 (0.1942)  auxiliary_vis: 0.1576 (0.1634)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2302 (0.2407)  time: 1.1601 (1.1704)  data: 0.0302 (0.0322)  lr: 0.640000  max mem: 6018\n",
      "2020-06-09 11:24:57,667 maskrcnn_benchmark INFO: eta: 11:32:50  iter: 4400  loss: 0.7432 (0.7482)  auxiliary_ctx: 0.1466 (0.1469)  auxiliary_frq: 0.1958 (0.1946)  auxiliary_vis: 0.1655 (0.1647)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2405 (0.2420)  time: 1.1634 (1.1677)  data: 0.0313 (0.0306)  lr: 0.640000  max mem: 6025\n",
      "2020-06-09 11:28:50,182 maskrcnn_benchmark INFO: eta: 11:27:56  iter: 4600  loss: 0.7399 (0.7473)  auxiliary_ctx: 0.1415 (0.1468)  auxiliary_frq: 0.1929 (0.1942)  auxiliary_vis: 0.1657 (0.1647)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2358 (0.2415)  time: 1.1668 (1.1660)  data: 0.0281 (0.0296)  lr: 0.640000  max mem: 6025\n",
      "2020-06-09 11:32:42,897 maskrcnn_benchmark INFO: eta: 11:23:41  iter: 4800  loss: 0.7612 (0.7501)  auxiliary_ctx: 0.1474 (0.1474)  auxiliary_frq: 0.1940 (0.1944)  auxiliary_vis: 0.1690 (0.1656)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2476 (0.2428)  time: 1.1510 (1.1654)  data: 0.0302 (0.0290)  lr: 0.640000  max mem: 6025\n",
      "2020-06-09 11:36:35,175 maskrcnn_benchmark INFO: eta: 11:19:20  iter: 5000  loss: 0.7478 (0.7519)  auxiliary_ctx: 0.1505 (0.1478)  auxiliary_frq: 0.1957 (0.1946)  auxiliary_vis: 0.1673 (0.1660)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2422 (0.2435)  time: 1.1754 (1.1646)  data: 0.0240 (0.0284)  lr: 0.640000  max mem: 6045\n",
      "2020-06-09 11:40:27,821 maskrcnn_benchmark INFO: eta: 11:15:19  iter: 5200  loss: 0.7314 (0.7515)  auxiliary_ctx: 0.1459 (0.1477)  auxiliary_frq: 0.1915 (0.1943)  auxiliary_vis: 0.1629 (0.1660)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2403 (0.2435)  time: 1.1558 (1.1644)  data: 0.0282 (0.0283)  lr: 0.640000  max mem: 6658\n",
      "2020-06-09 11:44:20,162 maskrcnn_benchmark INFO: eta: 11:11:13  iter: 5400  loss: 0.7385 (0.7517)  auxiliary_ctx: 0.1464 (0.1478)  auxiliary_frq: 0.1915 (0.1942)  auxiliary_vis: 0.1660 (0.1661)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2345 (0.2435)  time: 1.1581 (1.1640)  data: 0.0305 (0.0281)  lr: 0.640000  max mem: 6658\n",
      "2020-06-09 11:48:10,849 maskrcnn_benchmark INFO: eta: 11:06:35  iter: 5600  loss: 0.7671 (0.7508)  auxiliary_ctx: 0.1523 (0.1476)  auxiliary_frq: 0.1960 (0.1940)  auxiliary_vis: 0.1647 (0.1659)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2451 (0.2433)  time: 1.1449 (1.1627)  data: 0.0269 (0.0278)  lr: 0.640000  max mem: 6658\n",
      "2020-06-09 11:52:02,712 maskrcnn_benchmark INFO: eta: 11:02:30  iter: 5800  loss: 0.7431 (0.7500)  auxiliary_ctx: 0.1473 (0.1475)  auxiliary_frq: 0.1874 (0.1936)  auxiliary_vis: 0.1672 (0.1657)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2400 (0.2431)  time: 1.1497 (1.1623)  data: 0.0204 (0.0277)  lr: 0.640000  max mem: 6658\n",
      "2020-06-09 11:55:54,365 maskrcnn_benchmark INFO: eta: 10:58:24  iter: 6000  loss: 0.7142 (0.7497)  auxiliary_ctx: 0.1424 (0.1476)  auxiliary_frq: 0.1859 (0.1935)  auxiliary_vis: 0.1570 (0.1656)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2400 (0.2430)  time: 1.1630 (1.1619)  data: 0.0276 (0.0275)  lr: 0.640000  max mem: 6658\n",
      "2020-06-09 11:55:54,369 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0006000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 11:55:57,033 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 11:55:57,070 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.79it/s]\n",
      "2020-06-09 11:57:29,163 maskrcnn_benchmark INFO: Total run time: 0:01:32.091941 (0.14734710540771484 s / img per device, on 8 devices)\n",
      "2020-06-09 11:57:29,163 maskrcnn_benchmark INFO: Model inference time: 0:01:12.706450 (0.1163303207397461 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.82s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 11:59:13,365 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2229;   R @ 50: 0.3331;   R @ 100: 0.4062;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2621; ngR @ 50: 0.4429; ngR @ 100: 0.5969;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0889;  zR @ 50: 0.1296;  zR @ 100: 0.1756;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1432;  mR @ 50: 0.2048;  mR @ 100: 0.2428;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1905) (across:0.0000) (against:0.0000) (along:0.6218) (and:0.0000) (at:0.7076) (attached to:0.0000) (behind:0.6488) (belonging to:0.0000) (between:0.0000) (carrying:0.6184) (covered in:0.4405) (covering:0.1837) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.1176) (has:0.5876) (holding:0.2669) (in:0.3008) (in front of:0.3547) (laying on:0.0952) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0234) (of:0.5888) (on:0.3172) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.7830) (part of:0.0000) (playing:0.0000) (riding:0.9375) (says:0.0000) (sitting on:0.5182) (standing on:0.1322) (to:0.0000) (under:0.3023) (using:0.0000) (walking in:0.0000) (walking on:0.8572) (watching:0.6863) (wearing:0.8663) (wears:0.0000) (with:0.2134) \n",
      "SGG eval:   A @ 20: 0.4952;   A @ 50: 0.4995;   A @ 100: 0.4995;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 11:59:14,168 maskrcnn_benchmark INFO: Validation Result: 0.4062\n",
      "2020-06-09 12:03:05,865 maskrcnn_benchmark INFO: eta: 11:45:31  iter: 6200  loss: 0.7287 (0.7489)  auxiliary_ctx: 0.1446 (0.1475)  auxiliary_frq: 0.1896 (0.1933)  auxiliary_vis: 0.1609 (0.1653)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2336 (0.2427)  time: 1.1565 (1.2524)  data: 0.0179 (0.1181)  lr: 0.640000  max mem: 6658\n"
     ]
    }
   ],
   "source": [
    "# resume:\n",
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10025 --nproc_per_node=8 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE \\\n",
    "SOLVER.IMS_PER_BATCH 64 TEST.IMS_PER_BATCH 8 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 40000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:01:27.745272Z",
     "start_time": "2020-06-09T13:09:24.396319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-09 13:09:41,326 maskrcnn_benchmark INFO: Using 8 GPUs\n",
      "2020-06-09 13:09:41,326 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE'], skip_test=False)\n",
      "2020-06-09 13:09:41,326 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-09 13:09:46,234 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n",
      "2020-06-09 13:09:46,235 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml\n",
      "2020-06-09 13:09:46,235 maskrcnn_benchmark INFO: \n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MAX_SIZE_TEST: 1000\n",
      "MODEL:\n",
      "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
      "  WEIGHT: \"catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\"\n",
      "  BACKBONE:\n",
      "    CONV_BODY: \"R-101-FPN\" # VGG-16\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    STRIDE_IN_1X1: False\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RELATION_ON: True\n",
      "  ATTRIBUTE_ON: False\n",
      "  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false\n",
      "  RPN:\n",
      "    USE_FPN: True\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    RPN_MID_CHANNEL: 256\n",
      "  ROI_HEADS:\n",
      "    USE_FPN: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "  ROI_BOX_HEAD:\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA\n",
      "    MLP_HEAD_DIM: 4096\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight\n",
      "    POS_WEIGHT: 50.0\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA\n",
      "    MAX_ATTRIBUTES: 10             \n",
      "    ATTRIBUTE_BGFG_SAMPLE: True    \n",
      "    ATTRIBUTE_BGFG_RATIO: 3        \n",
      "  ROI_RELATION_HEAD:\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing\n",
      "    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain \"to the left of\" & \"to the right of\")\n",
      "    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    FEATURE_EXTRACTOR: \"RelationFeatureExtractor\"\n",
      "    #################### Select Relationship Model ####################\n",
      "    #PREDICTOR: \"MotifPredictor\"\n",
      "    #PREDICTOR: \"VCTreePredictor\"\n",
      "    #PREDICTOR: \"TransformerPredictor\"\n",
      "    PREDICTOR: \"CausalAnalysisPredictor\"\n",
      "    ################# Parameters for Motif Predictor ##################\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    ############# Parameters for Causal Unbias Predictor ##############\n",
      "    ### Implementation for paper \"Unbiased Scene Graph Generation from Biased Training\"\n",
      "    CAUSAL:\n",
      "      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'\n",
      "      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         \n",
      "      SEPARATE_SPATIAL: False         # separate spatial in union feature\n",
      "      CONTEXT_LAYER: \"motifs\"         # candicates: motifs, vctree, vtranse\n",
      "      SPATIAL_FOR_VISION: True\n",
      "      EFFECT_ANALYSIS: True\n",
      "    ############### Parameters for Transformer Predictor ##############\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      NUM_HEAD: 8\n",
      "      KEY_DIM: 64\n",
      "      VAL_DIM: 64\n",
      "      INNER_DIM: 2048 \n",
      "DATASETS:\n",
      "  TRAIN: (\"VG_stanford_filtered_with_attribute_train\",)\n",
      "  VAL: (\"VG_stanford_filtered_with_attribute_val\",)\n",
      "  TEST: (\"VG_stanford_filtered_with_attribute_test\",)\n",
      "DATALOADER:\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "SOLVER:\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  BASE_LR: 0.01\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  MOMENTUM: 0.9\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  STEPS: (10000, 16000)\n",
      "  MAX_ITER: 40000\n",
      "  VAL_PERIOD: 2000\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    # the following paramters are only used for WarmupReduceLROnPlateau\n",
      "    TYPE: \"WarmupReduceLROnPlateau\"    # WarmupMultiStepLR, WarmupReduceLROnPlateau\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "OUTPUT_DIR: './output/relation_baseline'\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  RELATION:\n",
      "    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem\n",
      "    REQUIRE_OVERLAP: False\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "\n",
      "2020-06-09 13:09:46,238 maskrcnn_benchmark INFO: Running with config:\n",
      "AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: TDE\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 64\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 8\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-09 13:09:46,239 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 13:09:46,271 maskrcnn_benchmark INFO: #################### prepare training ####################\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-09 13:09:49,571 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 13:09:49,571 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2020-06-09 13:09:49,572 maskrcnn_benchmark.data.build INFO: Loading data statistics from: checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-09 13:09:49,573 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors fromloading word vectors from  glove/glove.6B.200d.ptglove/glove.6B.200d.pt\n",
      "\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-09 13:09:50,998 maskrcnn_benchmark INFO: #################### end model construction ####################\n",
      "2020-06-09 13:09:51,412 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "2020-06-09 13:09:51,446 maskrcnn_benchmark INFO: #################### end distributed ####################\n",
      "2020-06-09 13:09:51,448 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0006000.pth\n",
      "2020-06-09 13:09:53,583 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0006000.pth\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-09 13:09:54,191 maskrcnn_benchmark INFO: #################### end load checkpointer ####################\n",
      "2020-06-09 13:09:54,191 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-09 13:09:56,937 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/labels.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 13:09:58,147 maskrcnn_benchmark INFO: #################### end dataloader ####################\n",
      "2020-06-09 13:09:58,147 maskrcnn_benchmark INFO: Validate before training\n",
      "2020-06-09 13:09:58,150 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.97it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.99it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.94it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.97it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.97it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.97it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.98it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.94it/s]\n",
      "2020-06-09 13:11:28,252 maskrcnn_benchmark INFO: Total run time: 0:01:30.102600 (0.14416416053771972 s / img per device, on 8 devices)\n",
      "2020-06-09 13:11:28,253 maskrcnn_benchmark INFO: Model inference time: 0:01:09.362297 (0.11097967529296875 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.55s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.62s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.31s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 13:13:00,439 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2232;   R @ 50: 0.3322;   R @ 100: 0.4054;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2625; ngR @ 50: 0.4420; ngR @ 100: 0.5965;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0889;  zR @ 50: 0.1296;  zR @ 100: 0.1756;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1435;  mR @ 50: 0.2044;  mR @ 100: 0.2426;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1895) (across:0.0000) (against:0.0000) (along:0.6218) (and:0.0000) (at:0.7076) (attached to:0.0000) (behind:0.6463) (belonging to:0.0000) (between:0.0000) (carrying:0.6184) (covered in:0.4405) (covering:0.1837) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.1176) (has:0.5864) (holding:0.2647) (in:0.3012) (in front of:0.3547) (laying on:0.0952) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0239) (of:0.5870) (on:0.3162) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.7830) (part of:0.0000) (playing:0.0000) (riding:0.9375) (says:0.0000) (sitting on:0.5182) (standing on:0.1322) (to:0.0000) (under:0.3023) (using:0.0000) (walking in:0.0000) (walking on:0.8572) (watching:0.6863) (wearing:0.8667) (wears:0.0000) (with:0.2125) \n",
      "SGG eval:   A @ 20: 0.4949;   A @ 50: 0.4992;   A @ 100: 0.4992;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 13:13:01,211 maskrcnn_benchmark INFO: Start training\n",
      "2020-06-09 13:13:03,228 maskrcnn_benchmark INFO: ---Total norm 0.28101 clip coef 17.79280-----------------\n",
      "2020-06-09 13:13:03,238 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.15195, (torch.Size([4096, 12544]))\n",
      "2020-06-09 13:13:03,238 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.09684, (torch.Size([4096, 12544]))\n",
      "2020-06-09 13:13:03,238 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.08358, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.08253, (torch.Size([51, 4096]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.07864, (torch.Size([51, 4096]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.07508, (torch.Size([4096, 4096]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.07111, (torch.Size([4096, 4096]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.06111, (torch.Size([4096, 1024]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.04314, (torch.Size([2048, 4808]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.04114, (torch.Size([2048, 4808]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03890, (torch.Size([1024, 512]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03783, (torch.Size([512, 1024]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03406, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.03289, (torch.Size([512, 32]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02817, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02742, (torch.Size([4096, 512]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01658, (torch.Size([51]))\n",
      "2020-06-09 13:13:03,239 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01178, (torch.Size([4096]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01177, (torch.Size([1024]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01159, (torch.Size([256]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01141, (torch.Size([512]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01132, (torch.Size([128]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01082, (torch.Size([151, 200]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00967, (torch.Size([256]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00951, (torch.Size([51]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00942, (torch.Size([4096]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00885, (torch.Size([512]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00875, (torch.Size([2048, 512]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00811, (torch.Size([2048, 512]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00707, (torch.Size([22801, 51]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00627, (torch.Size([4096]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00566, (torch.Size([2048]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00566, (torch.Size([2048]))\n",
      "2020-06-09 13:13:03,240 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00497, (torch.Size([2048]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00497, (torch.Size([2048]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00444, (torch.Size([128]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00295, (torch.Size([128]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00255, (torch.Size([256]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00226, (torch.Size([4096]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00209, (torch.Size([4096]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00092, (torch.Size([256]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00085, (torch.Size([2048, 4424]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00077, (torch.Size([2048, 4424]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00056, (torch.Size([4096]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00017, (torch.Size([512, 1024]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00014, (torch.Size([512]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00004, (torch.Size([2048, 512]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00003, (torch.Size([2048]))\n",
      "2020-06-09 13:13:03,241 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00003, (torch.Size([2048]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00003, (torch.Size([2048, 512]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00002, (torch.Size([2048]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00002, (torch.Size([2048]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00001, (torch.Size([151, 200]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 13:13:03,242 maskrcnn_benchmark INFO: -------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 13:16:51,725 maskrcnn_benchmark INFO: eta: 10:49:16  iter: 6200  loss: 0.7310 (0.7456)  auxiliary_ctx: 0.1449 (0.1476)  auxiliary_frq: 0.1868 (0.1923)  auxiliary_vis: 0.1581 (0.1636)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2425 (0.2421)  time: 1.1507 (1.1526)  data: 0.0274 (0.0301)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:20:41,370 maskrcnn_benchmark INFO: eta: 10:44:13  iter: 6400  loss: 0.7262 (0.7484)  auxiliary_ctx: 0.1420 (0.1482)  auxiliary_frq: 0.1855 (0.1924)  auxiliary_vis: 0.1588 (0.1646)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2345 (0.2432)  time: 1.1427 (1.1504)  data: 0.0251 (0.0273)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:24:31,515 maskrcnn_benchmark INFO: eta: 10:40:26  iter: 6600  loss: 0.7307 (0.7441)  auxiliary_ctx: 0.1495 (0.1471)  auxiliary_frq: 0.1906 (0.1915)  auxiliary_vis: 0.1586 (0.1639)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2377 (0.2416)  time: 1.1410 (1.1505)  data: 0.0278 (0.0268)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:28:21,376 maskrcnn_benchmark INFO: eta: 10:36:26  iter: 6800  loss: 0.7185 (0.7435)  auxiliary_ctx: 0.1482 (0.1470)  auxiliary_frq: 0.1866 (0.1911)  auxiliary_vis: 0.1581 (0.1639)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2283 (0.2416)  time: 1.1471 (1.1502)  data: 0.0262 (0.0264)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:32:11,333 maskrcnn_benchmark INFO: eta: 10:32:33  iter: 7000  loss: 0.7196 (0.7443)  auxiliary_ctx: 0.1404 (0.1472)  auxiliary_frq: 0.1907 (0.1912)  auxiliary_vis: 0.1575 (0.1641)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2260 (0.2418)  time: 1.1481 (1.1501)  data: 0.0252 (0.0259)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:36:01,357 maskrcnn_benchmark INFO: eta: 10:28:43  iter: 7200  loss: 0.7269 (0.7440)  auxiliary_ctx: 0.1477 (0.1472)  auxiliary_frq: 0.1885 (0.1912)  auxiliary_vis: 0.1595 (0.1639)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2326 (0.2418)  time: 1.1626 (1.1501)  data: 0.0264 (0.0257)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:39:51,021 maskrcnn_benchmark INFO: eta: 10:24:45  iter: 7400  loss: 0.7014 (0.7432)  auxiliary_ctx: 0.1416 (0.1470)  auxiliary_frq: 0.1838 (0.1910)  auxiliary_vis: 0.1548 (0.1638)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2234 (0.2415)  time: 1.1379 (1.1499)  data: 0.0177 (0.0252)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:43:40,486 maskrcnn_benchmark INFO: eta: 10:20:45  iter: 7600  loss: 0.7566 (0.7430)  auxiliary_ctx: 0.1505 (0.1470)  auxiliary_frq: 0.1896 (0.1908)  auxiliary_vis: 0.1649 (0.1637)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2494 (0.2415)  time: 1.1371 (1.1495)  data: 0.0220 (0.0250)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:47:30,518 maskrcnn_benchmark INFO: eta: 10:16:57  iter: 7800  loss: 0.7548 (0.7424)  auxiliary_ctx: 0.1553 (0.1469)  auxiliary_frq: 0.1895 (0.1906)  auxiliary_vis: 0.1685 (0.1636)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2454 (0.2413)  time: 1.1417 (1.1496)  data: 0.0241 (0.0246)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:51:20,610 maskrcnn_benchmark INFO: ---Total norm 0.23787 clip coef 21.01965-----------------\n",
      "2020-06-09 13:51:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.13979, (torch.Size([4096, 12544]))\n",
      "2020-06-09 13:51:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.09050, (torch.Size([4096, 12544]))\n",
      "2020-06-09 13:51:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.08111, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-09 13:51:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06818, (torch.Size([4096, 4096]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06240, (torch.Size([4096, 4096]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.05788, (torch.Size([51, 4096]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.04814, (torch.Size([51, 4096]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04050, (torch.Size([4096, 1024]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03190, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03124, (torch.Size([2048, 4808]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03066, (torch.Size([2048, 4808]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02691, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02544, (torch.Size([1024, 512]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02275, (torch.Size([512, 1024]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02068, (torch.Size([512, 32]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01482, (torch.Size([128]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01410, (torch.Size([4096, 512]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00997, (torch.Size([151, 200]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00851, (torch.Size([256]))\n",
      "2020-06-09 13:51:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00780, (torch.Size([2048, 512]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00707, (torch.Size([2048, 512]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00700, (torch.Size([256]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00696, (torch.Size([51]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00632, (torch.Size([22801, 51]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00620, (torch.Size([512]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00602, (torch.Size([51]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00597, (torch.Size([4096]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00575, (torch.Size([4096]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00552, (torch.Size([1024]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00533, (torch.Size([128]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00531, (torch.Size([512]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00502, (torch.Size([4096]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00430, (torch.Size([2048]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00430, (torch.Size([2048]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00311, (torch.Size([128]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00286, (torch.Size([2048]))\n",
      "2020-06-09 13:51:20,622 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00286, (torch.Size([2048]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00236, (torch.Size([256]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00196, (torch.Size([4096]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00196, (torch.Size([4096]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00094, (torch.Size([256]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00060, (torch.Size([4096]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00043, (torch.Size([512]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00042, (torch.Size([512, 1024]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00041, (torch.Size([2048, 4424]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00039, (torch.Size([2048, 4424]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00005, (torch.Size([2048]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00005, (torch.Size([2048]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00004, (torch.Size([2048, 512]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00004, (torch.Size([2048]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00004, (torch.Size([2048]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00002, (torch.Size([2048, 512]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-09 13:51:20,623 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 13:51:20,624 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-09 13:51:20,627 maskrcnn_benchmark INFO: eta: 10:13:10  iter: 8000  loss: 0.7197 (0.7417)  auxiliary_ctx: 0.1423 (0.1468)  auxiliary_frq: 0.1879 (0.1906)  auxiliary_vis: 0.1602 (0.1634)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2304 (0.2410)  time: 1.1401 (1.1497)  data: 0.0270 (0.0246)  lr: 0.640000  max mem: 6316\n",
      "2020-06-09 13:51:20,630 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0008000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 13:51:23,162 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 13:51:23,194 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.86it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "2020-06-09 13:52:54,326 maskrcnn_benchmark INFO: Total run time: 0:01:31.131692 (0.14581070671081542 s / img per device, on 8 devices)\n",
      "2020-06-09 13:52:54,326 maskrcnn_benchmark INFO: Model inference time: 0:01:10.586701 (0.1129387222290039 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.50s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.31s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 13:54:27,805 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2349;   R @ 50: 0.3245;   R @ 100: 0.3823;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2908; ngR @ 50: 0.4674; ngR @ 100: 0.6169;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0822;  zR @ 50: 0.1289;  zR @ 100: 0.1570;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1756;  mR @ 50: 0.2371;  mR @ 100: 0.2706;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2658) (across:0.0000) (against:0.0000) (along:0.6667) (and:0.0000) (at:0.6857) (attached to:0.0229) (behind:0.5187) (belonging to:0.0000) (between:0.0000) (carrying:0.7083) (covered in:0.4405) (covering:0.2639) (eating:1.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.3603) (has:0.5211) (holding:0.4191) (in:0.3745) (in front of:0.4588) (laying on:0.0000) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0184) (of:0.4182) (on:0.3196) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.9124) (part of:0.0000) (playing:0.0000) (riding:0.9330) (says:0.0000) (sitting on:0.6511) (standing on:0.1902) (to:0.0000) (under:0.3180) (using:0.0385) (walking in:0.0000) (walking on:0.9473) (watching:0.6275) (wearing:0.5517) (wears:0.3795) (with:0.3408) \n",
      "SGG eval:   A @ 20: 0.4344;   A @ 50: 0.4382;   A @ 100: 0.4382;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 13:54:28,566 maskrcnn_benchmark INFO: Validation Result: 0.3823\n",
      "2020-06-09 13:58:18,014 maskrcnn_benchmark INFO: eta: 10:54:30  iter: 8200  loss: 0.7496 (0.7411)  auxiliary_ctx: 0.1468 (0.1467)  auxiliary_frq: 0.1955 (0.1904)  auxiliary_vis: 0.1742 (0.1632)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2361 (0.2408)  time: 1.1398 (1.2349)  data: 0.0206 (0.1099)  lr: 0.640000  max mem: 6376\n",
      "2020-06-09 14:02:08,076 maskrcnn_benchmark INFO: eta: 10:46:40  iter: 8400  loss: 0.7183 (0.7409)  auxiliary_ctx: 0.1429 (0.1466)  auxiliary_frq: 0.1865 (0.1903)  auxiliary_vis: 0.1573 (0.1632)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2247 (0.2407)  time: 1.1482 (1.2279)  data: 0.0234 (0.1028)  lr: 0.640000  max mem: 6376\n",
      "2020-06-09 14:05:58,271 maskrcnn_benchmark INFO: eta: 10:39:29  iter: 8600  loss: 0.6910 (0.7407)  auxiliary_ctx: 0.1385 (0.1466)  auxiliary_frq: 0.1828 (0.1902)  auxiliary_vis: 0.1534 (0.1632)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2283 (0.2407)  time: 1.1463 (1.2219)  data: 0.0237 (0.0968)  lr: 0.640000  max mem: 6376\n",
      "2020-06-09 14:09:48,196 maskrcnn_benchmark INFO: eta: 10:32:43  iter: 8800  loss: 0.7290 (0.7399)  auxiliary_ctx: 0.1403 (0.1464)  auxiliary_frq: 0.1866 (0.1900)  auxiliary_vis: 0.1569 (0.1630)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2346 (0.2404)  time: 1.1440 (1.2168)  data: 0.0258 (0.0915)  lr: 0.640000  max mem: 6376\n",
      "2020-06-09 14:13:37,897 maskrcnn_benchmark INFO: eta: 10:26:19  iter: 9000  loss: 0.7641 (0.7392)  auxiliary_ctx: 0.1482 (0.1463)  auxiliary_frq: 0.1928 (0.1899)  auxiliary_vis: 0.1683 (0.1628)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2528 (0.2401)  time: 1.1434 (1.2122)  data: 0.0272 (0.0871)  lr: 0.640000  max mem: 6376\n",
      "2020-06-09 14:17:27,724 maskrcnn_benchmark INFO: eta: 10:20:15  iter: 9200  loss: 0.7320 (0.7389)  auxiliary_ctx: 0.1473 (0.1463)  auxiliary_frq: 0.1868 (0.1898)  auxiliary_vis: 0.1576 (0.1628)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2350 (0.2400)  time: 1.1444 (1.2083)  data: 0.0259 (0.0832)  lr: 0.640000  max mem: 6376\n",
      "2020-06-09 14:21:17,409 maskrcnn_benchmark INFO: eta: 10:14:25  iter: 9400  loss: 0.7119 (0.7383)  auxiliary_ctx: 0.1389 (0.1462)  auxiliary_frq: 0.1841 (0.1896)  auxiliary_vis: 0.1583 (0.1626)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2316 (0.2399)  time: 1.1439 (1.2048)  data: 0.0211 (0.0798)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 14:25:07,324 maskrcnn_benchmark INFO: eta: 10:08:51  iter: 9600  loss: 0.7379 (0.7382)  auxiliary_ctx: 0.1417 (0.1462)  auxiliary_frq: 0.1858 (0.1895)  auxiliary_vis: 0.1606 (0.1626)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2312 (0.2399)  time: 1.1428 (1.2017)  data: 0.0211 (0.0766)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 14:28:57,007 maskrcnn_benchmark INFO: eta: 10:03:26  iter: 9800  loss: 0.7238 (0.7379)  auxiliary_ctx: 0.1423 (0.1462)  auxiliary_frq: 0.1827 (0.1894)  auxiliary_vis: 0.1523 (0.1625)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2315 (0.2398)  time: 1.1448 (1.1989)  data: 0.0182 (0.0738)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 14:32:47,243 maskrcnn_benchmark INFO: eta: 9:58:15  iter: 10000  loss: 0.6749 (0.7371)  auxiliary_ctx: 0.1352 (0.1460)  auxiliary_frq: 0.1802 (0.1893)  auxiliary_vis: 0.1490 (0.1623)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2154 (0.2395)  time: 1.1480 (1.1965)  data: 0.0228 (0.0714)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 14:32:47,246 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0010000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 14:32:49,441 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 14:32:49,474 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.72it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.72it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.72it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.72it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.72it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.88it/s]\n",
      "2020-06-09 14:34:20,373 maskrcnn_benchmark INFO: Total run time: 0:01:30.898760 (0.14543801574707033 s / img per device, on 8 devices)\n",
      "2020-06-09 14:34:20,374 maskrcnn_benchmark INFO: Model inference time: 0:01:10.134195 (0.11221471214294433 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.52s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.32s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 14:35:55,112 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2532;   R @ 50: 0.3618;   R @ 100: 0.4269;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3114; ngR @ 50: 0.4984; ngR @ 100: 0.6415;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0756;  zR @ 50: 0.1489;  zR @ 100: 0.1785;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1706;  mR @ 50: 0.2449;  mR @ 100: 0.2799;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2082) (across:0.0000) (against:0.0000) (along:0.7372) (and:0.0000) (at:0.8271) (attached to:0.0459) (behind:0.5347) (belonging to:0.0000) (between:0.0000) (carrying:0.7412) (covered in:0.5833) (covering:0.3095) (eating:0.8571) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.4044) (has:0.5941) (holding:0.2650) (in:0.3224) (in front of:0.4912) (laying on:0.0952) (looking at:0.0217) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0193) (of:0.5958) (on:0.4092) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.8806) (part of:0.0000) (playing:0.0000) (riding:0.8438) (says:0.0000) (sitting on:0.5818) (standing on:0.2261) (to:0.0000) (under:0.3227) (using:0.1923) (walking in:0.0000) (walking on:0.9283) (watching:0.6471) (wearing:0.4468) (wears:0.4175) (with:0.2986) \n",
      "SGG eval:   A @ 20: 0.4990;   A @ 50: 0.5037;   A @ 100: 0.5037;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 14:35:55,878 maskrcnn_benchmark INFO: Validation Result: 0.4269\n",
      "2020-06-09 14:39:45,761 maskrcnn_benchmark INFO: eta: 10:15:27  iter: 10200  loss: 0.7203 (0.7366)  auxiliary_ctx: 0.1450 (0.1460)  auxiliary_frq: 0.1863 (0.1891)  auxiliary_vis: 0.1588 (0.1622)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2310 (0.2393)  time: 1.1421 (1.2392)  data: 0.0271 (0.1141)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 14:43:35,747 maskrcnn_benchmark INFO: eta: 10:09:19  iter: 10400  loss: 0.7157 (0.7366)  auxiliary_ctx: 0.1436 (0.1460)  auxiliary_frq: 0.1823 (0.1891)  auxiliary_vis: 0.1620 (0.1622)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2362 (0.2393)  time: 1.1560 (1.2351)  data: 0.0250 (0.1101)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 14:47:25,830 maskrcnn_benchmark INFO: eta: 10:03:24  iter: 10600  loss: 0.7234 (0.7362)  auxiliary_ctx: 0.1425 (0.1459)  auxiliary_frq: 0.1888 (0.1890)  auxiliary_vis: 0.1570 (0.1621)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2387 (0.2392)  time: 1.1384 (1.2314)  data: 0.0253 (0.1063)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 14:51:15,505 maskrcnn_benchmark INFO: eta: 9:57:36  iter: 10800  loss: 0.7033 (0.7359)  auxiliary_ctx: 0.1371 (0.1459)  auxiliary_frq: 0.1808 (0.1889)  auxiliary_vis: 0.1559 (0.1620)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2275 (0.2391)  time: 1.1445 (1.2280)  data: 0.0180 (0.1029)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 14:55:05,957 maskrcnn_benchmark INFO: eta: 9:52:03  iter: 11000  loss: 0.6908 (0.7355)  auxiliary_ctx: 0.1372 (0.1459)  auxiliary_frq: 0.1823 (0.1888)  auxiliary_vis: 0.1565 (0.1619)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2311 (0.2389)  time: 1.1466 (1.2249)  data: 0.0202 (0.0997)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 14:58:55,920 maskrcnn_benchmark INFO: eta: 9:46:35  iter: 11200  loss: 0.7205 (0.7353)  auxiliary_ctx: 0.1417 (0.1459)  auxiliary_frq: 0.1852 (0.1887)  auxiliary_vis: 0.1634 (0.1619)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2485 (0.2389)  time: 1.1456 (1.2221)  data: 0.0262 (0.0969)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:02:46,006 maskrcnn_benchmark INFO: eta: 9:41:15  iter: 11400  loss: 0.7248 (0.7353)  auxiliary_ctx: 0.1498 (0.1459)  auxiliary_frq: 0.1850 (0.1886)  auxiliary_vis: 0.1657 (0.1618)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2324 (0.2389)  time: 1.1415 (1.2194)  data: 0.0262 (0.0942)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:06:36,143 maskrcnn_benchmark INFO: eta: 9:36:01  iter: 11600  loss: 0.7097 (0.7348)  auxiliary_ctx: 0.1421 (0.1458)  auxiliary_frq: 0.1880 (0.1886)  auxiliary_vis: 0.1585 (0.1617)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2273 (0.2387)  time: 1.1516 (1.2170)  data: 0.0250 (0.0917)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:10:25,615 maskrcnn_benchmark INFO: eta: 9:30:50  iter: 11800  loss: 0.7244 (0.7344)  auxiliary_ctx: 0.1451 (0.1458)  auxiliary_frq: 0.1813 (0.1884)  auxiliary_vis: 0.1582 (0.1616)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2323 (0.2386)  time: 1.1492 (1.2146)  data: 0.0248 (0.0894)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:14:16,178 maskrcnn_benchmark INFO: ---Total norm 0.26517 clip coef 18.85568-----------------\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.16787, (torch.Size([4096, 12544]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.09149, (torch.Size([4096, 12544]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.08105, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.07374, (torch.Size([4096, 4096]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.07146, (torch.Size([4096, 4096]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05436, (torch.Size([51, 4096]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.05033, (torch.Size([51, 4096]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04834, (torch.Size([4096, 1024]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03785, (torch.Size([2048, 4808]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.03653, (torch.Size([512, 32]))\n",
      "2020-06-09 15:14:16,188 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03599, (torch.Size([2048, 4808]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02932, (torch.Size([512, 1024]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02873, (torch.Size([1024, 512]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02813, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02580, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01745, (torch.Size([4096, 512]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01268, (torch.Size([512]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01052, (torch.Size([1024]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01032, (torch.Size([51]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01020, (torch.Size([151, 200]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01014, (torch.Size([128]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00966, (torch.Size([512]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00921, (torch.Size([4096]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00843, (torch.Size([4096]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00815, (torch.Size([2048, 512]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00807, (torch.Size([2048, 512]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00709, (torch.Size([51]))\n",
      "2020-06-09 15:14:16,189 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00665, (torch.Size([22801, 51]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00647, (torch.Size([2048]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00647, (torch.Size([2048]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00554, (torch.Size([2048]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00554, (torch.Size([2048]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00496, (torch.Size([256]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00485, (torch.Size([4096]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00455, (torch.Size([128]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00445, (torch.Size([256]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00319, (torch.Size([128]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00226, (torch.Size([4096]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00225, (torch.Size([256]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00183, (torch.Size([4096]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00083, (torch.Size([256]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00059, (torch.Size([512]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00055, (torch.Size([4096]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00050, (torch.Size([512, 1024]))\n",
      "2020-06-09 15:14:16,190 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00011, (torch.Size([2048, 4424]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00007, (torch.Size([2048, 4424]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00002, (torch.Size([2048]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00002, (torch.Size([2048]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00001, (torch.Size([2048]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00001, (torch.Size([2048]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00001, (torch.Size([2048, 512]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00001, (torch.Size([2048, 512]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 15:14:16,191 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-09 15:14:16,194 maskrcnn_benchmark INFO: eta: 9:25:49  iter: 12000  loss: 0.6961 (0.7339)  auxiliary_ctx: 0.1384 (0.1457)  auxiliary_frq: 0.1810 (0.1883)  auxiliary_vis: 0.1494 (0.1615)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2189 (0.2384)  time: 1.1515 (1.2125)  data: 0.0258 (0.0872)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:14:16,197 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0012000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 15:14:18,456 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 15:14:18,510 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.89it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "2020-06-09 15:15:49,236 maskrcnn_benchmark INFO: Total run time: 0:01:30.725488 (0.14516078071594238 s / img per device, on 8 devices)\n",
      "2020-06-09 15:15:49,236 maskrcnn_benchmark INFO: Model inference time: 0:01:09.548147 (0.11127703552246093 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.61s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.34s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 15:17:22,052 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2452;   R @ 50: 0.3504;   R @ 100: 0.4141;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2882; ngR @ 50: 0.4622; ngR @ 100: 0.6101;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0889;  zR @ 50: 0.1415;  zR @ 100: 0.1578;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1687;  mR @ 50: 0.2256;  mR @ 100: 0.2597;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2432) (across:0.0000) (against:0.0000) (along:0.5000) (and:0.0000) (at:0.6561) (attached to:0.0000) (behind:0.5327) (belonging to:0.0000) (between:0.0000) (carrying:0.7741) (covered in:0.3690) (covering:0.2299) (eating:0.2857) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.7721) (has:0.5883) (holding:0.2120) (in:0.3119) (in front of:0.4917) (laying on:0.0000) (looking at:0.1087) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0285) (of:0.5246) (on:0.3655) (on back of:0.0000) (over:0.0793) (painted on:0.0000) (parked on:0.8847) (part of:0.0000) (playing:0.0000) (riding:0.9286) (says:0.0000) (sitting on:0.5991) (standing on:0.1250) (to:0.0000) (under:0.4324) (using:0.1923) (walking in:0.0000) (walking on:0.9661) (watching:0.6275) (wearing:0.5296) (wears:0.3146) (with:0.2748) \n",
      "SGG eval:   A @ 20: 0.4831;   A @ 50: 0.4875;   A @ 100: 0.4875;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 15:17:22,825 maskrcnn_benchmark INFO: Validation Result: 0.4141\n",
      "2020-06-09 15:21:12,457 maskrcnn_benchmark INFO: eta: 9:34:46  iter: 12200  loss: 0.7027 (0.7336)  auxiliary_ctx: 0.1396 (0.1456)  auxiliary_frq: 0.1829 (0.1882)  auxiliary_vis: 0.1520 (0.1614)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2215 (0.2383)  time: 1.1503 (1.2405)  data: 0.0254 (0.1153)  lr: 0.640000  max mem: 6460\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "2020-06-09 15:25:02,102 maskrcnn_benchmark INFO: eta: 9:29:18  iter: 12400  loss: 0.7152 (0.7332)  auxiliary_ctx: 0.1405 (0.1456)  auxiliary_frq: 0.1863 (0.1881)  auxiliary_vis: 0.1546 (0.1613)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2290 (0.2382)  time: 1.1446 (1.2376)  data: 0.0256 (0.1124)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:28:52,207 maskrcnn_benchmark INFO: eta: 9:23:58  iter: 12600  loss: 0.7331 (0.7328)  auxiliary_ctx: 0.1454 (0.1455)  auxiliary_frq: 0.1860 (0.1880)  auxiliary_vis: 0.1617 (0.1612)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2350 (0.2380)  time: 1.1527 (1.2350)  data: 0.0249 (0.1098)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:32:41,349 maskrcnn_benchmark INFO: eta: 9:18:40  iter: 12800  loss: 0.7041 (0.7323)  auxiliary_ctx: 0.1397 (0.1455)  auxiliary_frq: 0.1835 (0.1879)  auxiliary_vis: 0.1547 (0.1611)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2177 (0.2379)  time: 1.1421 (1.2324)  data: 0.0228 (0.1072)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:36:31,992 maskrcnn_benchmark INFO: eta: 9:13:32  iter: 13000  loss: 0.6919 (0.7320)  auxiliary_ctx: 0.1354 (0.1454)  auxiliary_frq: 0.1777 (0.1878)  auxiliary_vis: 0.1517 (0.1610)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2236 (0.2378)  time: 1.1571 (1.2301)  data: 0.0252 (0.1049)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:40:21,918 maskrcnn_benchmark INFO: eta: 9:08:27  iter: 13200  loss: 0.6953 (0.7322)  auxiliary_ctx: 0.1436 (0.1455)  auxiliary_frq: 0.1772 (0.1878)  auxiliary_vis: 0.1567 (0.1610)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2267 (0.2379)  time: 1.1470 (1.2279)  data: 0.0255 (0.1026)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:44:12,555 maskrcnn_benchmark INFO: eta: 9:03:27  iter: 13400  loss: 0.7165 (0.7317)  auxiliary_ctx: 0.1447 (0.1454)  auxiliary_frq: 0.1873 (0.1877)  auxiliary_vis: 0.1553 (0.1609)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2323 (0.2377)  time: 1.1504 (1.2259)  data: 0.0252 (0.1004)  lr: 0.640000  max mem: 6460\n",
      "2020-06-09 15:48:02,597 maskrcnn_benchmark INFO: eta: 8:58:30  iter: 13600  loss: 0.6963 (0.7316)  auxiliary_ctx: 0.1391 (0.1454)  auxiliary_frq: 0.1810 (0.1876)  auxiliary_vis: 0.1526 (0.1609)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2232 (0.2377)  time: 1.1453 (1.2239)  data: 0.0216 (0.0984)  lr: 0.640000  max mem: 6570\n",
      "2020-06-09 15:51:52,183 maskrcnn_benchmark INFO: eta: 8:53:34  iter: 13800  loss: 0.7170 (0.7314)  auxiliary_ctx: 0.1433 (0.1454)  auxiliary_frq: 0.1860 (0.1875)  auxiliary_vis: 0.1600 (0.1608)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2234 (0.2376)  time: 1.1406 (1.2219)  data: 0.0243 (0.0965)  lr: 0.640000  max mem: 6570\n",
      "2020-06-09 15:55:42,232 maskrcnn_benchmark INFO: eta: 8:48:43  iter: 14000  loss: 0.7014 (0.7311)  auxiliary_ctx: 0.1420 (0.1454)  auxiliary_frq: 0.1831 (0.1874)  auxiliary_vis: 0.1537 (0.1607)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2197 (0.2375)  time: 1.1374 (1.2201)  data: 0.0263 (0.0947)  lr: 0.640000  max mem: 6570\n",
      "2020-06-09 15:55:42,235 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0014000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 15:55:44,665 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 15:55:44,713 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.93it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "2020-06-09 15:57:14,974 maskrcnn_benchmark INFO: Total run time: 0:01:30.260776 (0.14441724166870118 s / img per device, on 8 devices)\n",
      "2020-06-09 15:57:14,974 maskrcnn_benchmark INFO: Model inference time: 0:01:09.535037 (0.11125605926513672 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.48s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=27.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.47s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 15:58:51,015 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2441;   R @ 50: 0.3395;   R @ 100: 0.3954;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3063; ngR @ 50: 0.4930; ngR @ 100: 0.6367;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.1059;  zR @ 50: 0.1370;  zR @ 100: 0.1674;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1900;  mR @ 50: 0.2443;  mR @ 100: 0.2765;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2046) (across:0.0000) (against:0.0000) (along:0.6154) (and:0.0000) (at:0.7791) (attached to:0.0564) (behind:0.5036) (belonging to:0.0000) (between:0.0000) (carrying:0.7281) (covered in:0.2143) (covering:0.2483) (eating:1.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.6765) (has:0.5976) (holding:0.4066) (in:0.3432) (in front of:0.5064) (laying on:0.0476) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0539) (of:0.4782) (on:0.3954) (on back of:0.0000) (over:0.1098) (painted on:0.0000) (parked on:0.8681) (part of:0.0000) (playing:0.0000) (riding:0.9241) (says:0.0000) (sitting on:0.5283) (standing on:0.1424) (to:0.0000) (under:0.2679) (using:0.1923) (walking in:0.0000) (walking on:0.9554) (watching:0.6863) (wearing:0.0239) (wears:0.8873) (with:0.2801) \n",
      "SGG eval:   A @ 20: 0.4589;   A @ 50: 0.4641;   A @ 100: 0.4641;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 15:58:51,762 maskrcnn_benchmark INFO: Validation Result: 0.3954\n",
      "2020-06-09 15:58:51,763 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "2020-06-09 16:02:41,463 maskrcnn_benchmark INFO: eta: 8:53:50  iter: 14200  loss: 0.6884 (0.7302)  auxiliary_ctx: 0.1360 (0.1452)  auxiliary_frq: 0.1829 (0.1874)  auxiliary_vis: 0.1465 (0.1605)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2119 (0.2371)  time: 1.1526 (1.2415)  data: 0.0250 (0.1160)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:06:31,136 maskrcnn_benchmark INFO: eta: 8:48:45  iter: 14400  loss: 0.6792 (0.7291)  auxiliary_ctx: 0.1355 (0.1450)  auxiliary_frq: 0.1838 (0.1873)  auxiliary_vis: 0.1457 (0.1601)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2109 (0.2367)  time: 1.1416 (1.2393)  data: 0.0256 (0.1139)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:10:21,542 maskrcnn_benchmark INFO: eta: 8:43:46  iter: 14600  loss: 0.6602 (0.7276)  auxiliary_ctx: 0.1315 (0.1447)  auxiliary_frq: 0.1806 (0.1872)  auxiliary_vis: 0.1409 (0.1597)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2008 (0.2360)  time: 1.1352 (1.2372)  data: 0.0249 (0.1117)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:14:11,049 maskrcnn_benchmark INFO: eta: 8:38:47  iter: 14800  loss: 0.6812 (0.7263)  auxiliary_ctx: 0.1344 (0.1444)  auxiliary_frq: 0.1847 (0.1871)  auxiliary_vis: 0.1438 (0.1593)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2154 (0.2355)  time: 1.1426 (1.2352)  data: 0.0241 (0.1097)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:18:01,173 maskrcnn_benchmark INFO: eta: 8:33:53  iter: 15000  loss: 0.6842 (0.7250)  auxiliary_ctx: 0.1342 (0.1441)  auxiliary_frq: 0.1894 (0.1871)  auxiliary_vis: 0.1413 (0.1589)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2080 (0.2349)  time: 1.1441 (1.2333)  data: 0.0261 (0.1078)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:21:51,010 maskrcnn_benchmark INFO: eta: 8:29:01  iter: 15200  loss: 0.6459 (0.7235)  auxiliary_ctx: 0.1293 (0.1439)  auxiliary_frq: 0.1814 (0.1870)  auxiliary_vis: 0.1329 (0.1584)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2013 (0.2342)  time: 1.1525 (1.2315)  data: 0.0191 (0.1060)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:25:41,396 maskrcnn_benchmark INFO: eta: 8:24:13  iter: 15400  loss: 0.6511 (0.7222)  auxiliary_ctx: 0.1313 (0.1436)  auxiliary_frq: 0.1826 (0.1870)  auxiliary_vis: 0.1335 (0.1579)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1991 (0.2336)  time: 1.1484 (1.2298)  data: 0.0255 (0.1042)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:29:32,111 maskrcnn_benchmark INFO: eta: 8:19:28  iter: 15600  loss: 0.6296 (0.7207)  auxiliary_ctx: 0.1235 (0.1433)  auxiliary_frq: 0.1790 (0.1869)  auxiliary_vis: 0.1316 (0.1575)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1901 (0.2329)  time: 1.1441 (1.2282)  data: 0.0243 (0.1026)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:33:21,402 maskrcnn_benchmark INFO: eta: 8:14:42  iter: 15800  loss: 0.6455 (0.7193)  auxiliary_ctx: 0.1305 (0.1431)  auxiliary_frq: 0.1834 (0.1869)  auxiliary_vis: 0.1295 (0.1570)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1985 (0.2323)  time: 1.1402 (1.2265)  data: 0.0257 (0.1010)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:37:11,194 maskrcnn_benchmark INFO: ---Total norm 0.40948 clip coef 12.21072-----------------\n",
      "2020-06-09 16:37:11,203 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.29877, (torch.Size([4096, 12544]))\n",
      "2020-06-09 16:37:11,203 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.14996, (torch.Size([4096, 12544]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.10378, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.09945, (torch.Size([4096, 4096]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.09590, (torch.Size([4096, 4096]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.07359, (torch.Size([51, 4096]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.06515, (torch.Size([512, 32]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.04789, (torch.Size([4096, 512]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.04749, (torch.Size([2048, 4808]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04723, (torch.Size([4096, 1024]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.04554, (torch.Size([2048, 4808]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.04534, (torch.Size([51, 4096]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03487, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02951, (torch.Size([512, 1024]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02568, (torch.Size([1024, 512]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02037, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01763, (torch.Size([512]))\n",
      "2020-06-09 16:37:11,204 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01680, (torch.Size([512]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01401, (torch.Size([51]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01260, (torch.Size([151, 200]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01200, (torch.Size([4096]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01166, (torch.Size([1024]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01095, (torch.Size([2048]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01095, (torch.Size([2048]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01094, (torch.Size([2048, 512]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01087, (torch.Size([4096]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01085, (torch.Size([2048, 512]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00975, (torch.Size([2048]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00975, (torch.Size([2048]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00845, (torch.Size([51]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00745, (torch.Size([128]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00700, (torch.Size([256]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00576, (torch.Size([4096]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00512, (torch.Size([22801, 51]))\n",
      "2020-06-09 16:37:11,205 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00476, (torch.Size([256]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00439, (torch.Size([4096]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00371, (torch.Size([128]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00285, (torch.Size([256]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00279, (torch.Size([4096]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00273, (torch.Size([128]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00098, (torch.Size([256]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00089, (torch.Size([4096]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00081, (torch.Size([512, 1024]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00080, (torch.Size([512]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00013, (torch.Size([2048, 4424]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00010, (torch.Size([2048, 4424]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00004, (torch.Size([2048]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00004, (torch.Size([2048]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00003, (torch.Size([2048]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00003, (torch.Size([2048]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00003, (torch.Size([2048, 512]))\n",
      "2020-06-09 16:37:11,206 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00002, (torch.Size([2048, 512]))\n",
      "2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 16:37:11,207 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-09 16:37:11,210 maskrcnn_benchmark INFO: eta: 8:09:59  iter: 16000  loss: 0.6136 (0.7177)  auxiliary_ctx: 0.1250 (0.1428)  auxiliary_frq: 0.1815 (0.1868)  auxiliary_vis: 0.1243 (0.1565)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1855 (0.2316)  time: 1.1452 (1.2250)  data: 0.0243 (0.0994)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:37:11,212 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0016000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 16:37:13,509 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 16:37:13,540 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.96it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "2020-06-09 16:38:43,321 maskrcnn_benchmark INFO: Total run time: 0:01:29.780335 (0.1436485366821289 s / img per device, on 8 devices)\n",
      "2020-06-09 16:38:43,322 maskrcnn_benchmark INFO: Model inference time: 0:01:09.708071 (0.111532914352417 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.67s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.34s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 16:40:17,256 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2278;   R @ 50: 0.3229;   R @ 100: 0.3872;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2807; ngR @ 50: 0.4605; ngR @ 100: 0.6130;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0941;  zR @ 50: 0.1593;  zR @ 100: 0.1807;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1924;  mR @ 50: 0.2588;  mR @ 100: 0.2962;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2380) (across:0.0000) (against:0.0000) (along:0.7051) (and:0.0323) (at:0.7758) (attached to:0.0413) (behind:0.5030) (belonging to:0.1071) (between:0.0000) (carrying:0.8333) (covered in:0.5119) (covering:0.3381) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.6103) (has:0.5807) (holding:0.3430) (in:0.3587) (in front of:0.5137) (laying on:0.0476) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0630) (of:0.5002) (on:0.3227) (on back of:0.0000) (over:0.1524) (painted on:0.0000) (parked on:0.9083) (part of:0.0000) (playing:0.0000) (riding:0.9196) (says:0.0000) (sitting on:0.6036) (standing on:0.2370) (to:0.1111) (under:0.3788) (using:0.1154) (walking in:0.0000) (walking on:0.9713) (watching:0.7451) (wearing:0.3834) (wears:0.4994) (with:0.2947) \n",
      "SGG eval:   A @ 20: 0.4654;   A @ 50: 0.4698;   A @ 100: 0.4698;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 16:40:18,021 maskrcnn_benchmark INFO: Validation Result: 0.3872\n",
      "2020-06-09 16:44:07,754 maskrcnn_benchmark INFO: eta: 8:12:35  iter: 16200  loss: 0.6383 (0.7161)  auxiliary_ctx: 0.1287 (0.1425)  auxiliary_frq: 0.1858 (0.1868)  auxiliary_vis: 0.1315 (0.1560)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1940 (0.2308)  time: 1.1401 (1.2418)  data: 0.0253 (0.1162)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:47:58,270 maskrcnn_benchmark INFO: eta: 8:07:46  iter: 16400  loss: 0.6294 (0.7144)  auxiliary_ctx: 0.1302 (0.1423)  auxiliary_frq: 0.1851 (0.1867)  auxiliary_vis: 0.1264 (0.1554)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1903 (0.2300)  time: 1.1475 (1.2401)  data: 0.0257 (0.1144)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:51:48,338 maskrcnn_benchmark INFO: eta: 8:02:58  iter: 16600  loss: 0.6180 (0.7127)  auxiliary_ctx: 0.1247 (0.1420)  auxiliary_frq: 0.1837 (0.1867)  auxiliary_vis: 0.1251 (0.1549)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1860 (0.2292)  time: 1.1599 (1.2384)  data: 0.0251 (0.1127)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:55:38,184 maskrcnn_benchmark INFO: eta: 7:58:12  iter: 16800  loss: 0.6044 (0.7111)  auxiliary_ctx: 0.1246 (0.1417)  auxiliary_frq: 0.1821 (0.1867)  auxiliary_vis: 0.1250 (0.1543)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1857 (0.2285)  time: 1.1480 (1.2368)  data: 0.0184 (0.1111)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 16:59:27,873 maskrcnn_benchmark INFO: eta: 7:53:28  iter: 17000  loss: 0.6124 (0.7093)  auxiliary_ctx: 0.1262 (0.1414)  auxiliary_frq: 0.1859 (0.1866)  auxiliary_vis: 0.1236 (0.1537)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1779 (0.2276)  time: 1.1485 (1.2352)  data: 0.0265 (0.1095)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 17:03:18,076 maskrcnn_benchmark INFO: eta: 7:48:47  iter: 17200  loss: 0.5802 (0.7076)  auxiliary_ctx: 0.1198 (0.1411)  auxiliary_frq: 0.1739 (0.1866)  auxiliary_vis: 0.1149 (0.1532)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1670 (0.2268)  time: 1.1562 (1.2336)  data: 0.0257 (0.1080)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 17:07:08,079 maskrcnn_benchmark INFO: eta: 7:44:07  iter: 17400  loss: 0.6008 (0.7057)  auxiliary_ctx: 0.1249 (0.1408)  auxiliary_frq: 0.1826 (0.1865)  auxiliary_vis: 0.1178 (0.1526)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1764 (0.2259)  time: 1.1441 (1.2322)  data: 0.0252 (0.1065)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 17:10:57,962 maskrcnn_benchmark INFO: eta: 7:39:28  iter: 17600  loss: 0.6128 (0.7040)  auxiliary_ctx: 0.1275 (0.1405)  auxiliary_frq: 0.1844 (0.1864)  auxiliary_vis: 0.1228 (0.1520)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1793 (0.2250)  time: 1.1481 (1.2308)  data: 0.0240 (0.1051)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 17:14:47,980 maskrcnn_benchmark INFO: eta: 7:34:52  iter: 17800  loss: 0.5953 (0.7022)  auxiliary_ctx: 0.1229 (0.1402)  auxiliary_frq: 0.1863 (0.1864)  auxiliary_vis: 0.1145 (0.1514)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1664 (0.2242)  time: 1.1407 (1.2294)  data: 0.0259 (0.1037)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 17:18:38,036 maskrcnn_benchmark INFO: eta: 7:30:17  iter: 18000  loss: 0.5913 (0.7004)  auxiliary_ctx: 0.1223 (0.1399)  auxiliary_frq: 0.1866 (0.1864)  auxiliary_vis: 0.1153 (0.1508)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1598 (0.2233)  time: 1.1556 (1.2281)  data: 0.0261 (0.1024)  lr: 0.064000  max mem: 6570\n",
      "2020-06-09 17:18:38,039 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0018000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 17:18:40,278 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 17:18:40,319 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.89it/s]\n",
      "2020-06-09 17:20:11,020 maskrcnn_benchmark INFO: Total run time: 0:01:30.700822 (0.1451213146209717 s / img per device, on 8 devices)\n",
      "2020-06-09 17:20:11,021 maskrcnn_benchmark INFO: Model inference time: 0:01:09.849605 (0.11175936775207519 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.63s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 17:21:44,010 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2346;   R @ 50: 0.3335;   R @ 100: 0.3897;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2832; ngR @ 50: 0.4650; ngR @ 100: 0.6124;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.1030;  zR @ 50: 0.1585;  zR @ 100: 0.1896;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.2040;  mR @ 50: 0.2676;  mR @ 100: 0.3052;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2884) (across:0.0000) (against:0.0526) (along:0.7436) (and:0.0645) (at:0.7185) (attached to:0.0197) (behind:0.4954) (belonging to:0.3000) (between:0.0000) (carrying:0.7807) (covered in:0.7024) (covering:0.4095) (eating:1.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.2000) (hanging from:0.4375) (has:0.5096) (holding:0.3096) (in:0.3426) (in front of:0.5078) (laying on:0.2143) (looking at:0.0870) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0475) (of:0.2824) (on:0.3878) (on back of:0.0000) (over:0.1037) (painted on:0.0000) (parked on:0.9034) (part of:0.0000) (playing:0.0000) (riding:0.9018) (says:0.0000) (sitting on:0.5994) (standing on:0.2326) (to:0.1667) (under:0.3980) (using:0.1346) (walking in:0.0000) (walking on:0.9777) (watching:0.6863) (wearing:0.2459) (wears:0.6514) (with:0.3223) \n",
      "SGG eval:   A @ 20: 0.4567;   A @ 50: 0.4613;   A @ 100: 0.4613;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 17:21:44,780 maskrcnn_benchmark INFO: Validation Result: 0.3897\n",
      "2020-06-09 17:21:44,780 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "2020-06-09 17:25:35,095 maskrcnn_benchmark INFO: eta: 7:31:18  iter: 18200  loss: 0.5699 (0.6984)  auxiliary_ctx: 0.1146 (0.1396)  auxiliary_frq: 0.1827 (0.1863)  auxiliary_vis: 0.1082 (0.1502)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1612 (0.2223)  time: 1.1457 (1.2421)  data: 0.0256 (0.1164)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 17:29:25,388 maskrcnn_benchmark INFO: eta: 7:26:38  iter: 18400  loss: 0.5958 (0.6963)  auxiliary_ctx: 0.1250 (0.1393)  auxiliary_frq: 0.1855 (0.1863)  auxiliary_vis: 0.1148 (0.1495)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1681 (0.2213)  time: 1.1441 (1.2407)  data: 0.0214 (0.1149)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 17:33:15,836 maskrcnn_benchmark INFO: eta: 7:22:00  iter: 18600  loss: 0.5710 (0.6942)  auxiliary_ctx: 0.1193 (0.1389)  auxiliary_frq: 0.1873 (0.1862)  auxiliary_vis: 0.1085 (0.1488)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1528 (0.2203)  time: 1.1465 (1.2393)  data: 0.0256 (0.1135)  lr: 0.006400  max mem: 6570\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "2020-06-09 17:37:06,160 maskrcnn_benchmark INFO: eta: 7:17:23  iter: 18800  loss: 0.5494 (0.6921)  auxiliary_ctx: 0.1150 (0.1385)  auxiliary_frq: 0.1849 (0.1862)  auxiliary_vis: 0.1006 (0.1481)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1442 (0.2192)  time: 1.1472 (1.2379)  data: 0.0263 (0.1121)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 17:40:56,168 maskrcnn_benchmark INFO: eta: 7:12:47  iter: 19000  loss: 0.5252 (0.6898)  auxiliary_ctx: 0.1099 (0.1382)  auxiliary_frq: 0.1798 (0.1861)  auxiliary_vis: 0.0950 (0.1474)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1402 (0.2181)  time: 1.1539 (1.2365)  data: 0.0243 (0.1108)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 17:44:46,437 maskrcnn_benchmark INFO: eta: 7:08:13  iter: 19200  loss: 0.5501 (0.6877)  auxiliary_ctx: 0.1119 (0.1378)  auxiliary_frq: 0.1807 (0.1861)  auxiliary_vis: 0.1027 (0.1467)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1474 (0.2171)  time: 1.1504 (1.2352)  data: 0.0259 (0.1094)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 17:48:36,747 maskrcnn_benchmark INFO: eta: 7:03:40  iter: 19400  loss: 0.5498 (0.6856)  auxiliary_ctx: 0.1136 (0.1374)  auxiliary_frq: 0.1843 (0.1861)  auxiliary_vis: 0.1041 (0.1460)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1449 (0.2160)  time: 1.1417 (1.2340)  data: 0.0232 (0.1081)  lr: 0.006400  max mem: 6570\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "2020-06-09 17:52:27,329 maskrcnn_benchmark INFO: eta: 6:59:09  iter: 19600  loss: 0.5151 (0.6834)  auxiliary_ctx: 0.1086 (0.1371)  auxiliary_frq: 0.1816 (0.1860)  auxiliary_vis: 0.0914 (0.1454)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1372 (0.2150)  time: 1.1476 (1.2328)  data: 0.0263 (0.1069)  lr: 0.006400  max mem: 6570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 17:56:17,131 maskrcnn_benchmark INFO: eta: 6:54:38  iter: 19800  loss: 0.5411 (0.6813)  auxiliary_ctx: 0.1163 (0.1367)  auxiliary_frq: 0.1857 (0.1860)  auxiliary_vis: 0.1002 (0.1447)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1421 (0.2139)  time: 1.1473 (1.2316)  data: 0.0201 (0.1057)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:00:07,292 maskrcnn_benchmark INFO: ---Total norm 0.79692 clip coef 6.27412-----------------\n",
      "2020-06-09 18:00:07,302 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.61810, (torch.Size([4096, 12544]))\n",
      "2020-06-09 18:00:07,302 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.37834, (torch.Size([4096, 12544]))\n",
      "2020-06-09 18:00:07,302 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.19996, (torch.Size([4096, 4096]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.15556, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.15001, (torch.Size([4096, 4096]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.06588, (torch.Size([51, 4096]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.06041, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.04949, (torch.Size([2048, 4808]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04917, (torch.Size([4096, 1024]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.04883, (torch.Size([2048, 4808]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.04546, (torch.Size([51, 4096]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03981, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02745, (torch.Size([1024, 512]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02718, (torch.Size([4096, 512]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02345, (torch.Size([512, 1024]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01931, (torch.Size([512, 32]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01845, (torch.Size([151, 200]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01602, (torch.Size([128]))\n",
      "2020-06-09 18:00:07,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01355, (torch.Size([4096]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01257, (torch.Size([2048, 512]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01134, (torch.Size([2048, 512]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00942, (torch.Size([256]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00903, (torch.Size([51]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00830, (torch.Size([512]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00726, (torch.Size([2048]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00726, (torch.Size([2048]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00709, (torch.Size([4096]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00705, (torch.Size([1024]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00701, (torch.Size([4096]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00668, (torch.Size([256]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00600, (torch.Size([2048]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00600, (torch.Size([2048]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00581, (torch.Size([4096]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00576, (torch.Size([128]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00572, (torch.Size([512]))\n",
      "2020-06-09 18:00:07,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00549, (torch.Size([22801, 51]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00519, (torch.Size([256]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00487, (torch.Size([51]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00483, (torch.Size([128]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00456, (torch.Size([4096]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00206, (torch.Size([4096]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00138, (torch.Size([256]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00039, (torch.Size([512]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00037, (torch.Size([512, 1024]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00001, (torch.Size([2048, 4424]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00000, (torch.Size([2048, 4424]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00000, (torch.Size([2048]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00000, (torch.Size([2048]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-09 18:00:07,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-09 18:00:07,306 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-09 18:00:07,309 maskrcnn_benchmark INFO: eta: 6:50:08  iter: 20000  loss: 0.5278 (0.6792)  auxiliary_ctx: 0.1135 (0.1363)  auxiliary_frq: 0.1844 (0.1860)  auxiliary_vis: 0.0929 (0.1440)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1361 (0.2129)  time: 1.1516 (1.2304)  data: 0.0232 (0.1045)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:00:07,311 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0020000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 18:00:09,630 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 18:00:09,659 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.78it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.78it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.78it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.78it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.78it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.78it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.78it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.95it/s]\n",
      "2020-06-09 18:01:39,617 maskrcnn_benchmark INFO: Total run time: 0:01:29.958360 (0.14393337631225586 s / img per device, on 8 devices)\n",
      "2020-06-09 18:01:39,618 maskrcnn_benchmark INFO: Model inference time: 0:01:09.230126 (0.11076820220947266 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.69s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 18:03:12,217 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2133;   R @ 50: 0.3144;   R @ 100: 0.3778;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2614; ngR @ 50: 0.4384; ngR @ 100: 0.5939;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.1178;  zR @ 50: 0.1756;  zR @ 100: 0.1978;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1913;  mR @ 50: 0.2603;  mR @ 100: 0.3006;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2184) (across:0.0000) (against:0.0351) (along:0.7821) (and:0.0645) (at:0.7101) (attached to:0.0380) (behind:0.5113) (belonging to:0.3917) (between:0.0000) (carrying:0.7807) (covered in:0.6310) (covering:0.3238) (eating:0.8571) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.1667) (hanging from:0.5184) (has:0.4608) (holding:0.2994) (in:0.3598) (in front of:0.5261) (laying on:0.2143) (looking at:0.1087) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0494) (of:0.1992) (on:0.3271) (on back of:0.0000) (over:0.2000) (painted on:0.0000) (parked on:0.9073) (part of:0.0000) (playing:0.0000) (riding:0.9107) (says:0.0000) (sitting on:0.5713) (standing on:0.2141) (to:0.1389) (under:0.3610) (using:0.2885) (walking in:0.0000) (walking on:0.9512) (watching:0.6863) (wearing:0.5804) (wears:0.2766) (with:0.3322) \n",
      "SGG eval:   A @ 20: 0.4512;   A @ 50: 0.4549;   A @ 100: 0.4549;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 18:03:12,962 maskrcnn_benchmark INFO: Validation Result: 0.3778\n",
      "2020-06-09 18:07:02,556 maskrcnn_benchmark INFO: eta: 6:49:58  iter: 20200  loss: 0.5254 (0.6772)  auxiliary_ctx: 0.1086 (0.1360)  auxiliary_frq: 0.1819 (0.1859)  auxiliary_vis: 0.0917 (0.1434)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1396 (0.2119)  time: 1.1428 (1.2423)  data: 0.0251 (0.1164)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:10:52,541 maskrcnn_benchmark INFO: eta: 6:45:24  iter: 20400  loss: 0.5255 (0.6751)  auxiliary_ctx: 0.1104 (0.1356)  auxiliary_frq: 0.1834 (0.1859)  auxiliary_vis: 0.0956 (0.1427)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1392 (0.2109)  time: 1.1440 (1.2411)  data: 0.0254 (0.1151)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:14:42,800 maskrcnn_benchmark INFO: eta: 6:40:52  iter: 20600  loss: 0.5073 (0.6731)  auxiliary_ctx: 0.1046 (0.1353)  auxiliary_frq: 0.1787 (0.1859)  auxiliary_vis: 0.0911 (0.1420)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1315 (0.2099)  time: 1.1489 (1.2398)  data: 0.0259 (0.1139)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:18:32,632 maskrcnn_benchmark INFO: eta: 6:36:21  iter: 20800  loss: 0.5010 (0.6711)  auxiliary_ctx: 0.1053 (0.1349)  auxiliary_frq: 0.1783 (0.1859)  auxiliary_vis: 0.0898 (0.1414)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1315 (0.2089)  time: 1.1469 (1.2386)  data: 0.0256 (0.1127)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:22:23,173 maskrcnn_benchmark INFO: eta: 6:31:51  iter: 21000  loss: 0.5315 (0.6691)  auxiliary_ctx: 0.1126 (0.1346)  auxiliary_frq: 0.1846 (0.1858)  auxiliary_vis: 0.0948 (0.1407)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1394 (0.2079)  time: 1.1494 (1.2375)  data: 0.0208 (0.1115)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:26:13,501 maskrcnn_benchmark INFO: eta: 6:27:23  iter: 21200  loss: 0.5263 (0.6671)  auxiliary_ctx: 0.1113 (0.1343)  auxiliary_frq: 0.1867 (0.1858)  auxiliary_vis: 0.0936 (0.1401)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1341 (0.2069)  time: 1.1439 (1.2363)  data: 0.0253 (0.1103)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:30:03,302 maskrcnn_benchmark INFO: eta: 6:22:54  iter: 21400  loss: 0.5055 (0.6652)  auxiliary_ctx: 0.1044 (0.1339)  auxiliary_frq: 0.1831 (0.1858)  auxiliary_vis: 0.0891 (0.1395)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1330 (0.2060)  time: 1.1429 (1.2352)  data: 0.0255 (0.1092)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:33:52,870 maskrcnn_benchmark INFO: eta: 6:18:27  iter: 21600  loss: 0.5005 (0.6633)  auxiliary_ctx: 0.1046 (0.1336)  auxiliary_frq: 0.1828 (0.1858)  auxiliary_vis: 0.0884 (0.1389)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1321 (0.2050)  time: 1.1497 (1.2341)  data: 0.0256 (0.1081)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:37:43,278 maskrcnn_benchmark INFO: eta: 6:14:01  iter: 21800  loss: 0.5202 (0.6613)  auxiliary_ctx: 0.1055 (0.1333)  auxiliary_frq: 0.1852 (0.1857)  auxiliary_vis: 0.0929 (0.1382)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1296 (0.2040)  time: 1.1474 (1.2330)  data: 0.0247 (0.1071)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:41:33,341 maskrcnn_benchmark INFO: eta: 6:09:36  iter: 22000  loss: 0.4795 (0.6593)  auxiliary_ctx: 0.1011 (0.1329)  auxiliary_frq: 0.1821 (0.1857)  auxiliary_vis: 0.0822 (0.1376)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1136 (0.2031)  time: 1.1513 (1.2320)  data: 0.0250 (0.1060)  lr: 0.006400  max mem: 6570\n",
      "2020-06-09 18:41:33,344 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE/model_0022000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-09 18:41:35,757 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-09 18:41:35,784 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.93it/s]\n",
      "2020-06-09 18:43:06,026 maskrcnn_benchmark INFO: Total run time: 0:01:30.241856 (0.14438696899414064 s / img per device, on 8 devices)\n",
      "2020-06-09 18:43:06,026 maskrcnn_benchmark INFO: Model inference time: 0:01:10.400124 (0.11264019889831543 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 18:44:39,813 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2198;   R @ 50: 0.3194;   R @ 100: 0.3815;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2645; ngR @ 50: 0.4354; ngR @ 100: 0.5853;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.1222;  zR @ 50: 0.1637;  zR @ 100: 0.1874;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1922;  mR @ 50: 0.2617;  mR @ 100: 0.3048;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2356) (across:0.0000) (against:0.0877) (along:0.7051) (and:0.0645) (at:0.7101) (attached to:0.0564) (behind:0.5131) (belonging to:0.4321) (between:0.0000) (carrying:0.7544) (covered in:0.6667) (covering:0.3238) (eating:1.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.2333) (hanging from:0.4890) (has:0.4842) (holding:0.3162) (in:0.3477) (in front of:0.5195) (laying on:0.1667) (looking at:0.1522) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0574) (of:0.1920) (on:0.3169) (on back of:0.0000) (over:0.2000) (painted on:0.0000) (parked on:0.8994) (part of:0.0000) (playing:0.0000) (riding:0.9107) (says:0.0000) (sitting on:0.5710) (standing on:0.1938) (to:0.2500) (under:0.3686) (using:0.2115) (walking in:0.0000) (walking on:0.9382) (watching:0.6863) (wearing:0.6657) (wears:0.1934) (with:0.2896) \n",
      "SGG eval:   A @ 20: 0.4544;   A @ 50: 0.4585;   A @ 100: 0.4585;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-09 18:44:40,579 maskrcnn_benchmark INFO: Validation Result: 0.3815\n",
      "2020-06-09 18:44:40,579 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "2020-06-09 18:44:40,579 maskrcnn_benchmark INFO: Trigger MAX_DECAY_STEP at iteration 22000.\n",
      "2020-06-09 18:44:40,872 maskrcnn_benchmark INFO: Total training time: 5:31:39.661527 (0.4975 s / it)\n",
      "2020-06-09 18:44:42,825 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:51<00:00,  7.01it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:51<00:00,  7.01it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:51<00:00,  7.01it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:51<00:00,  7.01it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:51<00:00,  7.01it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:51<00:00,  7.01it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:51<00:00,  7.01it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:51<00:00,  7.01it/s]\n",
      "2020-06-09 18:52:34,686 maskrcnn_benchmark INFO: Total run time: 0:07:51.860212 (0.1427392306165905 s / img per device, on 8 devices)\n",
      "2020-06-09 18:52:34,686 maskrcnn_benchmark INFO: Model inference time: 0:06:12.209526 (0.1125945778790269 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(325563, 7)\n",
      "0/325563\n",
      "DONE (t=3.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=137.38s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=19.82s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.659\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.995\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-09 19:01:17,444 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9995\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2503;   R @ 50: 0.3583;   R @ 100: 0.4147;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2947; ngR @ 50: 0.4774; ngR @ 100: 0.6148;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0765;  zR @ 50: 0.1217;  zR @ 100: 0.1507;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1735;  mR @ 50: 0.2466;  mR @ 100: 0.2881;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2126) (across:0.0000) (against:0.0645) (along:0.3731) (and:0.0651) (at:0.5288) (attached to:0.0573) (behind:0.5791) (belonging to:0.4395) (between:0.0035) (carrying:0.6556) (covered in:0.7220) (covering:0.4043) (eating:0.6625) (flying in:0.0000) (for:0.1210) (from:0.0000) (growing on:0.1897) (hanging from:0.3042) (has:0.5607) (holding:0.4697) (in:0.3309) (in front of:0.4084) (laying on:0.2849) (looking at:0.1422) (lying on:0.0102) (made of:0.0000) (mounted on:0.0104) (near:0.0484) (of:0.2657) (on:0.3058) (on back of:0.0591) (over:0.1727) (painted on:0.0216) (parked on:0.8238) (part of:0.0000) (playing:0.0000) (riding:0.8881) (says:0.0000) (sitting on:0.5616) (standing on:0.2560) (to:0.1298) (under:0.4380) (using:0.2964) (walking in:0.0070) (walking on:0.8113) (watching:0.6163) (wearing:0.7736) (wears:0.0993) (with:0.2313) \n",
      "SGG eval:   A @ 20: 0.4617;   A @ 50: 0.4634;   A @ 100: 0.4634;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# resume:\n",
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10025 --nproc_per_node=8 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE \\\n",
    "SOLVER.IMS_PER_BATCH 64 TEST.IMS_PER_BATCH 8 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 40000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/precls-CausalAnalysisPredictor-motifs-sum-TDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T16:19:57.056790Z",
     "start_time": "2020-06-10T09:03:42.520485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-10 09:04:00,443 maskrcnn_benchmark INFO: Using 8 GPUs\n",
      "2020-06-10 09:04:00,443 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'gate', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE'], skip_test=False)\n",
      "2020-06-10 09:04:00,443 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-10 09:04:05,572 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n",
      "2020-06-10 09:04:05,573 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml\n",
      "2020-06-10 09:04:05,573 maskrcnn_benchmark INFO: \n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MAX_SIZE_TEST: 1000\n",
      "MODEL:\n",
      "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
      "  WEIGHT: \"catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\"\n",
      "  BACKBONE:\n",
      "    CONV_BODY: \"R-101-FPN\" # VGG-16\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    STRIDE_IN_1X1: False\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RELATION_ON: True\n",
      "  ATTRIBUTE_ON: False\n",
      "  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false\n",
      "  RPN:\n",
      "    USE_FPN: True\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    RPN_MID_CHANNEL: 256\n",
      "  ROI_HEADS:\n",
      "    USE_FPN: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "  ROI_BOX_HEAD:\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA\n",
      "    MLP_HEAD_DIM: 4096\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight\n",
      "    POS_WEIGHT: 50.0\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA\n",
      "    MAX_ATTRIBUTES: 10             \n",
      "    ATTRIBUTE_BGFG_SAMPLE: True    \n",
      "    ATTRIBUTE_BGFG_RATIO: 3        \n",
      "  ROI_RELATION_HEAD:\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing\n",
      "    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain \"to the left of\" & \"to the right of\")\n",
      "    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    FEATURE_EXTRACTOR: \"RelationFeatureExtractor\"\n",
      "    #################### Select Relationship Model ####################\n",
      "    #PREDICTOR: \"MotifPredictor\"\n",
      "    #PREDICTOR: \"VCTreePredictor\"\n",
      "    #PREDICTOR: \"TransformerPredictor\"\n",
      "    PREDICTOR: \"CausalAnalysisPredictor\"\n",
      "    ################# Parameters for Motif Predictor ##################\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    ############# Parameters for Causal Unbias Predictor ##############\n",
      "    ### Implementation for paper \"Unbiased Scene Graph Generation from Biased Training\"\n",
      "    CAUSAL:\n",
      "      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'\n",
      "      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         \n",
      "      SEPARATE_SPATIAL: False         # separate spatial in union feature\n",
      "      CONTEXT_LAYER: \"motifs\"         # candicates: motifs, vctree, vtranse\n",
      "      SPATIAL_FOR_VISION: True\n",
      "      EFFECT_ANALYSIS: True\n",
      "    ############### Parameters for Transformer Predictor ##############\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      NUM_HEAD: 8\n",
      "      KEY_DIM: 64\n",
      "      VAL_DIM: 64\n",
      "      INNER_DIM: 2048 \n",
      "DATASETS:\n",
      "  TRAIN: (\"VG_stanford_filtered_with_attribute_train\",)\n",
      "  VAL: (\"VG_stanford_filtered_with_attribute_val\",)\n",
      "  TEST: (\"VG_stanford_filtered_with_attribute_test\",)\n",
      "DATALOADER:\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "SOLVER:\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  BASE_LR: 0.01\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  MOMENTUM: 0.9\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  STEPS: (10000, 16000)\n",
      "  MAX_ITER: 40000\n",
      "  VAL_PERIOD: 2000\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    # the following paramters are only used for WarmupReduceLROnPlateau\n",
      "    TYPE: \"WarmupReduceLROnPlateau\"    # WarmupMultiStepLR, WarmupReduceLROnPlateau\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "OUTPUT_DIR: './output/relation_baseline'\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  RELATION:\n",
      "    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem\n",
      "    REQUIRE_OVERLAP: False\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "\n",
      "2020-06-10 09:04:05,576 maskrcnn_benchmark INFO: Running with config:\n",
      "AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: TDE\n",
      "      FUSION_TYPE: gate\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 64\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 8\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-10 09:04:05,577 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-10 09:04:05,609 maskrcnn_benchmark INFO: #################### prepare training ####################\n",
      "2020-06-10 09:04:08,923 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-10 09:04:08,923 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7165.13it/s]\n",
      " 92%|████████████████████████████████▏  | 51741/56224 [00:07<00:00, 6484.30it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7165.99it/s]\n",
      " 93%|████████████████████████████████▍  | 52131/56224 [00:07<00:00, 6317.67it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6977.83it/s]\n",
      " 94%|████████████████████████████████▊  | 52764/56224 [00:07<00:00, 6281.42it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 95%|█████████████████████████████████▏ | 53393/56224 [00:07<00:00, 6193.26it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 95%|█████████████████████████████████▏ | 53395/56224 [00:07<00:00, 6128.42it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 96%|█████████████████████████████████▋ | 54063/56224 [00:07<00:00, 6333.69it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 88%|██████████████████████████████▉    | 49638/56224 [00:07<00:01, 4809.40it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7221.32it/s]\n",
      " 98%|██████████████████████████████████▍| 55311/56224 [00:07<00:00, 5933.34it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-10 09:04:36,134 maskrcnn_benchmark.data.build INFO: finish\n",
      "2020-06-10 09:04:36,135 maskrcnn_benchmark.data.build INFO: Save data statistics to: checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-10 09:04:36,135 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7074.00it/s]\n",
      " 90%|███████████████████████████████▌   | 50603/56224 [00:07<00:01, 4746.93it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7058.69it/s]\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      " 91%|███████████████████████████████▊   | 51110/56224 [00:07<00:01, 4837.68it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      " 92%|████████████████████████████████   | 51595/56224 [00:08<00:00, 4813.16it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 99%|██████████████████████████████████▊| 55823/56224 [00:08<00:00, 5809.32it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6881.65it/s]\n",
      " 94%|████████████████████████████████▊  | 52748/56224 [00:08<00:00, 5270.58it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 95%|█████████████████████████████████▏ | 53339/56224 [00:08<00:00, 5446.08it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      " 96%|█████████████████████████████████▌ | 54005/56224 [00:08<00:00, 5760.27it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      " 97%|██████████████████████████████████ | 54631/56224 [00:08<00:00, 5900.94it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 98%|██████████████████████████████████▍| 55229/56224 [00:08<00:00, 5787.61it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6338.30it/s]\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "2020-06-10 09:04:37,448 maskrcnn_benchmark INFO: #################### end model construction ####################\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "2020-06-10 09:04:38,085 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "2020-06-10 09:04:38,117 maskrcnn_benchmark INFO: #################### end distributed ####################\n",
      "2020-06-10 09:04:38,118 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.\n",
      "2020-06-10 09:04:38,972 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-10 09:04:39,035 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)\r\n",
      "2020-06-10 09:04:39,036 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)\r\n",
      "2020-06-10 09:04:39,037 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_gate_fc.bias of shape (51,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_gate_fc.weight of shape (51, 4096)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\r\n",
      "2020-06-10 09:04:39,038 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)\r\n",
      "2020-06-10 09:04:39,039 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-10 09:04:40,192 maskrcnn_benchmark INFO: #################### end load checkpointer ####################\n",
      "2020-06-10 09:04:40,192 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-10 09:04:42,836 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/labels.json\n",
      "2020-06-10 09:04:44,090 maskrcnn_benchmark INFO: #################### end dataloader ####################\n",
      "2020-06-10 09:04:44,090 maskrcnn_benchmark INFO: Validate before training\n",
      "2020-06-10 09:04:44,099 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "2020-06-10 09:06:17,635 maskrcnn_benchmark INFO: Total run time: 0:01:33.535637 (0.14965701904296874 s / img per device, on 8 devices)\n",
      "2020-06-10 09:06:17,635 maskrcnn_benchmark INFO: Model inference time: 0:01:10.575044 (0.11292007064819336 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.69s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 09:07:46,691 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2350;   R @ 50: 0.2797;   R @ 100: 0.2974;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.2393; ngR @ 50: 0.2830; ngR @ 100: 0.3153;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0000;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.0915;  mR @ 50: 0.1250;  mR @ 100: 0.1454;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1384) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.1774) (at:0.4119) (attached to:0.3359) (behind:0.0478) (belonging to:0.0643) (between:0.0385) (carrying:0.4539) (covered in:0.2143) (covering:0.1265) (eating:0.5000) (flying in:0.0000) (for:0.1389) (from:0.0000) (growing on:0.2333) (hanging from:0.0000) (has:0.6083) (holding:0.0481) (in:0.0520) (in front of:0.1884) (laying on:0.0952) (looking at:0.1522) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2170) (of:0.1625) (on:0.3643) (on back of:0.0000) (over:0.0878) (painted on:0.0000) (parked on:0.2372) (part of:0.0000) (playing:0.0000) (riding:0.5536) (says:0.0000) (sitting on:0.4178) (standing on:0.0507) (to:0.3333) (under:0.0128) (using:0.0000) (walking in:0.0769) (walking on:0.1988) (watching:0.1078) (wearing:0.1664) (wears:0.2186) (with:0.0368) \n",
      "SGG eval:   A @ 20: 0.3185;   A @ 50: 0.3197;   A @ 100: 0.3197;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 09:07:47,456 maskrcnn_benchmark INFO: Start training\n",
      "2020-06-10 09:07:49,524 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: inf, (torch.Size([51]))\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 83070.70312, (torch.Size([4096, 512]))\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 24541.57617, (torch.Size([4096]))\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 23865.15625, (torch.Size([512, 32]))\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 10595.10156, (torch.Size([51, 4096]))\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.02020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 7474.11572, (torch.Size([512]))\n",
      "\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.weight: 920.74127, (torch.Size([51, 4096]))\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 896.81366, (torch.Size([51]))\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.bias: 896.81366, (torch.Size([51]))\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 41.01875, (torch.Size([22801, 51]))\n",
      "2020-06-10 09:07:49,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 1.34684, (torch.Size([51, 4096]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.84392, (torch.Size([512, 1024]))\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.81733, (torch.Size([4096, 1024]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.69849, (torch.Size([4096, 4096]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.43498, (torch.Size([2048, 4808]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.41860, (torch.Size([2048, 4808]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.34039, (torch.Size([4096, 12544]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.32916, (torch.Size([512]))\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.28837, (torch.Size([4096, 4096]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.26497, (torch.Size([4096, 12544]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.09148, (torch.Size([512, 1024]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.07414, (torch.Size([2048, 512]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.07137, (torch.Size([2048, 512]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.05117, (torch.Size([4096]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.04891, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-10 09:07:49,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.04805, (torch.Size([2048, 4424]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.04619, (torch.Size([2048, 4424]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.04494, (torch.Size([2048]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.04494, (torch.Size([2048]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.04320, (torch.Size([2048]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.04320, (torch.Size([2048]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03804, (torch.Size([1024, 512]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.03512, (torch.Size([512]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.03299, (torch.Size([1024]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02444, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01895, (torch.Size([4096]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00811, (torch.Size([2048, 512]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00776, (torch.Size([2048, 512]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00652, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00481, (torch.Size([2048]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00481, (torch.Size([2048]))\n",
      "2020-06-10 09:07:49,537 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00460, (torch.Size([2048]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00460, (torch.Size([2048]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00447, (torch.Size([4096]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00350, (torch.Size([151, 200]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00301, (torch.Size([4096]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00217, (torch.Size([128, 32]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00213, (torch.Size([256]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00137, (torch.Size([4096]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00120, (torch.Size([32, 9]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00113, (torch.Size([128]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00110, (torch.Size([256]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00091, (torch.Size([128]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00057, (torch.Size([32]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00042, (torch.Size([256]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00041, (torch.Size([128]))\n",
      "2020-06-10 09:07:49,538 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00041, (torch.Size([128]))\n",
      "2020-06-10 09:07:49,539 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00040, (torch.Size([256]))\n",
      "2020-06-10 09:07:49,539 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00040, (torch.Size([151, 200]))\n",
      "2020-06-10 09:07:49,539 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00020, (torch.Size([32]))\n",
      "2020-06-10 09:07:49,539 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 09:07:49,539 maskrcnn_benchmark INFO: -------------------------------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-10 09:11:38,157 maskrcnn_benchmark INFO: eta: 12:45:09  iter: 200  loss: 0.3642 (0.6130)  auxiliary_ctx: 0.1711 (0.2972)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1903 (0.3158)  time: 1.1426 (1.1535)  data: 0.0211 (0.0276)  lr: 0.293248  max mem: 6070\n",
      "2020-06-10 09:15:28,499 maskrcnn_benchmark INFO: eta: 12:40:43  iter: 400  loss: 0.3286 (0.4783)  auxiliary_ctx: 0.1582 (0.2299)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1740 (0.2484)  time: 1.1466 (1.1526)  data: 0.0257 (0.0264)  lr: 0.523648  max mem: 6070\n",
      "2020-06-10 09:19:18,239 maskrcnn_benchmark INFO: eta: 12:36:01  iter: 600  loss: 0.3005 (0.4278)  auxiliary_ctx: 0.1419 (0.2045)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1599 (0.2232)  time: 1.1492 (1.1513)  data: 0.0253 (0.0260)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 09:23:07,967 maskrcnn_benchmark INFO: eta: 12:31:45  iter: 800  loss: 0.3227 (0.3999)  auxiliary_ctx: 0.1504 (0.1905)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1708 (0.2094)  time: 1.1369 (1.1506)  data: 0.0244 (0.0253)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 09:26:57,308 maskrcnn_benchmark INFO: eta: 12:27:24  iter: 1000  loss: 0.2865 (0.3809)  auxiliary_ctx: 0.1405 (0.1815)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1454 (0.1994)  time: 1.1396 (1.1499)  data: 0.0165 (0.0249)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 09:30:47,424 maskrcnn_benchmark INFO: eta: 12:23:38  iter: 1200  loss: 0.2797 (0.3658)  auxiliary_ctx: 0.1370 (0.1749)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1423 (0.1909)  time: 1.1503 (1.1500)  data: 0.0249 (0.0244)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 09:34:37,445 maskrcnn_benchmark INFO: eta: 12:19:49  iter: 1400  loss: 0.2894 (0.3544)  auxiliary_ctx: 0.1417 (0.1700)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1469 (0.1844)  time: 1.1530 (1.1500)  data: 0.0253 (0.0244)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 09:38:27,227 maskrcnn_benchmark INFO: eta: 12:15:54  iter: 1600  loss: 0.2852 (0.3458)  auxiliary_ctx: 0.1418 (0.1663)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1449 (0.1794)  time: 1.1462 (1.1499)  data: 0.0261 (0.0244)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 09:42:17,583 maskrcnn_benchmark INFO: eta: 12:12:12  iter: 1800  loss: 0.2885 (0.3390)  auxiliary_ctx: 0.1422 (0.1635)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1463 (0.1755)  time: 1.1614 (1.1501)  data: 0.0256 (0.0245)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 09:46:07,337 maskrcnn_benchmark INFO: eta: 12:08:17  iter: 2000  loss: 0.2743 (0.3332)  auxiliary_ctx: 0.1352 (0.1610)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1392 (0.1722)  time: 1.1485 (1.1499)  data: 0.0247 (0.0245)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 09:46:07,340 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0002000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 09:46:10,003 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 09:46:10,026 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.82it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "2020-06-10 09:47:41,668 maskrcnn_benchmark INFO: Total run time: 0:01:31.642134 (0.14662741508483887 s / img per device, on 8 devices)\n",
      "2020-06-10 09:47:41,668 maskrcnn_benchmark INFO: Model inference time: 0:01:10.621488 (0.11299438018798828 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 09:49:15,555 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3179;   R @ 50: 0.4100;   R @ 100: 0.4570;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3741; ngR @ 50: 0.5314; ngR @ 100: 0.6429;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0800;  zR @ 50: 0.1207;  zR @ 100: 0.1644;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1487;  mR @ 50: 0.1958;  mR @ 100: 0.2198;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2785) (across:0.0000) (against:0.0000) (along:0.2692) (and:0.0000) (at:0.7468) (attached to:0.0000) (behind:0.5210) (belonging to:0.0000) (between:0.0000) (carrying:0.3465) (covered in:0.1429) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.2721) (has:0.7315) (holding:0.6024) (in:0.3086) (in front of:0.5194) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0071) (of:0.6282) (on:0.3903) (on back of:0.0000) (over:0.0427) (painted on:0.0000) (parked on:0.9537) (part of:0.0000) (playing:0.0000) (riding:0.9375) (says:0.0000) (sitting on:0.5554) (standing on:0.0725) (to:0.0000) (under:0.1437) (using:0.0000) (walking in:0.0000) (walking on:0.9787) (watching:0.5098) (wearing:0.9779) (wears:0.0000) (with:0.0147) \n",
      "SGG eval:   A @ 20: 0.5084;   A @ 50: 0.5117;   A @ 100: 0.5117;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 09:49:16,326 maskrcnn_benchmark INFO: Validation Result: 0.4570\n",
      "2020-06-10 09:53:05,993 maskrcnn_benchmark INFO: eta: 12:58:29  iter: 2200  loss: 0.2793 (0.3280)  auxiliary_ctx: 0.1396 (0.1588)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1397 (0.1692)  time: 1.1452 (1.2357)  data: 0.0258 (0.1104)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 09:56:56,164 maskrcnn_benchmark INFO: eta: 12:49:56  iter: 2400  loss: 0.2706 (0.3233)  auxiliary_ctx: 0.1353 (0.1569)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1353 (0.1664)  time: 1.1485 (1.2286)  data: 0.0259 (0.1032)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:00:46,420 maskrcnn_benchmark INFO: eta: 12:42:08  iter: 2600  loss: 0.2687 (0.3195)  auxiliary_ctx: 0.1344 (0.1554)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1344 (0.1642)  time: 1.1431 (1.2227)  data: 0.0202 (0.0970)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:04:36,879 maskrcnn_benchmark INFO: eta: 12:34:56  iter: 2800  loss: 0.2710 (0.3160)  auxiliary_ctx: 0.1355 (0.1539)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1355 (0.1621)  time: 1.1434 (1.2177)  data: 0.0259 (0.0919)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:08:26,733 maskrcnn_benchmark INFO: eta: 12:28:04  iter: 3000  loss: 0.2739 (0.3130)  auxiliary_ctx: 0.1371 (0.1527)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1369 (0.1603)  time: 1.1491 (1.2131)  data: 0.0260 (0.0874)  lr: 0.640000  max mem: 6130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-10 10:12:17,051 maskrcnn_benchmark INFO: eta: 12:21:40  iter: 3200  loss: 0.2682 (0.3103)  auxiliary_ctx: 0.1341 (0.1516)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1341 (0.1587)  time: 1.1470 (1.2092)  data: 0.0218 (0.0834)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:16:07,374 maskrcnn_benchmark INFO: eta: 12:15:34  iter: 3400  loss: 0.2683 (0.3079)  auxiliary_ctx: 0.1342 (0.1506)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1339 (0.1573)  time: 1.1452 (1.2059)  data: 0.0180 (0.0799)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:19:57,267 maskrcnn_benchmark INFO: eta: 12:09:39  iter: 3600  loss: 0.2818 (0.3059)  auxiliary_ctx: 0.1409 (0.1498)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1409 (0.1561)  time: 1.1454 (1.2027)  data: 0.0260 (0.0768)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:23:46,879 maskrcnn_benchmark INFO: eta: 12:03:54  iter: 3800  loss: 0.2510 (0.3041)  auxiliary_ctx: 0.1255 (0.1490)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1255 (0.1550)  time: 1.1517 (1.1998)  data: 0.0252 (0.0740)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:27:37,290 maskrcnn_benchmark INFO: ---Total norm 0.15258 clip coef 32.76953-----------------\n",
      "2020-06-10 10:27:37,301 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.08401, (torch.Size([4096, 12544]))\n",
      "2020-06-10 10:27:37,301 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06014, (torch.Size([4096, 4096]))\n",
      "2020-06-10 10:27:37,301 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05172, (torch.Size([51, 4096]))\n",
      "2020-06-10 10:27:37,301 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.04947, (torch.Size([512, 32]))\n",
      "2020-06-10 10:27:37,301 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04379, (torch.Size([4096, 1024]))\n",
      "2020-06-10 10:27:37,301 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03897, (torch.Size([2048, 4808]))\n",
      "2020-06-10 10:27:37,301 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03339, (torch.Size([2048, 4808]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02768, (torch.Size([512, 1024]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02479, (torch.Size([1024, 512]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02463, (torch.Size([4096, 512]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01493, (torch.Size([512]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01161, (torch.Size([512]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01074, (torch.Size([4096]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00977, (torch.Size([151, 200]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00916, (torch.Size([51]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00826, (torch.Size([2048, 512]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00755, (torch.Size([1024]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00593, (torch.Size([2048, 512]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00590, (torch.Size([2048]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00590, (torch.Size([2048]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00498, (torch.Size([4096]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00386, (torch.Size([2048]))\n",
      "2020-06-10 10:27:37,302 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00386, (torch.Size([2048]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00173, (torch.Size([4096]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00131, (torch.Size([2048, 4424]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.00116, (torch.Size([51, 4096]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00109, (torch.Size([2048, 4424]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00092, (torch.Size([512, 1024]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.00057, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00054, (torch.Size([512]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00048, (torch.Size([4096]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.00022, (torch.Size([4096, 12544]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.00022, (torch.Size([4096, 4096]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00016, (torch.Size([2048, 512]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.weight: 0.00016, (torch.Size([51, 4096]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00012, (torch.Size([2048]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00012, (torch.Size([2048]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00007, (torch.Size([2048]))\n",
      "2020-06-10 10:27:37,303 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00007, (torch.Size([2048]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.00003, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00003, (torch.Size([2048, 512]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00003, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00002, (torch.Size([128]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00002, (torch.Size([22801, 51]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00002, (torch.Size([51]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.bias: 0.00002, (torch.Size([51]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00002, (torch.Size([151, 200]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00001, (torch.Size([256]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00001, (torch.Size([256]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00001, (torch.Size([256]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00000, (torch.Size([256]))\n",
      "2020-06-10 10:27:37,304 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00000, (torch.Size([4096]))\n",
      "2020-06-10 10:27:37,305 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00000, (torch.Size([4096]))\n",
      "2020-06-10 10:27:37,305 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 10:27:37,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 10:27:37,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 10:27:37,305 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 10:27:37,305 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 10:27:37,305 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-10 10:27:37,308 maskrcnn_benchmark INFO: eta: 11:58:28  iter: 4000  loss: 0.2794 (0.3024)  auxiliary_ctx: 0.1397 (0.1483)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1397 (0.1540)  time: 1.1461 (1.1975)  data: 0.0266 (0.0715)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:27:37,310 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0004000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 10:27:39,983 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 10:27:40,006 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.88it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "2020-06-10 10:29:10,846 maskrcnn_benchmark INFO: Total run time: 0:01:30.840174 (0.14534427795410157 s / img per device, on 8 devices)\n",
      "2020-06-10 10:29:10,847 maskrcnn_benchmark INFO: Model inference time: 0:01:10.298806 (0.1124780891418457 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.29s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 10:30:46,593 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3230;   R @ 50: 0.4280;   R @ 100: 0.4850;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3748; ngR @ 50: 0.5421; ngR @ 100: 0.6683;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0911;  zR @ 50: 0.1474;  zR @ 100: 0.1926;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1663;  mR @ 50: 0.2260;  mR @ 100: 0.2565;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2927) (across:0.0000) (against:0.0000) (along:0.7436) (and:0.0000) (at:0.7892) (attached to:0.0092) (behind:0.5374) (belonging to:0.0000) (between:0.0000) (carrying:0.7259) (covered in:0.2262) (covering:0.2041) (eating:0.8571) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0441) (has:0.7174) (holding:0.3249) (in:0.3644) (in front of:0.4953) (laying on:0.0000) (looking at:0.1087) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1235) (of:0.5869) (on:0.4246) (on back of:0.0000) (over:0.0854) (painted on:0.0000) (parked on:0.6896) (part of:0.0000) (playing:0.0000) (riding:0.9107) (says:0.0000) (sitting on:0.3683) (standing on:0.0779) (to:0.0000) (under:0.2105) (using:0.1923) (walking in:0.0000) (walking on:0.9790) (watching:0.5686) (wearing:0.9790) (wears:0.0000) (with:0.1509) \n",
      "SGG eval:   A @ 20: 0.5415;   A @ 50: 0.5459;   A @ 100: 0.5459;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 10:30:47,377 maskrcnn_benchmark INFO: Validation Result: 0.4850\n",
      "2020-06-10 10:34:37,253 maskrcnn_benchmark INFO: eta: 12:20:07  iter: 4200  loss: 0.2757 (0.3008)  auxiliary_ctx: 0.1379 (0.1477)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1378 (0.1531)  time: 1.1388 (1.2404)  data: 0.0254 (0.1145)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:38:27,454 maskrcnn_benchmark INFO: eta: 12:13:34  iter: 4400  loss: 0.2560 (0.2993)  auxiliary_ctx: 0.1281 (0.1471)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1279 (0.1523)  time: 1.1486 (1.2364)  data: 0.0256 (0.1104)  lr: 0.640000  max mem: 6130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "2020-06-10 10:42:17,919 maskrcnn_benchmark INFO: eta: 12:07:17  iter: 4600  loss: 0.2777 (0.2981)  auxiliary_ctx: 0.1390 (0.1466)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1387 (0.1516)  time: 1.1643 (1.2327)  data: 0.0254 (0.1067)  lr: 0.640000  max mem: 6130\n",
      "2020-06-10 10:46:08,001 maskrcnn_benchmark INFO: eta: 12:01:10  iter: 4800  loss: 0.2612 (0.2968)  auxiliary_ctx: 0.1307 (0.1460)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1306 (0.1507)  time: 1.1441 (1.2293)  data: 0.0246 (0.1033)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 10:49:57,826 maskrcnn_benchmark INFO: eta: 11:55:12  iter: 5000  loss: 0.2695 (0.2955)  auxiliary_ctx: 0.1349 (0.1455)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1346 (0.1500)  time: 1.1553 (1.2261)  data: 0.0253 (0.1001)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 10:53:47,777 maskrcnn_benchmark INFO: eta: 11:49:25  iter: 5200  loss: 0.2571 (0.2945)  auxiliary_ctx: 0.1283 (0.1451)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1288 (0.1494)  time: 1.1443 (1.2231)  data: 0.0262 (0.0972)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 10:57:36,988 maskrcnn_benchmark INFO: eta: 11:43:41  iter: 5400  loss: 0.2610 (0.2935)  auxiliary_ctx: 0.1307 (0.1447)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1302 (0.1488)  time: 1.1408 (1.2203)  data: 0.0258 (0.0945)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:01:27,170 maskrcnn_benchmark INFO: eta: 11:38:12  iter: 5600  loss: 0.2705 (0.2925)  auxiliary_ctx: 0.1354 (0.1442)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1350 (0.1482)  time: 1.1445 (1.2178)  data: 0.0265 (0.0920)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:05:16,722 maskrcnn_benchmark INFO: eta: 11:32:46  iter: 5800  loss: 0.2651 (0.2916)  auxiliary_ctx: 0.1337 (0.1439)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1315 (0.1477)  time: 1.1499 (1.2154)  data: 0.0163 (0.0897)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:09:05,870 maskrcnn_benchmark INFO: eta: 11:27:24  iter: 6000  loss: 0.2567 (0.2908)  auxiliary_ctx: 0.1290 (0.1436)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1276 (0.1472)  time: 1.1419 (1.2131)  data: 0.0247 (0.0874)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:09:05,873 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0006000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 11:09:08,533 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 11:09:08,557 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.66it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.66it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.84it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.66it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.66it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.66it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.66it/s]\n",
      "2020-06-10 11:10:39,897 maskrcnn_benchmark INFO: Total run time: 0:01:31.340379 (0.14614460678100585 s / img per device, on 8 devices)\n",
      "2020-06-10 11:10:39,898 maskrcnn_benchmark INFO: Model inference time: 0:01:10.229582 (0.1123673309326172 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 11:12:16,735 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3334;   R @ 50: 0.4550;   R @ 100: 0.5121;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3852; ngR @ 50: 0.5704; ngR @ 100: 0.6940;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0941;  zR @ 50: 0.1533;  zR @ 100: 0.1711;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1788;  mR @ 50: 0.2315;  mR @ 100: 0.2595;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.4189) (across:0.0000) (against:0.0000) (along:0.5385) (and:0.0000) (at:0.7227) (attached to:0.0000) (behind:0.5965) (belonging to:0.0000) (between:0.0000) (carrying:0.8070) (covered in:0.2976) (covering:0.1673) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.2426) (has:0.7535) (holding:0.2659) (in:0.3836) (in front of:0.3876) (laying on:0.0952) (looking at:0.1739) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1001) (of:0.5114) (on:0.4879) (on back of:0.0000) (over:0.0691) (painted on:0.0000) (parked on:0.9106) (part of:0.0000) (playing:0.0000) (riding:0.8512) (says:0.0000) (sitting on:0.3965) (standing on:0.1511) (to:0.0000) (under:0.1986) (using:0.0385) (walking in:0.0000) (walking on:0.9699) (watching:0.6471) (wearing:0.9293) (wears:0.0000) (with:0.1460) \n",
      "SGG eval:   A @ 20: 0.5665;   A @ 50: 0.5713;   A @ 100: 0.5713;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 11:12:17,517 maskrcnn_benchmark INFO: Validation Result: 0.5121\n",
      "2020-06-10 11:16:06,821 maskrcnn_benchmark INFO: eta: 11:39:33  iter: 6200  loss: 0.2646 (0.2901)  auxiliary_ctx: 0.1330 (0.1433)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1312 (0.1468)  time: 1.1395 (1.2418)  data: 0.0224 (0.1162)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:19:56,861 maskrcnn_benchmark INFO: eta: 11:33:49  iter: 6400  loss: 0.2588 (0.2894)  auxiliary_ctx: 0.1294 (0.1430)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1294 (0.1464)  time: 1.1495 (1.2390)  data: 0.0255 (0.1134)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:23:46,896 maskrcnn_benchmark INFO: eta: 11:28:11  iter: 6600  loss: 0.2560 (0.2886)  auxiliary_ctx: 0.1280 (0.1427)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1280 (0.1460)  time: 1.1447 (1.2363)  data: 0.0257 (0.1106)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:27:36,482 maskrcnn_benchmark INFO: eta: 11:22:38  iter: 6800  loss: 0.2575 (0.2880)  auxiliary_ctx: 0.1293 (0.1424)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1285 (0.1456)  time: 1.1455 (1.2337)  data: 0.0267 (0.1081)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:31:27,128 maskrcnn_benchmark INFO: eta: 11:17:15  iter: 7000  loss: 0.2589 (0.2874)  auxiliary_ctx: 0.1298 (0.1422)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1291 (0.1452)  time: 1.1494 (1.2314)  data: 0.0256 (0.1057)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:35:16,964 maskrcnn_benchmark INFO: eta: 11:11:54  iter: 7200  loss: 0.2698 (0.2869)  auxiliary_ctx: 0.1355 (0.1420)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1343 (0.1449)  time: 1.1423 (1.2291)  data: 0.0236 (0.1034)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:39:06,135 maskrcnn_benchmark INFO: eta: 11:06:35  iter: 7400  loss: 0.2632 (0.2863)  auxiliary_ctx: 0.1316 (0.1417)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1316 (0.1446)  time: 1.1388 (1.2268)  data: 0.0171 (0.1012)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:42:55,861 maskrcnn_benchmark INFO: eta: 11:01:23  iter: 7600  loss: 0.2745 (0.2857)  auxiliary_ctx: 0.1373 (0.1414)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1373 (0.1442)  time: 1.1569 (1.2248)  data: 0.0257 (0.0992)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:46:45,562 maskrcnn_benchmark INFO: eta: 10:56:15  iter: 7800  loss: 0.2575 (0.2853)  auxiliary_ctx: 0.1300 (0.1413)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1272 (0.1440)  time: 1.1469 (1.2228)  data: 0.0262 (0.0973)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:50:35,211 maskrcnn_benchmark INFO: ---Total norm 0.13376 clip coef 37.37962-----------------\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.07465, (torch.Size([4096, 12544]))\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06220, (torch.Size([4096, 4096]))\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.03966, (torch.Size([51, 4096]))\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03743, (torch.Size([51, 4096]))\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03528, (torch.Size([4096, 1024]))\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03237, (torch.Size([2048, 4808]))\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.02875, (torch.Size([2048, 4808]))\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02244, (torch.Size([1024, 512]))\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.01973, (torch.Size([512, 1024]))\n",
      "2020-06-10 11:50:35,222 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.01788, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.01480, (torch.Size([4096, 12544]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.01464, (torch.Size([4096, 4096]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01308, (torch.Size([512, 32]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01205, (torch.Size([4096, 512]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00867, (torch.Size([151, 200]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00740, (torch.Size([2048, 512]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.weight: 0.00634, (torch.Size([51, 4096]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00606, (torch.Size([1024]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00579, (torch.Size([4096]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00570, (torch.Size([51]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00564, (torch.Size([512]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00549, (torch.Size([2048, 512]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00417, (torch.Size([4096]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00275, (torch.Size([512]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00258, (torch.Size([2048]))\n",
      "2020-06-10 11:50:35,223 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00258, (torch.Size([2048]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00249, (torch.Size([2048]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00249, (torch.Size([2048]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00162, (torch.Size([51]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.bias: 0.00162, (torch.Size([51]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00154, (torch.Size([4096]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00094, (torch.Size([512]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00093, (torch.Size([22801, 51]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00084, (torch.Size([512, 1024]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00041, (torch.Size([4096]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00039, (torch.Size([2048, 4424]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00038, (torch.Size([2048, 4424]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00029, (torch.Size([256]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00028, (torch.Size([256]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00026, (torch.Size([4096]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00010, (torch.Size([4096]))\n",
      "2020-06-10 11:50:35,224 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00009, (torch.Size([2048]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00009, (torch.Size([2048]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00008, (torch.Size([2048]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00008, (torch.Size([2048]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00007, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00006, (torch.Size([2048, 512]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00004, (torch.Size([2048, 512]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.00003, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00001, (torch.Size([128]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00000, (torch.Size([256]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-10 11:50:35,225 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 11:50:35,226 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00000, (torch.Size([256]))\n",
      "2020-06-10 11:50:35,226 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-10 11:50:35,226 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 11:50:35,226 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 11:50:35,226 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-10 11:50:35,229 maskrcnn_benchmark INFO: eta: 10:51:11  iter: 8000  loss: 0.2689 (0.2847)  auxiliary_ctx: 0.1352 (0.1411)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1337 (0.1437)  time: 1.1373 (1.2210)  data: 0.0243 (0.0954)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 11:50:35,231 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0008000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 11:50:37,708 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 11:50:37,732 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.95it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.77it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.77it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.77it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.77it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.77it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.77it/s]\n",
      "\n",
      "2020-06-10 11:52:07,679 maskrcnn_benchmark INFO: Total run time: 0:01:29.946186 (0.14391389694213866 s / img per device, on 8 devices)\n",
      "2020-06-10 11:52:07,679 maskrcnn_benchmark INFO: Model inference time: 0:01:10.198292 (0.11231726684570313 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 11:53:44,741 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3415;   R @ 50: 0.4735;   R @ 100: 0.5421;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3986; ngR @ 50: 0.5969; ngR @ 100: 0.7354;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0600;  zR @ 50: 0.1000;  zR @ 100: 0.1222;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1914;  mR @ 50: 0.2440;  mR @ 100: 0.2704;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.3734) (across:0.0000) (against:0.0000) (along:0.5897) (and:0.0000) (at:0.7564) (attached to:0.0000) (behind:0.5165) (belonging to:0.0000) (between:0.0000) (carrying:0.7807) (covered in:0.4048) (covering:0.3333) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0956) (has:0.7399) (holding:0.4178) (in:0.3401) (in front of:0.4766) (laying on:0.0000) (looking at:0.1739) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1400) (of:0.5573) (on:0.5433) (on back of:0.0227) (over:0.0732) (painted on:0.0000) (parked on:0.9296) (part of:0.0000) (playing:0.0000) (riding:0.8467) (says:0.0000) (sitting on:0.5545) (standing on:0.1522) (to:0.0000) (under:0.2564) (using:0.0385) (walking in:0.0000) (walking on:0.9614) (watching:0.6471) (wearing:0.9262) (wears:0.0000) (with:0.1559) \n",
      "SGG eval:   A @ 20: 0.5992;   A @ 50: 0.6040;   A @ 100: 0.6040;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 11:53:45,505 maskrcnn_benchmark INFO: Validation Result: 0.5421\n",
      "2020-06-10 11:57:35,006 maskrcnn_benchmark INFO: eta: 10:58:27  iter: 8200  loss: 0.2553 (0.2842)  auxiliary_ctx: 0.1290 (0.1409)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1263 (0.1434)  time: 1.1487 (1.2424)  data: 0.0193 (0.1168)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 12:01:24,362 maskrcnn_benchmark INFO: eta: 10:53:07  iter: 8400  loss: 0.2525 (0.2837)  auxiliary_ctx: 0.1277 (0.1407)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1255 (0.1430)  time: 1.1513 (1.2401)  data: 0.0260 (0.1146)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 12:05:14,192 maskrcnn_benchmark INFO: eta: 10:47:52  iter: 8600  loss: 0.2603 (0.2833)  auxiliary_ctx: 0.1302 (0.1405)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1302 (0.1428)  time: 1.1283 (1.2380)  data: 0.0256 (0.1125)  lr: 0.640000  max mem: 6346\n",
      "2020-06-10 12:09:03,921 maskrcnn_benchmark INFO: eta: 10:42:41  iter: 8800  loss: 0.2602 (0.2829)  auxiliary_ctx: 0.1312 (0.1404)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1288 (0.1425)  time: 1.1530 (1.2360)  data: 0.0253 (0.1105)  lr: 0.640000  max mem: 6370\n",
      "2020-06-10 12:12:53,148 maskrcnn_benchmark INFO: eta: 10:37:32  iter: 9000  loss: 0.2684 (0.2825)  auxiliary_ctx: 0.1362 (0.1402)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1322 (0.1423)  time: 1.1414 (1.2340)  data: 0.0253 (0.1086)  lr: 0.640000  max mem: 6370\n",
      "2020-06-10 12:16:42,837 maskrcnn_benchmark INFO: eta: 10:32:28  iter: 9200  loss: 0.2723 (0.2820)  auxiliary_ctx: 0.1376 (0.1401)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1347 (0.1420)  time: 1.1433 (1.2321)  data: 0.0241 (0.1067)  lr: 0.640000  max mem: 6370\n",
      "2020-06-10 12:20:33,025 maskrcnn_benchmark INFO: eta: 10:27:29  iter: 9400  loss: 0.2680 (0.2816)  auxiliary_ctx: 0.1360 (0.1399)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1315 (0.1417)  time: 1.1480 (1.2304)  data: 0.0254 (0.1049)  lr: 0.640000  max mem: 6370\n",
      "2020-06-10 12:24:22,805 maskrcnn_benchmark INFO: eta: 10:22:31  iter: 9600  loss: 0.2673 (0.2813)  auxiliary_ctx: 0.1357 (0.1398)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1316 (0.1415)  time: 1.1436 (1.2287)  data: 0.0210 (0.1032)  lr: 0.640000  max mem: 6370\n",
      "2020-06-10 12:28:12,616 maskrcnn_benchmark INFO: eta: 10:17:37  iter: 9800  loss: 0.2504 (0.2809)  auxiliary_ctx: 0.1278 (0.1397)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1234 (0.1413)  time: 1.1519 (1.2271)  data: 0.0185 (0.1016)  lr: 0.640000  max mem: 6370\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "2020-06-10 12:32:02,515 maskrcnn_benchmark INFO: eta: 10:12:45  iter: 10000  loss: 0.2468 (0.2806)  auxiliary_ctx: 0.1255 (0.1395)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1230 (0.1410)  time: 1.1404 (1.2255)  data: 0.0253 (0.1000)  lr: 0.640000  max mem: 6388\n",
      "2020-06-10 12:32:02,518 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0010000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 12:32:05,115 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 12:32:05,139 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.89it/s]\n",
      "2020-06-10 12:33:35,851 maskrcnn_benchmark INFO: Total run time: 0:01:30.711370 (0.14513819160461425 s / img per device, on 8 devices)\n",
      "2020-06-10 12:33:35,852 maskrcnn_benchmark INFO: Model inference time: 0:01:10.505076 (0.11280812149047852 s / img per device, on 8 devices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.77s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.24s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 12:35:10,823 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2921;   R @ 50: 0.4159;   R @ 100: 0.4814;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3416; ngR @ 50: 0.5315; ngR @ 100: 0.6705;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0556;  zR @ 50: 0.0867;  zR @ 100: 0.1089;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1809;  mR @ 50: 0.2429;  mR @ 100: 0.2774;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1337) (across:0.0000) (against:0.0000) (along:0.6667) (and:0.0000) (at:0.7362) (attached to:0.0000) (behind:0.5770) (belonging to:0.0000) (between:0.0000) (carrying:0.6053) (covered in:0.2976) (covering:0.2578) (eating:0.7143) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.4449) (has:0.6914) (holding:0.5511) (in:0.3994) (in front of:0.4487) (laying on:0.0000) (looking at:0.1522) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1454) (of:0.5168) (on:0.4120) (on back of:0.0227) (over:0.1220) (painted on:0.0000) (parked on:0.9250) (part of:0.0000) (playing:0.0000) (riding:0.8929) (says:0.0000) (sitting on:0.5597) (standing on:0.1214) (to:0.0000) (under:0.3699) (using:0.2692) (walking in:0.0769) (walking on:0.9487) (watching:0.6275) (wearing:0.9277) (wears:0.0000) (with:0.2214) \n",
      "SGG eval:   A @ 20: 0.5491;   A @ 50: 0.5534;   A @ 100: 0.5534;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 12:35:11,598 maskrcnn_benchmark INFO: Validation Result: 0.4814\n",
      "2020-06-10 12:39:01,277 maskrcnn_benchmark INFO: eta: 10:17:07  iter: 10200  loss: 0.2511 (0.2802)  auxiliary_ctx: 0.1283 (0.1394)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1242 (0.1408)  time: 1.1523 (1.2425)  data: 0.0245 (0.1171)  lr: 0.640000  max mem: 6388\n",
      "2020-06-10 12:42:51,155 maskrcnn_benchmark INFO: eta: 10:12:05  iter: 10400  loss: 0.2611 (0.2799)  auxiliary_ctx: 0.1333 (0.1393)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1294 (0.1406)  time: 1.1475 (1.2407)  data: 0.0253 (0.1153)  lr: 0.640000  max mem: 6388\n",
      "2020-06-10 12:46:45,151 maskrcnn_benchmark INFO: eta: 10:07:18  iter: 10600  loss: 0.2619 (0.2796)  auxiliary_ctx: 0.1328 (0.1392)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1289 (0.1404)  time: 1.1421 (1.2394)  data: 0.0241 (0.1136)  lr: 0.640000  max mem: 6388\n",
      "2020-06-10 12:50:35,204 maskrcnn_benchmark INFO: eta: 10:02:22  iter: 10800  loss: 0.2625 (0.2793)  auxiliary_ctx: 0.1339 (0.1391)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1288 (0.1402)  time: 1.1393 (1.2378)  data: 0.0242 (0.1119)  lr: 0.640000  max mem: 6388\n",
      "2020-06-10 12:54:25,172 maskrcnn_benchmark INFO: eta: 9:57:28  iter: 11000  loss: 0.2615 (0.2789)  auxiliary_ctx: 0.1328 (0.1390)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1282 (0.1399)  time: 1.1493 (1.2362)  data: 0.0260 (0.1103)  lr: 0.640000  max mem: 6388\n",
      "2020-06-10 12:58:15,584 maskrcnn_benchmark INFO: eta: 9:52:38  iter: 11200  loss: 0.2740 (0.2787)  auxiliary_ctx: 0.1395 (0.1389)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1345 (0.1398)  time: 1.1526 (1.2347)  data: 0.0248 (0.1088)  lr: 0.640000  max mem: 6388\n",
      "2020-06-10 13:02:06,055 maskrcnn_benchmark INFO: eta: 9:47:49  iter: 11400  loss: 0.2647 (0.2784)  auxiliary_ctx: 0.1346 (0.1388)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1301 (0.1396)  time: 1.1580 (1.2332)  data: 0.0231 (0.1073)  lr: 0.640000  max mem: 6388\n",
      "2020-06-10 13:05:56,260 maskrcnn_benchmark INFO: eta: 9:43:02  iter: 11600  loss: 0.2478 (0.2781)  auxiliary_ctx: 0.1252 (0.1387)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1208 (0.1394)  time: 1.1542 (1.2318)  data: 0.0208 (0.1059)  lr: 0.640000  max mem: 6395\n",
      "2020-06-10 13:09:45,707 maskrcnn_benchmark INFO: eta: 9:38:16  iter: 11800  loss: 0.2560 (0.2778)  auxiliary_ctx: 0.1307 (0.1386)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1266 (0.1392)  time: 1.1439 (1.2304)  data: 0.0255 (0.1045)  lr: 0.640000  max mem: 6395\n",
      "2020-06-10 13:13:35,899 maskrcnn_benchmark INFO: ---Total norm 0.16226 clip coef 30.81419-----------------\n",
      "2020-06-10 13:13:35,909 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.09263, (torch.Size([4096, 12544]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06514, (torch.Size([4096, 4096]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.06361, (torch.Size([51, 4096]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.04829, (torch.Size([512, 32]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04541, (torch.Size([4096, 1024]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03189, (torch.Size([2048, 4808]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.02864, (torch.Size([2048, 4808]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02746, (torch.Size([1024, 512]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02550, (torch.Size([4096, 512]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02324, (torch.Size([512, 1024]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01202, (torch.Size([512]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01096, (torch.Size([4096]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.01042, (torch.Size([4096, 12544]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.01001, (torch.Size([51, 4096]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00994, (torch.Size([512]))\n",
      "2020-06-10 13:13:35,910 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.00978, (torch.Size([4096, 4096]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00976, (torch.Size([51]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00951, (torch.Size([151, 200]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.00932, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00918, (torch.Size([1024]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00819, (torch.Size([4096]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00739, (torch.Size([2048, 512]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00634, (torch.Size([2048, 512]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00506, (torch.Size([2048]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00506, (torch.Size([2048]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00392, (torch.Size([2048]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00392, (torch.Size([2048]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.weight: 0.00244, (torch.Size([51, 4096]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00223, (torch.Size([4096]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00078, (torch.Size([512]))\n",
      "2020-06-10 13:13:35,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00075, (torch.Size([512, 1024]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00055, (torch.Size([4096]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00046, (torch.Size([51]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.bias: 0.00046, (torch.Size([51]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00035, (torch.Size([22801, 51]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00028, (torch.Size([4096]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00026, (torch.Size([256]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00021, (torch.Size([256]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00016, (torch.Size([4096]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00009, (torch.Size([2048, 4424]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00008, (torch.Size([2048, 4424]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00003, (torch.Size([2048]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00003, (torch.Size([2048]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00002, (torch.Size([2048]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00002, (torch.Size([2048]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00002, (torch.Size([2048, 512]))\n",
      "2020-06-10 13:13:35,912 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00001, (torch.Size([2048, 512]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.00000, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00000, (torch.Size([256]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00000, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00000, (torch.Size([256]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 13:13:35,913 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-10 13:13:35,916 maskrcnn_benchmark INFO: eta: 9:33:33  iter: 12000  loss: 0.2525 (0.2776)  auxiliary_ctx: 0.1288 (0.1385)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1237 (0.1390)  time: 1.1512 (1.2290)  data: 0.0250 (0.1031)  lr: 0.640000  max mem: 6395\n",
      "2020-06-10 13:13:35,919 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0012000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 13:13:38,670 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 13:13:38,687 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.92it/s]\n",
      "2020-06-10 13:15:08,979 maskrcnn_benchmark INFO: Total run time: 0:01:30.291744 (0.14446679000854493 s / img per device, on 8 devices)\n",
      "2020-06-10 13:15:08,979 maskrcnn_benchmark INFO: Model inference time: 0:01:10.603725 (0.11296595993041993 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.73s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.29s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 13:16:46,178 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3406;   R @ 50: 0.4751;   R @ 100: 0.5370;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3785; ngR @ 50: 0.5679; ngR @ 100: 0.6883;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0733;  zR @ 50: 0.0822;  zR @ 100: 0.1156;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1662;  mR @ 50: 0.2308;  mR @ 100: 0.2718;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2289) (across:0.0000) (against:0.0000) (along:0.7051) (and:0.0000) (at:0.6823) (attached to:0.0138) (behind:0.5872) (belonging to:0.0000) (between:0.0000) (carrying:0.8070) (covered in:0.5238) (covering:0.3429) (eating:0.8571) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.5441) (has:0.6214) (holding:0.2737) (in:0.3059) (in front of:0.5441) (laying on:0.0476) (looking at:0.0652) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0605) (of:0.3349) (on:0.5936) (on back of:0.0455) (over:0.0854) (painted on:0.0000) (parked on:0.7736) (part of:0.0000) (playing:0.0000) (riding:0.9107) (says:0.0000) (sitting on:0.4026) (standing on:0.2283) (to:0.0000) (under:0.3469) (using:0.0385) (walking in:0.0000) (walking on:0.9015) (watching:0.5098) (wearing:0.8973) (wears:0.0000) (with:0.2728) \n",
      "SGG eval:   A @ 20: 0.5894;   A @ 50: 0.5943;   A @ 100: 0.5943;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 13:16:46,950 maskrcnn_benchmark INFO: Validation Result: 0.5370\n",
      "2020-06-10 13:16:46,951 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "2020-06-10 13:20:36,360 maskrcnn_benchmark INFO: eta: 9:36:05  iter: 12200  loss: 0.2390 (0.2771)  auxiliary_ctx: 0.1209 (0.1383)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1182 (0.1388)  time: 1.1457 (1.2434)  data: 0.0250 (0.1175)  lr: 0.064000  max mem: 6395\n",
      "2020-06-10 13:24:26,376 maskrcnn_benchmark INFO: eta: 9:31:15  iter: 12400  loss: 0.2506 (0.2767)  auxiliary_ctx: 0.1272 (0.1381)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1233 (0.1385)  time: 1.1500 (1.2418)  data: 0.0252 (0.1160)  lr: 0.064000  max mem: 6395\n",
      "2020-06-10 13:28:16,885 maskrcnn_benchmark INFO: eta: 9:26:27  iter: 12600  loss: 0.2405 (0.2762)  auxiliary_ctx: 0.1216 (0.1379)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1189 (0.1382)  time: 1.1421 (1.2404)  data: 0.0235 (0.1145)  lr: 0.064000  max mem: 6395\n",
      "2020-06-10 13:32:06,786 maskrcnn_benchmark INFO: eta: 9:21:41  iter: 12800  loss: 0.2323 (0.2756)  auxiliary_ctx: 0.1190 (0.1377)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1141 (0.1379)  time: 1.1419 (1.2390)  data: 0.0255 (0.1131)  lr: 0.064000  max mem: 6395\n",
      "2020-06-10 13:35:56,945 maskrcnn_benchmark INFO: eta: 9:16:56  iter: 13000  loss: 0.2397 (0.2751)  auxiliary_ctx: 0.1214 (0.1374)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1182 (0.1376)  time: 1.1473 (1.2377)  data: 0.0180 (0.1117)  lr: 0.064000  max mem: 6395\n",
      "2020-06-10 13:39:47,544 maskrcnn_benchmark INFO: eta: 9:12:14  iter: 13200  loss: 0.2441 (0.2745)  auxiliary_ctx: 0.1235 (0.1372)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1204 (0.1373)  time: 1.1447 (1.2364)  data: 0.0230 (0.1103)  lr: 0.064000  max mem: 6395\n",
      "2020-06-10 13:43:37,945 maskrcnn_benchmark INFO: eta: 9:07:33  iter: 13400  loss: 0.2248 (0.2740)  auxiliary_ctx: 0.1142 (0.1370)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1114 (0.1371)  time: 1.1505 (1.2351)  data: 0.0217 (0.1091)  lr: 0.064000  max mem: 6395\n",
      "2020-06-10 13:47:28,315 maskrcnn_benchmark INFO: eta: 9:02:54  iter: 13600  loss: 0.2310 (0.2735)  auxiliary_ctx: 0.1164 (0.1367)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1147 (0.1368)  time: 1.1462 (1.2339)  data: 0.0252 (0.1078)  lr: 0.064000  max mem: 6395\n",
      "2020-06-10 13:51:18,677 maskrcnn_benchmark INFO: eta: 8:58:16  iter: 13800  loss: 0.2355 (0.2729)  auxiliary_ctx: 0.1193 (0.1365)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1162 (0.1365)  time: 1.1585 (1.2327)  data: 0.0253 (0.1066)  lr: 0.064000  max mem: 6405\n",
      "2020-06-10 13:55:08,355 maskrcnn_benchmark INFO: eta: 8:53:38  iter: 14000  loss: 0.2253 (0.2724)  auxiliary_ctx: 0.1150 (0.1362)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1107 (0.1362)  time: 1.1509 (1.2315)  data: 0.0225 (0.1054)  lr: 0.064000  max mem: 6405\n",
      "2020-06-10 13:55:08,358 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0014000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 13:55:10,985 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 13:55:11,009 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.92it/s]\n",
      "2020-06-10 13:56:41,296 maskrcnn_benchmark INFO: Total run time: 0:01:30.285617 (0.14445698738098145 s / img per device, on 8 devices)\n",
      "2020-06-10 13:56:41,296 maskrcnn_benchmark INFO: Model inference time: 0:01:10.815261 (0.11330441780090332 s / img per device, on 8 devices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.61s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 13:58:18,410 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3501;   R @ 50: 0.4821;   R @ 100: 0.5357;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3963; ngR @ 50: 0.5914; ngR @ 100: 0.7061;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0733;  zR @ 50: 0.1289;  zR @ 100: 0.1600;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.2160;  mR @ 50: 0.2829;  mR @ 100: 0.3140;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2763) (across:0.0556) (against:0.0526) (along:0.7051) (and:0.0000) (at:0.7589) (attached to:0.0211) (behind:0.5296) (belonging to:0.1833) (between:0.0000) (carrying:0.7807) (covered in:0.6667) (covering:0.2667) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.1333) (hanging from:0.5515) (has:0.6023) (holding:0.4741) (in:0.3283) (in front of:0.5288) (laying on:0.0952) (looking at:0.1739) (lying on:0.0000) (made of:0.0000) (mounted on:0.0435) (near:0.1512) (of:0.3805) (on:0.5536) (on back of:0.0455) (over:0.1585) (painted on:0.0000) (parked on:0.9471) (part of:0.0000) (playing:0.0000) (riding:0.9286) (says:0.0000) (sitting on:0.5298) (standing on:0.2033) (to:0.0000) (under:0.3316) (using:0.2692) (walking in:0.0769) (walking on:0.9710) (watching:0.6863) (wearing:0.9400) (wears:0.0000) (with:0.3012) \n",
      "SGG eval:   A @ 20: 0.5818;   A @ 50: 0.5862;   A @ 100: 0.5862;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 13:58:19,184 maskrcnn_benchmark INFO: Validation Result: 0.5357\n",
      "2020-06-10 14:02:08,944 maskrcnn_benchmark INFO: eta: 8:54:49  iter: 14200  loss: 0.2322 (0.2718)  auxiliary_ctx: 0.1175 (0.1360)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1147 (0.1359)  time: 1.1548 (1.2438)  data: 0.0252 (0.1177)  lr: 0.064000  max mem: 6405\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "2020-06-10 14:05:59,012 maskrcnn_benchmark INFO: eta: 8:50:07  iter: 14400  loss: 0.2228 (0.2713)  auxiliary_ctx: 0.1132 (0.1357)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1105 (0.1356)  time: 1.1525 (1.2425)  data: 0.0254 (0.1164)  lr: 0.064000  max mem: 6405\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "2020-06-10 14:09:49,356 maskrcnn_benchmark INFO: eta: 8:45:27  iter: 14600  loss: 0.2247 (0.2707)  auxiliary_ctx: 0.1140 (0.1354)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1107 (0.1353)  time: 1.1497 (1.2412)  data: 0.0258 (0.1151)  lr: 0.064000  max mem: 6405\n",
      "2020-06-10 14:13:39,591 maskrcnn_benchmark INFO: eta: 8:40:48  iter: 14800  loss: 0.2281 (0.2701)  auxiliary_ctx: 0.1164 (0.1352)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1117 (0.1349)  time: 1.1522 (1.2400)  data: 0.0203 (0.1139)  lr: 0.064000  max mem: 6405\n",
      "2020-06-10 14:17:29,720 maskrcnn_benchmark INFO: eta: 8:36:10  iter: 15000  loss: 0.2202 (0.2696)  auxiliary_ctx: 0.1116 (0.1349)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1088 (0.1347)  time: 1.1410 (1.2388)  data: 0.0258 (0.1127)  lr: 0.064000  max mem: 6405\n",
      "2020-06-10 14:21:19,786 maskrcnn_benchmark INFO: eta: 8:31:33  iter: 15200  loss: 0.2118 (0.2690)  auxiliary_ctx: 0.1077 (0.1346)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1045 (0.1344)  time: 1.1539 (1.2377)  data: 0.0252 (0.1115)  lr: 0.064000  max mem: 6405\n",
      "2020-06-10 14:25:10,382 maskrcnn_benchmark INFO: eta: 8:26:59  iter: 15400  loss: 0.2065 (0.2684)  auxiliary_ctx: 0.1050 (0.1344)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1017 (0.1340)  time: 1.1464 (1.2366)  data: 0.0230 (0.1104)  lr: 0.064000  max mem: 6405\n",
      "2020-06-10 14:29:00,898 maskrcnn_benchmark INFO: eta: 8:22:25  iter: 15600  loss: 0.2070 (0.2678)  auxiliary_ctx: 0.1050 (0.1341)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1017 (0.1337)  time: 1.1496 (1.2355)  data: 0.0257 (0.1093)  lr: 0.064000  max mem: 6405\n",
      "2020-06-10 14:32:51,295 maskrcnn_benchmark INFO: eta: 8:17:52  iter: 15800  loss: 0.2121 (0.2672)  auxiliary_ctx: 0.1076 (0.1338)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1045 (0.1334)  time: 1.1547 (1.2344)  data: 0.0241 (0.1082)  lr: 0.064000  max mem: 6405\n",
      "2020-06-10 14:36:41,902 maskrcnn_benchmark INFO: ---Total norm 0.39386 clip coef 12.69495-----------------\n",
      "2020-06-10 14:36:41,913 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.30716, (torch.Size([4096, 12544]))\n",
      "2020-06-10 14:36:41,913 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.16760, (torch.Size([4096, 4096]))\n",
      "2020-06-10 14:36:41,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.10588, (torch.Size([51, 4096]))\n",
      "2020-06-10 14:36:41,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.06698, (torch.Size([4096, 1024]))\n",
      "2020-06-10 14:36:41,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.05843, (torch.Size([4096, 512]))\n",
      "2020-06-10 14:36:41,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.05549, (torch.Size([2048, 4808]))\n",
      "2020-06-10 14:36:41,913 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.05466, (torch.Size([2048, 4808]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.04116, (torch.Size([512, 32]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03708, (torch.Size([1024, 512]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03684, (torch.Size([512, 1024]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.02013, (torch.Size([512]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01789, (torch.Size([151, 200]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01700, (torch.Size([4096]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01684, (torch.Size([1024]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01431, (torch.Size([2048, 512]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01367, (torch.Size([2048, 512]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.01335, (torch.Size([51, 4096]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01257, (torch.Size([51]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01210, (torch.Size([2048]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01210, (torch.Size([2048]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01169, (torch.Size([2048]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01169, (torch.Size([2048]))\n",
      "2020-06-10 14:36:41,914 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01104, (torch.Size([512]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.01090, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00855, (torch.Size([4096]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00776, (torch.Size([4096]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.00726, (torch.Size([4096, 12544]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.00617, (torch.Size([4096, 4096]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.weight: 0.00486, (torch.Size([51, 4096]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00186, (torch.Size([4096]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00090, (torch.Size([512]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00086, (torch.Size([512, 1024]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00054, (torch.Size([51]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.bias: 0.00054, (torch.Size([51]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00041, (torch.Size([22801, 51]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00026, (torch.Size([256]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00020, (torch.Size([256]))\n",
      "2020-06-10 14:36:41,915 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00018, (torch.Size([4096]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00012, (torch.Size([4096]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00011, (torch.Size([2048, 4424]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00010, (torch.Size([2048, 4424]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00004, (torch.Size([2048]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00004, (torch.Size([2048]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00004, (torch.Size([2048]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00004, (torch.Size([2048]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00002, (torch.Size([2048, 512]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00002, (torch.Size([2048, 512]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.00000, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00000, (torch.Size([256]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00000, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-10 14:36:41,916 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 14:36:41,917 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-10 14:36:41,917 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 14:36:41,917 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00000, (torch.Size([256]))\n",
      "2020-06-10 14:36:41,917 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 14:36:41,917 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-10 14:36:41,917 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 14:36:41,917 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 14:36:41,917 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-10 14:36:41,920 maskrcnn_benchmark INFO: eta: 8:13:21  iter: 16000  loss: 0.2206 (0.2667)  auxiliary_ctx: 0.1118 (0.1336)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1088 (0.1331)  time: 1.1579 (1.2334)  data: 0.0205 (0.1071)  lr: 0.064000  max mem: 6405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-10 14:36:41,923 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0016000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 14:36:44,435 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 14:36:44,464 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.94it/s]\n",
      "2020-06-10 14:38:14,484 maskrcnn_benchmark INFO: Total run time: 0:01:30.020168 (0.14403226928710938 s / img per device, on 8 devices)\n",
      "2020-06-10 14:38:14,485 maskrcnn_benchmark INFO: Model inference time: 0:01:10.565695 (0.11290511245727539 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.29s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 14:39:50,245 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3019;   R @ 50: 0.4282;   R @ 100: 0.4888;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3481; ngR @ 50: 0.5406; ngR @ 100: 0.6696;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0815;  zR @ 50: 0.1341;  zR @ 100: 0.1578;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1976;  mR @ 50: 0.2624;  mR @ 100: 0.3051;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.3021) (across:0.0000) (against:0.0526) (along:0.7051) (and:0.0000) (at:0.6857) (attached to:0.0190) (behind:0.5166) (belonging to:0.1762) (between:0.0000) (carrying:0.7412) (covered in:0.6667) (covering:0.2626) (eating:0.8571) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.1667) (hanging from:0.3971) (has:0.5845) (holding:0.5290) (in:0.3377) (in front of:0.5330) (laying on:0.1429) (looking at:0.1304) (lying on:0.0000) (made of:0.0000) (mounted on:0.0435) (near:0.1178) (of:0.3836) (on:0.4612) (on back of:0.0455) (over:0.1220) (painted on:0.0000) (parked on:0.9616) (part of:0.0000) (playing:0.0000) (riding:0.9018) (says:0.0000) (sitting on:0.5743) (standing on:0.2098) (to:0.0556) (under:0.3852) (using:0.1923) (walking in:0.0769) (walking on:0.9650) (watching:0.6863) (wearing:0.9332) (wears:0.0000) (with:0.2960) \n",
      "SGG eval:   A @ 20: 0.5431;   A @ 50: 0.5477;   A @ 100: 0.5477;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 14:39:51,018 maskrcnn_benchmark INFO: Validation Result: 0.4888\n",
      "2020-06-10 14:39:51,018 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "2020-06-10 14:43:40,177 maskrcnn_benchmark INFO: eta: 8:13:27  iter: 16200  loss: 0.2218 (0.2662)  auxiliary_ctx: 0.1121 (0.1333)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1096 (0.1328)  time: 1.1408 (1.2440)  data: 0.0246 (0.1177)  lr: 0.006400  max mem: 6405\n",
      "2020-06-10 14:47:29,934 maskrcnn_benchmark INFO: eta: 8:08:50  iter: 16400  loss: 0.2144 (0.2655)  auxiliary_ctx: 0.1085 (0.1330)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1060 (0.1325)  time: 1.1425 (1.2428)  data: 0.0254 (0.1166)  lr: 0.006400  max mem: 6405\n",
      "2020-06-10 14:51:20,112 maskrcnn_benchmark INFO: eta: 8:04:16  iter: 16600  loss: 0.2073 (0.2649)  auxiliary_ctx: 0.1047 (0.1327)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1025 (0.1322)  time: 1.1510 (1.2417)  data: 0.0191 (0.1155)  lr: 0.006400  max mem: 6433\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "2020-06-10 14:55:09,917 maskrcnn_benchmark INFO: eta: 7:59:42  iter: 16800  loss: 0.2048 (0.2642)  auxiliary_ctx: 0.1035 (0.1324)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1014 (0.1318)  time: 1.1416 (1.2406)  data: 0.0251 (0.1144)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 14:58:59,301 maskrcnn_benchmark INFO: eta: 7:55:08  iter: 17000  loss: 0.1974 (0.2636)  auxiliary_ctx: 0.1003 (0.1321)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0971 (0.1315)  time: 1.1416 (1.2395)  data: 0.0255 (0.1133)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:02:48,871 maskrcnn_benchmark INFO: eta: 7:50:36  iter: 17200  loss: 0.2015 (0.2629)  auxiliary_ctx: 0.1021 (0.1317)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0998 (0.1311)  time: 1.1409 (1.2385)  data: 0.0261 (0.1123)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:06:39,477 maskrcnn_benchmark INFO: eta: 7:46:06  iter: 17400  loss: 0.1962 (0.2622)  auxiliary_ctx: 0.0991 (0.1314)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0975 (0.1308)  time: 1.1515 (1.2375)  data: 0.0231 (0.1112)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:10:29,376 maskrcnn_benchmark INFO: eta: 7:41:36  iter: 17600  loss: 0.2115 (0.2616)  auxiliary_ctx: 0.1072 (0.1311)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1041 (0.1305)  time: 1.1367 (1.2365)  data: 0.0257 (0.1102)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:14:19,181 maskrcnn_benchmark INFO: eta: 7:37:07  iter: 17800  loss: 0.1960 (0.2609)  auxiliary_ctx: 0.0996 (0.1308)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0964 (0.1301)  time: 1.1518 (1.2355)  data: 0.0240 (0.1093)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:18:09,361 maskrcnn_benchmark INFO: eta: 7:32:40  iter: 18000  loss: 0.2112 (0.2603)  auxiliary_ctx: 0.1065 (0.1305)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1047 (0.1298)  time: 1.1498 (1.2345)  data: 0.0240 (0.1083)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:18:09,363 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0018000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 15:18:11,934 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 15:18:11,964 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:29<00:00,  6.98it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.80it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.79it/s]\n",
      "2020-06-10 15:19:41,499 maskrcnn_benchmark INFO: Total run time: 0:01:29.534733 (0.1432555721282959 s / img per device, on 8 devices)\n",
      "2020-06-10 15:19:41,500 maskrcnn_benchmark INFO: Model inference time: 0:01:10.167780 (0.11226844749450683 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.67s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.31s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 15:21:17,421 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3126;   R @ 50: 0.4339;   R @ 100: 0.4896;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3572; ngR @ 50: 0.5434; ngR @ 100: 0.6705;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0733;  zR @ 50: 0.1296;  zR @ 100: 0.1600;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1973;  mR @ 50: 0.2643;  mR @ 100: 0.3035;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.3352) (across:0.0000) (against:0.0526) (along:0.7051) (and:0.0000) (at:0.6958) (attached to:0.0121) (behind:0.5442) (belonging to:0.2452) (between:0.0000) (carrying:0.7215) (covered in:0.6548) (covering:0.2810) (eating:0.7143) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0333) (hanging from:0.4743) (has:0.5205) (holding:0.4923) (in:0.3262) (in front of:0.5443) (laying on:0.1905) (looking at:0.2174) (lying on:0.0000) (made of:0.0000) (mounted on:0.0435) (near:0.0906) (of:0.2626) (on:0.4915) (on back of:0.0455) (over:0.1098) (painted on:0.0000) (parked on:0.9590) (part of:0.0000) (playing:0.0000) (riding:0.9107) (says:0.0000) (sitting on:0.5623) (standing on:0.2098) (to:0.1111) (under:0.3852) (using:0.2692) (walking in:0.0769) (walking on:0.9512) (watching:0.6863) (wearing:0.9297) (wears:0.0000) (with:0.2846) \n",
      "SGG eval:   A @ 20: 0.5429;   A @ 50: 0.5468;   A @ 100: 0.5468;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 15:21:18,214 maskrcnn_benchmark INFO: Validation Result: 0.4896\n",
      "2020-06-10 15:25:07,493 maskrcnn_benchmark INFO: eta: 7:31:58  iter: 18200  loss: 0.1874 (0.2596)  auxiliary_ctx: 0.0956 (0.1301)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0918 (0.1294)  time: 1.1409 (1.2440)  data: 0.0251 (0.1177)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:28:57,673 maskrcnn_benchmark INFO: eta: 7:27:27  iter: 18400  loss: 0.1947 (0.2589)  auxiliary_ctx: 0.0991 (0.1298)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0956 (0.1291)  time: 1.1472 (1.2429)  data: 0.0261 (0.1167)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:32:47,589 maskrcnn_benchmark INFO: eta: 7:22:57  iter: 18600  loss: 0.2018 (0.2583)  auxiliary_ctx: 0.1020 (0.1295)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0992 (0.1288)  time: 1.1420 (1.2419)  data: 0.0252 (0.1157)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:36:37,498 maskrcnn_benchmark INFO: eta: 7:18:28  iter: 18800  loss: 0.1951 (0.2577)  auxiliary_ctx: 0.0989 (0.1292)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0962 (0.1285)  time: 1.1424 (1.2410)  data: 0.0231 (0.1147)  lr: 0.006400  max mem: 6433\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "2020-06-10 15:40:27,320 maskrcnn_benchmark INFO: eta: 7:13:59  iter: 19000  loss: 0.1797 (0.2570)  auxiliary_ctx: 0.0909 (0.1289)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0887 (0.1281)  time: 1.1405 (1.2400)  data: 0.0255 (0.1138)  lr: 0.006400  max mem: 6433\n",
      "2020-06-10 15:44:17,166 maskrcnn_benchmark INFO: eta: 7:09:32  iter: 19200  loss: 0.1998 (0.2564)  auxiliary_ctx: 0.1011 (0.1286)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0987 (0.1278)  time: 1.1423 (1.2390)  data: 0.0251 (0.1128)  lr: 0.006400  max mem: 6541\n",
      "2020-06-10 15:48:07,046 maskrcnn_benchmark INFO: eta: 7:05:05  iter: 19400  loss: 0.2021 (0.2558)  auxiliary_ctx: 0.1023 (0.1283)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0995 (0.1275)  time: 1.1492 (1.2381)  data: 0.0252 (0.1119)  lr: 0.006400  max mem: 6541\n",
      "2020-06-10 15:51:56,899 maskrcnn_benchmark INFO: eta: 7:00:39  iter: 19600  loss: 0.1869 (0.2551)  auxiliary_ctx: 0.0949 (0.1280)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0919 (0.1271)  time: 1.1529 (1.2372)  data: 0.0215 (0.1110)  lr: 0.006400  max mem: 6541\n",
      "2020-06-10 15:55:46,447 maskrcnn_benchmark INFO: eta: 6:56:13  iter: 19800  loss: 0.1925 (0.2545)  auxiliary_ctx: 0.0982 (0.1277)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0943 (0.1268)  time: 1.1410 (1.2363)  data: 0.0196 (0.1101)  lr: 0.006400  max mem: 6541\n",
      "2020-06-10 15:59:36,555 maskrcnn_benchmark INFO: ---Total norm 0.63699 clip coef 7.84940-----------------\n",
      "2020-06-10 15:59:36,565 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.54053, (torch.Size([4096, 12544]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.28032, (torch.Size([4096, 4096]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.10095, (torch.Size([51, 4096]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.07408, (torch.Size([4096, 1024]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.07212, (torch.Size([2048, 4808]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.06968, (torch.Size([2048, 4808]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.04964, (torch.Size([4096, 512]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.04060, (torch.Size([1024, 512]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03803, (torch.Size([512, 1024]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02313, (torch.Size([151, 200]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02101, (torch.Size([512, 32]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01892, (torch.Size([1024]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01884, (torch.Size([512]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01870, (torch.Size([4096]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01713, (torch.Size([2048, 512]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01581, (torch.Size([2048, 512]))\n",
      "2020-06-10 15:59:36,566 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01229, (torch.Size([2048]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01229, (torch.Size([2048]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01220, (torch.Size([4096]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.01189, (torch.Size([51, 4096]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01136, (torch.Size([2048]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01136, (torch.Size([2048]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00876, (torch.Size([51]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.00815, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00563, (torch.Size([4096]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.00512, (torch.Size([4096, 12544]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.weight: 0.00512, (torch.Size([51, 4096]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00504, (torch.Size([512]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.00430, (torch.Size([4096, 4096]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00323, (torch.Size([4096]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00045, (torch.Size([51]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_gate_fc.bias: 0.00045, (torch.Size([51]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00039, (torch.Size([22801, 51]))\n",
      "2020-06-10 15:59:36,567 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00018, (torch.Size([256]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00017, (torch.Size([512]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00016, (torch.Size([512, 1024]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00014, (torch.Size([256]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00013, (torch.Size([2048, 4424]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00011, (torch.Size([4096]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00011, (torch.Size([2048, 4424]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00008, (torch.Size([4096]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00001, (torch.Size([2048]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00001, (torch.Size([2048]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00001, (torch.Size([2048, 512]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00001, (torch.Size([2048]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00001, (torch.Size([2048]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00000, (torch.Size([2048, 512]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.00000, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.00000, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-10 15:59:36,568 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00000, (torch.Size([256]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00000, (torch.Size([128]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00000, (torch.Size([256]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-10 15:59:36,569 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-10 15:59:36,572 maskrcnn_benchmark INFO: eta: 6:51:49  iter: 20000  loss: 0.1721 (0.2539)  auxiliary_ctx: 0.0872 (0.1274)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.0849 (0.1265)  time: 1.1494 (1.2355)  data: 0.0256 (0.1093)  lr: 0.006400  max mem: 6541\n",
      "2020-06-10 15:59:36,575 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE/model_0020000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-10 15:59:39,063 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-10 15:59:39,083 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.78it/s]\n",
      "2020-06-10 16:01:11,274 maskrcnn_benchmark INFO: Total run time: 0:01:32.190812 (0.14750529861450196 s / img per device, on 8 devices)\n",
      "2020-06-10 16:01:11,274 maskrcnn_benchmark INFO: Model inference time: 0:01:11.409257 (0.11425481071472168 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.96s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 16:02:47,596 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3171;   R @ 50: 0.4319;   R @ 100: 0.4837;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3617; ngR @ 50: 0.5368; ngR @ 100: 0.6637;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0800;  zR @ 50: 0.1467;  zR @ 100: 0.1667;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1999;  mR @ 50: 0.2637;  mR @ 100: 0.3005;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2972) (across:0.0000) (against:0.0526) (along:0.6667) (and:0.0000) (at:0.6857) (attached to:0.0213) (behind:0.5213) (belonging to:0.2726) (between:0.0000) (carrying:0.7281) (covered in:0.6548) (covering:0.2810) (eating:0.7143) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.1333) (hanging from:0.4191) (has:0.4988) (holding:0.4725) (in:0.3214) (in front of:0.5336) (laying on:0.2381) (looking at:0.1739) (lying on:0.0000) (made of:0.0000) (mounted on:0.0435) (near:0.0827) (of:0.2538) (on:0.4966) (on back of:0.0455) (over:0.0854) (painted on:0.0000) (parked on:0.9511) (part of:0.0000) (playing:0.0000) (riding:0.9107) (says:0.0000) (sitting on:0.5438) (standing on:0.1815) (to:0.1389) (under:0.3495) (using:0.2885) (walking in:0.0769) (walking on:0.9527) (watching:0.6863) (wearing:0.9328) (wears:0.0000) (with:0.2813) \n",
      "SGG eval:   A @ 20: 0.5358;   A @ 50: 0.5398;   A @ 100: 0.5398;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-10 16:02:48,361 maskrcnn_benchmark INFO: Validation Result: 0.4837\n",
      "2020-06-10 16:02:48,361 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "2020-06-10 16:02:48,361 maskrcnn_benchmark INFO: Trigger MAX_DECAY_STEP at iteration 20000.\n",
      "2020-06-10 16:02:48,660 maskrcnn_benchmark INFO: Total training time: 6:55:01.203293 (0.6225 s / it)\n",
      "  0%|                                                  | 0/3306 [00:00<?, ?it/s]2020-06-10 16:02:50,649 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:56<00:00,  6.94it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:56<00:00,  6.94it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:56<00:00,  6.94it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:56<00:00,  6.94it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:56<00:00,  6.94it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:56<00:00,  6.94it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:56<00:00,  6.94it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:56<00:00,  6.94it/s]\n",
      "2020-06-10 16:10:47,150 maskrcnn_benchmark INFO: Total run time: 0:07:56.500396 (0.14414290145658235 s / img per device, on 8 devices)\n",
      "2020-06-10 16:10:47,151 maskrcnn_benchmark INFO: Model inference time: 0:06:15.216506 (0.11350419904842578 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(325563, 7)\n",
      "0/325563\n",
      "DONE (t=2.99s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=137.71s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=19.60s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.659\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.995\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-10 16:19:46,525 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9995\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3310;   R @ 50: 0.4448;   R @ 100: 0.4940;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3699; ngR @ 50: 0.5500; ngR @ 100: 0.6699;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0546;  zR @ 50: 0.0915;  zR @ 100: 0.1196;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1870;  mR @ 50: 0.2586;  mR @ 100: 0.2968;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2359) (across:0.0000) (against:0.1290) (along:0.3983) (and:0.0118) (at:0.5300) (attached to:0.0349) (behind:0.6025) (belonging to:0.3707) (between:0.0208) (carrying:0.5859) (covered in:0.7157) (covering:0.3905) (eating:0.5982) (flying in:0.0000) (for:0.0779) (from:0.0000) (growing on:0.1996) (hanging from:0.3013) (has:0.5605) (holding:0.5950) (in:0.3101) (in front of:0.4260) (laying on:0.3188) (looking at:0.1727) (lying on:0.0204) (made of:0.0000) (mounted on:0.0747) (near:0.0832) (of:0.3387) (on:0.4441) (on back of:0.0236) (over:0.0794) (painted on:0.0240) (parked on:0.8800) (part of:0.0000) (playing:0.0000) (riding:0.9238) (says:0.0000) (sitting on:0.5100) (standing on:0.2499) (to:0.1127) (under:0.4299) (using:0.3739) (walking in:0.0211) (walking on:0.8770) (watching:0.6256) (wearing:0.9381) (wears:0.0000) (with:0.2256) \n",
      "SGG eval:   A @ 20: 0.5303;   A @ 50: 0.5322;   A @ 100: 0.5322;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10025 --nproc_per_node=8 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE gate \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE \\\n",
    "SOLVER.IMS_PER_BATCH 64 TEST.IMS_PER_BATCH 8 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 40000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/precls-CausalAnalysisPredictor-motifs-gate-TDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T10:11:46.173011Z",
     "start_time": "2020-06-11T09:36:25.379853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-11 09:36:37,290 maskrcnn_benchmark INFO: Using 8 GPUs\n",
      "2020-06-11 09:36:37,290 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'dist', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-dist1-TDE'], skip_test=False)\n",
      "2020-06-11 09:36:37,290 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-11 09:36:41,945 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n",
      "2020-06-11 09:36:41,945 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml\n",
      "2020-06-11 09:36:41,946 maskrcnn_benchmark INFO: \n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MAX_SIZE_TEST: 1000\n",
      "MODEL:\n",
      "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
      "  WEIGHT: \"catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\"\n",
      "  BACKBONE:\n",
      "    CONV_BODY: \"R-101-FPN\" # VGG-16\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    STRIDE_IN_1X1: False\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RELATION_ON: True\n",
      "  ATTRIBUTE_ON: False\n",
      "  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false\n",
      "  RPN:\n",
      "    USE_FPN: True\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    RPN_MID_CHANNEL: 256\n",
      "  ROI_HEADS:\n",
      "    USE_FPN: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "  ROI_BOX_HEAD:\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA\n",
      "    MLP_HEAD_DIM: 4096\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight\n",
      "    POS_WEIGHT: 50.0\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA\n",
      "    MAX_ATTRIBUTES: 10             \n",
      "    ATTRIBUTE_BGFG_SAMPLE: True    \n",
      "    ATTRIBUTE_BGFG_RATIO: 3        \n",
      "  ROI_RELATION_HEAD:\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing\n",
      "    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain \"to the left of\" & \"to the right of\")\n",
      "    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    FEATURE_EXTRACTOR: \"RelationFeatureExtractor\"\n",
      "    #################### Select Relationship Model ####################\n",
      "    #PREDICTOR: \"MotifPredictor\"\n",
      "    #PREDICTOR: \"VCTreePredictor\"\n",
      "    #PREDICTOR: \"TransformerPredictor\"\n",
      "    PREDICTOR: \"CausalAnalysisPredictor\"\n",
      "    ################# Parameters for Motif Predictor ##################\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    ############# Parameters for Causal Unbias Predictor ##############\n",
      "    ### Implementation for paper \"Unbiased Scene Graph Generation from Biased Training\"\n",
      "    CAUSAL:\n",
      "      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'\n",
      "      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate', 'dist'\n",
      "      SEPARATE_SPATIAL: False         # separate spatial in union feature\n",
      "      CONTEXT_LAYER: \"motifs\"         # candicates: motifs, vctree, vtranse\n",
      "      SPATIAL_FOR_VISION: True\n",
      "      EFFECT_ANALYSIS: True\n",
      "    ############### Parameters for Transformer Predictor ##############\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      NUM_HEAD: 8\n",
      "      KEY_DIM: 64\n",
      "      VAL_DIM: 64\n",
      "      INNER_DIM: 2048 \n",
      "DATASETS:\n",
      "  TRAIN: (\"VG_stanford_filtered_with_attribute_train\",)\n",
      "  VAL: (\"VG_stanford_filtered_with_attribute_val\",)\n",
      "  TEST: (\"VG_stanford_filtered_with_attribute_test\",)\n",
      "DATALOADER:\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "SOLVER:\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  BASE_LR: 0.01\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  MOMENTUM: 0.9\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  STEPS: (10000, 16000)\n",
      "  MAX_ITER: 40000\n",
      "  VAL_PERIOD: 2000\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    # the following paramters are only used for WarmupReduceLROnPlateau\n",
      "    TYPE: \"WarmupReduceLROnPlateau\"    # WarmupMultiStepLR, WarmupReduceLROnPlateau\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "OUTPUT_DIR: './output/relation_baseline'\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  RELATION:\n",
      "    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem\n",
      "    REQUIRE_OVERLAP: False\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "\n",
      "2020-06-11 09:36:41,948 maskrcnn_benchmark INFO: Running with config:\n",
      "AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: TDE\n",
      "      FUSION_TYPE: dist\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-dist1-TDE\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 64\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 8\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-11 09:36:41,949 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-dist1-TDE/config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-11 09:36:41,985 maskrcnn_benchmark INFO: #################### prepare training ####################\n",
      "2020-06-11 09:36:45,294 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-11 09:36:45,294 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7168.69it/s]\n",
      " 93%|████████████████████████████████▋  | 52417/56224 [00:07<00:00, 6229.75it/s]2020-06-11 09:37:12,414 maskrcnn_benchmark.data.build INFO: finish\n",
      " 88%|██████████████████████████████▉    | 49703/56224 [00:06<00:01, 6347.56it/s]2020-06-11 09:37:12,415 maskrcnn_benchmark.data.build INFO: Save data statistics to: checkpoint/precls-CausalAnalysisPredictor-motifs-dist1-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-11 09:37:12,415 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      " 28%|█████████▉                         | 16012/56224 [00:02<00:05, 7322.14it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 99%|██████████████████████████████████▌| 55581/56224 [00:07<00:00, 6123.26it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7122.19it/s]\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7028.71it/s]\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7057.80it/s]\n",
      " 99%|██████████████████████████████████▋| 55722/56224 [00:07<00:00, 6057.21it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 38%|█████████████▍                     | 21526/56224 [00:03<00:04, 7656.65it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7131.29it/s]\n",
      " 98%|██████████████████████████████████▏| 54830/56224 [00:07<00:00, 6240.86it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 99%|██████████████████████████████████▊| 55929/56224 [00:08<00:00, 5792.02it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6896.92it/s]\n",
      " 41%|██████████████▎                    | 23068/56224 [00:03<00:04, 7604.83it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7078.78it/s]\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      " 42%|██████████████▊                    | 23830/56224 [00:03<00:04, 7594.37it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 44%|███████████████▎                   | 24590/56224 [00:03<00:04, 7590.11it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      " 45%|███████████████▊                   | 25356/56224 [00:03<00:04, 7608.93it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "2020-06-11 09:37:13,709 maskrcnn_benchmark INFO: #################### end model construction ####################\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      " 48%|████████████████▊                  | 26917/56224 [00:03<00:03, 7700.87it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      " 49%|█████████████████▏                 | 27688/56224 [00:03<00:03, 7512.56it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      " 51%|█████████████████▋                 | 28441/56224 [00:03<00:03, 6973.15it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      " 52%|██████████████████▏                | 29147/56224 [00:04<00:04, 6602.39it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "2020-06-11 09:37:14,331 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      " 53%|██████████████████▌                | 29818/56224 [00:04<00:04, 6454.26it/s]2020-06-11 09:37:14,379 maskrcnn_benchmark INFO: #################### end distributed ####################\n",
      "2020-06-11 09:37:14,381 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      " 54%|██████████████████▉                | 30472/56224 [00:04<00:04, 6338.90it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 62%|█████████████████████▋             | 34802/56224 [00:05<00:03, 6043.61it/s]2020-06-11 09:37:15,265 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-11 09:37:15,265 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-11 09:37:15,265 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-11 09:37:15,265 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-11 09:37:15,265 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-11 09:37:15,265 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-11 09:37:15,266 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-11 09:37:15,266 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-11 09:37:15,266 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.\n",
      "2020-06-11 09:37:15,266 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████             | 35423/56224 [00:05<00:03, 6088.76it/s]2020-06-11 09:37:15,327 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\r\n",
      "2020-06-11 09:37:15,327 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\r\n",
      "2020-06-11 09:37:15,327 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\r\n",
      "2020-06-11 09:37:15,327 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\r\n",
      "2020-06-11 09:37:15,327 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)\r\n",
      "2020-06-11 09:37:15,328 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)\r\n",
      "2020-06-11 09:37:15,329 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)\r\n",
      "2020-06-11 09:37:15,330 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)\r\n",
      "2020-06-11 09:37:15,331 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)\r\n",
      "2020-06-11 09:37:15,331 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)\r\n",
      "2020-06-11 09:37:15,331 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)\r\n",
      "2020-06-11 09:37:15,331 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)\r\n",
      "2020-06-11 09:37:15,331 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()\r\n",
      "2020-06-11 09:37:15,331 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)\r\n",
      "2020-06-11 09:37:15,331 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)\r\n",
      "2020-06-11 09:37:15,331 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6419.75it/s]\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-11 09:37:21,652 maskrcnn_benchmark INFO: #################### end load checkpointer ####################\n",
      "2020-06-11 09:37:21,652 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-11 09:37:24,428 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-dist1-TDE/labels.json\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 09:37:25,787 maskrcnn_benchmark INFO: #################### end dataloader ####################\n",
      "2020-06-11 09:37:25,787 maskrcnn_benchmark INFO: Validate before training\n",
      "2020-06-11 09:37:25,797 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.84it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.75it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "2020-06-11 09:38:58,332 maskrcnn_benchmark INFO: Total run time: 0:01:32.535412 (0.14805665855407715 s / img per device, on 8 devices)\n",
      "2020-06-11 09:38:58,333 maskrcnn_benchmark INFO: Model inference time: 0:01:10.627927 (0.11300468292236328 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.29s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 09:40:05,774 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.0026;   R @ 50: 0.0041;   R @ 100: 0.0054;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.0069; ngR @ 50: 0.0226; ngR @ 100: 0.0469;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0044;  zR @ 50: 0.0044;  zR @ 100: 0.0044;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.0092;  mR @ 50: 0.0150;  mR @ 100: 0.0203;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.0011) (across:0.0000) (against:0.0000) (along:0.4551) (and:0.0000) (at:0.0000) (attached to:0.0336) (behind:0.0009) (belonging to:0.0000) (between:0.0577) (carrying:0.0395) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.1029) (has:0.0071) (holding:0.0000) (in:0.0065) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.1556) (made of:0.0000) (mounted on:0.0000) (near:0.0002) (of:0.0003) (on:0.0016) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0000) (standing on:0.0000) (to:0.0000) (under:0.0000) (using:0.0000) (walking in:0.0000) (walking on:0.0409) (watching:0.0000) (wearing:0.0005) (wears:0.0600) (with:0.0018) \n",
      "SGG eval:   A @ 20: 0.0056;   A @ 50: 0.0056;   A @ 100: 0.0056;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 09:40:06,552 maskrcnn_benchmark INFO: Start training\n",
      "2020-06-11 09:40:08,893 maskrcnn_benchmark INFO: ---Total norm nan clip coef nan-----------------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: inf, (torch.Size([51]))\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: inf, (torch.Size([51]))\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 146448.65625, (torch.Size([4096, 512]))\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 50120.32031, (torch.Size([4096]))\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 47715.27734, (torch.Size([512, 32]))\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 15001.07324, (torch.Size([512]))\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 737.55078, (torch.Size([22801, 51]))\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 10.26378, (torch.Size([4096, 4096]))\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 9.84869, (torch.Size([4096, 12544]))\n",
      "2020-06-11 09:40:08,907 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 2.42199, (torch.Size([51, 4096]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 2.09434, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 1.49996, (torch.Size([4096, 1024]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 1.45765, (torch.Size([512, 1024]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 1.25547, (torch.Size([4096, 4096]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.11699, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.75550, (torch.Size([2048, 4808]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.73836, (torch.Size([2048, 4808]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.60211, (torch.Size([4096, 12544]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.57587, (torch.Size([512]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.25230, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.17128, (torch.Size([512, 1024]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.12528, (torch.Size([2048, 512]))\n",
      "2020-06-11 09:40:08,908 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.12419, (torch.Size([2048, 512]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.10514, (torch.Size([4096]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.09271, (torch.Size([4096]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.08885, (torch.Size([2048, 4424]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.08400, (torch.Size([2048, 4424]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.07775, (torch.Size([2048]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.07775, (torch.Size([2048]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.07771, (torch.Size([256]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.07576, (torch.Size([2048]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.07576, (torch.Size([2048]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.06862, (torch.Size([1024, 512]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.06490, (torch.Size([512]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.05867, (torch.Size([1024]))\n",
      "2020-06-11 09:40:08,909 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.04749, (torch.Size([4096]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.04241, (torch.Size([256]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.03624, (torch.Size([128]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.03400, (torch.Size([4096]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.02102, (torch.Size([256]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.02065, (torch.Size([256]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01889, (torch.Size([128]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.01539, (torch.Size([128]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.01513, (torch.Size([2048, 512]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.01429, (torch.Size([2048, 512]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00886, (torch.Size([2048]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00886, (torch.Size([2048]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00838, (torch.Size([2048]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00838, (torch.Size([2048]))\n",
      "2020-06-11 09:40:08,910 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00787, (torch.Size([4096]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00581, (torch.Size([151, 200]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00426, (torch.Size([128, 32]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00254, (torch.Size([32, 9]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00181, (torch.Size([128]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00109, (torch.Size([32]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00071, (torch.Size([151, 200]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00045, (torch.Size([32]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: nan, (torch.Size([51, 4096]))\n",
      "2020-06-11 09:40:08,911 maskrcnn_benchmark INFO: -------------------------------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "2020-06-11 09:43:58,270 maskrcnn_benchmark INFO: eta: 12:48:31  iter: 200  loss: 9.9814 (292.5421)  auxiliary_ctx: 0.3217 (0.7073)  auxiliary_frq: 0.2069 (0.2092)  auxiliary_vis: 0.5190 (2.9279)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 8.9012 (288.6978)  time: 1.1456 (1.1586)  data: 0.0252 (0.0289)  lr: 0.293248  max mem: 6064\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
      "2020-06-11 09:47:49,116 maskrcnn_benchmark INFO: eta: 12:43:13  iter: 400  loss: 566.7425 (43774.6654)  auxiliary_ctx: 0.2917 (0.5189)  auxiliary_frq: 0.2083 (0.2091)  auxiliary_vis: 1.3283 (14.5733)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 565.3185 (43759.3649)  time: 1.1465 (1.1564)  data: 0.0253 (0.0264)  lr: 0.523648  max mem: 6064\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
      "\n",
      "2020-06-11 09:51:39,534 maskrcnn_benchmark INFO: eta: 12:38:25  iter: 600  loss: 326.1679 (inf)  auxiliary_ctx: 0.4108 (18.7832)  auxiliary_frq: 0.2061 (0.2092)  auxiliary_vis: 1.3777 (inf)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 312.4322 (inf)  time: 1.1456 (1.1550)  data: 0.0250 (0.0255)  lr: 0.640000  max mem: 6128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34\n",
      "\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65\n",
      "\n",
      "2020-06-11 09:55:26,554 maskrcnn_benchmark INFO: eta: 12:31:20  iter: 800  loss: inf (inf)  auxiliary_ctx: 0.3403 (14.1696)  auxiliary_frq: 0.2132 (0.2092)  auxiliary_vis: inf (inf)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: inf (inf)  time: 1.1282 (1.1500)  data: 0.0231 (0.0251)  lr: 0.640000  max mem: 6128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4063678720065206e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4063678720065206e-108Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4063678720065206e-108\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4063678720065206e-108Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4063678720065206e-108Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4063678720065206e-108\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4063678720065206e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4063678720065206e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7031839360032603e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7031839360032603e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7031839360032603e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7031839360032603e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7031839360032603e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7031839360032603e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7031839360032603e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7031839360032603e-108\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.515919680016301e-109Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.515919680016301e-109\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.515919680016301e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.515919680016301e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.515919680016301e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.515919680016301e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.515919680016301e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.515919680016301e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.257959840008151e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.257959840008151e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.257959840008151e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.257959840008151e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.257959840008151e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.257959840008151e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.257959840008151e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.257959840008151e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1289799200040754e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1289799200040754e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1289799200040754e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1289799200040754e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1289799200040754e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1289799200040754e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1289799200040754e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1289799200040754e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0644899600020377e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0644899600020377e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0644899600020377e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0644899600020377e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0644899600020377e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0644899600020377e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0644899600020377e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0644899600020377e-109\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.3224498000101884e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.3224498000101884e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.3224498000101884e-110Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.3224498000101884e-110\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.3224498000101884e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.3224498000101884e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.3224498000101884e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.3224498000101884e-110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6612249000050942e-110Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6612249000050942e-110\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6612249000050942e-110Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6612249000050942e-110\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6612249000050942e-110Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6612249000050942e-110\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6612249000050942e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6612249000050942e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3306124500025471e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3306124500025471e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3306124500025471e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3306124500025471e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3306124500025471e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3306124500025471e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3306124500025471e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3306124500025471e-110\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.653062250012736e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.653062250012736e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.653062250012736e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.653062250012736e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.653062250012736e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.653062250012736e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.653062250012736e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.653062250012736e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.326531125006368e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.326531125006368e-111Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.326531125006368e-111\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.326531125006368e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.326531125006368e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.326531125006368e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.326531125006368e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.326531125006368e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.663265562503184e-111Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.663265562503184e-111\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.663265562503184e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.663265562503184e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.663265562503184e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.663265562503184e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.663265562503184e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.663265562503184e-111\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.31632781251592e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.31632781251592e-112Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.31632781251592e-112\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.31632781251592e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.31632781251592e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.31632781251592e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.31632781251592e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.31632781251592e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.15816390625796e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.15816390625796e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.15816390625796e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.15816390625796e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.15816390625796e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.15816390625796e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.15816390625796e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.15816390625796e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.07908195312898e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.07908195312898e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.07908195312898e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.07908195312898e-112Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.07908195312898e-112\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.07908195312898e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.07908195312898e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.07908195312898e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.03954097656449e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.03954097656449e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.03954097656449e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.03954097656449e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.03954097656449e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.03954097656449e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.03954097656449e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.03954097656449e-112\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.19770488282245e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.19770488282245e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.19770488282245e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.19770488282245e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.19770488282245e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.19770488282245e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.19770488282245e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.19770488282245e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.598852441411225e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.598852441411225e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.598852441411225e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.598852441411225e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.598852441411225e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.598852441411225e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.598852441411225e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.598852441411225e-113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2994262207056124e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2994262207056124e-113Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2994262207056124e-113Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2994262207056124e-113\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2994262207056124e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2994262207056124e-113Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2994262207056124e-113\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2994262207056124e-113\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.497131103528062e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.497131103528062e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.497131103528062e-114Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.497131103528062e-114\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.497131103528062e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.497131103528062e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.497131103528062e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.497131103528062e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.248565551764031e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.248565551764031e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.248565551764031e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.248565551764031e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.248565551764031e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.248565551764031e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.248565551764031e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.248565551764031e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6242827758820155e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6242827758820155e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6242827758820155e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6242827758820155e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6242827758820155e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6242827758820155e-114Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6242827758820155e-114\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6242827758820155e-114\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.121413879410078e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.121413879410078e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.121413879410078e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.121413879410078e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.121413879410078e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.121413879410078e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.121413879410078e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.121413879410078e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.060706939705039e-115Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.060706939705039e-115\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.060706939705039e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.060706939705039e-115Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.060706939705039e-115\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.060706939705039e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.060706939705039e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.060706939705039e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0303534698525194e-115Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0303534698525194e-115\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0303534698525194e-115Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0303534698525194e-115\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0303534698525194e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0303534698525194e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0303534698525194e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0303534698525194e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0151767349262597e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0151767349262597e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0151767349262597e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0151767349262597e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0151767349262597e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0151767349262597e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0151767349262597e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0151767349262597e-115\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.075883674631299e-116Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.075883674631299e-116\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.075883674631299e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.075883674631299e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.075883674631299e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.075883674631299e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.075883674631299e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.075883674631299e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5379418373156492e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5379418373156492e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5379418373156492e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5379418373156492e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5379418373156492e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5379418373156492e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5379418373156492e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5379418373156492e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2689709186578246e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2689709186578246e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2689709186578246e-116Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2689709186578246e-116\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2689709186578246e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2689709186578246e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2689709186578246e-116\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2689709186578246e-116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.344854593289123e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.344854593289123e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.344854593289123e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.344854593289123e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.344854593289123e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.344854593289123e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.344854593289123e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.344854593289123e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1724272966445615e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1724272966445615e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1724272966445615e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1724272966445615e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1724272966445615e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1724272966445615e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1724272966445615e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1724272966445615e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5862136483222808e-117Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5862136483222808e-117\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5862136483222808e-117Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5862136483222808e-117\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5862136483222808e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5862136483222808e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5862136483222808e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5862136483222808e-117\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.931068241611404e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.931068241611404e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.931068241611404e-118Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.931068241611404e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.931068241611404e-118\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.931068241611404e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.931068241611404e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.931068241611404e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.965534120805702e-118Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.965534120805702e-118\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.965534120805702e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.965534120805702e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.965534120805702e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.965534120805702e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.965534120805702e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.965534120805702e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.982767060402851e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.982767060402851e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.982767060402851e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.982767060402851e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.982767060402851e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.982767060402851e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.982767060402851e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.982767060402851e-118\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.913835302014255e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.913835302014255e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.913835302014255e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.913835302014255e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.913835302014255e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.913835302014255e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.913835302014255e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.913835302014255e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9569176510071274e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9569176510071274e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9569176510071274e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9569176510071274e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9569176510071274e-119Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9569176510071274e-119Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9569176510071274e-119\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9569176510071274e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4784588255035637e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4784588255035637e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4784588255035637e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4784588255035637e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4784588255035637e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4784588255035637e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4784588255035637e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4784588255035637e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2392294127517818e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2392294127517818e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2392294127517818e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2392294127517818e-119Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2392294127517818e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2392294127517818e-119\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2392294127517818e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2392294127517818e-119\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.196147063758909e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.196147063758909e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.196147063758909e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.196147063758909e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.196147063758909e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.196147063758909e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.196147063758909e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.196147063758909e-120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0980735318794546e-120Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0980735318794546e-120\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0980735318794546e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0980735318794546e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0980735318794546e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0980735318794546e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0980735318794546e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0980735318794546e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5490367659397273e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5490367659397273e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5490367659397273e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5490367659397273e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5490367659397273e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5490367659397273e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5490367659397273e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5490367659397273e-120\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.745183829698637e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.745183829698637e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.745183829698637e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.745183829698637e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.745183829698637e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.745183829698637e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.745183829698637e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.745183829698637e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8725919148493183e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8725919148493183e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8725919148493183e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8725919148493183e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8725919148493183e-121Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8725919148493183e-121\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8725919148493183e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8725919148493183e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9362959574246591e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9362959574246591e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9362959574246591e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9362959574246591e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9362959574246591e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9362959574246591e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9362959574246591e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9362959574246591e-121\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.681479787123296e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.681479787123296e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.681479787123296e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.681479787123296e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.681479787123296e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.681479787123296e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.681479787123296e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.681479787123296e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.840739893561648e-122Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.840739893561648e-122Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.840739893561648e-122\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.840739893561648e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.840739893561648e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.840739893561648e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.840739893561648e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.840739893561648e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.420369946780824e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.420369946780824e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.420369946780824e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.420369946780824e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.420369946780824e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.420369946780824e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.420369946780824e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.420369946780824e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.210184973390412e-122Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.210184973390412e-122\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.210184973390412e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.210184973390412e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.210184973390412e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.210184973390412e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.210184973390412e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.210184973390412e-122\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.05092486695206e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.05092486695206e-123Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.05092486695206e-123\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.05092486695206e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.05092486695206e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.05092486695206e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.05092486695206e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.05092486695206e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.02546243347603e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.02546243347603e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.02546243347603e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.02546243347603e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.02546243347603e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.02546243347603e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.02546243347603e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.02546243347603e-123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.512731216738015e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.512731216738015e-123Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.512731216738015e-123\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.512731216738015e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.512731216738015e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.512731216738015e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.512731216738015e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.512731216738015e-123\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.563656083690075e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.563656083690075e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.563656083690075e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.563656083690075e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.563656083690075e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.563656083690075e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.563656083690075e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.563656083690075e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7818280418450374e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7818280418450374e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7818280418450374e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7818280418450374e-124Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7818280418450374e-124\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7818280418450374e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7818280418450374e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7818280418450374e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8909140209225187e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8909140209225187e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8909140209225187e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8909140209225187e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8909140209225187e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8909140209225187e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8909140209225187e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8909140209225187e-124\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.454570104612593e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.454570104612593e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.454570104612593e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.454570104612593e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.454570104612593e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.454570104612593e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.454570104612593e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.454570104612593e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.727285052306297e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.727285052306297e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.727285052306297e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.727285052306297e-125Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.727285052306297e-125\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.727285052306297e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.727285052306297e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.727285052306297e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3636425261531484e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3636425261531484e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3636425261531484e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3636425261531484e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3636425261531484e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3636425261531484e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3636425261531484e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3636425261531484e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1818212630765742e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1818212630765742e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1818212630765742e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1818212630765742e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1818212630765742e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1818212630765742e-125\n",
      "2020-06-11 09:59:13,569 maskrcnn_benchmark INFO: eta: 12:25:33  iter: 1000  loss: inf (inf)  auxiliary_ctx: 0.3170 (11.4014)  auxiliary_frq: 0.2052 (0.2093)  auxiliary_vis: inf (inf)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: inf (inf)  time: 1.1320 (1.1470)  data: 0.0244 (0.0249)  lr: 0.640000  max mem: 6128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1818212630765742e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1818212630765742e-125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.909106315382871e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.909106315382871e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.909106315382871e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.909106315382871e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.909106315382871e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.909106315382871e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.909106315382871e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.909106315382871e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9545531576914354e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9545531576914354e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9545531576914354e-126Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9545531576914354e-126\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9545531576914354e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9545531576914354e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9545531576914354e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9545531576914354e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4772765788457177e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4772765788457177e-126Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4772765788457177e-126\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4772765788457177e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4772765788457177e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4772765788457177e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4772765788457177e-126\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4772765788457177e-126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.386382894228589e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.386382894228589e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.386382894228589e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.386382894228589e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.386382894228589e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.386382894228589e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.386382894228589e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.386382894228589e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6931914471142943e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6931914471142943e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6931914471142943e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6931914471142943e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6931914471142943e-127Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6931914471142943e-127\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6931914471142943e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6931914471142943e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8465957235571472e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8465957235571472e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8465957235571472e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8465957235571472e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8465957235571472e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8465957235571472e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8465957235571472e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8465957235571472e-127\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.232978617785736e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.232978617785736e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.232978617785736e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.232978617785736e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.232978617785736e-128Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.232978617785736e-128\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.232978617785736e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.232978617785736e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.616489308892868e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.616489308892868e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.616489308892868e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.616489308892868e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.616489308892868e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.616489308892868e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.616489308892868e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.616489308892868e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.308244654446434e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.308244654446434e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.308244654446434e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.308244654446434e-128Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.308244654446434e-128\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.308244654446434e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.308244654446434e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.308244654446434e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.154122327223217e-128Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.154122327223217e-128\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.154122327223217e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.154122327223217e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.154122327223217e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.154122327223217e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.154122327223217e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.154122327223217e-128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.770611636116085e-129Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.770611636116085e-129\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.770611636116085e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.770611636116085e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.770611636116085e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.770611636116085e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.770611636116085e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.770611636116085e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8853058180580424e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8853058180580424e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8853058180580424e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8853058180580424e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8853058180580424e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8853058180580424e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8853058180580424e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8853058180580424e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4426529090290212e-129Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4426529090290212e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4426529090290212e-129\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4426529090290212e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4426529090290212e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4426529090290212e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4426529090290212e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4426529090290212e-129\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.213264545145106e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.213264545145106e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.213264545145106e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.213264545145106e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.213264545145106e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.213264545145106e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.213264545145106e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.213264545145106e-130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.606632272572553e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.606632272572553e-130Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.606632272572553e-130\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.606632272572553e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.606632272572553e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.606632272572553e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.606632272572553e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.606632272572553e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8033161362862765e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8033161362862765e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8033161362862765e-130Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8033161362862765e-130\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8033161362862765e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8033161362862765e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8033161362862765e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8033161362862765e-130\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.016580681431383e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.016580681431383e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.016580681431383e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.016580681431383e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.016580681431383e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.016580681431383e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.016580681431383e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.016580681431383e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5082903407156913e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5082903407156913e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5082903407156913e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5082903407156913e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5082903407156913e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5082903407156913e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5082903407156913e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5082903407156913e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2541451703578456e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2541451703578456e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2541451703578456e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2541451703578456e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2541451703578456e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2541451703578456e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2541451703578456e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2541451703578456e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1270725851789228e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1270725851789228e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1270725851789228e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1270725851789228e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1270725851789228e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1270725851789228e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1270725851789228e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1270725851789228e-131\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.635362925894614e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.635362925894614e-132Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.635362925894614e-132\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.635362925894614e-132Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.635362925894614e-132\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.635362925894614e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.635362925894614e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.635362925894614e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.817681462947307e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.817681462947307e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.817681462947307e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.817681462947307e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.817681462947307e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.817681462947307e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.817681462947307e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.817681462947307e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4088407314736535e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4088407314736535e-132Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4088407314736535e-132\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4088407314736535e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4088407314736535e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4088407314736535e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4088407314736535e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4088407314736535e-132\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.044203657368268e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.044203657368268e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.044203657368268e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.044203657368268e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.044203657368268e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.044203657368268e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.044203657368268e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.044203657368268e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.522101828684134e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.522101828684134e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.522101828684134e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.522101828684134e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.522101828684134e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.522101828684134e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.522101828684134e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.522101828684134e-133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.761050914342067e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.761050914342067e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.761050914342067e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.761050914342067e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.761050914342067e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.761050914342067e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.761050914342067e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.761050914342067e-133\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.805254571710335e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.805254571710335e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.805254571710335e-134Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.805254571710335e-134Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.805254571710335e-134\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.805254571710335e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.805254571710335e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.805254571710335e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4026272858551673e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4026272858551673e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4026272858551673e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4026272858551673e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4026272858551673e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4026272858551673e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4026272858551673e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4026272858551673e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2013136429275836e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2013136429275836e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2013136429275836e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2013136429275836e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2013136429275836e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2013136429275836e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2013136429275836e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2013136429275836e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1006568214637918e-134Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1006568214637918e-134\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1006568214637918e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1006568214637918e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1006568214637918e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1006568214637918e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1006568214637918e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1006568214637918e-134\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.503284107318959e-135Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.503284107318959e-135\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.503284107318959e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.503284107318959e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.503284107318959e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.503284107318959e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.503284107318959e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.503284107318959e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7516420536594796e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7516420536594796e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7516420536594796e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7516420536594796e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7516420536594796e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7516420536594796e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7516420536594796e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7516420536594796e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3758210268297398e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3758210268297398e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3758210268297398e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3758210268297398e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3758210268297398e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3758210268297398e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3758210268297398e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3758210268297398e-135\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.879105134148699e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.879105134148699e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.879105134148699e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.879105134148699e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.879105134148699e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.879105134148699e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.879105134148699e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.879105134148699e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4395525670743494e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4395525670743494e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4395525670743494e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4395525670743494e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4395525670743494e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4395525670743494e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4395525670743494e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4395525670743494e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7197762835371747e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7197762835371747e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7197762835371747e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7197762835371747e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7197762835371747e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7197762835371747e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7197762835371747e-136\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7197762835371747e-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.598881417685874e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.598881417685874e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.598881417685874e-137Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.598881417685874e-137\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.598881417685874e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.598881417685874e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.598881417685874e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.598881417685874e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.299440708842937e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.299440708842937e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.299440708842937e-137Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.299440708842937e-137\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.299440708842937e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.299440708842937e-137Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.299440708842937e-137\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.299440708842937e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1497203544214684e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1497203544214684e-137Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1497203544214684e-137\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1497203544214684e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1497203544214684e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1497203544214684e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1497203544214684e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1497203544214684e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0748601772107342e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0748601772107342e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0748601772107342e-137Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0748601772107342e-137\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0748601772107342e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0748601772107342e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0748601772107342e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0748601772107342e-137\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.374300886053671e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.374300886053671e-138Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.374300886053671e-138\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.374300886053671e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.374300886053671e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.374300886053671e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.374300886053671e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.374300886053671e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6871504430268355e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6871504430268355e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6871504430268355e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6871504430268355e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6871504430268355e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6871504430268355e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6871504430268355e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6871504430268355e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3435752215134178e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3435752215134178e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3435752215134178e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3435752215134178e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3435752215134178e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3435752215134178e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3435752215134178e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3435752215134178e-138\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.717876107567089e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.717876107567089e-139Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.717876107567089e-139\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.717876107567089e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.717876107567089e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.717876107567089e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.717876107567089e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.717876107567089e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3589380537835444e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3589380537835444e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3589380537835444e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3589380537835444e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3589380537835444e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3589380537835444e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3589380537835444e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3589380537835444e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6794690268917722e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6794690268917722e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6794690268917722e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6794690268917722e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6794690268917722e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6794690268917722e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6794690268917722e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6794690268917722e-139\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.397345134458861e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.397345134458861e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.397345134458861e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.397345134458861e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.397345134458861e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.397345134458861e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.397345134458861e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.397345134458861e-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1986725672294305e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1986725672294305e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1986725672294305e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1986725672294305e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1986725672294305e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1986725672294305e-140Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1986725672294305e-140\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1986725672294305e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0993362836147152e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0993362836147152e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0993362836147152e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0993362836147152e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0993362836147152e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0993362836147152e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0993362836147152e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0993362836147152e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0496681418073576e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0496681418073576e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0496681418073576e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0496681418073576e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0496681418073576e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0496681418073576e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0496681418073576e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0496681418073576e-140\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.248340709036788e-141Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.248340709036788e-141\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.248340709036788e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.248340709036788e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.248340709036788e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.248340709036788e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.248340709036788e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.248340709036788e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.624170354518394e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.624170354518394e-141Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.624170354518394e-141\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.624170354518394e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.624170354518394e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.624170354518394e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.624170354518394e-141Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.624170354518394e-141\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.312085177259197e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.312085177259197e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.312085177259197e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.312085177259197e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.312085177259197e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.312085177259197e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.312085177259197e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.312085177259197e-141\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.560425886295985e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.560425886295985e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.560425886295985e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.560425886295985e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.560425886295985e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.560425886295985e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.560425886295985e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.560425886295985e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2802129431479926e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2802129431479926e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2802129431479926e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2802129431479926e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2802129431479926e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2802129431479926e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2802129431479926e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2802129431479926e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6401064715739963e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6401064715739963e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6401064715739963e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6401064715739963e-142Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6401064715739963e-142\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6401064715739963e-142\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6401064715739963e-142Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6401064715739963e-142\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.200532357869981e-143Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.200532357869981e-143\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.200532357869981e-143Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.200532357869981e-143\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.200532357869981e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.200532357869981e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.200532357869981e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.200532357869981e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.100266178934991e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.100266178934991e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.100266178934991e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.100266178934991e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.100266178934991e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.100266178934991e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.100266178934991e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.100266178934991e-143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0501330894674953e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0501330894674953e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0501330894674953e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0501330894674953e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0501330894674953e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0501330894674953e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0501330894674953e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0501330894674953e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0250665447337477e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0250665447337477e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0250665447337477e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0250665447337477e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0250665447337477e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0250665447337477e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0250665447337477e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0250665447337477e-143\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1253327236687384e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1253327236687384e-144Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1253327236687384e-144\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1253327236687384e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1253327236687384e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1253327236687384e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1253327236687384e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1253327236687384e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5626663618343692e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5626663618343692e-144Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5626663618343692e-144\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5626663618343692e-144Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5626663618343692e-144\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5626663618343692e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5626663618343692e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5626663618343692e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2813331809171846e-144Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2813331809171846e-144\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2813331809171846e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2813331809171846e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2813331809171846e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2813331809171846e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2813331809171846e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2813331809171846e-144\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.406665904585923e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.406665904585923e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.406665904585923e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.406665904585923e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.406665904585923e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.406665904585923e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.406665904585923e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.406665904585923e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2033329522929615e-145Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2033329522929615e-145\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2033329522929615e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2033329522929615e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2033329522929615e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2033329522929615e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2033329522929615e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2033329522929615e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6016664761464807e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6016664761464807e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6016664761464807e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6016664761464807e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6016664761464807e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6016664761464807e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6016664761464807e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6016664761464807e-145\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.008332380732404e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.008332380732404e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.008332380732404e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.008332380732404e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.008332380732404e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.008332380732404e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.008332380732404e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.008332380732404e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.004166190366202e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.004166190366202e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.004166190366202e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.004166190366202e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.004166190366202e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.004166190366202e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.004166190366202e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.004166190366202e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.002083095183101e-146Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.002083095183101e-146\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.002083095183101e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.002083095183101e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.002083095183101e-146Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.002083095183101e-146\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.002083095183101e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.002083095183101e-146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0010415475915505e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0010415475915505e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0010415475915505e-146Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0010415475915505e-146\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0010415475915505e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0010415475915505e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0010415475915505e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0010415475915505e-146\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0052077379577523e-147Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0052077379577523e-147\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0052077379577523e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0052077379577523e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0052077379577523e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0052077379577523e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0052077379577523e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0052077379577523e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5026038689788762e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5026038689788762e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5026038689788762e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5026038689788762e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5026038689788762e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5026038689788762e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5026038689788762e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5026038689788762e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2513019344894381e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2513019344894381e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2513019344894381e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2513019344894381e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2513019344894381e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2513019344894381e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2513019344894381e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2513019344894381e-147\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.256509672447191e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.256509672447191e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.256509672447191e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.256509672447191e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.256509672447191e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.256509672447191e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.256509672447191e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.256509672447191e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1282548362235952e-148Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1282548362235952e-148\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1282548362235952e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1282548362235952e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1282548362235952e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1282548362235952e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1282548362235952e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1282548362235952e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5641274181117976e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5641274181117976e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5641274181117976e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5641274181117976e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5641274181117976e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5641274181117976e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5641274181117976e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5641274181117976e-148\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.820637090558988e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.820637090558988e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.820637090558988e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.820637090558988e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.820637090558988e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.820637090558988e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.820637090558988e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.820637090558988e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.910318545279494e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.910318545279494e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.910318545279494e-149Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.910318545279494e-149\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.910318545279494e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.910318545279494e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.910318545279494e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.910318545279494e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.955159272639747e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.955159272639747e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.955159272639747e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.955159272639747e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.955159272639747e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.955159272639747e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.955159272639747e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.955159272639747e-149\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.775796363198735e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.775796363198735e-150Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.775796363198735e-150\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.775796363198735e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.775796363198735e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.775796363198735e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.775796363198735e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.775796363198735e-150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.887898181599368e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.887898181599368e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.887898181599368e-150Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.887898181599368e-150\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.887898181599368e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.887898181599368e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.887898181599368e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.887898181599368e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.443949090799684e-150Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.443949090799684e-150\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.443949090799684e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.443949090799684e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.443949090799684e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.443949090799684e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.443949090799684e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.443949090799684e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.221974545399842e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.221974545399842e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.221974545399842e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.221974545399842e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.221974545399842e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.221974545399842e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.221974545399842e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.221974545399842e-150\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.10987272699921e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.10987272699921e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.10987272699921e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.10987272699921e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.10987272699921e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.10987272699921e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.10987272699921e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.10987272699921e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.054936363499605e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.054936363499605e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.054936363499605e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.054936363499605e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.054936363499605e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.054936363499605e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.054936363499605e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.054936363499605e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5274681817498023e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5274681817498023e-151Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5274681817498023e-151Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5274681817498023e-151\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5274681817498023e-151\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5274681817498023e-151Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5274681817498023e-151\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5274681817498023e-151\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.637340908749012e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.637340908749012e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.637340908749012e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.637340908749012e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.637340908749012e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.637340908749012e-152Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.637340908749012e-152\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.637340908749012e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.818670454374506e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.818670454374506e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.818670454374506e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.818670454374506e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.818670454374506e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.818670454374506e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.818670454374506e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.818670454374506e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.909335227187253e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.909335227187253e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.909335227187253e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.909335227187253e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.909335227187253e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.909335227187253e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.909335227187253e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.909335227187253e-152\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.546676135936265e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.546676135936265e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.546676135936265e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.546676135936265e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.546676135936265e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.546676135936265e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.546676135936265e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.546676135936265e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7733380679681323e-153Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7733380679681323e-153\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7733380679681323e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7733380679681323e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7733380679681323e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7733380679681323e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7733380679681323e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7733380679681323e-153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3866690339840662e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3866690339840662e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3866690339840662e-153Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3866690339840662e-153\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3866690339840662e-153Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3866690339840662e-153\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3866690339840662e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3866690339840662e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1933345169920331e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1933345169920331e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1933345169920331e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1933345169920331e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1933345169920331e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1933345169920331e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1933345169920331e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1933345169920331e-153\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.966672584960166e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.966672584960166e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.966672584960166e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.966672584960166e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.966672584960166e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.966672584960166e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.966672584960166e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.966672584960166e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.983336292480083e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.983336292480083e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.983336292480083e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.983336292480083e-154Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.983336292480083e-154\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.983336292480083e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.983336292480083e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.983336292480083e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4916681462400413e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4916681462400413e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4916681462400413e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4916681462400413e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4916681462400413e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4916681462400413e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4916681462400413e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4916681462400413e-154\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.458340731200207e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.458340731200207e-155Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.458340731200207e-155\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.458340731200207e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.458340731200207e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.458340731200207e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.458340731200207e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.458340731200207e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7291703656001034e-155Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7291703656001034e-155\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7291703656001034e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7291703656001034e-155Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7291703656001034e-155\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7291703656001034e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7291703656001034e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7291703656001034e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8645851828000517e-155Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8645851828000517e-155\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8645851828000517e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8645851828000517e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8645851828000517e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8645851828000517e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8645851828000517e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8645851828000517e-155\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.322925914000258e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.322925914000258e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.322925914000258e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.322925914000258e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.322925914000258e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.322925914000258e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.322925914000258e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.322925914000258e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.661462957000129e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.661462957000129e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.661462957000129e-156Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.661462957000129e-156\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.661462957000129e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.661462957000129e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.661462957000129e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.661462957000129e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3307314785000646e-156Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3307314785000646e-156Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3307314785000646e-156\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3307314785000646e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3307314785000646e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3307314785000646e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3307314785000646e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3307314785000646e-156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1653657392500323e-156Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1653657392500323e-156\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1653657392500323e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1653657392500323e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1653657392500323e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1653657392500323e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1653657392500323e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1653657392500323e-156\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.826828696250162e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.826828696250162e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.826828696250162e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.826828696250162e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.826828696250162e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.826828696250162e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.826828696250162e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.826828696250162e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.913414348125081e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.913414348125081e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.913414348125081e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.913414348125081e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.913414348125081e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.913414348125081e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.913414348125081e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.913414348125081e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4567071740625404e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4567071740625404e-157Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4567071740625404e-157\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4567071740625404e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4567071740625404e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4567071740625404e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4567071740625404e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4567071740625404e-157\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.283535870312702e-158Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.283535870312702e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.283535870312702e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.283535870312702e-158\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.283535870312702e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.283535870312702e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.283535870312702e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.283535870312702e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.641767935156351e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.641767935156351e-158Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.641767935156351e-158\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.641767935156351e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.641767935156351e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.641767935156351e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.641767935156351e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.641767935156351e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8208839675781755e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8208839675781755e-158Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8208839675781755e-158\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8208839675781755e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8208839675781755e-158Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8208839675781755e-158\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8208839675781755e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8208839675781755e-158\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.104419837890877e-159Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.104419837890877e-159\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.104419837890877e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.104419837890877e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.104419837890877e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.104419837890877e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.104419837890877e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.104419837890877e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.552209918945439e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.552209918945439e-159Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.552209918945439e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.552209918945439e-159\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.552209918945439e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.552209918945439e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.552209918945439e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.552209918945439e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2761049594727193e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2761049594727193e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2761049594727193e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2761049594727193e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2761049594727193e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2761049594727193e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2761049594727193e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2761049594727193e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1380524797363597e-159Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1380524797363597e-159\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1380524797363597e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1380524797363597e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1380524797363597e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1380524797363597e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1380524797363597e-159\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1380524797363597e-159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.6902623986817984e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.6902623986817984e-160Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.6902623986817984e-160\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.6902623986817984e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.6902623986817984e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.6902623986817984e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.6902623986817984e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.6902623986817984e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8451311993408992e-160Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8451311993408992e-160\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8451311993408992e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8451311993408992e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8451311993408992e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8451311993408992e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8451311993408992e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8451311993408992e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4225655996704496e-160Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4225655996704496e-160\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4225655996704496e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4225655996704496e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4225655996704496e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4225655996704496e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4225655996704496e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4225655996704496e-160\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.112827998352248e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.112827998352248e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.112827998352248e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.112827998352248e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.112827998352248e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.112827998352248e-161Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.112827998352248e-161\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.112827998352248e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.556413999176124e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.556413999176124e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.556413999176124e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.556413999176124e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.556413999176124e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.556413999176124e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.556413999176124e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.556413999176124e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.778206999588062e-161Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.778206999588062e-161\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.778206999588062e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.778206999588062e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.778206999588062e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.778206999588062e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.778206999588062e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.778206999588062e-161\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.89103499794031e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.89103499794031e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.89103499794031e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.89103499794031e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.89103499794031e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.89103499794031e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.89103499794031e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.89103499794031e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.445517498970155e-162Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.445517498970155e-162\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.445517498970155e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.445517498970155e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.445517498970155e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.445517498970155e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.445517498970155e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.445517498970155e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2227587494850775e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2227587494850775e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2227587494850775e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2227587494850775e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2227587494850775e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2227587494850775e-162Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2227587494850775e-162\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2227587494850775e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1113793747425387e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1113793747425387e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1113793747425387e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1113793747425387e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1113793747425387e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1113793747425387e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1113793747425387e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1113793747425387e-162\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.556896873712694e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.556896873712694e-163Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.556896873712694e-163\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.556896873712694e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.556896873712694e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.556896873712694e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.556896873712694e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.556896873712694e-163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.778448436856347e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.778448436856347e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.778448436856347e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.778448436856347e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.778448436856347e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.778448436856347e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.778448436856347e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.778448436856347e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3892242184281734e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3892242184281734e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3892242184281734e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3892242184281734e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3892242184281734e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3892242184281734e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3892242184281734e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3892242184281734e-163\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.946121092140867e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.946121092140867e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.946121092140867e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.946121092140867e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.946121092140867e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.946121092140867e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.946121092140867e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.946121092140867e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4730605460704336e-164Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4730605460704336e-164\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4730605460704336e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4730605460704336e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4730605460704336e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4730605460704336e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4730605460704336e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4730605460704336e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7365302730352168e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7365302730352168e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7365302730352168e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7365302730352168e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7365302730352168e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7365302730352168e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7365302730352168e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7365302730352168e-164\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.682651365176084e-165Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.682651365176084e-165\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.682651365176084e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.682651365176084e-165Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.682651365176084e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.682651365176084e-165\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.682651365176084e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.682651365176084e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.341325682588042e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.341325682588042e-165Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.341325682588042e-165\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.341325682588042e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.341325682588042e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.341325682588042e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.341325682588042e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.341325682588042e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.170662841294021e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.170662841294021e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.170662841294021e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.170662841294021e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.170662841294021e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.170662841294021e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.170662841294021e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.170662841294021e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0853314206470105e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0853314206470105e-165Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0853314206470105e-165\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0853314206470105e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0853314206470105e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0853314206470105e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0853314206470105e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0853314206470105e-165\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.426657103235053e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.426657103235053e-166Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.426657103235053e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.426657103235053e-166\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.426657103235053e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.426657103235053e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.426657103235053e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.426657103235053e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7133285516175262e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7133285516175262e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7133285516175262e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7133285516175262e-166Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7133285516175262e-166\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7133285516175262e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7133285516175262e-166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7133285516175262e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3566642758087631e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3566642758087631e-166Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3566642758087631e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3566642758087631e-166\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3566642758087631e-166Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3566642758087631e-166\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3566642758087631e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3566642758087631e-166\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.783321379043816e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.783321379043816e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.783321379043816e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.783321379043816e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.783321379043816e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.783321379043816e-167Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.783321379043816e-167\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.783321379043816e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.391660689521908e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.391660689521908e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.391660689521908e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.391660689521908e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.391660689521908e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.391660689521908e-167Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.391660689521908e-167\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.391660689521908e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.695830344760954e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.695830344760954e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.695830344760954e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.695830344760954e-167Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.695830344760954e-167Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.695830344760954e-167\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.695830344760954e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.695830344760954e-167\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.47915172380477e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.47915172380477e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.47915172380477e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.47915172380477e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.47915172380477e-168Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.47915172380477e-168\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.47915172380477e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.47915172380477e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.239575861902385e-168Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.239575861902385e-168\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.239575861902385e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.239575861902385e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.239575861902385e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.239575861902385e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.239575861902385e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.239575861902385e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1197879309511924e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1197879309511924e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1197879309511924e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1197879309511924e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1197879309511924e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1197879309511924e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1197879309511924e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1197879309511924e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0598939654755962e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0598939654755962e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0598939654755962e-168Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0598939654755962e-168Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0598939654755962e-168\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0598939654755962e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0598939654755962e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0598939654755962e-168\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.299469827377981e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.299469827377981e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.299469827377981e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.299469827377981e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.299469827377981e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.299469827377981e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.299469827377981e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.299469827377981e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6497349136889905e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6497349136889905e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6497349136889905e-169Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6497349136889905e-169\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6497349136889905e-169Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6497349136889905e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6497349136889905e-169\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6497349136889905e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3248674568444952e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3248674568444952e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3248674568444952e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3248674568444952e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3248674568444952e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3248674568444952e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3248674568444952e-169\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3248674568444952e-169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.624337284222476e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.624337284222476e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.624337284222476e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.624337284222476e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.624337284222476e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.624337284222476e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.624337284222476e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.624337284222476e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.312168642111238e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.312168642111238e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.312168642111238e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.312168642111238e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.312168642111238e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.312168642111238e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.312168642111238e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.312168642111238e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.656084321055619e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.656084321055619e-170Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.656084321055619e-170Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.656084321055619e-170Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.656084321055619e-170\n",
      "\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.656084321055619e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.656084321055619e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.656084321055619e-170\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.280421605278095e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.280421605278095e-171Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.280421605278095e-171Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.280421605278095e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.280421605278095e-171\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.280421605278095e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.280421605278095e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.280421605278095e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.140210802639048e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.140210802639048e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.140210802639048e-171Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.140210802639048e-171\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.140210802639048e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.140210802639048e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.140210802639048e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.140210802639048e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.070105401319524e-171Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.070105401319524e-171Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.070105401319524e-171\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.070105401319524e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.070105401319524e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.070105401319524e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.070105401319524e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.070105401319524e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.035052700659762e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.035052700659762e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.035052700659762e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.035052700659762e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.035052700659762e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.035052700659762e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.035052700659762e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.035052700659762e-171\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.17526350329881e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.17526350329881e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.17526350329881e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.17526350329881e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.17526350329881e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.17526350329881e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.17526350329881e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.17526350329881e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.587631751649405e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.587631751649405e-172Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.587631751649405e-172\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.587631751649405e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.587631751649405e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.587631751649405e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.587631751649405e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.587631751649405e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2938158758247024e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2938158758247024e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2938158758247024e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2938158758247024e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2938158758247024e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2938158758247024e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2938158758247024e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2938158758247024e-172\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.469079379123512e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.469079379123512e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.469079379123512e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.469079379123512e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.469079379123512e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.469079379123512e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.469079379123512e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.469079379123512e-173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.234539689561756e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.234539689561756e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.234539689561756e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.234539689561756e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.234539689561756e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.234539689561756e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.234539689561756e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.234539689561756e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.617269844780878e-173Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.617269844780878e-173\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.617269844780878e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.617269844780878e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.617269844780878e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.617269844780878e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.617269844780878e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.617269844780878e-173\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.08634922390439e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.08634922390439e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.08634922390439e-174Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.08634922390439e-174\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.08634922390439e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.08634922390439e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.08634922390439e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.08634922390439e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.043174611952195e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.043174611952195e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.043174611952195e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.043174611952195e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.043174611952195e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.043174611952195e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.043174611952195e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.043174611952195e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0215873059760975e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0215873059760975e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0215873059760975e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0215873059760975e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0215873059760975e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0215873059760975e-174Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0215873059760975e-174\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0215873059760975e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0107936529880487e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0107936529880487e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0107936529880487e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0107936529880487e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0107936529880487e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0107936529880487e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0107936529880487e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0107936529880487e-174\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.053968264940244e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.053968264940244e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.053968264940244e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.053968264940244e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.053968264940244e-175Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.053968264940244e-175Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.053968264940244e-175\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.053968264940244e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.526984132470122e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.526984132470122e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.526984132470122e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.526984132470122e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.526984132470122e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.526984132470122e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.526984132470122e-175Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.526984132470122e-175\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.263492066235061e-175Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.263492066235061e-175\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.263492066235061e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.263492066235061e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.263492066235061e-175Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.263492066235061e-175\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.263492066235061e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.263492066235061e-175\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.317460331175305e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.317460331175305e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.317460331175305e-176Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.317460331175305e-176\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.317460331175305e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.317460331175305e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.317460331175305e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.317460331175305e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1587301655876523e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1587301655876523e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1587301655876523e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1587301655876523e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1587301655876523e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1587301655876523e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1587301655876523e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1587301655876523e-176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5793650827938261e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5793650827938261e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5793650827938261e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5793650827938261e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5793650827938261e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5793650827938261e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5793650827938261e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5793650827938261e-176\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.896825413969131e-177Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.896825413969131e-177\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.896825413969131e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.896825413969131e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.896825413969131e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.896825413969131e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.896825413969131e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.896825413969131e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9484127069845653e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9484127069845653e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9484127069845653e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9484127069845653e-177Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9484127069845653e-177\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9484127069845653e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9484127069845653e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9484127069845653e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9742063534922827e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9742063534922827e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9742063534922827e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9742063534922827e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9742063534922827e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9742063534922827e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9742063534922827e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9742063534922827e-177\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.871031767461413e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.871031767461413e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.871031767461413e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.871031767461413e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.871031767461413e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.871031767461413e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.871031767461413e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.871031767461413e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.935515883730707e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.935515883730707e-178Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.935515883730707e-178\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.935515883730707e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.935515883730707e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.935515883730707e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.935515883730707e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.935515883730707e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4677579418653533e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4677579418653533e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4677579418653533e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4677579418653533e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4677579418653533e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4677579418653533e-178Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4677579418653533e-178\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4677579418653533e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2338789709326767e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2338789709326767e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2338789709326767e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2338789709326767e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2338789709326767e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2338789709326767e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2338789709326767e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2338789709326767e-178\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.169394854663383e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.169394854663383e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.169394854663383e-179Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.169394854663383e-179\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.169394854663383e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.169394854663383e-179Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.169394854663383e-179\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.169394854663383e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.084697427331692e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.084697427331692e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.084697427331692e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.084697427331692e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.084697427331692e-179Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.084697427331692e-179\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.084697427331692e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.084697427331692e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.542348713665846e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.542348713665846e-179Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.542348713665846e-179\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.542348713665846e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.542348713665846e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.542348713665846e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.542348713665846e-179\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.542348713665846e-179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.71174356832923e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.71174356832923e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.71174356832923e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.71174356832923e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.71174356832923e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.71174356832923e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.71174356832923e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.71174356832923e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.855871784164615e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.855871784164615e-180Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.855871784164615e-180\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.855871784164615e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.855871784164615e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.855871784164615e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.855871784164615e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.855871784164615e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9279358920823073e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9279358920823073e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9279358920823073e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9279358920823073e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9279358920823073e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9279358920823073e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9279358920823073e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9279358920823073e-180\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.639679460411536e-181Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.639679460411536e-181\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.639679460411536e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.639679460411536e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.639679460411536e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.639679460411536e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.639679460411536e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.639679460411536e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.819839730205768e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.819839730205768e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.819839730205768e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.819839730205768e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.819839730205768e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.819839730205768e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.819839730205768e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.819839730205768e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.409919865102884e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.409919865102884e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.409919865102884e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.409919865102884e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.409919865102884e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.409919865102884e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.409919865102884e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.409919865102884e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.204959932551442e-181Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.204959932551442e-181\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.204959932551442e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.204959932551442e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.204959932551442e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.204959932551442e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.204959932551442e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.204959932551442e-181\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.02479966275721e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.02479966275721e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.02479966275721e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.02479966275721e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.02479966275721e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.02479966275721e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.02479966275721e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.02479966275721e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.012399831378605e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.012399831378605e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.012399831378605e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.012399831378605e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.012399831378605e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.012399831378605e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.012399831378605e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.012399831378605e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5061999156893026e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5061999156893026e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5061999156893026e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5061999156893026e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5061999156893026e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5061999156893026e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5061999156893026e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5061999156893026e-182\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.530999578446513e-183Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.530999578446513e-183\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.530999578446513e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.530999578446513e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.530999578446513e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.530999578446513e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.530999578446513e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.530999578446513e-183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7654997892232564e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7654997892232564e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7654997892232564e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7654997892232564e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7654997892232564e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7654997892232564e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7654997892232564e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7654997892232564e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8827498946116282e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8827498946116282e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8827498946116282e-183Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8827498946116282e-183\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8827498946116282e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8827498946116282e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8827498946116282e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8827498946116282e-183\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.413749473058141e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.413749473058141e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.413749473058141e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.413749473058141e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.413749473058141e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.413749473058141e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.413749473058141e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.413749473058141e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.706874736529071e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.706874736529071e-184Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.706874736529071e-184\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.706874736529071e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.706874736529071e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.706874736529071e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.706874736529071e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.706874736529071e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3534373682645353e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3534373682645353e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3534373682645353e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3534373682645353e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3534373682645353e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3534373682645353e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3534373682645353e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3534373682645353e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1767186841322676e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1767186841322676e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1767186841322676e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1767186841322676e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1767186841322676e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1767186841322676e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1767186841322676e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1767186841322676e-184\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.883593420661338e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.883593420661338e-185Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.883593420661338e-185\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.883593420661338e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.883593420661338e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.883593420661338e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.883593420661338e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.883593420661338e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.941796710330669e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.941796710330669e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.941796710330669e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.941796710330669e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.941796710330669e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.941796710330669e-185Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.941796710330669e-185\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.941796710330669e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4708983551653345e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4708983551653345e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4708983551653345e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4708983551653345e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4708983551653345e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4708983551653345e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4708983551653345e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4708983551653345e-185\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.354491775826673e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.354491775826673e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.354491775826673e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.354491775826673e-186\n",
      "2020-06-11 10:03:00,854 maskrcnn_benchmark INFO: eta: 12:20:35  iter: 1200  loss: inf (inf)  auxiliary_ctx: 0.3206 (9.5564)  auxiliary_frq: 0.2054 (0.2094)  auxiliary_vis: inf (inf)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: inf (inf)  time: 1.1381 (1.1453)  data: 0.0242 (0.0247)  lr: 0.640000  max mem: 6128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.354491775826673e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.354491775826673e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.354491775826673e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.354491775826673e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6772458879133364e-186Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6772458879133364e-186\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6772458879133364e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6772458879133364e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6772458879133364e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6772458879133364e-186Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6772458879133364e-186\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6772458879133364e-186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8386229439566682e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8386229439566682e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8386229439566682e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8386229439566682e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8386229439566682e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8386229439566682e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8386229439566682e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8386229439566682e-186\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.193114719783341e-187Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.193114719783341e-187\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.193114719783341e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.193114719783341e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.193114719783341e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.193114719783341e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.193114719783341e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.193114719783341e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5965573598916705e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5965573598916705e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5965573598916705e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5965573598916705e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5965573598916705e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5965573598916705e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5965573598916705e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5965573598916705e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2982786799458352e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2982786799458352e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2982786799458352e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2982786799458352e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2982786799458352e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2982786799458352e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2982786799458352e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2982786799458352e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1491393399729176e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1491393399729176e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1491393399729176e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1491393399729176e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1491393399729176e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1491393399729176e-187Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1491393399729176e-187\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1491393399729176e-187\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.745696699864588e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.745696699864588e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.745696699864588e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.745696699864588e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.745696699864588e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.745696699864588e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.745696699864588e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.745696699864588e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.872848349932294e-188Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.872848349932294e-188\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.872848349932294e-188Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.872848349932294e-188\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.872848349932294e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.872848349932294e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.872848349932294e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.872848349932294e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.436424174966147e-188Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.436424174966147e-188Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.436424174966147e-188\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.436424174966147e-188Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.436424174966147e-188\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.436424174966147e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.436424174966147e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.436424174966147e-188\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.182120874830735e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.182120874830735e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.182120874830735e-189Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.182120874830735e-189\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.182120874830735e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.182120874830735e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.182120874830735e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.182120874830735e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5910604374153675e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5910604374153675e-189Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5910604374153675e-189\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5910604374153675e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5910604374153675e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5910604374153675e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5910604374153675e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5910604374153675e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7955302187076838e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7955302187076838e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7955302187076838e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7955302187076838e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7955302187076838e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7955302187076838e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7955302187076838e-189\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7955302187076838e-189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.977651093538419e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.977651093538419e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.977651093538419e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.977651093538419e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.977651093538419e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.977651093538419e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.977651093538419e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.977651093538419e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4888255467692094e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4888255467692094e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4888255467692094e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4888255467692094e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4888255467692094e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4888255467692094e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4888255467692094e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4888255467692094e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2444127733846047e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2444127733846047e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2444127733846047e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2444127733846047e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2444127733846047e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2444127733846047e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2444127733846047e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2444127733846047e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1222063866923024e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1222063866923024e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1222063866923024e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1222063866923024e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1222063866923024e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1222063866923024e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1222063866923024e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1222063866923024e-190\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.611031933461512e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.611031933461512e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.611031933461512e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.611031933461512e-191Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.611031933461512e-191\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.611031933461512e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.611031933461512e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.611031933461512e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.805515966730756e-191Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.805515966730756e-191\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.805515966730756e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.805515966730756e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.805515966730756e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.805515966730756e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.805515966730756e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.805515966730756e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.402757983365378e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.402757983365378e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.402757983365378e-191Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.402757983365378e-191\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.402757983365378e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.402757983365378e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.402757983365378e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.402757983365378e-191\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.01378991682689e-192Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.01378991682689e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.01378991682689e-192\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.01378991682689e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.01378991682689e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.01378991682689e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.01378991682689e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.01378991682689e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.506894958413445e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.506894958413445e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.506894958413445e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.506894958413445e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.506894958413445e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.506894958413445e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.506894958413445e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.506894958413445e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7534474792067224e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7534474792067224e-192Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7534474792067224e-192\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7534474792067224e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7534474792067224e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7534474792067224e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7534474792067224e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7534474792067224e-192\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.767237396033612e-193Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.767237396033612e-193\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.767237396033612e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.767237396033612e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.767237396033612e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.767237396033612e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.767237396033612e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.767237396033612e-193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.383618698016806e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.383618698016806e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.383618698016806e-193Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.383618698016806e-193Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.383618698016806e-193\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.383618698016806e-193\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.383618698016806e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.383618698016806e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.191809349008403e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.191809349008403e-193Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.191809349008403e-193Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.191809349008403e-193\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.191809349008403e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.191809349008403e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.191809349008403e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.191809349008403e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0959046745042015e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0959046745042015e-193Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0959046745042015e-193\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0959046745042015e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0959046745042015e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0959046745042015e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0959046745042015e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0959046745042015e-193\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.479523372521008e-194Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.479523372521008e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.479523372521008e-194\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.479523372521008e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.479523372521008e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.479523372521008e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.479523372521008e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.479523372521008e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.739761686260504e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.739761686260504e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.739761686260504e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.739761686260504e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.739761686260504e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.739761686260504e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.739761686260504e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.739761686260504e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.369880843130252e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.369880843130252e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.369880843130252e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.369880843130252e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.369880843130252e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.369880843130252e-194\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.369880843130252e-194Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.369880843130252e-194\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.84940421565126e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.84940421565126e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.84940421565126e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.84940421565126e-195Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.84940421565126e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.84940421565126e-195\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.84940421565126e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.84940421565126e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.42470210782563e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.42470210782563e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.42470210782563e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.42470210782563e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.42470210782563e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.42470210782563e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.42470210782563e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.42470210782563e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.712351053912815e-195Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.712351053912815e-195\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.712351053912815e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.712351053912815e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.712351053912815e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.712351053912815e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.712351053912815e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.712351053912815e-195\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.561755269564074e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.561755269564074e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.561755269564074e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.561755269564074e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.561755269564074e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.561755269564074e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.561755269564074e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.561755269564074e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.280877634782037e-196Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.280877634782037e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.280877634782037e-196\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.280877634782037e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.280877634782037e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.280877634782037e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.280877634782037e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.280877634782037e-196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1404388173910186e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1404388173910186e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1404388173910186e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1404388173910186e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1404388173910186e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1404388173910186e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1404388173910186e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1404388173910186e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0702194086955093e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0702194086955093e-196Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0702194086955093e-196Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0702194086955093e-196\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0702194086955093e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0702194086955093e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0702194086955093e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0702194086955093e-196\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.351097043477547e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.351097043477547e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.351097043477547e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.351097043477547e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.351097043477547e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.351097043477547e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.351097043477547e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.351097043477547e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6755485217387732e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6755485217387732e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6755485217387732e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6755485217387732e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6755485217387732e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6755485217387732e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6755485217387732e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6755485217387732e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3377742608693866e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3377742608693866e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3377742608693866e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3377742608693866e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3377742608693866e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3377742608693866e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3377742608693866e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3377742608693866e-197\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.688871304346933e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.688871304346933e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.688871304346933e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.688871304346933e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.688871304346933e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.688871304346933e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.688871304346933e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.688871304346933e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3444356521734666e-198Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3444356521734666e-198Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3444356521734666e-198\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3444356521734666e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3444356521734666e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3444356521734666e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3444356521734666e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3444356521734666e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6722178260867333e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6722178260867333e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6722178260867333e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6722178260867333e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6722178260867333e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6722178260867333e-198Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6722178260867333e-198\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6722178260867333e-198\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.361089130433666e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.361089130433666e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.361089130433666e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.361089130433666e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.361089130433666e-199Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.361089130433666e-199\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.361089130433666e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.361089130433666e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.180544565216833e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.180544565216833e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.180544565216833e-199Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.180544565216833e-199\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.180544565216833e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.180544565216833e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.180544565216833e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.180544565216833e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0902722826084166e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0902722826084166e-199Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0902722826084166e-199\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0902722826084166e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0902722826084166e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0902722826084166e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0902722826084166e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0902722826084166e-199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0451361413042083e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0451361413042083e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0451361413042083e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0451361413042083e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0451361413042083e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0451361413042083e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0451361413042083e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0451361413042083e-199\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.225680706521042e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.225680706521042e-200Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.225680706521042e-200\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.225680706521042e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.225680706521042e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.225680706521042e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.225680706521042e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.225680706521042e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.612840353260521e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.612840353260521e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.612840353260521e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.612840353260521e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.612840353260521e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.612840353260521e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.612840353260521e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.612840353260521e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3064201766302604e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3064201766302604e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3064201766302604e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3064201766302604e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3064201766302604e-200Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3064201766302604e-200\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3064201766302604e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3064201766302604e-200\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.532100883151302e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.532100883151302e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.532100883151302e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.532100883151302e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.532100883151302e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.532100883151302e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.532100883151302e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.532100883151302e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.266050441575651e-201Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.266050441575651e-201\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.266050441575651e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.266050441575651e-201Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.266050441575651e-201\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.266050441575651e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.266050441575651e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.266050441575651e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6330252207878255e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6330252207878255e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6330252207878255e-201Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6330252207878255e-201\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6330252207878255e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6330252207878255e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6330252207878255e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6330252207878255e-201\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.165126103939127e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.165126103939127e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.165126103939127e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.165126103939127e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.165126103939127e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.165126103939127e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.165126103939127e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.165126103939127e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.082563051969564e-202Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.082563051969564e-202\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.082563051969564e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.082563051969564e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.082563051969564e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.082563051969564e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.082563051969564e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.082563051969564e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.041281525984782e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.041281525984782e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.041281525984782e-202Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.041281525984782e-202\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.041281525984782e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.041281525984782e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.041281525984782e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.041281525984782e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.020640762992391e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.020640762992391e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.020640762992391e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.020640762992391e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.020640762992391e-202Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.020640762992391e-202\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.020640762992391e-202\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.020640762992391e-202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.103203814961955e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.103203814961955e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.103203814961955e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.103203814961955e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.103203814961955e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.103203814961955e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.103203814961955e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.103203814961955e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5516019074809773e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5516019074809773e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5516019074809773e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5516019074809773e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5516019074809773e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5516019074809773e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5516019074809773e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5516019074809773e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2758009537404886e-203Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2758009537404886e-203\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2758009537404886e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2758009537404886e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2758009537404886e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2758009537404886e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2758009537404886e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2758009537404886e-203\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.379004768702443e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.379004768702443e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.379004768702443e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.379004768702443e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.379004768702443e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.379004768702443e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.379004768702443e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.379004768702443e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1895023843512216e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1895023843512216e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1895023843512216e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1895023843512216e-204Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1895023843512216e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1895023843512216e-204\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1895023843512216e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1895023843512216e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5947511921756108e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5947511921756108e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5947511921756108e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5947511921756108e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5947511921756108e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5947511921756108e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5947511921756108e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5947511921756108e-204\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.973755960878054e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.973755960878054e-205Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.973755960878054e-205\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.973755960878054e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.973755960878054e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.973755960878054e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.973755960878054e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.973755960878054e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.986877980439027e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.986877980439027e-205Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.986877980439027e-205\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.986877980439027e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.986877980439027e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.986877980439027e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.986877980439027e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.986877980439027e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9934389902195135e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9934389902195135e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9934389902195135e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9934389902195135e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9934389902195135e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9934389902195135e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9934389902195135e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9934389902195135e-205\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.967194951097568e-206Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.967194951097568e-206\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.967194951097568e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.967194951097568e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.967194951097568e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.967194951097568e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.967194951097568e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.967194951097568e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.983597475548784e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.983597475548784e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.983597475548784e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.983597475548784e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.983597475548784e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.983597475548784e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.983597475548784e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.983597475548784e-206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.491798737774392e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.491798737774392e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.491798737774392e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.491798737774392e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.491798737774392e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.491798737774392e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.491798737774392e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.491798737774392e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.245899368887196e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.245899368887196e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.245899368887196e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.245899368887196e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.245899368887196e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.245899368887196e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.245899368887196e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.245899368887196e-206\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.22949684443598e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.22949684443598e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.22949684443598e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.22949684443598e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.22949684443598e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.22949684443598e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.22949684443598e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.22949684443598e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.11474842221799e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.11474842221799e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.11474842221799e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.11474842221799e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.11474842221799e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.11474842221799e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.11474842221799e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.11474842221799e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.557374211108995e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.557374211108995e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.557374211108995e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.557374211108995e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.557374211108995e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.557374211108995e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.557374211108995e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.557374211108995e-207\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.786871055544975e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.786871055544975e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.786871055544975e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.786871055544975e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.786871055544975e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.786871055544975e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.786871055544975e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.786871055544975e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8934355277724873e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8934355277724873e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8934355277724873e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8934355277724873e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8934355277724873e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8934355277724873e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8934355277724873e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8934355277724873e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9467177638862437e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9467177638862437e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9467177638862437e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9467177638862437e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9467177638862437e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9467177638862437e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9467177638862437e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9467177638862437e-208\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.733588819431218e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.733588819431218e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.733588819431218e-209Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.733588819431218e-209\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.733588819431218e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.733588819431218e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.733588819431218e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.733588819431218e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.866794409715609e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.866794409715609e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.866794409715609e-209Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.866794409715609e-209\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.866794409715609e-209Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.866794409715609e-209\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.866794409715609e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.866794409715609e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4333972048578046e-209Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4333972048578046e-209\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4333972048578046e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4333972048578046e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4333972048578046e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4333972048578046e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4333972048578046e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4333972048578046e-209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2166986024289023e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2166986024289023e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2166986024289023e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2166986024289023e-209Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2166986024289023e-209\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2166986024289023e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2166986024289023e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2166986024289023e-209\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.083493012144512e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.083493012144512e-210Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.083493012144512e-210\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.083493012144512e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.083493012144512e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.083493012144512e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.083493012144512e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.083493012144512e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.041746506072256e-210Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.041746506072256e-210\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.041746506072256e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.041746506072256e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.041746506072256e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.041746506072256e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.041746506072256e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.041746506072256e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.520873253036128e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.520873253036128e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.520873253036128e-210Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.520873253036128e-210\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.520873253036128e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.520873253036128e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.520873253036128e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.520873253036128e-210\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.60436626518064e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.60436626518064e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.60436626518064e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.60436626518064e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.60436626518064e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.60436626518064e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.60436626518064e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.60436626518064e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.80218313259032e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.80218313259032e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.80218313259032e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.80218313259032e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.80218313259032e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.80218313259032e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.80218313259032e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.80218313259032e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.90109156629516e-211Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.90109156629516e-211\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.90109156629516e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.90109156629516e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.90109156629516e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.90109156629516e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.90109156629516e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.90109156629516e-211\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5054578314758e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5054578314758e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5054578314758e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5054578314758e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5054578314758e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5054578314758e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5054578314758e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5054578314758e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7527289157379e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7527289157379e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7527289157379e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7527289157379e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7527289157379e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7527289157379e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7527289157379e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7527289157379e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.37636445786895e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.37636445786895e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.37636445786895e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.37636445786895e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.37636445786895e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.37636445786895e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.37636445786895e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.37636445786895e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.188182228934475e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.188182228934475e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.188182228934475e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.188182228934475e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.188182228934475e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.188182228934475e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.188182228934475e-212\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.188182228934475e-212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.940911144672375e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.940911144672375e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.940911144672375e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.940911144672375e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.940911144672375e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.940911144672375e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.940911144672375e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.940911144672375e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9704555723361872e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9704555723361872e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9704555723361872e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9704555723361872e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9704555723361872e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9704555723361872e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9704555723361872e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9704555723361872e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4852277861680936e-213Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4852277861680936e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4852277861680936e-213\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4852277861680936e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4852277861680936e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4852277861680936e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4852277861680936e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4852277861680936e-213\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.426138930840468e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.426138930840468e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.426138930840468e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.426138930840468e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.426138930840468e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.426138930840468e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.426138930840468e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.426138930840468e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.713069465420234e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.713069465420234e-214Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.713069465420234e-214\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.713069465420234e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.713069465420234e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.713069465420234e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.713069465420234e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.713069465420234e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.856534732710117e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.856534732710117e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.856534732710117e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.856534732710117e-214Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.856534732710117e-214\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.856534732710117e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.856534732710117e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.856534732710117e-214\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.282673663550585e-215Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.282673663550585e-215Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.282673663550585e-215\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.282673663550585e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.282673663550585e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.282673663550585e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.282673663550585e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.282673663550585e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.641336831775293e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.641336831775293e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.641336831775293e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.641336831775293e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.641336831775293e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.641336831775293e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.641336831775293e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.641336831775293e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3206684158876463e-215Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3206684158876463e-215\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3206684158876463e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3206684158876463e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3206684158876463e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3206684158876463e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3206684158876463e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3206684158876463e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1603342079438231e-215Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1603342079438231e-215\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1603342079438231e-215Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1603342079438231e-215\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1603342079438231e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1603342079438231e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1603342079438231e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1603342079438231e-215\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.801671039719116e-216Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.801671039719116e-216\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.801671039719116e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.801671039719116e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.801671039719116e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.801671039719116e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.801671039719116e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.801671039719116e-216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.900835519859558e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.900835519859558e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.900835519859558e-216Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.900835519859558e-216\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.900835519859558e-216Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.900835519859558e-216\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.900835519859558e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.900835519859558e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.450417759929779e-216Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.450417759929779e-216\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.450417759929779e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.450417759929779e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.450417759929779e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.450417759929779e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.450417759929779e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.450417759929779e-216\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.252088799648895e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.252088799648895e-217Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.252088799648895e-217\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.252088799648895e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.252088799648895e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.252088799648895e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.252088799648895e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.252088799648895e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6260443998244473e-217Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6260443998244473e-217\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6260443998244473e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6260443998244473e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6260443998244473e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6260443998244473e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6260443998244473e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6260443998244473e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8130221999122236e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8130221999122236e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8130221999122236e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8130221999122236e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8130221999122236e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8130221999122236e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8130221999122236e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8130221999122236e-217\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.065110999561118e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.065110999561118e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.065110999561118e-218Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.065110999561118e-218\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.065110999561118e-218Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.065110999561118e-218\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.065110999561118e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.065110999561118e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.532555499780559e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.532555499780559e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.532555499780559e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.532555499780559e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.532555499780559e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.532555499780559e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.532555499780559e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.532555499780559e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2662777498902796e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2662777498902796e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2662777498902796e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2662777498902796e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2662777498902796e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2662777498902796e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2662777498902796e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2662777498902796e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1331388749451398e-218Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1331388749451398e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1331388749451398e-218\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1331388749451398e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1331388749451398e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1331388749451398e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1331388749451398e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1331388749451398e-218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.665694374725699e-219Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.665694374725699e-219\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.665694374725699e-219Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.665694374725699e-219\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.665694374725699e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.665694374725699e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.665694374725699e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.665694374725699e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8328471873628494e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8328471873628494e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8328471873628494e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8328471873628494e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8328471873628494e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8328471873628494e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8328471873628494e-219Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8328471873628494e-219\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4164235936814247e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4164235936814247e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4164235936814247e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4164235936814247e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4164235936814247e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4164235936814247e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4164235936814247e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4164235936814247e-219\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.082117968407124e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.082117968407124e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.082117968407124e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.082117968407124e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.082117968407124e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.082117968407124e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.082117968407124e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.082117968407124e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.541058984203562e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.541058984203562e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.541058984203562e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.541058984203562e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.541058984203562e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.541058984203562e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.541058984203562e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.541058984203562e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.770529492101781e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.770529492101781e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.770529492101781e-220Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.770529492101781e-220\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.770529492101781e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.770529492101781e-220Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.770529492101781e-220\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.770529492101781e-220\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.852647460508905e-221Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.852647460508905e-221\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.852647460508905e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.852647460508905e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.852647460508905e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.852647460508905e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.852647460508905e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.852647460508905e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4263237302544523e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4263237302544523e-221Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4263237302544523e-221Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4263237302544523e-221\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4263237302544523e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4263237302544523e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4263237302544523e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4263237302544523e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2131618651272261e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2131618651272261e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2131618651272261e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2131618651272261e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2131618651272261e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2131618651272261e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2131618651272261e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2131618651272261e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1065809325636131e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1065809325636131e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1065809325636131e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1065809325636131e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1065809325636131e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1065809325636131e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1065809325636131e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1065809325636131e-221\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5329046628180653e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5329046628180653e-222Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5329046628180653e-222Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5329046628180653e-222\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5329046628180653e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5329046628180653e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5329046628180653e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5329046628180653e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7664523314090327e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7664523314090327e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7664523314090327e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7664523314090327e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7664523314090327e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7664523314090327e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7664523314090327e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7664523314090327e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3832261657045163e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3832261657045163e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3832261657045163e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3832261657045163e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3832261657045163e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3832261657045163e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3832261657045163e-222\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3832261657045163e-222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.916130828522582e-223Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.916130828522582e-223\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.916130828522582e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.916130828522582e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.916130828522582e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.916130828522582e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.916130828522582e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.916130828522582e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.458065414261291e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.458065414261291e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.458065414261291e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.458065414261291e-223Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.458065414261291e-223\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.458065414261291e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.458065414261291e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.458065414261291e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7290327071306454e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7290327071306454e-223Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7290327071306454e-223\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7290327071306454e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7290327071306454e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7290327071306454e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7290327071306454e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7290327071306454e-223\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.645163535653227e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.645163535653227e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.645163535653227e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.645163535653227e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.645163535653227e-224Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.645163535653227e-224\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.645163535653227e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.645163535653227e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.322581767826614e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.322581767826614e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.322581767826614e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.322581767826614e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.322581767826614e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.322581767826614e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.322581767826614e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.322581767826614e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.161290883913307e-224Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.161290883913307e-224\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.161290883913307e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.161290883913307e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.161290883913307e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.161290883913307e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.161290883913307e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.161290883913307e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0806454419566534e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0806454419566534e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0806454419566534e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0806454419566534e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0806454419566534e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0806454419566534e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0806454419566534e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0806454419566534e-224\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.403227209783267e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.403227209783267e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.403227209783267e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.403227209783267e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.403227209783267e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.403227209783267e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.403227209783267e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.403227209783267e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7016136048916335e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7016136048916335e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7016136048916335e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7016136048916335e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7016136048916335e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7016136048916335e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7016136048916335e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7016136048916335e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3508068024458167e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3508068024458167e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3508068024458167e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3508068024458167e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3508068024458167e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3508068024458167e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3508068024458167e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3508068024458167e-225\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.754034012229084e-226Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.754034012229084e-226\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.754034012229084e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.754034012229084e-226Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.754034012229084e-226\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.754034012229084e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.754034012229084e-226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.754034012229084e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.377017006114542e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.377017006114542e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.377017006114542e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.377017006114542e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.377017006114542e-226Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.377017006114542e-226\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.377017006114542e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.377017006114542e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.688508503057271e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.688508503057271e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.688508503057271e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.688508503057271e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.688508503057271e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.688508503057271e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.688508503057271e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.688508503057271e-226\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.442542515286355e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.442542515286355e-227Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.442542515286355e-227\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.442542515286355e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.442542515286355e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.442542515286355e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.442542515286355e-227Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.442542515286355e-227\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2212712576431773e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2212712576431773e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2212712576431773e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2212712576431773e-227Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2212712576431773e-227\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2212712576431773e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2212712576431773e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2212712576431773e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1106356288215886e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1106356288215886e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1106356288215886e-227Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1106356288215886e-227\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1106356288215886e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1106356288215886e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1106356288215886e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1106356288215886e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0553178144107943e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0553178144107943e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0553178144107943e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0553178144107943e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0553178144107943e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0553178144107943e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0553178144107943e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0553178144107943e-227\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.276589072053972e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.276589072053972e-228Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.276589072053972e-228\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.276589072053972e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.276589072053972e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.276589072053972e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.276589072053972e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.276589072053972e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.638294536026986e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.638294536026986e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.638294536026986e-228Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.638294536026986e-228\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.638294536026986e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.638294536026986e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.638294536026986e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.638294536026986e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.319147268013493e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.319147268013493e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.319147268013493e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.319147268013493e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.319147268013493e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.319147268013493e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.319147268013493e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.319147268013493e-228\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.595736340067465e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.595736340067465e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.595736340067465e-229Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.595736340067465e-229\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.595736340067465e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.595736340067465e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.595736340067465e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.595736340067465e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2978681700337323e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2978681700337323e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2978681700337323e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2978681700337323e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2978681700337323e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2978681700337323e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2978681700337323e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2978681700337323e-229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6489340850168661e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6489340850168661e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6489340850168661e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6489340850168661e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6489340850168661e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6489340850168661e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6489340850168661e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6489340850168661e-229\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.244670425084331e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.244670425084331e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.244670425084331e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.244670425084331e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.244670425084331e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.244670425084331e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.244670425084331e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.244670425084331e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1223352125421653e-230Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1223352125421653e-230Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1223352125421653e-230Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1223352125421653e-230Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1223352125421653e-230\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1223352125421653e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1223352125421653e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1223352125421653e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0611676062710827e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0611676062710827e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0611676062710827e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0611676062710827e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0611676062710827e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0611676062710827e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0611676062710827e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0611676062710827e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0305838031355413e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0305838031355413e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0305838031355413e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0305838031355413e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0305838031355413e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0305838031355413e-230Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0305838031355413e-230\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0305838031355413e-230\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.152919015677707e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.152919015677707e-231Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.152919015677707e-231\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.152919015677707e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.152919015677707e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.152919015677707e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.152919015677707e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.152919015677707e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5764595078388533e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5764595078388533e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5764595078388533e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5764595078388533e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5764595078388533e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5764595078388533e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5764595078388533e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5764595078388533e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2882297539194267e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2882297539194267e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2882297539194267e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2882297539194267e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2882297539194267e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2882297539194267e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2882297539194267e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2882297539194267e-231\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.441148769597133e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.441148769597133e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.441148769597133e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.441148769597133e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.441148769597133e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.441148769597133e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.441148769597133e-232Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.441148769597133e-232\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.220574384798567e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.220574384798567e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.220574384798567e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.220574384798567e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.220574384798567e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.220574384798567e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.220574384798567e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.220574384798567e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6102871923992833e-232Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6102871923992833e-232\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6102871923992833e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6102871923992833e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6102871923992833e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6102871923992833e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6102871923992833e-232\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6102871923992833e-232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.051435961996417e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.051435961996417e-233Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.051435961996417e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.051435961996417e-233\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.051435961996417e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.051435961996417e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.051435961996417e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.051435961996417e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0257179809982083e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0257179809982083e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0257179809982083e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0257179809982083e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0257179809982083e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0257179809982083e-233Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0257179809982083e-233\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0257179809982083e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0128589904991042e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0128589904991042e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0128589904991042e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0128589904991042e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0128589904991042e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0128589904991042e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0128589904991042e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0128589904991042e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0064294952495521e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0064294952495521e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0064294952495521e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0064294952495521e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0064294952495521e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0064294952495521e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0064294952495521e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0064294952495521e-233\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0321474762477604e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0321474762477604e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0321474762477604e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0321474762477604e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0321474762477604e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0321474762477604e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0321474762477604e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0321474762477604e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5160737381238802e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5160737381238802e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5160737381238802e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5160737381238802e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5160737381238802e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5160737381238802e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5160737381238802e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5160737381238802e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2580368690619401e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2580368690619401e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2580368690619401e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2580368690619401e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2580368690619401e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2580368690619401e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2580368690619401e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2580368690619401e-234\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.290184345309701e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.290184345309701e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.290184345309701e-235Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.290184345309701e-235\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.290184345309701e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.290184345309701e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.290184345309701e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.290184345309701e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1450921726548502e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1450921726548502e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1450921726548502e-235Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1450921726548502e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1450921726548502e-235\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1450921726548502e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1450921726548502e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1450921726548502e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5725460863274251e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5725460863274251e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5725460863274251e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5725460863274251e-235Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5725460863274251e-235\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5725460863274251e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5725460863274251e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5725460863274251e-235\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.862730431637126e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.862730431637126e-236Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.862730431637126e-236\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.862730431637126e-236Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.862730431637126e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.862730431637126e-236\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.862730431637126e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.862730431637126e-236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.931365215818563e-236Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.931365215818563e-236\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.931365215818563e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.931365215818563e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.931365215818563e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.931365215818563e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.931365215818563e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.931365215818563e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9656826079092814e-236Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9656826079092814e-236\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9656826079092814e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9656826079092814e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9656826079092814e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9656826079092814e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9656826079092814e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9656826079092814e-236\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.828413039546407e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.828413039546407e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.828413039546407e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.828413039546407e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.828413039546407e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.828413039546407e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.828413039546407e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.828413039546407e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.914206519773204e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.914206519773204e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.914206519773204e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.914206519773204e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.914206519773204e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.914206519773204e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.914206519773204e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.914206519773204e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.457103259886602e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.457103259886602e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.457103259886602e-237Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.457103259886602e-237\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.457103259886602e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.457103259886602e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.457103259886602e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.457103259886602e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.228551629943301e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.228551629943301e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.228551629943301e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.228551629943301e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.228551629943301e-237Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.228551629943301e-237\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.228551629943301e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.228551629943301e-237\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.142758149716505e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.142758149716505e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.142758149716505e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.142758149716505e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.142758149716505e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.142758149716505e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.142758149716505e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.142758149716505e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0713790748582522e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0713790748582522e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0713790748582522e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0713790748582522e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0713790748582522e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0713790748582522e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0713790748582522e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0713790748582522e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5356895374291261e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5356895374291261e-238Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5356895374291261e-238\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5356895374291261e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5356895374291261e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5356895374291261e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5356895374291261e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5356895374291261e-238\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.678447687145631e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.678447687145631e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.678447687145631e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.678447687145631e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.678447687145631e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.678447687145631e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.678447687145631e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.678447687145631e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8392238435728152e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8392238435728152e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8392238435728152e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8392238435728152e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8392238435728152e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8392238435728152e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8392238435728152e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8392238435728152e-239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9196119217864076e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9196119217864076e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9196119217864076e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9196119217864076e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9196119217864076e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9196119217864076e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9196119217864076e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9196119217864076e-239\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.598059608932038e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.598059608932038e-240Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.598059608932038e-240\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.598059608932038e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.598059608932038e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.598059608932038e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.598059608932038e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.598059608932038e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.799029804466019e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.799029804466019e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.799029804466019e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.799029804466019e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.799029804466019e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.799029804466019e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.799029804466019e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.799029804466019e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3995149022330095e-240Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3995149022330095e-240\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3995149022330095e-240Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3995149022330095e-240\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3995149022330095e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3995149022330095e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3995149022330095e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3995149022330095e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1997574511165048e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1997574511165048e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1997574511165048e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1997574511165048e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1997574511165048e-240Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1997574511165048e-240Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1997574511165048e-240\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1997574511165048e-240\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.998787255582524e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.998787255582524e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.998787255582524e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.998787255582524e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.998787255582524e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.998787255582524e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.998787255582524e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.998787255582524e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.999393627791262e-241Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.999393627791262e-241\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.999393627791262e-241Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.999393627791262e-241\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.999393627791262e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.999393627791262e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.999393627791262e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.999393627791262e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.499696813895631e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.499696813895631e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.499696813895631e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.499696813895631e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.499696813895631e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.499696813895631e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.499696813895631e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.499696813895631e-241\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.498484069478155e-242Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.498484069478155e-242Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.498484069478155e-242\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.498484069478155e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.498484069478155e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.498484069478155e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.498484069478155e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.498484069478155e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7492420347390774e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7492420347390774e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7492420347390774e-242Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7492420347390774e-242\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7492420347390774e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7492420347390774e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7492420347390774e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7492420347390774e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8746210173695387e-242Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8746210173695387e-242\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8746210173695387e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8746210173695387e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8746210173695387e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8746210173695387e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8746210173695387e-242\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8746210173695387e-242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.373105086847693e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.373105086847693e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.373105086847693e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.373105086847693e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.373105086847693e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.373105086847693e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.373105086847693e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.373105086847693e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.686552543423847e-243Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.686552543423847e-243\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.686552543423847e-243Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.686552543423847e-243\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.686552543423847e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.686552543423847e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.686552543423847e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.686552543423847e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3432762717119234e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3432762717119234e-243Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3432762717119234e-243\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3432762717119234e-243Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3432762717119234e-243\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3432762717119234e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3432762717119234e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3432762717119234e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1716381358559617e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1716381358559617e-243Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1716381358559617e-243\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1716381358559617e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1716381358559617e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1716381358559617e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1716381358559617e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1716381358559617e-243\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.858190679279809e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.858190679279809e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.858190679279809e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.858190679279809e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.858190679279809e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.858190679279809e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.858190679279809e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.858190679279809e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9290953396399042e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9290953396399042e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9290953396399042e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9290953396399042e-244Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9290953396399042e-244\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9290953396399042e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9290953396399042e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9290953396399042e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4645476698199521e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4645476698199521e-244Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4645476698199521e-244\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4645476698199521e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4645476698199521e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4645476698199521e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4645476698199521e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4645476698199521e-244\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.322738349099761e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.322738349099761e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.322738349099761e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.322738349099761e-245Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.322738349099761e-245\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.322738349099761e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.322738349099761e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.322738349099761e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6613691745498803e-245Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6613691745498803e-245\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6613691745498803e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6613691745498803e-245Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6613691745498803e-245\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6613691745498803e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6613691745498803e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6613691745498803e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8306845872749401e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8306845872749401e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8306845872749401e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8306845872749401e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8306845872749401e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8306845872749401e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8306845872749401e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8306845872749401e-245\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.153422936374701e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.153422936374701e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.153422936374701e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.153422936374701e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.153422936374701e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.153422936374701e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.153422936374701e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.153422936374701e-246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5767114681873503e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5767114681873503e-246Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5767114681873503e-246\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5767114681873503e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5767114681873503e-246\n",
      "2020-06-11 10:06:47,606 maskrcnn_benchmark INFO: eta: 12:15:43  iter: 1400  loss: inf (inf)  auxiliary_ctx: 0.3285 (8.2378)  auxiliary_frq: 0.2110 (0.2092)  auxiliary_vis: inf (inf)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: inf (inf)  time: 1.1287 (1.1436)  data: 0.0247 (0.0246)  lr: 0.640000  max mem: 6128\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5767114681873503e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5767114681873503e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5767114681873503e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2883557340936752e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2883557340936752e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2883557340936752e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2883557340936752e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2883557340936752e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2883557340936752e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2883557340936752e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2883557340936752e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1441778670468376e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1441778670468376e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1441778670468376e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1441778670468376e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1441778670468376e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1441778670468376e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1441778670468376e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1441778670468376e-246\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.720889335234188e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.720889335234188e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.720889335234188e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.720889335234188e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.720889335234188e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.720889335234188e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.720889335234188e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.720889335234188e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.860444667617094e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.860444667617094e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.860444667617094e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.860444667617094e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.860444667617094e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.860444667617094e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.860444667617094e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.860444667617094e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.430222333808547e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.430222333808547e-247Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.430222333808547e-247\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.430222333808547e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.430222333808547e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.430222333808547e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.430222333808547e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.430222333808547e-247\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.151111669042735e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.151111669042735e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.151111669042735e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.151111669042735e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.151111669042735e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.151111669042735e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.151111669042735e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.151111669042735e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5755558345213674e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5755558345213674e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5755558345213674e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5755558345213674e-248Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5755558345213674e-248\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5755558345213674e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5755558345213674e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5755558345213674e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7877779172606837e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7877779172606837e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7877779172606837e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7877779172606837e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7877779172606837e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7877779172606837e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7877779172606837e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7877779172606837e-248\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.938889586303419e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.938889586303419e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.938889586303419e-249Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.938889586303419e-249\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.938889586303419e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.938889586303419e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.938889586303419e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.938889586303419e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4694447931517093e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4694447931517093e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4694447931517093e-249Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4694447931517093e-249\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4694447931517093e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4694447931517093e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4694447931517093e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4694447931517093e-249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2347223965758547e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2347223965758547e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2347223965758547e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2347223965758547e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2347223965758547e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2347223965758547e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2347223965758547e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2347223965758547e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1173611982879273e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1173611982879273e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1173611982879273e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1173611982879273e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1173611982879273e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1173611982879273e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1173611982879273e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1173611982879273e-249\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.586805991439637e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.586805991439637e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.586805991439637e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.586805991439637e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.586805991439637e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.586805991439637e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.586805991439637e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.586805991439637e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7934029957198183e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7934029957198183e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7934029957198183e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7934029957198183e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7934029957198183e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7934029957198183e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7934029957198183e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7934029957198183e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3967014978599092e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3967014978599092e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3967014978599092e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3967014978599092e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3967014978599092e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3967014978599092e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3967014978599092e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3967014978599092e-250\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.983507489299546e-251Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.983507489299546e-251\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.983507489299546e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.983507489299546e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.983507489299546e-251Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.983507489299546e-251\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.983507489299546e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.983507489299546e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.491753744649773e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.491753744649773e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.491753744649773e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.491753744649773e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.491753744649773e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.491753744649773e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.491753744649773e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.491753744649773e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7458768723248864e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7458768723248864e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7458768723248864e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7458768723248864e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7458768723248864e-251Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7458768723248864e-251\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7458768723248864e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7458768723248864e-251\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.729384361624432e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.729384361624432e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.729384361624432e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.729384361624432e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.729384361624432e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.729384361624432e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.729384361624432e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.729384361624432e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.364692180812216e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.364692180812216e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.364692180812216e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.364692180812216e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.364692180812216e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.364692180812216e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.364692180812216e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.364692180812216e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.182346090406108e-252Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.182346090406108e-252\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.182346090406108e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.182346090406108e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.182346090406108e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.182346090406108e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.182346090406108e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.182346090406108e-252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.091173045203054e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.091173045203054e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.091173045203054e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.091173045203054e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.091173045203054e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.091173045203054e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.091173045203054e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.091173045203054e-252\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.45586522601527e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.45586522601527e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.45586522601527e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.45586522601527e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.45586522601527e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.45586522601527e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.45586522601527e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.45586522601527e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.727932613007635e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.727932613007635e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.727932613007635e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.727932613007635e-253Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.727932613007635e-253\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.727932613007635e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.727932613007635e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.727932613007635e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3639663065038175e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3639663065038175e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3639663065038175e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3639663065038175e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3639663065038175e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3639663065038175e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3639663065038175e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3639663065038175e-253\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.819831532519088e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.819831532519088e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.819831532519088e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.819831532519088e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.819831532519088e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.819831532519088e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.819831532519088e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.819831532519088e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.409915766259544e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.409915766259544e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.409915766259544e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.409915766259544e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.409915766259544e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.409915766259544e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.409915766259544e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.409915766259544e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.704957883129772e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.704957883129772e-254Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.704957883129772e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.704957883129772e-254\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.704957883129772e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.704957883129772e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.704957883129772e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.704957883129772e-254\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.52478941564886e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.52478941564886e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.52478941564886e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.52478941564886e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.52478941564886e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.52478941564886e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.52478941564886e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.52478941564886e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.26239470782443e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.26239470782443e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.26239470782443e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.26239470782443e-255Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.26239470782443e-255\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.26239470782443e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.26239470782443e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.26239470782443e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.131197353912215e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.131197353912215e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.131197353912215e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.131197353912215e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.131197353912215e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.131197353912215e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.131197353912215e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.131197353912215e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0655986769561075e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0655986769561075e-255Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0655986769561075e-255\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0655986769561075e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0655986769561075e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0655986769561075e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0655986769561075e-255\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0655986769561075e-255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.327993384780537e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.327993384780537e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.327993384780537e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.327993384780537e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.327993384780537e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.327993384780537e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.327993384780537e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.327993384780537e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6639966923902686e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6639966923902686e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6639966923902686e-256Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6639966923902686e-256\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6639966923902686e-256Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6639966923902686e-256\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6639966923902686e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6639966923902686e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3319983461951343e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3319983461951343e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3319983461951343e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3319983461951343e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3319983461951343e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3319983461951343e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3319983461951343e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3319983461951343e-256\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.659991730975672e-257Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.659991730975672e-257Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.659991730975672e-257\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.659991730975672e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.659991730975672e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.659991730975672e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.659991730975672e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.659991730975672e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.329995865487836e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.329995865487836e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.329995865487836e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.329995865487836e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.329995865487836e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.329995865487836e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.329995865487836e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.329995865487836e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.664997932743918e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.664997932743918e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.664997932743918e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.664997932743918e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.664997932743918e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.664997932743918e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.664997932743918e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.664997932743918e-257\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.32498966371959e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.32498966371959e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.32498966371959e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.32498966371959e-258Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.32498966371959e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.32498966371959e-258\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.32498966371959e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.32498966371959e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.162494831859795e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.162494831859795e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.162494831859795e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.162494831859795e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.162494831859795e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.162494831859795e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.162494831859795e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.162494831859795e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0812474159298974e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0812474159298974e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0812474159298974e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0812474159298974e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0812474159298974e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0812474159298974e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0812474159298974e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0812474159298974e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0406237079649487e-258Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0406237079649487e-258\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0406237079649487e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0406237079649487e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0406237079649487e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0406237079649487e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0406237079649487e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0406237079649487e-258\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.2031185398247434e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.2031185398247434e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.2031185398247434e-259Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.2031185398247434e-259\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.2031185398247434e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.2031185398247434e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.2031185398247434e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.2031185398247434e-259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6015592699123717e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6015592699123717e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6015592699123717e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6015592699123717e-259Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6015592699123717e-259\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6015592699123717e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6015592699123717e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6015592699123717e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3007796349561859e-259Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3007796349561859e-259Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3007796349561859e-259\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3007796349561859e-259Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3007796349561859e-259\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3007796349561859e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3007796349561859e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3007796349561859e-259\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.503898174780929e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.503898174780929e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.503898174780929e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.503898174780929e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.503898174780929e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.503898174780929e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.503898174780929e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.503898174780929e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2519490873904646e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2519490873904646e-260Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2519490873904646e-260\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2519490873904646e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2519490873904646e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2519490873904646e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2519490873904646e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2519490873904646e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6259745436952323e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6259745436952323e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6259745436952323e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6259745436952323e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6259745436952323e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6259745436952323e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6259745436952323e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6259745436952323e-260\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.129872718476162e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.129872718476162e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.129872718476162e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.129872718476162e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.129872718476162e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.129872718476162e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.129872718476162e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.129872718476162e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.064936359238081e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.064936359238081e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.064936359238081e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.064936359238081e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.064936359238081e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.064936359238081e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.064936359238081e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.064936359238081e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0324681796190404e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0324681796190404e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0324681796190404e-261Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0324681796190404e-261\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0324681796190404e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0324681796190404e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0324681796190404e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0324681796190404e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0162340898095202e-261Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0162340898095202e-261Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0162340898095202e-261\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0162340898095202e-261\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0162340898095202e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0162340898095202e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0162340898095202e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0162340898095202e-261\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.081170449047601e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.081170449047601e-262Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.081170449047601e-262\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.081170449047601e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.081170449047601e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.081170449047601e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.081170449047601e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.081170449047601e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5405852245238005e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5405852245238005e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5405852245238005e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5405852245238005e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5405852245238005e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5405852245238005e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5405852245238005e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5405852245238005e-262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2702926122619002e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2702926122619002e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2702926122619002e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2702926122619002e-262Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2702926122619002e-262\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2702926122619002e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2702926122619002e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2702926122619002e-262\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.351463061309501e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.351463061309501e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.351463061309501e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.351463061309501e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.351463061309501e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.351463061309501e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.351463061309501e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.351463061309501e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1757315306547506e-263Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1757315306547506e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1757315306547506e-263\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1757315306547506e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1757315306547506e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1757315306547506e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1757315306547506e-263Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1757315306547506e-263\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5878657653273753e-263Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5878657653273753e-263\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5878657653273753e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5878657653273753e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5878657653273753e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5878657653273753e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5878657653273753e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5878657653273753e-263\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.939328826636877e-264Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.939328826636877e-264\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.939328826636877e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.939328826636877e-264Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.939328826636877e-264\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.939328826636877e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.939328826636877e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.939328826636877e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9696644133184383e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9696644133184383e-264Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9696644133184383e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9696644133184383e-264\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9696644133184383e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9696644133184383e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9696644133184383e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9696644133184383e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9848322066592191e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9848322066592191e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9848322066592191e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9848322066592191e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9848322066592191e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9848322066592191e-264\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9848322066592191e-264Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9848322066592191e-264\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.924161033296096e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.924161033296096e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.924161033296096e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.924161033296096e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.924161033296096e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.924161033296096e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.924161033296096e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.924161033296096e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.962080516648048e-265Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.962080516648048e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.962080516648048e-265\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.962080516648048e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.962080516648048e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.962080516648048e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.962080516648048e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.962080516648048e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.481040258324024e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.481040258324024e-265Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.481040258324024e-265Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.481040258324024e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.481040258324024e-265\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.481040258324024e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.481040258324024e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.481040258324024e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.240520129162012e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.240520129162012e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.240520129162012e-265\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.240520129162012e-265Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.240520129162012e-265Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.240520129162012e-265\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.240520129162012e-265\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.240520129162012e-265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.20260064581006e-266Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.20260064581006e-266Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.20260064581006e-266\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.20260064581006e-266\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.20260064581006e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.20260064581006e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.20260064581006e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.20260064581006e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.10130032290503e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.10130032290503e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.10130032290503e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.10130032290503e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.10130032290503e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.10130032290503e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.10130032290503e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.10130032290503e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.550650161452515e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.550650161452515e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.550650161452515e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.550650161452515e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.550650161452515e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.550650161452515e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.550650161452515e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.550650161452515e-266\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.753250807262575e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.753250807262575e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.753250807262575e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.753250807262575e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.753250807262575e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.753250807262575e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.753250807262575e-267Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.753250807262575e-267\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8766254036312874e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8766254036312874e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8766254036312874e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8766254036312874e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8766254036312874e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8766254036312874e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8766254036312874e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8766254036312874e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9383127018156437e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9383127018156437e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9383127018156437e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9383127018156437e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9383127018156437e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9383127018156437e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9383127018156437e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9383127018156437e-267\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.691563509078218e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.691563509078218e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.691563509078218e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.691563509078218e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.691563509078218e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.691563509078218e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.691563509078218e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.691563509078218e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.845781754539109e-268Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.845781754539109e-268\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.845781754539109e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.845781754539109e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.845781754539109e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.845781754539109e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.845781754539109e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.845781754539109e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4228908772695546e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4228908772695546e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4228908772695546e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4228908772695546e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4228908772695546e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4228908772695546e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4228908772695546e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4228908772695546e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2114454386347773e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2114454386347773e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2114454386347773e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2114454386347773e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2114454386347773e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2114454386347773e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2114454386347773e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2114454386347773e-268\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.057227193173887e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.057227193173887e-269Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.057227193173887e-269\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.057227193173887e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.057227193173887e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.057227193173887e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.057227193173887e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.057227193173887e-269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0286135965869433e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0286135965869433e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0286135965869433e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0286135965869433e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0286135965869433e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0286135965869433e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0286135965869433e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0286135965869433e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5143067982934716e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5143067982934716e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5143067982934716e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5143067982934716e-269Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5143067982934716e-269\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5143067982934716e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5143067982934716e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5143067982934716e-269\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.571533991467358e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.571533991467358e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.571533991467358e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.571533991467358e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.571533991467358e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.571533991467358e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.571533991467358e-270Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.571533991467358e-270\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.785766995733679e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.785766995733679e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.785766995733679e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.785766995733679e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.785766995733679e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.785766995733679e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.785766995733679e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.785766995733679e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8928834978668395e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8928834978668395e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8928834978668395e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8928834978668395e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8928834978668395e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8928834978668395e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8928834978668395e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8928834978668395e-270\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.464417489334198e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.464417489334198e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.464417489334198e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.464417489334198e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.464417489334198e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.464417489334198e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.464417489334198e-271Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.464417489334198e-271\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.732208744667099e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.732208744667099e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.732208744667099e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.732208744667099e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.732208744667099e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.732208744667099e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.732208744667099e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.732208744667099e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3661043723335494e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3661043723335494e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3661043723335494e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3661043723335494e-271Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3661043723335494e-271\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3661043723335494e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3661043723335494e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3661043723335494e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1830521861667747e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1830521861667747e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1830521861667747e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1830521861667747e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1830521861667747e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1830521861667747e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1830521861667747e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1830521861667747e-271\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.915260930833874e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.915260930833874e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.915260930833874e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.915260930833874e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.915260930833874e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.915260930833874e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.915260930833874e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.915260930833874e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.957630465416937e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.957630465416937e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.957630465416937e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.957630465416937e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.957630465416937e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.957630465416937e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.957630465416937e-272Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.957630465416937e-272\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4788152327084684e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4788152327084684e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4788152327084684e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4788152327084684e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4788152327084684e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4788152327084684e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4788152327084684e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4788152327084684e-272\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.394076163542342e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.394076163542342e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.394076163542342e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.394076163542342e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.394076163542342e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.394076163542342e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.394076163542342e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.394076163542342e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.697038081771171e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.697038081771171e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.697038081771171e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.697038081771171e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.697038081771171e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.697038081771171e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.697038081771171e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.697038081771171e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8485190408855855e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8485190408855855e-273Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8485190408855855e-273\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8485190408855855e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8485190408855855e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8485190408855855e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8485190408855855e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8485190408855855e-273\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.242595204427927e-274Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.242595204427927e-274\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.242595204427927e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.242595204427927e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.242595204427927e-274Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.242595204427927e-274\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.242595204427927e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.242595204427927e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.621297602213964e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.621297602213964e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.621297602213964e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.621297602213964e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.621297602213964e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.621297602213964e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.621297602213964e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.621297602213964e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.310648801106982e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.310648801106982e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.310648801106982e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.310648801106982e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.310648801106982e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.310648801106982e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.310648801106982e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.310648801106982e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.155324400553491e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.155324400553491e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.155324400553491e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.155324400553491e-274Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.155324400553491e-274\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.155324400553491e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.155324400553491e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.155324400553491e-274\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.776622002767455e-275Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.776622002767455e-275Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.776622002767455e-275\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.776622002767455e-275Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.776622002767455e-275\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.776622002767455e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.776622002767455e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.776622002767455e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8883110013837273e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8883110013837273e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8883110013837273e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8883110013837273e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8883110013837273e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8883110013837273e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8883110013837273e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8883110013837273e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4441555006918637e-275Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4441555006918637e-275\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4441555006918637e-275Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4441555006918637e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4441555006918637e-275\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4441555006918637e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4441555006918637e-275\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4441555006918637e-275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.220777503459318e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.220777503459318e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.220777503459318e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.220777503459318e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.220777503459318e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.220777503459318e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.220777503459318e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.220777503459318e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.610388751729659e-276Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.610388751729659e-276\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.610388751729659e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.610388751729659e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.610388751729659e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.610388751729659e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.610388751729659e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.610388751729659e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8051943758648296e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8051943758648296e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8051943758648296e-276Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8051943758648296e-276\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8051943758648296e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8051943758648296e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8051943758648296e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8051943758648296e-276\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.025971879324148e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.025971879324148e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.025971879324148e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.025971879324148e-277Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.025971879324148e-277\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.025971879324148e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.025971879324148e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.025971879324148e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.512985939662074e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.512985939662074e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.512985939662074e-277Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.512985939662074e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.512985939662074e-277\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.512985939662074e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.512985939662074e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.512985939662074e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.256492969831037e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.256492969831037e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.256492969831037e-277Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.256492969831037e-277\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.256492969831037e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.256492969831037e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.256492969831037e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.256492969831037e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1282464849155185e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1282464849155185e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1282464849155185e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1282464849155185e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1282464849155185e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1282464849155185e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1282464849155185e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1282464849155185e-277\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.641232424577593e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.641232424577593e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.641232424577593e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.641232424577593e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.641232424577593e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.641232424577593e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.641232424577593e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.641232424577593e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8206162122887962e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8206162122887962e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8206162122887962e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8206162122887962e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8206162122887962e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8206162122887962e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8206162122887962e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8206162122887962e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4103081061443981e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4103081061443981e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4103081061443981e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4103081061443981e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4103081061443981e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4103081061443981e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4103081061443981e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4103081061443981e-278\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.051540530721991e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.051540530721991e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.051540530721991e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.051540530721991e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.051540530721991e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.051540530721991e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.051540530721991e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.051540530721991e-279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5257702653609953e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5257702653609953e-279Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5257702653609953e-279\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5257702653609953e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5257702653609953e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5257702653609953e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5257702653609953e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5257702653609953e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7628851326804976e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7628851326804976e-279Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7628851326804976e-279Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7628851326804976e-279\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7628851326804976e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7628851326804976e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7628851326804976e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7628851326804976e-279\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.814425663402488e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.814425663402488e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.814425663402488e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.814425663402488e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.814425663402488e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.814425663402488e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.814425663402488e-280Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.814425663402488e-280\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.407212831701244e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.407212831701244e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.407212831701244e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.407212831701244e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.407212831701244e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.407212831701244e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.407212831701244e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.407212831701244e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.203606415850622e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.203606415850622e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.203606415850622e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.203606415850622e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.203606415850622e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.203606415850622e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.203606415850622e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.203606415850622e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.101803207925311e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.101803207925311e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.101803207925311e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.101803207925311e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.101803207925311e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.101803207925311e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.101803207925311e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.101803207925311e-280\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.509016039626555e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.509016039626555e-281Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.509016039626555e-281\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.509016039626555e-281Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.509016039626555e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.509016039626555e-281\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.509016039626555e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.509016039626555e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7545080198132776e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7545080198132776e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7545080198132776e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7545080198132776e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7545080198132776e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7545080198132776e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7545080198132776e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7545080198132776e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3772540099066388e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3772540099066388e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3772540099066388e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3772540099066388e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3772540099066388e-281Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3772540099066388e-281\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3772540099066388e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3772540099066388e-281\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.886270049533194e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.886270049533194e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.886270049533194e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.886270049533194e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.886270049533194e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.886270049533194e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.886270049533194e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.886270049533194e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.443135024766597e-282Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.443135024766597e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.443135024766597e-282\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.443135024766597e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.443135024766597e-282Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.443135024766597e-282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.443135024766597e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.443135024766597e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7215675123832985e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7215675123832985e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7215675123832985e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7215675123832985e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7215675123832985e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7215675123832985e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7215675123832985e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7215675123832985e-282\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.607837561916492e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.607837561916492e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.607837561916492e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.607837561916492e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.607837561916492e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.607837561916492e-283Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.607837561916492e-283Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.607837561916492e-283\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.303918780958246e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.303918780958246e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.303918780958246e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.303918780958246e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.303918780958246e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.303918780958246e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.303918780958246e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.303918780958246e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.151959390479123e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.151959390479123e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.151959390479123e-283Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.151959390479123e-283Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.151959390479123e-283\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.151959390479123e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.151959390479123e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.151959390479123e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0759796952395615e-283Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0759796952395615e-283\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0759796952395615e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0759796952395615e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0759796952395615e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0759796952395615e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0759796952395615e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0759796952395615e-283\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.379898476197808e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.379898476197808e-284Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.379898476197808e-284\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.379898476197808e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.379898476197808e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.379898476197808e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.379898476197808e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.379898476197808e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.689949238098904e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.689949238098904e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.689949238098904e-284Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.689949238098904e-284\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.689949238098904e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.689949238098904e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.689949238098904e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.689949238098904e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.344974619049452e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.344974619049452e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.344974619049452e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.344974619049452e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.344974619049452e-284Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.344974619049452e-284\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.344974619049452e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.344974619049452e-284\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.72487309524726e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.72487309524726e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.72487309524726e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.72487309524726e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.72487309524726e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.72487309524726e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.72487309524726e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.72487309524726e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.36243654762363e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.36243654762363e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.36243654762363e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.36243654762363e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.36243654762363e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.36243654762363e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.36243654762363e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.36243654762363e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.681218273811815e-285Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.681218273811815e-285Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.681218273811815e-285\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.681218273811815e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.681218273811815e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.681218273811815e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.681218273811815e-285\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.681218273811815e-285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.406091369059075e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.406091369059075e-286Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.406091369059075e-286Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.406091369059075e-286\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.406091369059075e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.406091369059075e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.406091369059075e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.406091369059075e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2030456845295373e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2030456845295373e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2030456845295373e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2030456845295373e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2030456845295373e-286Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2030456845295373e-286\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2030456845295373e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2030456845295373e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1015228422647686e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1015228422647686e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1015228422647686e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1015228422647686e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1015228422647686e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1015228422647686e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1015228422647686e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1015228422647686e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0507614211323843e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0507614211323843e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0507614211323843e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0507614211323843e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0507614211323843e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0507614211323843e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0507614211323843e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0507614211323843e-286\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.253807105661922e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.253807105661922e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.253807105661922e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.253807105661922e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.253807105661922e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.253807105661922e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.253807105661922e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.253807105661922e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.626903552830961e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.626903552830961e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.626903552830961e-287Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.626903552830961e-287\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.626903552830961e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.626903552830961e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.626903552830961e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.626903552830961e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3134517764154804e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3134517764154804e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3134517764154804e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3134517764154804e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3134517764154804e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3134517764154804e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3134517764154804e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3134517764154804e-287\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.567258882077402e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.567258882077402e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.567258882077402e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.567258882077402e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.567258882077402e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.567258882077402e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.567258882077402e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.567258882077402e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.283629441038701e-288Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.283629441038701e-288Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.283629441038701e-288\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.283629441038701e-288Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.283629441038701e-288\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.283629441038701e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.283629441038701e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.283629441038701e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6418147205193505e-288Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6418147205193505e-288\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6418147205193505e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6418147205193505e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6418147205193505e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6418147205193505e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6418147205193505e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6418147205193505e-288\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.209073602596753e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.209073602596753e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.209073602596753e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.209073602596753e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.209073602596753e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.209073602596753e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.209073602596753e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.209073602596753e-289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1045368012983762e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1045368012983762e-289Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1045368012983762e-289\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1045368012983762e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1045368012983762e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1045368012983762e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1045368012983762e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1045368012983762e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0522684006491881e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0522684006491881e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0522684006491881e-289Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0522684006491881e-289Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0522684006491881e-289\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0522684006491881e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0522684006491881e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0522684006491881e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0261342003245941e-289Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0261342003245941e-289\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0261342003245941e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0261342003245941e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0261342003245941e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0261342003245941e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0261342003245941e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0261342003245941e-289\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1306710016229703e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1306710016229703e-290Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1306710016229703e-290\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1306710016229703e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1306710016229703e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1306710016229703e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1306710016229703e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1306710016229703e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5653355008114852e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5653355008114852e-290Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5653355008114852e-290\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5653355008114852e-290Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5653355008114852e-290\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5653355008114852e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5653355008114852e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5653355008114852e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2826677504057426e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2826677504057426e-290Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2826677504057426e-290Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2826677504057426e-290\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2826677504057426e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2826677504057426e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2826677504057426e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2826677504057426e-290\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.413338752028713e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.413338752028713e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.413338752028713e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.413338752028713e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.413338752028713e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.413338752028713e-291Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.413338752028713e-291\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.413338752028713e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2066693760143564e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2066693760143564e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2066693760143564e-291Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2066693760143564e-291Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2066693760143564e-291\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2066693760143564e-291Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2066693760143564e-291\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2066693760143564e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6033346880071782e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6033346880071782e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6033346880071782e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6033346880071782e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6033346880071782e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6033346880071782e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6033346880071782e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6033346880071782e-291\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.016673440035891e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.016673440035891e-292Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.016673440035891e-292\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.016673440035891e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.016673440035891e-292Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.016673440035891e-292\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.016673440035891e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.016673440035891e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.008336720017946e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.008336720017946e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.008336720017946e-292Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.008336720017946e-292\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.008336720017946e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.008336720017946e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.008336720017946e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.008336720017946e-292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.004168360008973e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.004168360008973e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.004168360008973e-292Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.004168360008973e-292\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.004168360008973e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.004168360008973e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.004168360008973e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.004168360008973e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0020841800044864e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0020841800044864e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0020841800044864e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0020841800044864e-292Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0020841800044864e-292Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0020841800044864e-292\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0020841800044864e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0020841800044864e-292\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.010420900022432e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.010420900022432e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.010420900022432e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.010420900022432e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.010420900022432e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.010420900022432e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.010420900022432e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.010420900022432e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.505210450011216e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.505210450011216e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.505210450011216e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.505210450011216e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.505210450011216e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.505210450011216e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.505210450011216e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.505210450011216e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.252605225005608e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.252605225005608e-293Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.252605225005608e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.252605225005608e-293\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.252605225005608e-293Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.252605225005608e-293\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.252605225005608e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.252605225005608e-293\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.26302612502804e-294Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.26302612502804e-294Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.26302612502804e-294\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.26302612502804e-294Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.26302612502804e-294\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.26302612502804e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.26302612502804e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.26302612502804e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.13151306251402e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.13151306251402e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.13151306251402e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.13151306251402e-294Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.13151306251402e-294\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.13151306251402e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.13151306251402e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.13151306251402e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.56575653125701e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.56575653125701e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.56575653125701e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.56575653125701e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.56575653125701e-294Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.56575653125701e-294\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.56575653125701e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.56575653125701e-294\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.82878265628505e-295Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.82878265628505e-295\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.82878265628505e-295Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.82878265628505e-295\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.82878265628505e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.82878265628505e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.82878265628505e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.82878265628505e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.914391328142525e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.914391328142525e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.914391328142525e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.914391328142525e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.914391328142525e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.914391328142525e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.914391328142525e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.914391328142525e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9571956640712625e-295Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9571956640712625e-295\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9571956640712625e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9571956640712625e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9571956640712625e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9571956640712625e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9571956640712625e-295\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9571956640712625e-295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.785978320356312e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.785978320356312e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.785978320356312e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.785978320356312e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.785978320356312e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.785978320356312e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.785978320356312e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.785978320356312e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.892989160178156e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.892989160178156e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.892989160178156e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.892989160178156e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.892989160178156e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.892989160178156e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.892989160178156e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.892989160178156e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.446494580089078e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.446494580089078e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.446494580089078e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.446494580089078e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.446494580089078e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.446494580089078e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.446494580089078e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.446494580089078e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.223247290044539e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.223247290044539e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.223247290044539e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.223247290044539e-296Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.223247290044539e-296\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.223247290044539e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.223247290044539e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.223247290044539e-296\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.116236450222695e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.116236450222695e-297Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.116236450222695e-297\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.116236450222695e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.116236450222695e-297Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.116236450222695e-297\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.116236450222695e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.116236450222695e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0581182251113476e-297Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0581182251113476e-297\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0581182251113476e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0581182251113476e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0581182251113476e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0581182251113476e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0581182251113476e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0581182251113476e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5290591125556738e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5290591125556738e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5290591125556738e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5290591125556738e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5290591125556738e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5290591125556738e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5290591125556738e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5290591125556738e-297\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.645295562778369e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.645295562778369e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.645295562778369e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.645295562778369e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.645295562778369e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.645295562778369e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.645295562778369e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.645295562778369e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8226477813891845e-298Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8226477813891845e-298Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8226477813891845e-298\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8226477813891845e-298Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8226477813891845e-298\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8226477813891845e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8226477813891845e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8226477813891845e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9113238906945923e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9113238906945923e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9113238906945923e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9113238906945923e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9113238906945923e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9113238906945923e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9113238906945923e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9113238906945923e-298\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.556619453472961e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.556619453472961e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.556619453472961e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.556619453472961e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.556619453472961e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.556619453472961e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.556619453472961e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.556619453472961e-299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.778309726736481e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.778309726736481e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.778309726736481e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.778309726736481e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.778309726736481e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.778309726736481e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.778309726736481e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.778309726736481e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3891548633682403e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3891548633682403e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3891548633682403e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3891548633682403e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3891548633682403e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3891548633682403e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3891548633682403e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3891548633682403e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1945774316841202e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1945774316841202e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1945774316841202e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1945774316841202e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1945774316841202e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1945774316841202e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1945774316841202e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1945774316841202e-299\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.972887158420601e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.972887158420601e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.972887158420601e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.972887158420601e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.972887158420601e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.972887158420601e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.972887158420601e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.972887158420601e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9864435792103004e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9864435792103004e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9864435792103004e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9864435792103004e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9864435792103004e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9864435792103004e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9864435792103004e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9864435792103004e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4932217896051502e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4932217896051502e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4932217896051502e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4932217896051502e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4932217896051502e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4932217896051502e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4932217896051502e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4932217896051502e-300\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.466108948025751e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.466108948025751e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.466108948025751e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.466108948025751e-301Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.466108948025751e-301\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.466108948025751e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.466108948025751e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.466108948025751e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7330544740128755e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7330544740128755e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7330544740128755e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7330544740128755e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7330544740128755e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7330544740128755e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7330544740128755e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7330544740128755e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8665272370064378e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8665272370064378e-301Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8665272370064378e-301\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8665272370064378e-301Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8665272370064378e-301\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8665272370064378e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8665272370064378e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8665272370064378e-301\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.332636185032189e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.332636185032189e-302Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.332636185032189e-302Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.332636185032189e-302\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.332636185032189e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.332636185032189e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.332636185032189e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.332636185032189e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6663180925160944e-302Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6663180925160944e-302\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6663180925160944e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6663180925160944e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6663180925160944e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6663180925160944e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6663180925160944e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6663180925160944e-302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3331590462580472e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3331590462580472e-302Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3331590462580472e-302\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3331590462580472e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3331590462580472e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3331590462580472e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3331590462580472e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3331590462580472e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1665795231290236e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1665795231290236e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1665795231290236e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1665795231290236e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1665795231290236e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1665795231290236e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1665795231290236e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1665795231290236e-302\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.832897615645118e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.832897615645118e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.832897615645118e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.832897615645118e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.832897615645118e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.832897615645118e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.832897615645118e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.832897615645118e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.916448807822559e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.916448807822559e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.916448807822559e-303Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.916448807822559e-303\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.916448807822559e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.916448807822559e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.916448807822559e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.916448807822559e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4582244039112795e-303Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4582244039112795e-303\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4582244039112795e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4582244039112795e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4582244039112795e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4582244039112795e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4582244039112795e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4582244039112795e-303\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.291122019556398e-304Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.291122019556398e-304\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.291122019556398e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.291122019556398e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.291122019556398e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.291122019556398e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.291122019556398e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.291122019556398e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.645561009778199e-304Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.645561009778199e-304\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.645561009778199e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.645561009778199e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.645561009778199e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.645561009778199e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.645561009778199e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.645561009778199e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8227805048890994e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8227805048890994e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8227805048890994e-304Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8227805048890994e-304\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8227805048890994e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8227805048890994e-304Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8227805048890994e-304\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8227805048890994e-304\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.113902524445497e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.113902524445497e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.113902524445497e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.113902524445497e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.113902524445497e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.113902524445497e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.113902524445497e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.113902524445497e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5569512622227484e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5569512622227484e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5569512622227484e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5569512622227484e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5569512622227484e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5569512622227484e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5569512622227484e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5569512622227484e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2784756311113742e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2784756311113742e-305Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2784756311113742e-305\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2784756311113742e-305Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2784756311113742e-305\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2784756311113742e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2784756311113742e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2784756311113742e-305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1392378155556871e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1392378155556871e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1392378155556871e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1392378155556871e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1392378155556871e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1392378155556871e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1392378155556871e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1392378155556871e-305\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.696189077778436e-306Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.696189077778436e-306\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.696189077778436e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.696189077778436e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.696189077778436e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.696189077778436e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.696189077778436e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.696189077778436e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.848094538889218e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.848094538889218e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.848094538889218e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.848094538889218e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.848094538889218e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.848094538889218e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.848094538889218e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.848094538889218e-3062020-06-11 10:10:34,166 maskrcnn_benchmark INFO: eta: 12:11:02  iter: 1600  loss: inf (inf)  auxiliary_ctx: 0.3372 (7.2494)  auxiliary_frq: 0.2102 (0.2093)  auxiliary_vis: inf (inf)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: inf (inf)  time: 1.1372 (1.1423)  data: 0.0246 (0.0244)  lr: 0.640000  max mem: 6128\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.424047269444609e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.424047269444609e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.424047269444609e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.424047269444609e-306Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.424047269444609e-306\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.424047269444609e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.424047269444609e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.424047269444609e-306\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.120236347223045e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.120236347223045e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.120236347223045e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.120236347223045e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.120236347223045e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.120236347223045e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.120236347223045e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.120236347223045e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5601181736115222e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5601181736115222e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5601181736115222e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5601181736115222e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5601181736115222e-307Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5601181736115222e-307\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5601181736115222e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5601181736115222e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7800590868057611e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7800590868057611e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7800590868057611e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7800590868057611e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7800590868057611e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7800590868057611e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7800590868057611e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7800590868057611e-307\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.900295434028806e-308Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.900295434028806e-308\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.900295434028806e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.900295434028806e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.900295434028806e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.900295434028806e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.900295434028806e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.900295434028806e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.450147717014403e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.450147717014403e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.450147717014403e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.450147717014403e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.450147717014403e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.450147717014403e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.450147717014403e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.450147717014403e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2250738585072014e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2250738585072014e-308Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2250738585072014e-308\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2250738585072014e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2250738585072014e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2250738585072014e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2250738585072014e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2250738585072014e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1125369292536007e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1125369292536007e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1125369292536007e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1125369292536007e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1125369292536007e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1125369292536007e-308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1125369292536007e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1125369292536007e-308\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.562684646268003e-309Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.562684646268003e-309\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.562684646268003e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.562684646268003e-309Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.562684646268003e-309\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.562684646268003e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.562684646268003e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.562684646268003e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.781342323134e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.781342323134e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.781342323134e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.781342323134e-309Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.781342323134e-309\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.781342323134e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.781342323134e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.781342323134e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.390671161567e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.390671161567e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.390671161567e-309Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.390671161567e-309\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.390671161567e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.390671161567e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.390671161567e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.390671161567e-309\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.953355807835e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.953355807835e-310Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.953355807835e-310Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.953355807835e-310Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.953355807835e-310\n",
      "\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.953355807835e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.953355807835e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.953355807835e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4766779039175e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4766779039175e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4766779039175e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4766779039175e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4766779039175e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4766779039175e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4766779039175e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4766779039175e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.73833895195875e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.73833895195875e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.73833895195875e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.73833895195875e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.73833895195875e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.73833895195875e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.73833895195875e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.73833895195875e-310\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.691694759794e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.691694759794e-311Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.691694759794e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.691694759794e-311\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.691694759794e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.691694759794e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.691694759794e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.691694759794e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.345847379897e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.345847379897e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.345847379897e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.345847379897e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.345847379897e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.345847379897e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.345847379897e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.345847379897e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1729236899484e-311Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1729236899484e-311Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1729236899484e-311\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1729236899484e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1729236899484e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1729236899484e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1729236899484e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1729236899484e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.086461844974e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.086461844974e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.086461844974e-311Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.086461844974e-311\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.086461844974e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.086461844974e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.086461844974e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.086461844974e-311\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.43230922487e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.43230922487e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.43230922487e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.43230922487e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.43230922487e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.43230922487e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.43230922487e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.43230922487e-312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.716154612436e-312Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.716154612436e-312Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.716154612436e-312\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.716154612436e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.716154612436e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.716154612436e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.716154612436e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.716154612436e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.35807730622e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.35807730622e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.35807730622e-312Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.35807730622e-312\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.35807730622e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.35807730622e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.35807730622e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.35807730622e-312\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.7903865311e-313Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.7903865311e-313\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.7903865311e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.7903865311e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.7903865311e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.7903865311e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.7903865311e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.7903865311e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.39519326554e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.39519326554e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.39519326554e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.39519326554e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.39519326554e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.39519326554e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.39519326554e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.39519326554e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.69759663277e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.69759663277e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.69759663277e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.69759663277e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.69759663277e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.69759663277e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.69759663277e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.69759663277e-313\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.487983164e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.487983164e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.487983164e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.487983164e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.487983164e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.487983164e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.487983164e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.487983164e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.243991582e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.243991582e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.243991582e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.243991582e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.243991582e-314Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.243991582e-314\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.243991582e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.243991582e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.121995791e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.121995791e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.121995791e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.121995791e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.121995791e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.121995791e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.121995791e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.121995791e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0609978955e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0609978955e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0609978955e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0609978955e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0609978955e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0609978955e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0609978955e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0609978955e-314\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.304989477e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.304989477e-315Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.304989477e-315\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.304989477e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.304989477e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.304989477e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.304989477e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.304989477e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.65249474e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.65249474e-315Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.65249474e-315\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.65249474e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.65249474e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.65249474e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.65249474e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.65249474e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.32624737e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.32624737e-315Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.32624737e-315Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.32624737e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.32624737e-315\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.32624737e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.32624737e-315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.32624737e-315\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.63123685e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.63123685e-316Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.63123685e-316\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.63123685e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.63123685e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.63123685e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.63123685e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.63123685e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3156184e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3156184e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3156184e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3156184e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3156184e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3156184e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3156184e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3156184e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6578092e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6578092e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6578092e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6578092e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6578092e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6578092e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6578092e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6578092e-316\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.289046e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.289046e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.289046e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.289046e-317Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.289046e-317\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.289046e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.289046e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.289046e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.144523e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.144523e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.144523e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.144523e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.144523e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.144523e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.144523e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.144523e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0722615e-317Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0722615e-317\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0722615e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0722615e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0722615e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0722615e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0722615e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0722615e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.036131e-317Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.036131e-317\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.036131e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.036131e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.036131e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.036131e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.036131e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.036131e-317\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.180654e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.180654e-318Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.180654e-318Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.180654e-318\n",
      "\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.180654e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.180654e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.180654e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.180654e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.590327e-318Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.590327e-318\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.590327e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.590327e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.590327e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.590327e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.590327e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.590327e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.295163e-318Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.295163e-318\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.295163e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.295163e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.295163e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.295163e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.295163e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.295163e-318\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.4758e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.4758e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.4758e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.4758e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.4758e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.4758e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.4758e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.4758e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2379e-319Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2379e-319\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2379e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2379e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2379e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2379e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2379e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2379e-319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.61895e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.61895e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.61895e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.61895e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.61895e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.61895e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.61895e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.61895e-319\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.095e-320Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.095e-320\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.095e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.095e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.095e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.095e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.095e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.095e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0474e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0474e-320Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0474e-320\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0474e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0474e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0474e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0474e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0474e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0237e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0237e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0237e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0237e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0237e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0237e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0237e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0237e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.012e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.012e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.012e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.012e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.012e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.012e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.012e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.012e-320\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.06e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.06e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.06e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.06e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.06e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.06e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.06e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.06e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.53e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.53e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.53e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.53e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.53e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.53e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.53e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.53e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.265e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.265e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.265e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.265e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.265e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.265e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.265e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.265e-321\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.3e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.3e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.3e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.3e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.3e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.3e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.3e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.3e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.16e-322Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.16e-322\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.16e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.16e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.16e-322Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.16e-322\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.16e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.16e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6e-322Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6e-322\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6e-322\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8e-323Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8e-323\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4e-323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2e-323Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2e-323\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1e-323Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1e-323\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1e-323\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5e-324\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5e-324\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5e-324\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5e-324\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5e-324\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5e-324\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5e-324\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5e-324\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "    model = train(cfg, args.local_rank, args.distributed, logger)\n",
      "  File \"tools/relation_train_net.py\", line 160, in train\n",
      "    scaled_losses.backward()\n",
      "  File \"/opt/conda/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
      "    optimizer._post_amp_backward(loss_scaler)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 249, in post_backward_no_master_weights\n",
      "    post_backward_models_are_masters(scaler, params, stashed_grads)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 135, in post_backward_models_are_masters\n",
      "    scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/scaler.py\", line 183, in unscale_with_stashed\n",
      "    out_scale/grads_have_scale,\n",
      "ZeroDivisionError: float division by zero\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "    model = train(cfg, args.local_rank, args.distributed, logger)\n",
      "  File \"tools/relation_train_net.py\", line 160, in train\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "    scaled_losses.backward()\n",
      "  File \"/opt/conda/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
      "    next(self.gen)\n",
      "    model = train(cfg, args.local_rank, args.distributed, logger)  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
      "\n",
      "  File \"tools/relation_train_net.py\", line 160, in train\n",
      "    scaled_losses.backward()\n",
      "    main()  File \"/opt/conda/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
      "\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "    optimizer._post_amp_backward(loss_scaler)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 249, in post_backward_no_master_weights\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
      "        model = train(cfg, args.local_rank, args.distributed, logger)optimizer._post_amp_backward(loss_scaler)\n",
      "\n",
      "  File \"tools/relation_train_net.py\", line 160, in train\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 249, in post_backward_no_master_weights\n",
      "    post_backward_models_are_masters(scaler, params, stashed_grads)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 135, in post_backward_models_are_masters\n",
      "    scaled_losses.backward()\n",
      "  File \"/opt/conda/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
      "    post_backward_models_are_masters(scaler, params, stashed_grads)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 135, in post_backward_models_are_masters\n",
      "scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/scaler.py\", line 183, in unscale_with_stashed\n",
      "Traceback (most recent call last):\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
      "      File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/scaler.py\", line 183, in unscale_with_stashed\n",
      "    optimizer._post_amp_backward(loss_scaler)    \n",
      "out_scale/grads_have_scale,  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 249, in post_backward_no_master_weights\n",
      "\n",
      "    out_scale/grads_have_scale,\n",
      "ZeroDivisionErrorZeroDivisionError: float division by zero: \n",
      "float division by zero\n",
      "    post_backward_models_are_masters(scaler, params, stashed_grads)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 135, in post_backward_models_are_masters\n",
      "    scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/scaler.py\", line 183, in unscale_with_stashed\n",
      "    out_scale/grads_have_scale,\n",
      "ZeroDivisionError: float division by zero\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "    model = train(cfg, args.local_rank, args.distributed, logger)\n",
      "  File \"tools/relation_train_net.py\", line 160, in train\n",
      "    scaled_losses.backward()\n",
      "  File \"/opt/conda/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
      "    optimizer._post_amp_backward(loss_scaler)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 249, in post_backward_no_master_weights\n",
      "    post_backward_models_are_masters(scaler, params, stashed_grads)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 135, in post_backward_models_are_masters\n",
      "    scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/scaler.py\", line 183, in unscale_with_stashed\n",
      "    out_scale/grads_have_scale,\n",
      "ZeroDivisionError: float division by zero\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "    model = train(cfg, args.local_rank, args.distributed, logger)\n",
      "  File \"tools/relation_train_net.py\", line 160, in train\n",
      "    scaled_losses.backward()\n",
      "  File \"/opt/conda/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
      "    optimizer._post_amp_backward(loss_scaler)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 249, in post_backward_no_master_weights\n",
      "    post_backward_models_are_masters(scaler, params, stashed_grads)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 135, in post_backward_models_are_masters\n",
      "    scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/scaler.py\", line 183, in unscale_with_stashed\n",
      "    out_scale/grads_have_scale,\n",
      "ZeroDivisionError: float division by zero\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "    model = train(cfg, args.local_rank, args.distributed, logger)\n",
      "  File \"tools/relation_train_net.py\", line 160, in train\n",
      "    scaled_losses.backward()\n",
      "  File \"/opt/conda/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
      "    optimizer._post_amp_backward(loss_scaler)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 249, in post_backward_no_master_weights\n",
      "    post_backward_models_are_masters(scaler, params, stashed_grads)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 135, in post_backward_models_are_masters\n",
      "    scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/scaler.py\", line 183, in unscale_with_stashed\n",
      "    out_scale/grads_have_scale,\n",
      "ZeroDivisionError: float division by zero\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/relation_train_net.py\", line 379, in <module>\n",
      "    main()\n",
      "  File \"tools/relation_train_net.py\", line 372, in main\n",
      "    model = train(cfg, args.local_rank, args.distributed, logger)\n",
      "  File \"tools/relation_train_net.py\", line 160, in train\n",
      "    scaled_losses.backward()\n",
      "  File \"/opt/conda/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
      "    optimizer._post_amp_backward(loss_scaler)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 249, in post_backward_no_master_weights\n",
      "    post_backward_models_are_masters(scaler, params, stashed_grads)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 135, in post_backward_models_are_masters\n",
      "    scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/scaler.py\", line 183, in unscale_with_stashed\n",
      "    out_scale/grads_have_scale,\n",
      "ZeroDivisionError: float division by zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n",
      "    \"__main__\", mod_spec)\r\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py\", line 263, in <module>\r\n",
      "    main()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py\", line 259, in main\r\n",
      "    cmd=cmd)\r\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'tools/relation_train_net.py', '--local_rank=7', '--config-file', 'configs/e2e_relation_X_101_32_8_FPN_1x.yaml', 'MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'dist', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-dist1-TDE']' returned non-zero exit status 1.\r\n"
     ]
    }
   ],
   "source": [
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10025 --nproc_per_node=8 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE dist \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE \\\n",
    "SOLVER.IMS_PER_BATCH 64 TEST.IMS_PER_BATCH 8 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 40000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/precls-CausalAnalysisPredictor-motifs-dist1-TDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T20:49:08.072757Z",
     "start_time": "2020-06-11T12:06:22.769725Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2020-06-11 12:06:39,211 maskrcnn_benchmark INFO: Using 8 GPUs\n",
      "2020-06-11 12:06:39,211 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'dist', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'TDE', 'SOLVER.IMS_PER_BATCH', '64', 'TEST.IMS_PER_BATCH', '8', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '40000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', 'glove/', 'MODEL.PRETRAINED_DETECTOR_CKPT', 'checkpoint/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', 'checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE'], skip_test=False)\n",
      "2020-06-11 12:06:39,211 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2020-06-11 12:06:44,426 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce RTX 2080 Ti\n",
      "GPU 1: GeForce RTX 2080 Ti\n",
      "GPU 2: GeForce RTX 2080 Ti\n",
      "GPU 3: GeForce RTX 2080 Ti\n",
      "GPU 4: GeForce RTX 2080 Ti\n",
      "GPU 5: GeForce RTX 2080 Ti\n",
      "GPU 6: GeForce RTX 2080 Ti\n",
      "GPU 7: GeForce RTX 2080 Ti\n",
      "\n",
      "Nvidia driver version: 418.67\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n",
      "        Pillow (7.1.2)\n",
      "2020-06-11 12:06:44,426 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml\n",
      "2020-06-11 12:06:44,427 maskrcnn_benchmark INFO: \n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MAX_SIZE_TEST: 1000\n",
      "MODEL:\n",
      "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
      "  WEIGHT: \"catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\"\n",
      "  BACKBONE:\n",
      "    CONV_BODY: \"R-101-FPN\" # VGG-16\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    STRIDE_IN_1X1: False\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RELATION_ON: True\n",
      "  ATTRIBUTE_ON: False\n",
      "  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false\n",
      "  RPN:\n",
      "    USE_FPN: True\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    RPN_MID_CHANNEL: 256\n",
      "  ROI_HEADS:\n",
      "    USE_FPN: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "  ROI_BOX_HEAD:\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA\n",
      "    MLP_HEAD_DIM: 4096\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
      "    PREDICTOR: \"FPNPredictor\"\n",
      "    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight\n",
      "    POS_WEIGHT: 50.0\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA\n",
      "    MAX_ATTRIBUTES: 10             \n",
      "    ATTRIBUTE_BGFG_SAMPLE: True    \n",
      "    ATTRIBUTE_BGFG_RATIO: 3        \n",
      "  ROI_RELATION_HEAD:\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing\n",
      "    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain \"to the left of\" & \"to the right of\")\n",
      "    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    FEATURE_EXTRACTOR: \"RelationFeatureExtractor\"\n",
      "    #################### Select Relationship Model ####################\n",
      "    #PREDICTOR: \"MotifPredictor\"\n",
      "    #PREDICTOR: \"VCTreePredictor\"\n",
      "    #PREDICTOR: \"TransformerPredictor\"\n",
      "    PREDICTOR: \"CausalAnalysisPredictor\"\n",
      "    ################# Parameters for Motif Predictor ##################\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    ############# Parameters for Causal Unbias Predictor ##############\n",
      "    ### Implementation for paper \"Unbiased Scene Graph Generation from Biased Training\"\n",
      "    CAUSAL:\n",
      "      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'\n",
      "      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate', 'dist'\n",
      "      SEPARATE_SPATIAL: False         # separate spatial in union feature\n",
      "      CONTEXT_LAYER: \"motifs\"         # candicates: motifs, vctree, vtranse\n",
      "      SPATIAL_FOR_VISION: True\n",
      "      EFFECT_ANALYSIS: True\n",
      "    ############### Parameters for Transformer Predictor ##############\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      NUM_HEAD: 8\n",
      "      KEY_DIM: 64\n",
      "      VAL_DIM: 64\n",
      "      INNER_DIM: 2048 \n",
      "DATASETS:\n",
      "  TRAIN: (\"VG_stanford_filtered_with_attribute_train\",)\n",
      "  VAL: (\"VG_stanford_filtered_with_attribute_val\",)\n",
      "  TEST: (\"VG_stanford_filtered_with_attribute_test\",)\n",
      "DATALOADER:\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "SOLVER:\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  BASE_LR: 0.01\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  MOMENTUM: 0.9\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  STEPS: (10000, 16000)\n",
      "  MAX_ITER: 40000\n",
      "  VAL_PERIOD: 2000\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    # the following paramters are only used for WarmupReduceLROnPlateau\n",
      "    TYPE: \"WarmupReduceLROnPlateau\"    # WarmupMultiStepLR, WarmupReduceLROnPlateau\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "OUTPUT_DIR: './output/relation_baseline'\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  RELATION:\n",
      "    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem\n",
      "    REQUIRE_OVERLAP: False\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "\n",
      "2020-06-11 12:06:44,429 maskrcnn_benchmark INFO: Running with config:\n",
      "AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: glove/\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: TDE\n",
      "      FUSION_TYPE: dist\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: True\n",
      "    USE_GT_OBJECT_LABEL: True\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE\n",
      "PATHS_CATALOG: /root/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /root/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 64\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 8\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2020-06-11 12:06:44,430 maskrcnn_benchmark INFO: Saving config into: checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/config.yml\n",
      "2020-06-11 12:06:44,463 maskrcnn_benchmark INFO: #################### prepare training ####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-11 12:06:47,738 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2020-06-11 12:06:47,738 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7116.21it/s]\n",
      " 93%|████████████████████████████████▋  | 52420/56224 [00:07<00:00, 6291.90it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 97%|█████████████████████████████████▊ | 54369/56224 [00:07<00:00, 6445.00it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7101.16it/s]\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7194.06it/s]\n",
      " 40%|██████████████                     | 22593/56224 [00:03<00:04, 7518.16it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 97%|██████████████████████████████████ | 54649/56224 [00:07<00:00, 5804.24it/s]2020-06-11 12:07:15,050 maskrcnn_benchmark.data.build INFO: finish\n",
      "2020-06-11 12:07:15,050 maskrcnn_benchmark.data.build INFO: Save data statistics to: checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2020-06-11 12:07:15,050 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      " 42%|██████████████▌                    | 23346/56224 [00:03<00:04, 7517.99it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:07<00:00, 7216.19it/s]\n",
      " 44%|███████████████▍                   | 24870/56224 [00:03<00:04, 7523.57it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6809.36it/s]\n",
      " 97%|█████████████████████████████████▉ | 54469/56224 [00:07<00:00, 6189.06it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 90%|███████████████████████████████▍   | 50555/56224 [00:08<00:01, 4918.29it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      " 47%|████████████████▍                  | 26380/56224 [00:03<00:03, 7517.18it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 99%|██████████████████████████████████▋| 55688/56224 [00:08<00:00, 5873.22it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6783.43it/s]\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      " 93%|████████████████████████████████▍  | 52061/56224 [00:08<00:00, 4842.47it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 51%|█████████████████▊                 | 28602/56224 [00:04<00:04, 6652.56it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 93%|████████████████████████████████▋  | 52546/56224 [00:08<00:00, 4750.56it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      " 94%|█████████████████████████████████  | 53036/56224 [00:08<00:00, 4793.31it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 54%|███████████████████                | 30553/56224 [00:04<00:04, 6105.22it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      " 55%|███████████████████▍               | 31170/56224 [00:04<00:04, 6040.99it/s]2020-06-11 12:07:16,326 maskrcnn_benchmark INFO: #################### end model construction ####################\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "100%|███████████████████████████████████| 56224/56224 [00:09<00:00, 6093.44it/s]\n",
      " 59%|████████████████████▌              | 32952/56224 [00:04<00:04, 5762.66it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 60%|████████████████████▊              | 33531/56224 [00:04<00:03, 5739.32it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 62%|█████████████████████▌             | 34728/56224 [00:05<00:03, 5864.55it/s]2020-06-11 12:07:16,992 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "2020-06-11 12:07:17,021 maskrcnn_benchmark INFO: #################### end distributed ####################\n",
      "2020-06-11 12:07:17,022 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from checkpoint/pretrained_faster_rcnn/model_final.pth\n",
      " 64%|██████████████████████▍            | 35953/56224 [00:05<00:03, 5984.19it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 65%|██████████████████████▊            | 36577/56224 [00:05<00:03, 6056.67it/s]loading word vectors from glove/glove.6B.200d.pt\n",
      " 69%|████████████████████████▎          | 39023/56224 [00:05<00:02, 5963.76it/s]__background__ -> __background__ \n",
      "fail on __background__\n",
      " 70%|████████████████████████▋          | 39624/56224 [00:05<00:02, 5976.04it/s]2020-06-11 12:07:17,806 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.\n",
      "2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.\n",
      "2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.\n",
      "2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.\n",
      "2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.\n",
      "2020-06-11 12:07:17,807 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████          | 40228/56224 [00:06<00:02, 5989.64it/s]2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\n",
      "2020-06-11 12:07:17,871 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)\n",
      "2020-06-11 12:07:17,872 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)\n",
      "2020-06-11 12:07:17,873 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)\n",
      "2020-06-11 12:07:17,874 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 56224/56224 [00:08<00:00, 6306.72it/s]\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-11 12:07:23,440 maskrcnn_benchmark INFO: #################### end load checkpointer ####################\n",
      "2020-06-11 12:07:23,440 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2020-06-11 12:07:26,144 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/labels.json\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 12:07:27,376 maskrcnn_benchmark INFO: #################### end dataloader ####################\n",
      "2020-06-11 12:07:27,376 maskrcnn_benchmark INFO: Validate before training\n",
      "2020-06-11 12:07:27,385 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.62it/s]\n",
      "\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "2020-06-11 12:09:01,796 maskrcnn_benchmark INFO: Total run time: 0:01:34.410239 (0.1510563823699951 s / img per device, on 8 devices)\n",
      "2020-06-11 12:09:01,796 maskrcnn_benchmark INFO: Model inference time: 0:01:12.328440 (0.11572550468444824 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 12:10:10,087 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.0091;   R @ 50: 0.0125;   R @ 100: 0.0148;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.0147; ngR @ 50: 0.0313; ngR @ 100: 0.0582;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0044;  zR @ 50: 0.0044;  zR @ 100: 0.0044;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.0134;  mR @ 50: 0.0164;  mR @ 100: 0.0216;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.0526) (across:0.0556) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1667) (attached to:0.0000) (behind:0.1286) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0714) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.0000) (holding:0.0178) (in:0.0005) (in front of:0.0000) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0145) (near:0.0087) (of:0.0016) (on:0.0086) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0079) (part of:0.0444) (playing:0.0000) (riding:0.0045) (says:0.0000) (sitting on:0.0933) (standing on:0.0000) (to:0.0833) (under:0.2134) (using:0.0192) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.0017) (wears:0.0044) (with:0.0110) \n",
      "SGG eval:   A @ 20: 0.0135;   A @ 50: 0.0135;   A @ 100: 0.0135;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 12:10:10,854 maskrcnn_benchmark INFO: Start training\n",
      "2020-06-11 12:10:12,991 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------\n",
      "2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: inf, (torch.Size([51]))\n",
      "2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: inf, (torch.Size([51, 4096]))\n",
      "2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 75856.36719, (torch.Size([4096, 512]))\n",
      "2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 62804.63281, (torch.Size([51]))\n",
      "2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 24718.42773, (torch.Size([4096]))\n",
      "2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 23484.37891, (torch.Size([512, 32]))\n",
      "2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 7341.17041, (torch.Size([512]))\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 773.82178, (torch.Size([22801, 51]))\n",
      "2020-06-11 12:10:13,001 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 19.48577, (torch.Size([4096, 4096]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 18.34809, (torch.Size([4096, 12544]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 3.66618, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.74206, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 1.24670, (torch.Size([51, 4096]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.70901, (torch.Size([512, 1024]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.70414, (torch.Size([4096, 1024]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.58350, (torch.Size([4096, 4096]))\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.40628, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.36159, (torch.Size([2048, 4808]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.34821, (torch.Size([2048, 4808]))\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.27938, (torch.Size([4096, 12544]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.27581, (torch.Size([512]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.22798, (torch.Size([4096]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.16336, (torch.Size([256]))\n",
      "2020-06-11 12:10:13,002 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.09734, (torch.Size([4096]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.08560, (torch.Size([256]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.07801, (torch.Size([128]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.07708, (torch.Size([512, 1024]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.06171, (torch.Size([2048, 512]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.05970, (torch.Size([2048, 512]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.04464, (torch.Size([4096]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.03948, (torch.Size([2048, 4424]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.03729, (torch.Size([2048]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.03729, (torch.Size([2048]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.03596, (torch.Size([2048]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.03596, (torch.Size([2048]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.03585, (torch.Size([2048, 4424]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.03340, (torch.Size([128]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.03339, (torch.Size([256]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.03104, (torch.Size([128]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.02973, (torch.Size([256]))\n",
      "2020-06-11 12:10:13,003 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.02953, (torch.Size([512]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02947, (torch.Size([1024, 512]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.02745, (torch.Size([1024]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01582, (torch.Size([4096]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00651, (torch.Size([2048, 512]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00615, (torch.Size([2048, 512]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00392, (torch.Size([2048]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00392, (torch.Size([2048]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00363, (torch.Size([4096]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00355, (torch.Size([2048]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00355, (torch.Size([2048]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00275, (torch.Size([151, 200]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00202, (torch.Size([128, 32]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00133, (torch.Size([32, 9]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00084, (torch.Size([128]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00052, (torch.Size([32]))\n",
      "2020-06-11 12:10:13,004 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00031, (torch.Size([151, 200]))\n",
      "2020-06-11 12:10:13,005 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00019, (torch.Size([32]))\n",
      "2020-06-11 12:10:13,005 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 12:10:13,005 maskrcnn_benchmark INFO: -------------------------------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-06-11 12:14:02,701 maskrcnn_benchmark INFO: eta: 12:48:57  iter: 200  loss: 2.7360 (3.2315)  auxiliary_ctx: 0.2188 (0.4506)  auxiliary_frq: 0.2050 (0.2088)  auxiliary_vis: 0.1915 (0.3114)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1337 (2.2606)  time: 1.1488 (1.1592)  data: 0.0258 (0.0297)  lr: 0.293248  max mem: 6059\n",
      "2020-06-11 12:17:53,730 maskrcnn_benchmark INFO: eta: 12:43:44  iter: 400  loss: 2.7367 (2.9893)  auxiliary_ctx: 0.2014 (0.3341)  auxiliary_frq: 0.2056 (0.2079)  auxiliary_vis: 0.1812 (0.2491)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1353 (2.1981)  time: 1.1625 (1.1572)  data: 0.0262 (0.0276)  lr: 0.523648  max mem: 6059\n",
      "2020-06-11 12:21:44,230 maskrcnn_benchmark INFO: eta: 12:38:51  iter: 600  loss: 2.6536 (2.8927)  auxiliary_ctx: 0.1730 (0.2873)  auxiliary_frq: 0.2004 (0.2070)  auxiliary_vis: 0.1653 (0.2254)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1136 (2.1730)  time: 1.1487 (1.1556)  data: 0.0268 (0.0268)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 12:25:35,060 maskrcnn_benchmark INFO: eta: 12:34:46  iter: 800  loss: 2.6744 (2.8401)  auxiliary_ctx: 0.1816 (0.2619)  auxiliary_frq: 0.2061 (0.2060)  auxiliary_vis: 0.1757 (0.2126)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1182 (2.1596)  time: 1.1477 (1.1553)  data: 0.0262 (0.0266)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 12:29:25,555 maskrcnn_benchmark INFO: eta: 12:30:33  iter: 1000  loss: 2.6534 (2.8060)  auxiliary_ctx: 0.1778 (0.2457)  auxiliary_frq: 0.1967 (0.2051)  auxiliary_vis: 0.1613 (0.2041)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1118 (2.1511)  time: 1.1450 (1.1547)  data: 0.0273 (0.0265)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 12:33:16,521 maskrcnn_benchmark INFO: eta: 12:26:43  iter: 1200  loss: 2.6344 (2.7805)  auxiliary_ctx: 0.1596 (0.2336)  auxiliary_frq: 0.1955 (0.2042)  auxiliary_vis: 0.1592 (0.1978)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1094 (2.1448)  time: 1.1593 (1.1547)  data: 0.0254 (0.0264)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 12:37:07,412 maskrcnn_benchmark INFO: eta: 12:22:50  iter: 1400  loss: 2.6578 (2.7605)  auxiliary_ctx: 0.1655 (0.2244)  auxiliary_frq: 0.1997 (0.2032)  auxiliary_vis: 0.1650 (0.1928)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1128 (2.1401)  time: 1.1432 (1.1547)  data: 0.0260 (0.0264)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 12:40:57,629 maskrcnn_benchmark INFO: eta: 12:18:42  iter: 1600  loss: 2.6454 (2.7462)  auxiliary_ctx: 0.1685 (0.2177)  auxiliary_frq: 0.1961 (0.2025)  auxiliary_vis: 0.1615 (0.1892)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1112 (2.1368)  time: 1.1508 (1.1542)  data: 0.0267 (0.0262)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 12:44:48,013 maskrcnn_benchmark INFO: eta: 12:14:41  iter: 1800  loss: 2.6420 (2.7347)  auxiliary_ctx: 0.1668 (0.2124)  auxiliary_frq: 0.1967 (0.2019)  auxiliary_vis: 0.1664 (0.1864)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1133 (2.1340)  time: 1.1473 (1.1540)  data: 0.0260 (0.0262)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 12:48:38,293 maskrcnn_benchmark INFO: eta: 12:10:41  iter: 2000  loss: 2.6401 (2.7253)  auxiliary_ctx: 0.1730 (0.2081)  auxiliary_frq: 0.1933 (0.2013)  auxiliary_vis: 0.1670 (0.1840)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1095 (2.1319)  time: 1.1596 (1.1537)  data: 0.0273 (0.0262)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 12:48:38,296 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0002000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 12:48:40,868 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 12:48:40,884 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.59it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.59it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.59it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.77it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.59it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.59it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.59it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.59it/s]\n",
      "2020-06-11 12:50:13,253 maskrcnn_benchmark INFO: Total run time: 0:01:32.368775 (0.1477900405883789 s / img per device, on 8 devices)\n",
      "2020-06-11 12:50:13,254 maskrcnn_benchmark INFO: Model inference time: 0:01:12.632277 (0.1162116439819336 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.47s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.33s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 12:51:48,976 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.2884;   R @ 50: 0.3548;   R @ 100: 0.3768;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.3983; ngR @ 50: 0.6042; ngR @ 100: 0.7504;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.1067;  zR @ 50: 0.1563;  zR @ 100: 0.1711;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1438;  mR @ 50: 0.1800;  mR @ 100: 0.1945;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.5120) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2212) (attached to:0.0092) (behind:0.4655) (belonging to:0.0286) (between:0.0000) (carrying:0.1140) (covered in:0.0714) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0221) (has:0.5945) (holding:0.6073) (in:0.4204) (in front of:0.4279) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3406) (of:0.7042) (on:0.1990) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.9075) (part of:0.0000) (playing:0.0000) (riding:0.9062) (says:0.0000) (sitting on:0.3777) (standing on:0.0688) (to:0.0000) (under:0.1276) (using:0.0000) (walking in:0.0000) (walking on:0.9386) (watching:0.3333) (wearing:0.9759) (wears:0.0088) (with:0.3423) \n",
      "SGG eval:   A @ 20: 0.3840;   A @ 50: 0.3870;   A @ 100: 0.3870;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-11 12:51:49,763 maskrcnn_benchmark INFO: Validation Result: 0.3768\n",
      "2020-06-11 12:55:40,212 maskrcnn_benchmark INFO: eta: 13:01:35  iter: 2200  loss: 2.6416 (2.7166)  auxiliary_ctx: 0.1719 (0.2042)  auxiliary_frq: 0.1955 (0.2007)  auxiliary_vis: 0.1623 (0.1818)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1094 (2.1300)  time: 1.1467 (1.2406)  data: 0.0258 (0.1131)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 12:59:30,789 maskrcnn_benchmark INFO: eta: 12:52:52  iter: 2400  loss: 2.6260 (2.7090)  auxiliary_ctx: 0.1682 (0.2009)  auxiliary_frq: 0.1941 (0.2000)  auxiliary_vis: 0.1604 (0.1799)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1104 (2.1283)  time: 1.1495 (1.2333)  data: 0.0259 (0.1057)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:03:21,876 maskrcnn_benchmark INFO: eta: 12:45:01  iter: 2600  loss: 2.6151 (2.7028)  auxiliary_ctx: 0.1637 (0.1981)  auxiliary_frq: 0.1893 (0.1994)  auxiliary_vis: 0.1564 (0.1783)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1094 (2.1270)  time: 1.1475 (1.2273)  data: 0.0280 (0.0996)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:07:12,610 maskrcnn_benchmark INFO: eta: 12:37:40  iter: 2800  loss: 2.6230 (2.6971)  auxiliary_ctx: 0.1597 (0.1957)  auxiliary_frq: 0.1940 (0.1988)  auxiliary_vis: 0.1587 (0.1768)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1105 (2.1258)  time: 1.1495 (1.2221)  data: 0.0279 (0.0944)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:11:03,489 maskrcnn_benchmark INFO: eta: 12:30:49  iter: 3000  loss: 2.6262 (2.6920)  auxiliary_ctx: 0.1651 (0.1935)  auxiliary_frq: 0.1897 (0.1982)  auxiliary_vis: 0.1545 (0.1755)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1106 (2.1248)  time: 1.1457 (1.2175)  data: 0.0263 (0.0899)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:14:54,213 maskrcnn_benchmark INFO: eta: 12:24:18  iter: 3200  loss: 2.6246 (2.6875)  auxiliary_ctx: 0.1626 (0.1916)  auxiliary_frq: 0.1930 (0.1978)  auxiliary_vis: 0.1595 (0.1744)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1091 (2.1238)  time: 1.1475 (1.2135)  data: 0.0262 (0.0859)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:18:45,068 maskrcnn_benchmark INFO: eta: 12:18:08  iter: 3400  loss: 2.6271 (2.6837)  auxiliary_ctx: 0.1660 (0.1900)  auxiliary_frq: 0.1915 (0.1973)  auxiliary_vis: 0.1547 (0.1734)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1068 (2.1231)  time: 1.1485 (1.2101)  data: 0.0260 (0.0824)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:22:35,414 maskrcnn_benchmark INFO: eta: 12:12:08  iter: 3600  loss: 2.6362 (2.6803)  auxiliary_ctx: 0.1686 (0.1886)  auxiliary_frq: 0.1891 (0.1968)  auxiliary_vis: 0.1597 (0.1725)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1110 (2.1224)  time: 1.1497 (1.2068)  data: 0.0261 (0.0792)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:26:25,704 maskrcnn_benchmark INFO: eta: 12:06:21  iter: 3800  loss: 2.5847 (2.6771)  auxiliary_ctx: 0.1568 (0.1873)  auxiliary_frq: 0.1817 (0.1964)  auxiliary_vis: 0.1460 (0.1717)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1060 (2.1217)  time: 1.1446 (1.2039)  data: 0.0265 (0.0763)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:30:16,377 maskrcnn_benchmark INFO: ---Total norm 0.22674 clip coef 22.05139-----------------\n",
      "2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.13920, (torch.Size([51, 4096]))\n",
      "2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.08823, (torch.Size([4096, 12544]))\n",
      "2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06597, (torch.Size([4096, 4096]))\n",
      "2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.06126, (torch.Size([4096, 12544]))\n",
      "2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.05402, (torch.Size([51, 4096]))\n",
      "2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.04933, (torch.Size([4096, 1024]))\n",
      "2020-06-11 13:30:16,387 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.04232, (torch.Size([2048, 4808]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03978, (torch.Size([2048, 4808]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.03862, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03561, (torch.Size([512, 1024]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03127, (torch.Size([4096, 4096]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02780, (torch.Size([512, 32]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02702, (torch.Size([1024, 512]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02070, (torch.Size([4096, 512]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01897, (torch.Size([51]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01658, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01489, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01308, (torch.Size([512]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01065, (torch.Size([51]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00848, (torch.Size([1024]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00827, (torch.Size([151, 200]))\n",
      "2020-06-11 13:30:16,388 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00796, (torch.Size([4096]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00769, (torch.Size([2048, 512]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00757, (torch.Size([512]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00720, (torch.Size([4096]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00688, (torch.Size([2048, 512]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00578, (torch.Size([256]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00424, (torch.Size([128]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00410, (torch.Size([2048]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00410, (torch.Size([2048]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00402, (torch.Size([4096]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00400, (torch.Size([2048]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00400, (torch.Size([2048]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00367, (torch.Size([22801, 51]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00304, (torch.Size([512, 1024]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00248, (torch.Size([128]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00218, (torch.Size([2048, 4424]))\n",
      "2020-06-11 13:30:16,389 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00213, (torch.Size([2048, 4424]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00203, (torch.Size([256]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00199, (torch.Size([128]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00192, (torch.Size([256]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00178, (torch.Size([4096]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00174, (torch.Size([512]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00115, (torch.Size([4096]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00052, (torch.Size([4096]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00049, (torch.Size([2048, 512]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00044, (torch.Size([2048, 512]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00043, (torch.Size([2048]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00043, (torch.Size([2048]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00040, (torch.Size([256]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00039, (torch.Size([2048]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00039, (torch.Size([2048]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00010, (torch.Size([128]))\n",
      "2020-06-11 13:30:16,390 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00002, (torch.Size([151, 200]))\n",
      "2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))\n",
      "2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))\n",
      "2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00001, (torch.Size([32]))\n",
      "2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 13:30:16,391 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-11 13:30:16,394 maskrcnn_benchmark INFO: eta: 12:00:49  iter: 4000  loss: 2.6398 (2.6742)  auxiliary_ctx: 0.1710 (0.1861)  auxiliary_frq: 0.1935 (0.1960)  auxiliary_vis: 0.1629 (0.1709)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1124 (2.1211)  time: 1.1496 (1.2014)  data: 0.0278 (0.0738)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:30:16,396 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0004000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 13:30:18,995 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 13:30:19,021 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.92it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.73it/s]\n",
      "2020-06-11 13:31:49,352 maskrcnn_benchmark INFO: Total run time: 0:01:30.330572 (0.14452891578674315 s / img per device, on 8 devices)\n",
      "2020-06-11 13:31:49,353 maskrcnn_benchmark INFO: Model inference time: 0:01:11.800131 (0.11488020896911622 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.23s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 13:33:31,216 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.3868;   R @ 50: 0.4669;   R @ 100: 0.4890;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.5406; ngR @ 50: 0.7561; ngR @ 100: 0.8450;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0844;  zR @ 50: 0.1733;  zR @ 100: 0.1859;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1447;  mR @ 50: 0.1720;  mR @ 100: 0.1810;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.3630) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.4182) (attached to:0.0092) (behind:0.4736) (belonging to:0.0000) (between:0.0000) (carrying:0.3816) (covered in:0.0000) (covering:0.0000) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.6650) (holding:0.5558) (in:0.4409) (in front of:0.1302) (laying on:0.0000) (looking at:0.0217) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4220) (of:0.5800) (on:0.4929) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.8839) (says:0.0000) (sitting on:0.3184) (standing on:0.0072) (to:0.0000) (under:0.1403) (using:0.0000) (walking in:0.0000) (walking on:0.5253) (watching:0.3235) (wearing:0.9636) (wears:0.0000) (with:0.2031) \n",
      "SGG eval:   A @ 20: 0.5180;   A @ 50: 0.5224;   A @ 100: 0.5224;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 13:33:31,992 maskrcnn_benchmark INFO: Validation Result: 0.4890\n",
      "2020-06-11 13:37:22,444 maskrcnn_benchmark INFO: eta: 12:23:13  iter: 4200  loss: 2.6320 (2.6716)  auxiliary_ctx: 0.1669 (0.1851)  auxiliary_frq: 0.1905 (0.1956)  auxiliary_vis: 0.1640 (0.1702)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1112 (2.1207)  time: 1.1412 (1.2456)  data: 0.0278 (0.1181)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:41:13,830 maskrcnn_benchmark INFO: eta: 12:16:40  iter: 4400  loss: 2.5950 (2.6692)  auxiliary_ctx: 0.1587 (0.1841)  auxiliary_frq: 0.1829 (0.1953)  auxiliary_vis: 0.1486 (0.1696)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1071 (2.1202)  time: 1.1472 (1.2416)  data: 0.0266 (0.1140)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:45:04,575 maskrcnn_benchmark INFO: eta: 12:10:16  iter: 4600  loss: 2.6381 (2.6674)  auxiliary_ctx: 0.1703 (0.1835)  auxiliary_frq: 0.1925 (0.1950)  auxiliary_vis: 0.1601 (0.1692)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1129 (2.1198)  time: 1.1570 (1.2378)  data: 0.0215 (0.1100)  lr: 0.640000  max mem: 6119\n",
      "2020-06-11 13:48:55,474 maskrcnn_benchmark INFO: eta: 12:04:07  iter: 4800  loss: 2.5947 (2.6650)  auxiliary_ctx: 0.1560 (0.1825)  auxiliary_frq: 0.1844 (0.1945)  auxiliary_vis: 0.1476 (0.1685)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1067 (2.1194)  time: 1.1567 (1.2343)  data: 0.0278 (0.1066)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 13:52:46,492 maskrcnn_benchmark INFO: eta: 11:58:09  iter: 5000  loss: 2.6203 (2.6628)  auxiliary_ctx: 0.1588 (0.1817)  auxiliary_frq: 0.1852 (0.1942)  auxiliary_vis: 0.1557 (0.1679)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1091 (2.1190)  time: 1.1526 (1.2311)  data: 0.0260 (0.1033)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 13:56:36,780 maskrcnn_benchmark INFO: eta: 11:52:16  iter: 5200  loss: 2.5950 (2.6610)  auxiliary_ctx: 0.1526 (0.1810)  auxiliary_frq: 0.1804 (0.1939)  auxiliary_vis: 0.1511 (0.1674)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1064 (2.1187)  time: 1.1414 (1.2281)  data: 0.0269 (0.1003)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:00:27,197 maskrcnn_benchmark INFO: eta: 11:46:33  iter: 5400  loss: 2.5873 (2.6591)  auxiliary_ctx: 0.1569 (0.1803)  auxiliary_frq: 0.1798 (0.1936)  auxiliary_vis: 0.1468 (0.1670)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1077 (2.1183)  time: 1.1388 (1.2252)  data: 0.0269 (0.0976)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:04:17,609 maskrcnn_benchmark INFO: eta: 11:40:58  iter: 5600  loss: 2.6053 (2.6573)  auxiliary_ctx: 0.1558 (0.1796)  auxiliary_frq: 0.1865 (0.1932)  auxiliary_vis: 0.1517 (0.1664)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1093 (2.1180)  time: 1.1500 (1.2226)  data: 0.0269 (0.0950)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:08:08,325 maskrcnn_benchmark INFO: eta: 11:35:32  iter: 5800  loss: 2.6035 (2.6557)  auxiliary_ctx: 0.1577 (0.1790)  auxiliary_frq: 0.1816 (0.1929)  auxiliary_vis: 0.1508 (0.1660)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1070 (2.1177)  time: 1.1552 (1.2203)  data: 0.0276 (0.0926)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:11:58,964 maskrcnn_benchmark INFO: eta: 11:30:12  iter: 6000  loss: 2.5881 (2.6542)  auxiliary_ctx: 0.1516 (0.1784)  auxiliary_frq: 0.1805 (0.1927)  auxiliary_vis: 0.1490 (0.1656)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1071 (2.1174)  time: 1.1547 (1.2180)  data: 0.0275 (0.0904)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:11:58,967 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0006000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 14:12:01,526 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 14:12:01,549 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.64it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.81it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-11 14:13:33,323 maskrcnn_benchmark INFO: Total run time: 0:01:31.773652 (0.14683784255981444 s / img per device, on 8 devices)\n",
      "2020-06-11 14:13:33,324 maskrcnn_benchmark INFO: Model inference time: 0:01:11.819916 (0.11491186561584472 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 14:15:16,017 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.4293;   R @ 50: 0.5171;   R @ 100: 0.5378;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.5877; ngR @ 50: 0.7765; ngR @ 100: 0.8485;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0711;  zR @ 50: 0.1756;  zR @ 100: 0.1815;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1286;  mR @ 50: 0.1629;  mR @ 100: 0.1733;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.3636) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1928) (attached to:0.0000) (behind:0.4635) (belonging to:0.0000) (between:0.0000) (carrying:0.2763) (covered in:0.0000) (covering:0.0000) (eating:0.5238) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.6784) (holding:0.5831) (in:0.4361) (in front of:0.1578) (laying on:0.0000) (looking at:0.1087) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4162) (of:0.5709) (on:0.6026) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0587) (part of:0.0000) (playing:0.0000) (riding:0.7009) (says:0.0000) (sitting on:0.2841) (standing on:0.0145) (to:0.0000) (under:0.1820) (using:0.0385) (walking in:0.0000) (walking on:0.3993) (watching:0.4118) (wearing:0.9665) (wears:0.0000) (with:0.2186) \n",
      "SGG eval:   A @ 20: 0.5872;   A @ 50: 0.5925;   A @ 100: 0.5925;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 14:15:16,790 maskrcnn_benchmark INFO: Validation Result: 0.5378\n",
      "2020-06-11 14:19:07,453 maskrcnn_benchmark INFO: eta: 11:42:56  iter: 6200  loss: 2.5938 (2.6528)  auxiliary_ctx: 0.1550 (0.1779)  auxiliary_frq: 0.1807 (0.1924)  auxiliary_vis: 0.1510 (0.1653)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1073 (2.1172)  time: 1.1474 (1.2478)  data: 0.0272 (0.1203)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:22:58,122 maskrcnn_benchmark INFO: eta: 11:37:08  iter: 6400  loss: 2.6008 (2.6514)  auxiliary_ctx: 0.1582 (0.1774)  auxiliary_frq: 0.1791 (0.1921)  auxiliary_vis: 0.1492 (0.1649)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1104 (2.1169)  time: 1.1523 (1.2449)  data: 0.0260 (0.1173)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:26:48,598 maskrcnn_benchmark INFO: eta: 11:31:25  iter: 6600  loss: 2.5939 (2.6501)  auxiliary_ctx: 0.1559 (0.1769)  auxiliary_frq: 0.1786 (0.1919)  auxiliary_vis: 0.1502 (0.1645)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1070 (2.1167)  time: 1.1492 (1.2421)  data: 0.0262 (0.1144)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:30:39,127 maskrcnn_benchmark INFO: eta: 11:25:49  iter: 6800  loss: 2.6000 (2.6487)  auxiliary_ctx: 0.1602 (0.1765)  auxiliary_frq: 0.1833 (0.1916)  auxiliary_vis: 0.1538 (0.1642)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1077 (2.1165)  time: 1.1502 (1.2395)  data: 0.0220 (0.1118)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:34:30,745 maskrcnn_benchmark INFO: eta: 11:20:25  iter: 7000  loss: 2.5933 (2.6477)  auxiliary_ctx: 0.1546 (0.1761)  auxiliary_frq: 0.1817 (0.1913)  auxiliary_vis: 0.1504 (0.1639)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1067 (2.1163)  time: 1.1451 (1.2371)  data: 0.0263 (0.1093)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:38:21,525 maskrcnn_benchmark INFO: eta: 11:15:01  iter: 7200  loss: 2.6245 (2.6467)  auxiliary_ctx: 0.1624 (0.1758)  auxiliary_frq: 0.1849 (0.1911)  auxiliary_vis: 0.1549 (0.1636)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1098 (2.1162)  time: 1.1526 (1.2348)  data: 0.0253 (0.1070)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:42:11,949 maskrcnn_benchmark INFO: eta: 11:09:42  iter: 7400  loss: 2.5974 (2.6454)  auxiliary_ctx: 0.1576 (0.1753)  auxiliary_frq: 0.1799 (0.1909)  auxiliary_vis: 0.1515 (0.1633)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1090 (2.1160)  time: 1.1415 (1.2326)  data: 0.0265 (0.1048)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:46:02,823 maskrcnn_benchmark INFO: eta: 11:04:28  iter: 7600  loss: 2.6261 (2.6442)  auxiliary_ctx: 0.1621 (0.1749)  auxiliary_frq: 0.1889 (0.1906)  auxiliary_vis: 0.1575 (0.1629)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1111 (2.1158)  time: 1.1517 (1.2305)  data: 0.0236 (0.1027)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:49:53,371 maskrcnn_benchmark INFO: eta: 10:59:18  iter: 7800  loss: 2.6015 (2.6434)  auxiliary_ctx: 0.1627 (0.1746)  auxiliary_frq: 0.1788 (0.1904)  auxiliary_vis: 0.1521 (0.1627)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1060 (2.1156)  time: 1.1588 (1.2285)  data: 0.0196 (0.1007)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:53:43,967 maskrcnn_benchmark INFO: ---Total norm 0.17305 clip coef 28.89305-----------------\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.07706, (torch.Size([4096, 12544]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.07483, (torch.Size([4096, 12544]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.06297, (torch.Size([4096, 4096]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.06097, (torch.Size([51, 4096]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.04561, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03802, (torch.Size([4096, 1024]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03554, (torch.Size([2048, 4808]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.03305, (torch.Size([51, 4096]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03237, (torch.Size([4096, 4096]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03082, (torch.Size([2048, 4808]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02595, (torch.Size([1024, 512]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02575, (torch.Size([512, 1024]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.01928, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-11 14:53:43,978 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01573, (torch.Size([4096, 512]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01472, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.01355, (torch.Size([512, 32]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00865, (torch.Size([151, 200]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00715, (torch.Size([2048, 512]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00688, (torch.Size([1024]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00650, (torch.Size([512]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00608, (torch.Size([128]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00597, (torch.Size([4096]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00574, (torch.Size([2048, 512]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00459, (torch.Size([22801, 51]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00429, (torch.Size([51]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00423, (torch.Size([256]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00360, (torch.Size([51]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00354, (torch.Size([256]))\n",
      "2020-06-11 14:53:43,979 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00332, (torch.Size([512]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00327, (torch.Size([2048]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00327, (torch.Size([2048]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00298, (torch.Size([4096]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00294, (torch.Size([4096]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00267, (torch.Size([2048]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00267, (torch.Size([2048]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00224, (torch.Size([128]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00197, (torch.Size([256]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00161, (torch.Size([128]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00157, (torch.Size([4096]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00146, (torch.Size([512, 1024]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00146, (torch.Size([512]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00113, (torch.Size([4096]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00086, (torch.Size([2048, 4424]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00076, (torch.Size([2048, 4424]))\n",
      "2020-06-11 14:53:43,980 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00044, (torch.Size([4096]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00043, (torch.Size([256]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00020, (torch.Size([2048]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00020, (torch.Size([2048]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00019, (torch.Size([2048]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00019, (torch.Size([2048]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00015, (torch.Size([2048, 512]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00013, (torch.Size([2048, 512]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00002, (torch.Size([128]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 14:53:43,981 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-11 14:53:43,984 maskrcnn_benchmark INFO: eta: 10:54:12  iter: 8000  loss: 2.6026 (2.6423)  auxiliary_ctx: 0.1643 (0.1742)  auxiliary_frq: 0.1804 (0.1902)  auxiliary_vis: 0.1515 (0.1624)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1068 (2.1154)  time: 1.1544 (1.2266)  data: 0.0279 (0.0988)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 14:53:43,987 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0008000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 14:53:46,557 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 14:53:46,600 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.65it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.65it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.65it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.65it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.65it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.65it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.83it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.65it/s]\n",
      "2020-06-11 14:55:18,176 maskrcnn_benchmark INFO: Total run time: 0:01:31.576112 (0.14652177848815917 s / img per device, on 8 devices)\n",
      "2020-06-11 14:55:18,177 maskrcnn_benchmark INFO: Model inference time: 0:01:11.464407 (0.11434305152893066 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 14:57:00,058 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.4208;   R @ 50: 0.4995;   R @ 100: 0.5224;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.5689; ngR @ 50: 0.7592; ngR @ 100: 0.8400;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0822;  zR @ 50: 0.1600;  zR @ 100: 0.1911;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1238;  mR @ 50: 0.1559;  mR @ 100: 0.1662;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2523) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0648) (attached to:0.0000) (behind:0.5139) (belonging to:0.0000) (between:0.0000) (carrying:0.1689) (covered in:0.1429) (covering:0.0000) (eating:0.4286) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.7073) (holding:0.5401) (in:0.4285) (in front of:0.1330) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3831) (of:0.6395) (on:0.5784) (on back of:0.0000) (over:0.0061) (painted on:0.0000) (parked on:0.0294) (part of:0.0000) (playing:0.0000) (riding:0.7366) (says:0.0000) (sitting on:0.4479) (standing on:0.0370) (to:0.0000) (under:0.1667) (using:0.0000) (walking in:0.0000) (walking on:0.3745) (watching:0.3922) (wearing:0.9745) (wears:0.0000) (with:0.1507) \n",
      "SGG eval:   A @ 20: 0.5651;   A @ 50: 0.5698;   A @ 100: 0.5698;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 14:57:00,836 maskrcnn_benchmark INFO: Validation Result: 0.5224\n",
      "2020-06-11 15:00:51,177 maskrcnn_benchmark INFO: eta: 11:01:52  iter: 8200  loss: 2.5819 (2.6414)  auxiliary_ctx: 0.1536 (0.1739)  auxiliary_frq: 0.1783 (0.1900)  auxiliary_vis: 0.1417 (0.1622)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1074 (2.1153)  time: 1.1598 (1.2488)  data: 0.0273 (0.1210)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 15:04:40,983 maskrcnn_benchmark INFO: eta: 10:56:27  iter: 8400  loss: 2.5806 (2.6404)  auxiliary_ctx: 0.1587 (0.1736)  auxiliary_frq: 0.1774 (0.1898)  auxiliary_vis: 0.1437 (0.1619)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1068 (2.1151)  time: 1.1514 (1.2464)  data: 0.0274 (0.1187)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 15:08:31,693 maskrcnn_benchmark INFO: eta: 10:51:10  iter: 8600  loss: 2.5972 (2.6395)  auxiliary_ctx: 0.1664 (0.1733)  auxiliary_frq: 0.1787 (0.1896)  auxiliary_vis: 0.1478 (0.1616)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1078 (2.1150)  time: 1.1448 (1.2443)  data: 0.0267 (0.1166)  lr: 0.640000  max mem: 6341\n",
      "2020-06-11 15:12:23,021 maskrcnn_benchmark INFO: eta: 10:45:59  iter: 8800  loss: 2.5990 (2.6388)  auxiliary_ctx: 0.1627 (0.1731)  auxiliary_frq: 0.1775 (0.1894)  auxiliary_vis: 0.1507 (0.1614)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1076 (2.1149)  time: 1.1569 (1.2423)  data: 0.0271 (0.1145)  lr: 0.640000  max mem: 6361\n",
      "2020-06-11 15:16:13,887 maskrcnn_benchmark INFO: eta: 10:40:50  iter: 9000  loss: 2.6393 (2.6381)  auxiliary_ctx: 0.1681 (0.1728)  auxiliary_frq: 0.1875 (0.1892)  auxiliary_vis: 0.1599 (0.1612)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1116 (2.1148)  time: 1.1412 (1.2403)  data: 0.0267 (0.1125)  lr: 0.640000  max mem: 6361\n",
      "2020-06-11 15:20:04,665 maskrcnn_benchmark INFO: eta: 10:35:44  iter: 9200  loss: 2.6212 (2.6372)  auxiliary_ctx: 0.1595 (0.1726)  auxiliary_frq: 0.1889 (0.1890)  auxiliary_vis: 0.1552 (0.1610)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1095 (2.1146)  time: 1.1517 (1.2385)  data: 0.0260 (0.1107)  lr: 0.640000  max mem: 6361\n",
      "2020-06-11 15:23:55,466 maskrcnn_benchmark INFO: eta: 10:30:41  iter: 9400  loss: 2.5993 (2.6363)  auxiliary_ctx: 0.1573 (0.1723)  auxiliary_frq: 0.1815 (0.1888)  auxiliary_vis: 0.1496 (0.1608)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1059 (2.1145)  time: 1.1477 (1.2367)  data: 0.0266 (0.1089)  lr: 0.640000  max mem: 6361\n",
      "2020-06-11 15:27:46,395 maskrcnn_benchmark INFO: eta: 10:25:42  iter: 9600  loss: 2.6148 (2.6356)  auxiliary_ctx: 0.1648 (0.1721)  auxiliary_frq: 0.1837 (0.1886)  auxiliary_vis: 0.1558 (0.1606)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1093 (2.1144)  time: 1.1494 (1.2350)  data: 0.0275 (0.1072)  lr: 0.640000  max mem: 6361\n",
      "2020-06-11 15:31:37,987 maskrcnn_benchmark INFO: eta: 10:20:48  iter: 9800  loss: 2.5792 (2.6349)  auxiliary_ctx: 0.1581 (0.1718)  auxiliary_frq: 0.1762 (0.1884)  auxiliary_vis: 0.1470 (0.1604)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1066 (2.1143)  time: 1.1522 (1.2334)  data: 0.0275 (0.1055)  lr: 0.640000  max mem: 6361\n",
      "2020-06-11 15:35:28,838 maskrcnn_benchmark INFO: eta: 10:15:53  iter: 10000  loss: 2.5719 (2.6342)  auxiliary_ctx: 0.1512 (0.1716)  auxiliary_frq: 0.1751 (0.1882)  auxiliary_vis: 0.1478 (0.1602)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1042 (2.1142)  time: 1.1527 (1.2318)  data: 0.0280 (0.1039)  lr: 0.640000  max mem: 6377\n",
      "2020-06-11 15:35:28,841 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0010000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 15:35:31,426 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 15:35:31,456 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.89it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "2020-06-11 15:37:02,232 maskrcnn_benchmark INFO: Total run time: 0:01:30.774738 (0.14523958129882814 s / img per device, on 8 devices)\n",
      "2020-06-11 15:37:02,232 maskrcnn_benchmark INFO: Model inference time: 0:01:10.712922 (0.11314067573547364 s / img per device, on 8 devices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.67s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 15:38:44,600 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.4049;   R @ 50: 0.4879;   R @ 100: 0.5094;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.5557; ngR @ 50: 0.7589; ngR @ 100: 0.8379;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0844;  zR @ 50: 0.1630;  zR @ 100: 0.1867;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1199;  mR @ 50: 0.1475;  mR @ 100: 0.1559;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2835) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1747) (attached to:0.0106) (behind:0.5046) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0714) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0625) (has:0.6940) (holding:0.6136) (in:0.4857) (in front of:0.1006) (laying on:0.0000) (looking at:0.0217) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5158) (of:0.6101) (on:0.5236) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.1455) (part of:0.0000) (playing:0.0000) (riding:0.7991) (says:0.0000) (sitting on:0.2446) (standing on:0.0011) (to:0.0000) (under:0.2628) (using:0.0000) (walking in:0.0000) (walking on:0.3545) (watching:0.1765) (wearing:0.9668) (wears:0.0000) (with:0.1577) \n",
      "SGG eval:   A @ 20: 0.5444;   A @ 50: 0.5492;   A @ 100: 0.5492;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 15:38:45,369 maskrcnn_benchmark INFO: Validation Result: 0.5094\n",
      "2020-06-11 15:38:45,369 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "2020-06-11 15:42:36,145 maskrcnn_benchmark INFO: eta: 10:20:36  iter: 10200  loss: 2.5577 (2.6332)  auxiliary_ctx: 0.1455 (0.1712)  auxiliary_frq: 0.1767 (0.1881)  auxiliary_vis: 0.1398 (0.1599)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1009 (2.1140)  time: 1.1537 (1.2495)  data: 0.0265 (0.1217)  lr: 0.064000  max mem: 6377\n",
      "2020-06-11 15:46:27,104 maskrcnn_benchmark INFO: eta: 10:15:32  iter: 10400  loss: 2.5618 (2.6319)  auxiliary_ctx: 0.1448 (0.1707)  auxiliary_frq: 0.1770 (0.1879)  auxiliary_vis: 0.1407 (0.1595)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1016 (2.1138)  time: 1.1462 (1.2477)  data: 0.0269 (0.1198)  lr: 0.064000  max mem: 6377\n",
      "2020-06-11 15:50:17,652 maskrcnn_benchmark INFO: eta: 10:10:30  iter: 10600  loss: 2.5567 (2.6307)  auxiliary_ctx: 0.1437 (0.1702)  auxiliary_frq: 0.1772 (0.1878)  auxiliary_vis: 0.1354 (0.1591)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1022 (2.1136)  time: 1.1459 (1.2459)  data: 0.0275 (0.1180)  lr: 0.064000  max mem: 6377\n",
      "2020-06-11 15:54:08,348 maskrcnn_benchmark INFO: eta: 10:05:30  iter: 10800  loss: 2.5667 (2.6295)  auxiliary_ctx: 0.1458 (0.1698)  auxiliary_frq: 0.1800 (0.1876)  auxiliary_vis: 0.1379 (0.1588)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1026 (2.1134)  time: 1.1501 (1.2442)  data: 0.0200 (0.1163)  lr: 0.064000  max mem: 6377\n",
      "2020-06-11 15:57:59,430 maskrcnn_benchmark INFO: eta: 10:00:35  iter: 11000  loss: 2.5558 (2.6282)  auxiliary_ctx: 0.1424 (0.1693)  auxiliary_frq: 0.1783 (0.1874)  auxiliary_vis: 0.1351 (0.1584)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1012 (2.1132)  time: 1.1491 (1.2426)  data: 0.0278 (0.1147)  lr: 0.064000  max mem: 6377\n",
      "2020-06-11 16:01:49,989 maskrcnn_benchmark INFO: eta: 9:55:40  iter: 11200  loss: 2.5785 (2.6271)  auxiliary_ctx: 0.1460 (0.1688)  auxiliary_frq: 0.1876 (0.1873)  auxiliary_vis: 0.1417 (0.1580)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1023 (2.1130)  time: 1.1537 (1.2410)  data: 0.0250 (0.1131)  lr: 0.064000  max mem: 6377\n",
      "2020-06-11 16:05:40,979 maskrcnn_benchmark INFO: eta: 9:50:49  iter: 11400  loss: 2.5454 (2.6259)  auxiliary_ctx: 0.1393 (0.1683)  auxiliary_frq: 0.1774 (0.1872)  auxiliary_vis: 0.1325 (0.1576)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0991 (2.1128)  time: 1.1501 (1.2395)  data: 0.0273 (0.1116)  lr: 0.064000  max mem: 6377\n",
      "2020-06-11 16:09:31,723 maskrcnn_benchmark INFO: eta: 9:45:59  iter: 11600  loss: 2.5371 (2.6247)  auxiliary_ctx: 0.1371 (0.1679)  auxiliary_frq: 0.1733 (0.1870)  auxiliary_vis: 0.1294 (0.1572)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0990 (2.1126)  time: 1.1556 (1.2380)  data: 0.0279 (0.1101)  lr: 0.064000  max mem: 6386\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "2020-06-11 16:13:22,941 maskrcnn_benchmark INFO: eta: 9:41:12  iter: 11800  loss: 2.5439 (2.6234)  auxiliary_ctx: 0.1410 (0.1674)  auxiliary_frq: 0.1742 (0.1869)  auxiliary_vis: 0.1320 (0.1568)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0997 (2.1123)  time: 1.1480 (1.2366)  data: 0.0268 (0.1087)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:17:13,868 maskrcnn_benchmark INFO: ---Total norm 0.23831 clip coef 20.98071-----------------\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.13686, (torch.Size([4096, 12544]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.13019, (torch.Size([4096, 12544]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.08380, (torch.Size([4096, 4096]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.05651, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.05038, (torch.Size([51, 4096]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.03953, (torch.Size([4096, 4096]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.03924, (torch.Size([4096, 1024]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.03401, (torch.Size([2048, 4808]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.03127, (torch.Size([2048, 4808]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02443, (torch.Size([1024, 512]))\n",
      "2020-06-11 16:17:13,879 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.02209, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.02186, (torch.Size([51, 4096]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02179, (torch.Size([512, 1024]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.01680, (torch.Size([4096, 512]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.01608, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01029, (torch.Size([151, 200]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00736, (torch.Size([2048, 512]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00704, (torch.Size([2048, 512]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00676, (torch.Size([1024]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00666, (torch.Size([512, 32]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00632, (torch.Size([4096]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00627, (torch.Size([512]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00606, (torch.Size([128]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00390, (torch.Size([2048]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00390, (torch.Size([2048]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00316, (torch.Size([22801, 51]))\n",
      "2020-06-11 16:17:13,880 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00309, (torch.Size([2048]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00309, (torch.Size([2048]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00289, (torch.Size([51]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00278, (torch.Size([512]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00256, (torch.Size([4096]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00248, (torch.Size([256]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00243, (torch.Size([256]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00237, (torch.Size([256]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00229, (torch.Size([4096]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00227, (torch.Size([128]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00214, (torch.Size([128]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00201, (torch.Size([51]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00196, (torch.Size([4096]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00133, (torch.Size([4096]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00075, (torch.Size([4096]))\n",
      "2020-06-11 16:17:13,881 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00069, (torch.Size([512, 1024]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00057, (torch.Size([512]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00049, (torch.Size([256]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00036, (torch.Size([2048, 4424]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00035, (torch.Size([2048, 4424]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00007, (torch.Size([2048]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00007, (torch.Size([2048]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00006, (torch.Size([2048, 512]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00005, (torch.Size([2048]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00005, (torch.Size([2048]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00003, (torch.Size([2048, 512]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00000, (torch.Size([128]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-11 16:17:13,882 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 16:17:13,883 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 16:17:13,883 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-11 16:17:13,885 maskrcnn_benchmark INFO: eta: 9:36:27  iter: 12000  loss: 2.5327 (2.6222)  auxiliary_ctx: 0.1360 (0.1669)  auxiliary_frq: 0.1743 (0.1867)  auxiliary_vis: 0.1276 (0.1564)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0976 (2.1121)  time: 1.1570 (1.2353)  data: 0.0266 (0.1073)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:17:13,888 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0012000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 16:17:16,615 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 16:17:16,641 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.82it/s]\n",
      "2020-06-11 16:18:48,335 maskrcnn_benchmark INFO: Total run time: 0:01:31.693489 (0.1467095821380615 s / img per device, on 8 devices)\n",
      "2020-06-11 16:18:48,335 maskrcnn_benchmark INFO: Model inference time: 0:01:11.526382 (0.1144422119140625 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.79s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.24s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 16:20:31,366 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.5217;   R @ 50: 0.5939;   R @ 100: 0.6095;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6457; ngR @ 50: 0.7933; ngR @ 100: 0.8586;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.1111;  zR @ 50: 0.1756;  zR @ 100: 0.1978;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1298;  mR @ 50: 0.1613;  mR @ 100: 0.1712;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2011) (across:0.0000) (against:0.0000) (along:0.0385) (and:0.0000) (at:0.2083) (attached to:0.0000) (behind:0.5168) (belonging to:0.0000) (between:0.0000) (carrying:0.4781) (covered in:0.0000) (covering:0.0000) (eating:0.5714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0294) (has:0.7668) (holding:0.6050) (in:0.3816) (in front of:0.1753) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4280) (of:0.5305) (on:0.7594) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.1163) (part of:0.0000) (playing:0.0000) (riding:0.5818) (says:0.0000) (sitting on:0.2765) (standing on:0.0065) (to:0.0000) (under:0.3193) (using:0.0385) (walking in:0.0000) (walking on:0.2093) (watching:0.2059) (wearing:0.9675) (wears:0.0000) (with:0.1251) \n",
      "SGG eval:   A @ 20: 0.6522;   A @ 50: 0.6572;   A @ 100: 0.6572;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 16:20:32,130 maskrcnn_benchmark INFO: Validation Result: 0.6095\n",
      "2020-06-11 16:24:22,645 maskrcnn_benchmark INFO: eta: 9:39:14  iter: 12200  loss: 2.5338 (2.6210)  auxiliary_ctx: 0.1368 (0.1664)  auxiliary_frq: 0.1747 (0.1866)  auxiliary_vis: 0.1290 (0.1560)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0987 (2.1119)  time: 1.1464 (1.2501)  data: 0.0249 (0.1222)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:28:13,475 maskrcnn_benchmark INFO: eta: 9:34:21  iter: 12400  loss: 2.5475 (2.6199)  auxiliary_ctx: 0.1348 (0.1660)  auxiliary_frq: 0.1791 (0.1865)  auxiliary_vis: 0.1329 (0.1556)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.1002 (2.1117)  time: 1.1429 (1.2486)  data: 0.0272 (0.1206)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:32:04,443 maskrcnn_benchmark INFO: eta: 9:29:30  iter: 12600  loss: 2.5423 (2.6187)  auxiliary_ctx: 0.1357 (0.1655)  auxiliary_frq: 0.1773 (0.1864)  auxiliary_vis: 0.1309 (0.1552)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0996 (2.1115)  time: 1.1446 (1.2471)  data: 0.0232 (0.1191)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:35:55,086 maskrcnn_benchmark INFO: eta: 9:24:41  iter: 12800  loss: 2.5314 (2.6175)  auxiliary_ctx: 0.1321 (0.1651)  auxiliary_frq: 0.1750 (0.1863)  auxiliary_vis: 0.1284 (0.1549)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0987 (2.1113)  time: 1.1493 (1.2456)  data: 0.0261 (0.1177)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:39:46,098 maskrcnn_benchmark INFO: eta: 9:19:54  iter: 13000  loss: 2.5461 (2.6164)  auxiliary_ctx: 0.1383 (0.1646)  auxiliary_frq: 0.1796 (0.1862)  auxiliary_vis: 0.1290 (0.1544)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0988 (2.1111)  time: 1.1510 (1.2442)  data: 0.0274 (0.1163)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:43:37,496 maskrcnn_benchmark INFO: eta: 9:15:10  iter: 13200  loss: 2.5397 (2.6152)  auxiliary_ctx: 0.1338 (0.1641)  auxiliary_frq: 0.1815 (0.1860)  auxiliary_vis: 0.1284 (0.1540)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0982 (2.1110)  time: 1.1497 (1.2429)  data: 0.0280 (0.1149)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:47:28,498 maskrcnn_benchmark INFO: eta: 9:10:26  iter: 13400  loss: 2.5195 (2.6141)  auxiliary_ctx: 0.1271 (0.1637)  auxiliary_frq: 0.1709 (0.1860)  auxiliary_vis: 0.1232 (0.1537)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0965 (2.1108)  time: 1.1526 (1.2416)  data: 0.0268 (0.1136)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:51:19,974 maskrcnn_benchmark INFO: eta: 9:05:45  iter: 13600  loss: 2.5255 (2.6130)  auxiliary_ctx: 0.1319 (0.1633)  auxiliary_frq: 0.1778 (0.1859)  auxiliary_vis: 0.1217 (0.1533)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0970 (2.1106)  time: 1.1489 (1.2404)  data: 0.0279 (0.1123)  lr: 0.064000  max mem: 6386\n",
      "2020-06-11 16:55:11,024 maskrcnn_benchmark INFO: eta: 9:01:05  iter: 13800  loss: 2.5315 (2.6119)  auxiliary_ctx: 0.1319 (0.1628)  auxiliary_frq: 0.1780 (0.1858)  auxiliary_vis: 0.1243 (0.1529)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0975 (2.1104)  time: 1.1547 (1.2391)  data: 0.0266 (0.1110)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 16:59:02,165 maskrcnn_benchmark INFO: eta: 8:56:26  iter: 14000  loss: 2.5291 (2.6108)  auxiliary_ctx: 0.1270 (0.1624)  auxiliary_frq: 0.1734 (0.1857)  auxiliary_vis: 0.1221 (0.1525)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0965 (2.1102)  time: 1.1536 (1.2380)  data: 0.0274 (0.1098)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 16:59:02,168 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0014000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 16:59:04,846 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 16:59:04,869 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.79it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "2020-06-11 17:00:36,923 maskrcnn_benchmark INFO: Total run time: 0:01:32.053613 (0.1472857810974121 s / img per device, on 8 devices)\n",
      "2020-06-11 17:00:36,924 maskrcnn_benchmark INFO: Model inference time: 0:01:12.098281 (0.11535724983215331 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=28.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 17:02:22,792 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.5455;   R @ 50: 0.6111;   R @ 100: 0.6259;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6546; ngR @ 50: 0.7940; ngR @ 100: 0.8562;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0933;  zR @ 50: 0.1778;  zR @ 100: 0.1867;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1281;  mR @ 50: 0.1584;  mR @ 100: 0.1698;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2442) (across:0.0000) (against:0.0000) (along:0.1154) (and:0.0000) (at:0.2059) (attached to:0.0092) (behind:0.4003) (belonging to:0.0000) (between:0.0000) (carrying:0.2741) (covered in:0.0714) (covering:0.0000) (eating:0.7143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0221) (has:0.7653) (holding:0.6073) (in:0.3827) (in front of:0.0886) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5063) (of:0.4609) (on:0.7875) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.1411) (part of:0.0000) (playing:0.0000) (riding:0.5015) (says:0.0000) (sitting on:0.2494) (standing on:0.0101) (to:0.0000) (under:0.1786) (using:0.0577) (walking in:0.0000) (walking on:0.3175) (watching:0.1765) (wearing:0.9732) (wears:0.0000) (with:0.1535) \n",
      "SGG eval:   A @ 20: 0.6592;   A @ 50: 0.6639;   A @ 100: 0.6639;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 17:02:23,566 maskrcnn_benchmark INFO: Validation Result: 0.6259\n",
      "2020-06-11 17:06:14,742 maskrcnn_benchmark INFO: eta: 8:57:55  iter: 14200  loss: 2.5356 (2.6097)  auxiliary_ctx: 0.1319 (0.1620)  auxiliary_frq: 0.1817 (0.1856)  auxiliary_vis: 0.1268 (0.1521)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0973 (2.1100)  time: 1.1620 (1.2510)  data: 0.0273 (0.1228)  lr: 0.064000  max mem: 6395\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "2020-06-11 17:10:04,910 maskrcnn_benchmark INFO: eta: 8:53:09  iter: 14400  loss: 2.5163 (2.6085)  auxiliary_ctx: 0.1258 (0.1615)  auxiliary_frq: 0.1749 (0.1855)  auxiliary_vis: 0.1188 (0.1517)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0950 (2.1099)  time: 1.1530 (1.2496)  data: 0.0249 (0.1215)  lr: 0.064000  max mem: 6395\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "2020-06-11 17:13:55,377 maskrcnn_benchmark INFO: eta: 8:48:25  iter: 14600  loss: 2.5136 (2.6074)  auxiliary_ctx: 0.1247 (0.1611)  auxiliary_frq: 0.1744 (0.1854)  auxiliary_vis: 0.1210 (0.1512)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0948 (2.1097)  time: 1.1460 (1.2483)  data: 0.0205 (0.1201)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:17:46,411 maskrcnn_benchmark INFO: eta: 8:43:44  iter: 14800  loss: 2.5187 (2.6063)  auxiliary_ctx: 0.1240 (0.1606)  auxiliary_frq: 0.1781 (0.1853)  auxiliary_vis: 0.1199 (0.1508)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0965 (2.1095)  time: 1.1610 (1.2470)  data: 0.0269 (0.1188)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:21:37,304 maskrcnn_benchmark INFO: eta: 8:39:04  iter: 15000  loss: 2.5095 (2.6052)  auxiliary_ctx: 0.1240 (0.1602)  auxiliary_frq: 0.1710 (0.1852)  auxiliary_vis: 0.1156 (0.1504)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0962 (2.1093)  time: 1.1423 (1.2458)  data: 0.0264 (0.1176)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:25:27,984 maskrcnn_benchmark INFO: eta: 8:34:24  iter: 15200  loss: 2.4948 (2.6041)  auxiliary_ctx: 0.1235 (0.1598)  auxiliary_frq: 0.1690 (0.1851)  auxiliary_vis: 0.1117 (0.1500)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0956 (2.1091)  time: 1.1646 (1.2445)  data: 0.0271 (0.1164)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:29:18,915 maskrcnn_benchmark INFO: eta: 8:29:47  iter: 15400  loss: 2.4882 (2.6030)  auxiliary_ctx: 0.1181 (0.1594)  auxiliary_frq: 0.1706 (0.1850)  auxiliary_vis: 0.1079 (0.1496)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0932 (2.1090)  time: 1.1508 (1.2434)  data: 0.0268 (0.1152)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:33:09,819 maskrcnn_benchmark INFO: eta: 8:25:10  iter: 15600  loss: 2.4824 (2.6019)  auxiliary_ctx: 0.1141 (0.1589)  auxiliary_frq: 0.1707 (0.1849)  auxiliary_vis: 0.1067 (0.1492)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0927 (2.1088)  time: 1.1471 (1.2422)  data: 0.0272 (0.1141)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:37:00,881 maskrcnn_benchmark INFO: eta: 8:20:35  iter: 15800  loss: 2.4990 (2.6007)  auxiliary_ctx: 0.1199 (0.1585)  auxiliary_frq: 0.1764 (0.1849)  auxiliary_vis: 0.1126 (0.1488)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0936 (2.1086)  time: 1.1513 (1.2411)  data: 0.0197 (0.1130)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:40:51,447 maskrcnn_benchmark INFO: ---Total norm 0.51895 clip coef 9.63475-----------------\n",
      "2020-06-11 17:40:51,457 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.30468, (torch.Size([4096, 12544]))\n",
      "2020-06-11 17:40:51,457 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.29325, (torch.Size([4096, 12544]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.17126, (torch.Size([4096, 4096]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.16163, (torch.Size([51, 4096]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.09965, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06590, (torch.Size([4096, 4096]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.05743, (torch.Size([4096, 1024]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.05739, (torch.Size([2048, 4808]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.05195, (torch.Size([2048, 4808]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.04770, (torch.Size([51, 4096]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.04665, (torch.Size([4096, 512]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04240, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03190, (torch.Size([1024, 512]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02835, (torch.Size([512, 32]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02805, (torch.Size([512, 1024]))\n",
      "2020-06-11 17:40:51,458 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02722, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01751, (torch.Size([151, 200]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01413, (torch.Size([2048, 512]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01237, (torch.Size([512]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01193, (torch.Size([2048, 512]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01142, (torch.Size([4096]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01050, (torch.Size([128]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00986, (torch.Size([2048]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00986, (torch.Size([2048]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00951, (torch.Size([1024]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00944, (torch.Size([51]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00896, (torch.Size([2048]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00896, (torch.Size([2048]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00697, (torch.Size([4096]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00682, (torch.Size([512]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00618, (torch.Size([4096]))\n",
      "2020-06-11 17:40:51,459 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00598, (torch.Size([256]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00515, (torch.Size([51]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00428, (torch.Size([256]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00421, (torch.Size([128]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00381, (torch.Size([22801, 51]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00360, (torch.Size([4096]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00327, (torch.Size([256]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00309, (torch.Size([4096]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00280, (torch.Size([128]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00180, (torch.Size([4096]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00097, (torch.Size([256]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00082, (torch.Size([512, 1024]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00074, (torch.Size([512]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00055, (torch.Size([2048, 4424]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00053, (torch.Size([2048, 4424]))\n",
      "2020-06-11 17:40:51,460 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00012, (torch.Size([2048]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00012, (torch.Size([2048]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00011, (torch.Size([2048, 512]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00010, (torch.Size([2048]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00010, (torch.Size([2048]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00003, (torch.Size([2048, 512]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 17:40:51,461 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-11 17:40:51,464 maskrcnn_benchmark INFO: eta: 8:16:00  iter: 16000  loss: 2.5115 (2.5997)  auxiliary_ctx: 0.1250 (0.1581)  auxiliary_frq: 0.1765 (0.1848)  auxiliary_vis: 0.1144 (0.1484)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0951 (2.1085)  time: 1.1517 (1.2400)  data: 0.0238 (0.1119)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:40:51,467 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0016000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 17:40:54,151 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 17:40:54,174 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.72it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.90it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.71it/s]\n",
      "2020-06-11 17:42:24,749 maskrcnn_benchmark INFO: Total run time: 0:01:30.574017 (0.14491842727661133 s / img per device, on 8 devices)\n",
      "2020-06-11 17:42:24,749 maskrcnn_benchmark INFO: Model inference time: 0:01:11.607731 (0.11457237014770508 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.30s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 17:44:08,442 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.5405;   R @ 50: 0.6083;   R @ 100: 0.6237;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6454; ngR @ 50: 0.7806; ngR @ 100: 0.8434;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0956;  zR @ 50: 0.1874;  zR @ 100: 0.1985;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1236;  mR @ 50: 0.1562;  mR @ 100: 0.1653;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2216) (across:0.0000) (against:0.0000) (along:0.0769) (and:0.0000) (at:0.1574) (attached to:0.0000) (behind:0.3889) (belonging to:0.0000) (between:0.0000) (carrying:0.3158) (covered in:0.0714) (covering:0.0000) (eating:0.5714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0147) (has:0.7721) (holding:0.5845) (in:0.3865) (in front of:0.0636) (laying on:0.0476) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4661) (of:0.4773) (on:0.7896) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.0198) (part of:0.0000) (playing:0.0000) (riding:0.3795) (says:0.0000) (sitting on:0.2501) (standing on:0.0370) (to:0.0000) (under:0.2389) (using:0.0385) (walking in:0.0000) (walking on:0.3990) (watching:0.3235) (wearing:0.9695) (wears:0.0000) (with:0.1502) \n",
      "SGG eval:   A @ 20: 0.6559;   A @ 50: 0.6610;   A @ 100: 0.6610;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 17:44:09,227 maskrcnn_benchmark INFO: Validation Result: 0.6237\n",
      "2020-06-11 17:48:00,070 maskrcnn_benchmark INFO: eta: 8:16:18  iter: 16200  loss: 2.5277 (2.5987)  auxiliary_ctx: 0.1342 (0.1577)  auxiliary_frq: 0.1762 (0.1848)  auxiliary_vis: 0.1187 (0.1480)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0972 (2.1083)  time: 1.1542 (1.2512)  data: 0.0262 (0.1230)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:51:51,267 maskrcnn_benchmark INFO: eta: 8:11:40  iter: 16400  loss: 2.5268 (2.5977)  auxiliary_ctx: 0.1293 (0.1573)  auxiliary_frq: 0.1867 (0.1847)  auxiliary_vis: 0.1154 (0.1476)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0942 (2.1081)  time: 1.1528 (1.2500)  data: 0.0255 (0.1218)  lr: 0.064000  max mem: 6395\n",
      "2020-06-11 17:55:42,183 maskrcnn_benchmark INFO: eta: 8:07:03  iter: 16600  loss: 2.5069 (2.5967)  auxiliary_ctx: 0.1206 (0.1569)  auxiliary_frq: 0.1778 (0.1846)  auxiliary_vis: 0.1108 (0.1471)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0935 (2.1080)  time: 1.1530 (1.2489)  data: 0.0265 (0.1207)  lr: 0.064000  max mem: 6423\n",
      "2020-06-11 17:59:32,798 maskrcnn_benchmark INFO: eta: 8:02:27  iter: 16800  loss: 2.5072 (2.5956)  auxiliary_ctx: 0.1216 (0.1565)  auxiliary_frq: 0.1793 (0.1846)  auxiliary_vis: 0.1079 (0.1467)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0934 (2.1078)  time: 1.1445 (1.2477)  data: 0.0278 (0.1195)  lr: 0.064000  max mem: 6423\n",
      "2020-06-11 18:03:23,952 maskrcnn_benchmark INFO: eta: 7:57:53  iter: 17000  loss: 2.4962 (2.5946)  auxiliary_ctx: 0.1170 (0.1561)  auxiliary_frq: 0.1736 (0.1845)  auxiliary_vis: 0.1075 (0.1463)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0917 (2.1077)  time: 1.1460 (1.2467)  data: 0.0271 (0.1184)  lr: 0.064000  max mem: 6423\n",
      "2020-06-11 18:07:14,789 maskrcnn_benchmark INFO: eta: 7:53:19  iter: 17200  loss: 2.5008 (2.5936)  auxiliary_ctx: 0.1208 (0.1557)  auxiliary_frq: 0.1795 (0.1844)  auxiliary_vis: 0.1059 (0.1459)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0934 (2.1075)  time: 1.1459 (1.2456)  data: 0.0263 (0.1174)  lr: 0.064000  max mem: 6423\n",
      "2020-06-11 18:11:06,308 maskrcnn_benchmark INFO: eta: 7:48:47  iter: 17400  loss: 2.4774 (2.5925)  auxiliary_ctx: 0.1138 (0.1553)  auxiliary_frq: 0.1707 (0.1844)  auxiliary_vis: 0.1024 (0.1455)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0909 (2.1073)  time: 1.1537 (1.2446)  data: 0.0264 (0.1163)  lr: 0.064000  max mem: 6423\n",
      "2020-06-11 18:14:57,283 maskrcnn_benchmark INFO: eta: 7:44:15  iter: 17600  loss: 2.5063 (2.5915)  auxiliary_ctx: 0.1211 (0.1550)  auxiliary_frq: 0.1810 (0.1843)  auxiliary_vis: 0.1098 (0.1451)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0937 (2.1072)  time: 1.1521 (1.2435)  data: 0.0266 (0.1153)  lr: 0.064000  max mem: 6423\n",
      "2020-06-11 18:18:47,937 maskrcnn_benchmark INFO: eta: 7:39:44  iter: 17800  loss: 2.4945 (2.5905)  auxiliary_ctx: 0.1170 (0.1546)  auxiliary_frq: 0.1749 (0.1842)  auxiliary_vis: 0.1051 (0.1446)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0926 (2.1070)  time: 1.1496 (1.2425)  data: 0.0250 (0.1143)  lr: 0.064000  max mem: 6423\n",
      "2020-06-11 18:22:39,509 maskrcnn_benchmark INFO: eta: 7:35:15  iter: 18000  loss: 2.5201 (2.5895)  auxiliary_ctx: 0.1245 (0.1542)  auxiliary_frq: 0.1873 (0.1842)  auxiliary_vis: 0.1128 (0.1442)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0946 (2.1069)  time: 1.1478 (1.2416)  data: 0.0265 (0.1133)  lr: 0.064000  max mem: 6423\n",
      "2020-06-11 18:22:39,512 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0018000.pth\n",
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 18:22:42,050 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 18:22:42,082 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:30<00:00,  6.87it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "2020-06-11 18:24:13,070 maskrcnn_benchmark INFO: Total run time: 0:01:30.988130 (0.14558100814819336 s / img per device, on 8 devices)\n",
      "2020-06-11 18:24:13,071 maskrcnn_benchmark INFO: Model inference time: 0:01:10.669924 (0.11307187843322754 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 18:25:56,887 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.5388;   R @ 50: 0.6023;   R @ 100: 0.6172;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6309; ngR @ 50: 0.7621; ngR @ 100: 0.8316;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.1000;  zR @ 50: 0.1956;  zR @ 100: 0.2200;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1351;  mR @ 50: 0.1693;  mR @ 100: 0.1786;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.2508) (across:0.0000) (against:0.0000) (along:0.0385) (and:0.0000) (at:0.3806) (attached to:0.0183) (behind:0.3851) (belonging to:0.0000) (between:0.0000) (carrying:0.5000) (covered in:0.0714) (covering:0.0000) (eating:0.5714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0588) (has:0.7698) (holding:0.5233) (in:0.3485) (in front of:0.0957) (laying on:0.0952) (looking at:0.0870) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4827) (of:0.5065) (on:0.7707) (on back of:0.0000) (over:0.0427) (painted on:0.0000) (parked on:0.0111) (part of:0.0000) (playing:0.0000) (riding:0.5074) (says:0.0000) (sitting on:0.2750) (standing on:0.0380) (to:0.0000) (under:0.2861) (using:0.2115) (walking in:0.0000) (walking on:0.2804) (watching:0.2549) (wearing:0.9706) (wears:0.0000) (with:0.0975) \n",
      "SGG eval:   A @ 20: 0.6531;   A @ 50: 0.6573;   A @ 100: 0.6573;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 18:25:57,664 maskrcnn_benchmark INFO: Validation Result: 0.6172\n",
      "2020-06-11 18:25:57,664 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "2020-06-11 18:29:47,983 maskrcnn_benchmark INFO: eta: 7:34:42  iter: 18200  loss: 2.4606 (2.5883)  auxiliary_ctx: 0.1050 (0.1537)  auxiliary_frq: 0.1729 (0.1841)  auxiliary_vis: 0.0951 (0.1438)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0880 (2.1067)  time: 1.1420 (1.2515)  data: 0.0257 (0.1232)  lr: 0.006400  max mem: 6423\n",
      "2020-06-11 18:33:38,789 maskrcnn_benchmark INFO: eta: 7:30:09  iter: 18400  loss: 2.4679 (2.5870)  auxiliary_ctx: 0.1036 (0.1532)  auxiliary_frq: 0.1802 (0.1840)  auxiliary_vis: 0.0970 (0.1433)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0880 (2.1065)  time: 1.1432 (1.2504)  data: 0.0255 (0.1222)  lr: 0.006400  max mem: 6423\n",
      "2020-06-11 18:37:29,880 maskrcnn_benchmark INFO: eta: 7:25:37  iter: 18600  loss: 2.4689 (2.5858)  auxiliary_ctx: 0.1053 (0.1527)  auxiliary_frq: 0.1788 (0.1840)  auxiliary_vis: 0.0959 (0.1428)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0883 (2.1063)  time: 1.1492 (1.2494)  data: 0.0252 (0.1211)  lr: 0.006400  max mem: 6423\n",
      "2020-06-11 18:41:20,947 maskrcnn_benchmark INFO: eta: 7:21:06  iter: 18800  loss: 2.4578 (2.5846)  auxiliary_ctx: 0.1043 (0.1522)  auxiliary_frq: 0.1758 (0.1839)  auxiliary_vis: 0.0962 (0.1423)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0877 (2.1061)  time: 1.1484 (1.2484)  data: 0.0256 (0.1201)  lr: 0.006400  max mem: 6423\n",
      "2020-06-11 18:45:11,917 maskrcnn_benchmark INFO: eta: 7:16:35  iter: 19000  loss: 2.4407 (2.5834)  auxiliary_ctx: 0.0939 (0.1517)  auxiliary_frq: 0.1719 (0.1839)  auxiliary_vis: 0.0881 (0.1418)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0850 (2.1059)  time: 1.1513 (1.2474)  data: 0.0269 (0.1191)  lr: 0.006400  max mem: 6423\n",
      "2020-06-11 18:49:02,653 maskrcnn_benchmark INFO: eta: 7:12:06  iter: 19200  loss: 2.4665 (2.5821)  auxiliary_ctx: 0.1017 (0.1512)  auxiliary_frq: 0.1802 (0.1839)  auxiliary_vis: 0.0951 (0.1413)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0865 (2.1057)  time: 1.1465 (1.2464)  data: 0.0261 (0.1181)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 18:52:54,114 maskrcnn_benchmark INFO: eta: 7:07:37  iter: 19400  loss: 2.4694 (2.5809)  auxiliary_ctx: 0.1064 (0.1507)  auxiliary_frq: 0.1839 (0.1838)  auxiliary_vis: 0.0961 (0.1409)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0874 (2.1055)  time: 1.1516 (1.2455)  data: 0.0263 (0.1172)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 18:56:45,134 maskrcnn_benchmark INFO: eta: 7:03:09  iter: 19600  loss: 2.4476 (2.5796)  auxiliary_ctx: 0.0957 (0.1502)  auxiliary_frq: 0.1716 (0.1837)  auxiliary_vis: 0.0910 (0.1404)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0857 (2.1053)  time: 1.1583 (1.2446)  data: 0.0265 (0.1163)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:00:35,741 maskrcnn_benchmark INFO: eta: 6:58:42  iter: 19800  loss: 2.4603 (2.5784)  auxiliary_ctx: 0.1019 (0.1497)  auxiliary_frq: 0.1827 (0.1837)  auxiliary_vis: 0.0910 (0.1399)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0860 (2.1051)  time: 1.1459 (1.2437)  data: 0.0252 (0.1153)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:04:27,241 maskrcnn_benchmark INFO: ---Total norm 0.71894 clip coef 6.95464-----------------\n",
      "2020-06-11 19:04:27,251 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.50864, (torch.Size([4096, 12544]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.35261, (torch.Size([4096, 12544]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.28404, (torch.Size([4096, 4096]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.10166, (torch.Size([51, 4096]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.09526, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.08010, (torch.Size([2048, 4808]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.07788, (torch.Size([2048, 4808]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.07304, (torch.Size([4096, 1024]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06780, (torch.Size([4096, 4096]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04900, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.04290, (torch.Size([51, 4096]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.04061, (torch.Size([512, 1024]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03938, (torch.Size([1024, 512]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02441, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02301, (torch.Size([151, 200]))\n",
      "2020-06-11 19:04:27,252 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02227, (torch.Size([4096, 512]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01801, (torch.Size([2048, 512]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01684, (torch.Size([512]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01671, (torch.Size([2048, 512]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01508, (torch.Size([1024]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01448, (torch.Size([4096]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01127, (torch.Size([4096]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01127, (torch.Size([2048]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01127, (torch.Size([2048]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01016, (torch.Size([2048]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01016, (torch.Size([2048]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00894, (torch.Size([128]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00710, (torch.Size([256]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00690, (torch.Size([4096]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00484, (torch.Size([512, 32]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00483, (torch.Size([51]))\n",
      "2020-06-11 19:04:27,253 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00478, (torch.Size([128]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00452, (torch.Size([256]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00436, (torch.Size([256]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00382, (torch.Size([22801, 51]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00381, (torch.Size([128]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00363, (torch.Size([4096]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00318, (torch.Size([51]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00294, (torch.Size([4096]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00158, (torch.Size([4096]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00092, (torch.Size([256]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00088, (torch.Size([512]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00059, (torch.Size([2048, 4424]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00052, (torch.Size([2048, 4424]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00038, (torch.Size([512, 1024]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00035, (torch.Size([512]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00006, (torch.Size([2048]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00006, (torch.Size([2048]))\n",
      "2020-06-11 19:04:27,254 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00006, (torch.Size([2048]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00006, (torch.Size([2048]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00006, (torch.Size([2048, 512]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00003, (torch.Size([2048, 512]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 19:04:27,255 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-11 19:04:27,258 maskrcnn_benchmark INFO: eta: 6:54:16  iter: 20000  loss: 2.4252 (2.5771)  auxiliary_ctx: 0.0924 (0.1492)  auxiliary_frq: 0.1673 (0.1837)  auxiliary_vis: 0.0828 (0.1394)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0828 (2.1049)  time: 1.1519 (1.2428)  data: 0.0274 (0.1144)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:04:27,261 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0020000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 19:04:29,422 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 19:04:29,450 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.84it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "2020-06-11 19:06:00,838 maskrcnn_benchmark INFO: Total run time: 0:01:31.387657 (0.1462202507019043 s / img per device, on 8 devices)\n",
      "2020-06-11 19:06:00,839 maskrcnn_benchmark INFO: Model inference time: 0:01:10.976703 (0.1135627254486084 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.43s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.32s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 19:07:46,543 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.5594;   R @ 50: 0.6136;   R @ 100: 0.6293;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6404; ngR @ 50: 0.7584; ngR @ 100: 0.8203;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0763;  zR @ 50: 0.1689;  zR @ 100: 0.2044;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1229;  mR @ 50: 0.1534;  mR @ 100: 0.1650;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1466) (across:0.0000) (against:0.0000) (along:0.1923) (and:0.0000) (at:0.2152) (attached to:0.0092) (behind:0.3842) (belonging to:0.0000) (between:0.0000) (carrying:0.4825) (covered in:0.1071) (covering:0.0000) (eating:0.4286) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0441) (has:0.7475) (holding:0.5296) (in:0.3579) (in front of:0.1069) (laying on:0.0476) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4111) (of:0.4369) (on:0.8271) (on back of:0.0000) (over:0.0467) (painted on:0.0000) (parked on:0.0190) (part of:0.0000) (playing:0.0000) (riding:0.4598) (says:0.0000) (sitting on:0.2501) (standing on:0.0272) (to:0.0000) (under:0.2219) (using:0.1346) (walking in:0.0000) (walking on:0.2567) (watching:0.2255) (wearing:0.9620) (wears:0.0000) (with:0.1305) \n",
      "SGG eval:   A @ 20: 0.6564;   A @ 50: 0.6600;   A @ 100: 0.6600;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 19:07:47,439 maskrcnn_benchmark INFO: Validation Result: 0.6293\n",
      "2020-06-11 19:11:37,705 maskrcnn_benchmark INFO: eta: 6:53:06  iter: 20200  loss: 2.4378 (2.5759)  auxiliary_ctx: 0.0932 (0.1486)  auxiliary_frq: 0.1727 (0.1836)  auxiliary_vis: 0.0854 (0.1389)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0844 (2.1047)  time: 1.1560 (1.2518)  data: 0.0235 (0.1235)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:15:28,513 maskrcnn_benchmark INFO: eta: 6:48:36  iter: 20400  loss: 2.4447 (2.5747)  auxiliary_ctx: 0.0955 (0.1481)  auxiliary_frq: 0.1750 (0.1836)  auxiliary_vis: 0.0895 (0.1384)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0841 (2.1045)  time: 1.1514 (1.2509)  data: 0.0240 (0.1225)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:19:19,447 maskrcnn_benchmark INFO: eta: 6:44:08  iter: 20600  loss: 2.4546 (2.5735)  auxiliary_ctx: 0.0965 (0.1476)  auxiliary_frq: 0.1812 (0.1835)  auxiliary_vis: 0.0893 (0.1380)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0851 (2.1044)  time: 1.1468 (1.2499)  data: 0.0266 (0.1216)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:23:10,562 maskrcnn_benchmark INFO: eta: 6:39:41  iter: 20800  loss: 2.4397 (2.5723)  auxiliary_ctx: 0.0932 (0.1472)  auxiliary_frq: 0.1785 (0.1835)  auxiliary_vis: 0.0869 (0.1375)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0836 (2.1042)  time: 1.1519 (1.2490)  data: 0.0242 (0.1206)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:27:01,452 maskrcnn_benchmark INFO: eta: 6:35:14  iter: 21000  loss: 2.4491 (2.5711)  auxiliary_ctx: 0.0956 (0.1466)  auxiliary_frq: 0.1814 (0.1834)  auxiliary_vis: 0.0886 (0.1370)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0841 (2.1040)  time: 1.1573 (1.2481)  data: 0.0261 (0.1197)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:30:51,553 maskrcnn_benchmark INFO: eta: 6:30:47  iter: 21200  loss: 2.4503 (2.5699)  auxiliary_ctx: 0.0986 (0.1462)  auxiliary_frq: 0.1808 (0.1834)  auxiliary_vis: 0.0904 (0.1366)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0844 (2.1038)  time: 1.1379 (1.2472)  data: 0.0264 (0.1188)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:34:42,459 maskrcnn_benchmark INFO: eta: 6:26:21  iter: 21400  loss: 2.4271 (2.5687)  auxiliary_ctx: 0.0875 (0.1457)  auxiliary_frq: 0.1704 (0.1834)  auxiliary_vis: 0.0842 (0.1361)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0823 (2.1036)  time: 1.1516 (1.2463)  data: 0.0220 (0.1179)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:38:33,688 maskrcnn_benchmark INFO: eta: 6:21:57  iter: 21600  loss: 2.4275 (2.5675)  auxiliary_ctx: 0.0907 (0.1452)  auxiliary_frq: 0.1747 (0.1833)  auxiliary_vis: 0.0854 (0.1356)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0825 (2.1034)  time: 1.1599 (1.2455)  data: 0.0255 (0.1171)  lr: 0.006400  max mem: 6535\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "2020-06-11 19:42:24,639 maskrcnn_benchmark INFO: eta: 6:17:32  iter: 21800  loss: 2.4382 (2.5664)  auxiliary_ctx: 0.0883 (0.1447)  auxiliary_frq: 0.1788 (0.1833)  auxiliary_vis: 0.0868 (0.1352)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0834 (2.1032)  time: 1.1490 (1.2447)  data: 0.0256 (0.1162)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:46:15,216 maskrcnn_benchmark INFO: eta: 6:13:09  iter: 22000  loss: 2.3989 (2.5652)  auxiliary_ctx: 0.0815 (0.1442)  auxiliary_frq: 0.1697 (0.1832)  auxiliary_vis: 0.0761 (0.1347)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0791 (2.1030)  time: 1.1634 (1.2438)  data: 0.0262 (0.1154)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:46:15,219 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0022000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 19:46:17,603 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 19:46:17,632 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:33<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:31<00:00,  6.85it/s]\n",
      "2020-06-11 19:47:48,887 maskrcnn_benchmark INFO: Total run time: 0:01:31.254602 (0.1460073631286621 s / img per device, on 8 devices)\n",
      "2020-06-11 19:47:48,888 maskrcnn_benchmark INFO: Model inference time: 0:01:11.992720 (0.11518835144042969 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.97s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.30s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 19:49:32,212 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.5544;   R @ 50: 0.6088;   R @ 100: 0.6249;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6305; ngR @ 50: 0.7446; ngR @ 100: 0.8085;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0778;  zR @ 50: 0.1667;  zR @ 100: 0.1911;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1226;  mR @ 50: 0.1513;  mR @ 100: 0.1642;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1446) (across:0.0000) (against:0.0000) (along:0.0769) (and:0.0323) (at:0.1978) (attached to:0.0367) (behind:0.3780) (belonging to:0.0000) (between:0.0000) (carrying:0.4342) (covered in:0.0714) (covering:0.0000) (eating:0.5000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0588) (has:0.7528) (holding:0.5389) (in:0.3481) (in front of:0.1496) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3915) (of:0.4581) (on:0.8149) (on back of:0.0000) (over:0.0467) (painted on:0.0000) (parked on:0.0345) (part of:0.0000) (playing:0.0000) (riding:0.4955) (says:0.0000) (sitting on:0.2435) (standing on:0.0163) (to:0.0000) (under:0.1981) (using:0.1346) (walking in:0.0000) (walking on:0.2963) (watching:0.2353) (wearing:0.9503) (wears:0.0000) (with:0.1278) \n",
      "SGG eval:   A @ 20: 0.6536;   A @ 50: 0.6578;   A @ 100: 0.6578;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 19:49:32,999 maskrcnn_benchmark INFO: Validation Result: 0.6249\n",
      "2020-06-11 19:53:23,950 maskrcnn_benchmark INFO: eta: 6:11:24  iter: 22200  loss: 2.4304 (2.5640)  auxiliary_ctx: 0.0898 (0.1437)  auxiliary_frq: 0.1753 (0.1832)  auxiliary_vis: 0.0832 (0.1343)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0817 (2.1029)  time: 1.1539 (1.2519)  data: 0.0264 (0.1235)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 19:57:15,003 maskrcnn_benchmark INFO: eta: 6:06:58  iter: 22400  loss: 2.4318 (2.5628)  auxiliary_ctx: 0.0878 (0.1432)  auxiliary_frq: 0.1808 (0.1832)  auxiliary_vis: 0.0849 (0.1338)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0814 (2.1027)  time: 1.1565 (1.2511)  data: 0.0264 (0.1226)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 20:01:06,688 maskrcnn_benchmark INFO: eta: 6:02:34  iter: 22600  loss: 2.4225 (2.5617)  auxiliary_ctx: 0.0841 (0.1427)  auxiliary_frq: 0.1773 (0.1831)  auxiliary_vis: 0.0834 (0.1334)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0815 (2.1025)  time: 1.1636 (1.2503)  data: 0.0285 (0.1218)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 20:04:57,990 maskrcnn_benchmark INFO: eta: 5:58:10  iter: 22800  loss: 2.4172 (2.5605)  auxiliary_ctx: 0.0861 (0.1422)  auxiliary_frq: 0.1766 (0.1831)  auxiliary_vis: 0.0792 (0.1329)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0811 (2.1023)  time: 1.1455 (1.2494)  data: 0.0265 (0.1209)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 20:08:48,601 maskrcnn_benchmark INFO: eta: 5:53:46  iter: 23000  loss: 2.4201 (2.5594)  auxiliary_ctx: 0.0846 (0.1417)  auxiliary_frq: 0.1747 (0.1831)  auxiliary_vis: 0.0799 (0.1325)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0809 (2.1021)  time: 1.1469 (1.2486)  data: 0.0269 (0.1201)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 20:12:39,796 maskrcnn_benchmark INFO: eta: 5:49:23  iter: 23200  loss: 2.4221 (2.5583)  auxiliary_ctx: 0.0834 (0.1413)  auxiliary_frq: 0.1813 (0.1830)  auxiliary_vis: 0.0811 (0.1320)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0808 (2.1019)  time: 1.1608 (1.2478)  data: 0.0252 (0.1193)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 20:16:30,192 maskrcnn_benchmark INFO: eta: 5:44:59  iter: 23400  loss: 2.4230 (2.5572)  auxiliary_ctx: 0.0846 (0.1408)  auxiliary_frq: 0.1783 (0.1830)  auxiliary_vis: 0.0801 (0.1316)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0798 (2.1018)  time: 1.1479 (1.2470)  data: 0.0266 (0.1185)  lr: 0.006400  max mem: 6535\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "2020-06-11 20:20:21,163 maskrcnn_benchmark INFO: eta: 5:40:37  iter: 23600  loss: 2.4345 (2.5560)  auxiliary_ctx: 0.0878 (0.1403)  auxiliary_frq: 0.1809 (0.1830)  auxiliary_vis: 0.0798 (0.1312)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0802 (2.1016)  time: 1.1446 (1.2462)  data: 0.0210 (0.1177)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 20:24:12,115 maskrcnn_benchmark INFO: eta: 5:36:15  iter: 23800  loss: 2.4218 (2.5549)  auxiliary_ctx: 0.0860 (0.1398)  auxiliary_frq: 0.1767 (0.1829)  auxiliary_vis: 0.0793 (0.1307)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0809 (2.1014)  time: 1.1541 (1.2454)  data: 0.0257 (0.1169)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 20:28:02,523 maskrcnn_benchmark INFO: ---Total norm 0.81789 clip coef 6.11331-----------------\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.59716, (torch.Size([4096, 12544]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.40959, (torch.Size([4096, 12544]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.32027, (torch.Size([4096, 4096]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.10014, (torch.Size([256, 1024, 3, 3]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.07434, (torch.Size([51, 4096]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.07134, (torch.Size([2048, 4808]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.07061, (torch.Size([2048, 4808]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.06120, (torch.Size([4096, 4096]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.06070, (torch.Size([4096, 1024]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.05633, (torch.Size([256, 128, 3, 3]))\n",
      "2020-06-11 20:28:02,533 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03298, (torch.Size([1024, 512]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03117, (torch.Size([128, 2, 7, 7]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.02859, (torch.Size([512, 1024]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02326, (torch.Size([151, 200]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02197, (torch.Size([4096, 512]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01846, (torch.Size([2048, 512]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.01748, (torch.Size([51, 4096]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01583, (torch.Size([2048, 512]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01034, (torch.Size([4096]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01017, (torch.Size([128]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00981, (torch.Size([4096]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00930, (torch.Size([512]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.00854, (torch.Size([512, 32]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00835, (torch.Size([2048]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00835, (torch.Size([2048]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00788, (torch.Size([2048]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00788, (torch.Size([2048]))\n",
      "2020-06-11 20:28:02,534 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00770, (torch.Size([1024]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00746, (torch.Size([256]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00495, (torch.Size([128]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00437, (torch.Size([128]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00374, (torch.Size([256]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00340, (torch.Size([22801, 51]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00326, (torch.Size([4096]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00322, (torch.Size([256]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00318, (torch.Size([4096]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00276, (torch.Size([4096]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00237, (torch.Size([51]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00186, (torch.Size([512]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.00140, (torch.Size([4096]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00127, (torch.Size([51]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00109, (torch.Size([512, 1024]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00100, (torch.Size([2048, 4424]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00086, (torch.Size([2048, 4424]))\n",
      "2020-06-11 20:28:02,535 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00083, (torch.Size([256]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00060, (torch.Size([512]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00016, (torch.Size([2048, 512]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00013, (torch.Size([2048, 512]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00013, (torch.Size([2048]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00013, (torch.Size([2048]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00013, (torch.Size([2048]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00013, (torch.Size([2048]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00002, (torch.Size([128]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00000, (torch.Size([151, 200]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00000, (torch.Size([128, 32]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))\n",
      "2020-06-11 20:28:02,536 maskrcnn_benchmark INFO: -------------------------------\n",
      "2020-06-11 20:28:02,539 maskrcnn_benchmark INFO: eta: 5:31:54  iter: 24000  loss: 2.4206 (2.5538)  auxiliary_ctx: 0.0824 (0.1394)  auxiliary_frq: 0.1737 (0.1829)  auxiliary_vis: 0.0772 (0.1303)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 2.0797 (2.1012)  time: 1.1427 (1.2447)  data: 0.0246 (0.1162)  lr: 0.006400  max mem: 6535\n",
      "2020-06-11 20:28:02,542 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE/model_0024000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/625 [00:00<?, ?it/s]2020-06-11 20:28:04,878 maskrcnn_benchmark INFO: Start validating\n",
      "2020-06-11 20:28:04,907 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.60it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.60it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.60it/s]\n",
      "100%|█████████████████████████████████████████| 625/625 [01:34<00:00,  6.60it/s]\n",
      "2020-06-11 20:29:37,336 maskrcnn_benchmark INFO: Total run time: 0:01:32.427971 (0.14788475303649903 s / img per device, on 8 devices)\n",
      "2020-06-11 20:29:37,336 maskrcnn_benchmark INFO: Model inference time: 0:01:11.333352 (0.11413336372375488 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(62754, 7)\n",
      "0/62754\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=25.77s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.24s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.994\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 20:31:20,187 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9999\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.5535;   R @ 50: 0.6057;   R @ 100: 0.6208;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6228; ngR @ 50: 0.7360; ngR @ 100: 0.7974;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0852;  zR @ 50: 0.1600;  zR @ 100: 0.1844;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1262;  mR @ 50: 0.1526;  mR @ 100: 0.1700;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1218) (across:0.0556) (against:0.0000) (along:0.1667) (and:0.0323) (at:0.2057) (attached to:0.0000) (behind:0.3702) (belonging to:0.0286) (between:0.0000) (carrying:0.4956) (covered in:0.1429) (covering:0.0000) (eating:0.5000) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0625) (has:0.7378) (holding:0.4911) (in:0.3435) (in front of:0.1441) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3510) (of:0.4253) (on:0.8163) (on back of:0.0000) (over:0.0467) (painted on:0.0000) (parked on:0.0511) (part of:0.0000) (playing:0.0000) (riding:0.5060) (says:0.0000) (sitting on:0.2391) (standing on:0.0322) (to:0.0000) (under:0.2092) (using:0.2115) (walking in:0.0000) (walking on:0.3292) (watching:0.2353) (wearing:0.9555) (wears:0.0000) (with:0.1102) \n",
      "SGG eval:   A @ 20: 0.6492;   A @ 50: 0.6531;   A @ 100: 0.6531;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n",
      "2020-06-11 20:31:20,957 maskrcnn_benchmark INFO: Validation Result: 0.6208\n",
      "2020-06-11 20:31:20,957 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1\n",
      "2020-06-11 20:31:20,957 maskrcnn_benchmark INFO: Trigger MAX_DECAY_STEP at iteration 24000.\n",
      "2020-06-11 20:31:21,275 maskrcnn_benchmark INFO: Total training time: 8:21:10.420090 (0.7518 s / it)\n",
      "2020-06-11 20:31:23,151 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:57<00:00,  6.93it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:57<00:00,  6.93it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:57<00:00,  6.93it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:57<00:00,  6.93it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:57<00:00,  6.93it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:57<00:00,  6.93it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:57<00:00,  6.93it/s]\n",
      "100%|███████████████████████████████████████| 3306/3306 [07:57<00:00,  6.93it/s]\n",
      "2020-06-11 20:39:20,338 maskrcnn_benchmark INFO: Total run time: 0:07:57.186201 (0.14435035962610593 s / img per device, on 8 devices)\n",
      "2020-06-11 20:39:20,339 maskrcnn_benchmark INFO: Model inference time: 0:06:17.861666 (0.11430436843806295 s / img per device, on 8 devices)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(325563, 7)\n",
      "0/325563\n",
      "DONE (t=3.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=140.81s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=19.69s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.659\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.995\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "2020-06-11 20:48:56,799 maskrcnn_benchmark INFO: \n",
      "====================================================================================================\n",
      "Detection evaluation mAp=0.9995\n",
      "====================================================================================================\n",
      "SGG eval:   R @ 20: 0.5354;   R @ 50: 0.6005;   R @ 100: 0.6206;  for mode=predcls, type=Recall(Main).\n",
      "SGG eval: ngR @ 20: 0.6042; ngR @ 50: 0.7359; ngR @ 100: 0.8031;  for mode=predcls, type=No Graph Constraint Recall(Main).\n",
      "SGG eval:  zR @ 20: 0.0624;  zR @ 50: 0.1092;  zR @ 100: 0.1362;  for mode=predcls, type=Zero Shot Recall.\n",
      "SGG eval:  mR @ 20: 0.1093;  mR @ 50: 0.1429;  mR @ 100: 0.1612;  for mode=predcls, type=Mean Recall.\n",
      "(above:0.1256) (across:0.0317) (against:0.0000) (along:0.0604) (and:0.1040) (at:0.2271) (attached to:0.0135) (behind:0.4994) (belonging to:0.0070) (between:0.0069) (carrying:0.2285) (covered in:0.2530) (covering:0.0495) (eating:0.2354) (flying in:0.0000) (for:0.0430) (from:0.0141) (growing on:0.0000) (hanging from:0.0366) (has:0.7644) (holding:0.6421) (in:0.3498) (in front of:0.1386) (laying on:0.0315) (looking at:0.0469) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3071) (of:0.5941) (on:0.7362) (on back of:0.0000) (over:0.0740) (painted on:0.0000) (parked on:0.0587) (part of:0.0000) (playing:0.0000) (riding:0.3493) (says:0.0000) (sitting on:0.2342) (standing on:0.0413) (to:0.0000) (under:0.2336) (using:0.0865) (walking in:0.0000) (walking on:0.1683) (watching:0.2184) (wearing:0.9487) (wears:0.0000) (with:0.1000) \n",
      "SGG eval:   A @ 20: 0.6391;   A @ 50: 0.6412;   A @ 100: 0.6412;  for mode=predcls, type=TopK Accuracy.\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10025 --nproc_per_node=8 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE dist \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE \\\n",
    "SOLVER.IMS_PER_BATCH 64 TEST.IMS_PER_BATCH 8 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 40000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/precls-CausalAnalysisPredictor-motifs-dist2-TDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFB\n",
    "nb of available GPU changed to 6 XD surpriiiise XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-28T18:47:40.807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\r\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "*****************************************\r\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.launch --master_port 10025 --nproc_per_node=7 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE mfb \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE \\\n",
    "SOLVER.IMS_PER_BATCH 56 TEST.IMS_PER_BATCH 7 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 40000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/precls-CausalAnalysisPredictor-motifs-mfb1-TDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "189.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
